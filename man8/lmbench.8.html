<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 19:12:58 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>LMBENCH(8) LMBENCH LMBENCH(8)</p>

<p style="margin-top: 1em">NAME <br>
lmbench - system benchmarks</p>

<p style="margin-top: 1em">DESCRIPTION <br>
lmbench is a series of micro benchmarks intended to measure
basic operating system and hardware system metrics. The
benchmarks fall into three general classes: bandwidth, <br>
latency, and &lsquo;&lsquo;other&rsquo;&rsquo;.</p>

<p style="margin-top: 1em">Most of the lmbench benchmarks
use a standard timing harness described in timing(3) and
have a few standard options: parallelism, warmup, and
repetitions. Parallelism specifies <br>
the number of benchmark processes to run in parallel. This
is primarily useful when measuring the performance of SMP or
distributed computers and can be used to evaluate the <br>
system&rsquo;s performance scalability. Warmup is the number
of minimum number of microseconds the benchmark should
execute the benchmarked capability before it begins
measuring per&acirc; <br>
formance. Again this is primarily useful for SMP or
distributed systems and it is intended to give the process
scheduler time to &quot;settle&quot; and migrate processes
to other proces&acirc; <br>
sors. By measuring performance over various warmup periods,
users may evaulate the scheduler&rsquo;s responsiveness.
Repetitions is the number of measurements that the benchmark
<br>
should take. This allows lmbench to provide greater or
lesser statistical strength to the results it reports. The
default number of repetitions is 11.</p>

<p style="margin-top: 1em">BANDWIDTH MEASUREMENTS <br>
Data movement is fundamental to the performance on most
computer systems. The bandwidth measurements are intended to
show how the system can move data. The results of the
band&acirc; <br>
width metrics can be compared but care must be taken to
understand what it is that is being compared. The bandwidth
benchmarks can be reduced to two main components: operating
<br>
system overhead and memory speeds. The bandwidth benchmarks
report their results as megabytes moved per second but
please note that the data moved is not necessarily the same
as <br>
the memory bandwidth used to move the data. Consult the
individual man pages for more information.</p>

<p style="margin-top: 1em">Each of the bandwidth benchmarks
is listed below with a brief overview of the intent of the
benchmark.</p>

<p style="margin-top: 1em">bw_file_rd reading and summing
of a file via the read(2) interface.</p>

<p style="margin-top: 1em">bw_mem_cp memory copy.</p>

<p style="margin-top: 1em">bw_mem_rd memory reading and
summing.</p>

<p style="margin-top: 1em">bw_mem_wr memory writing.</p>

<p style="margin-top: 1em">bw_mmap_rd reading and summing
of a file via the memory mapping mmap(2) interface.</p>

<p style="margin-top: 1em">bw_pipe reading of data via a
pipe.</p>

<p style="margin-top: 1em">bw_tcp reading of data via a
TCP/IP socket.</p>

<p style="margin-top: 1em">bw_unix reading data from a UNIX
socket.</p>

<p style="margin-top: 1em">LATENCY MEASUREMENTS <br>
Control messages are also fundamental to the performance on
most computer systems. The latency measurements are intended
to show how fast a system can be told to do some
opera&acirc; <br>
tion. The results of the latency metrics can be compared to
each other for the most part. In particular, the pipe, rpc,
tcp, and udp transactions are all identical benchmarks <br>
carried out over different system abstractions.</p>

<p style="margin-top: 1em">Latency numbers here should
mostly be in microseconds per operation.</p>

<p style="margin-top: 1em">lat_connect the time it takes to
establish a TCP/IP connection.</p>

<p style="margin-top: 1em">lat_ctx context switching; the
number and size of processes is varied.</p>

<p style="margin-top: 1em">lat_fcntl fcntl file
locking.</p>

<p style="margin-top: 1em">lat_fifo &lsquo;&lsquo;hot
potato&rsquo;&rsquo; transaction through a UNIX FIFO.</p>

<p style="margin-top: 1em">lat_fs creating and deleting
small files.</p>

<p style="margin-top: 1em">lat_pagefault the time it takes
to fault in a page from a file.</p>

<p style="margin-top: 1em">lat_mem_rd memory read latency
(accurate to the ~2-5 nanosecond range, reported in
nanoseconds).</p>

<p style="margin-top: 1em">lat_mmap time to set up a memory
mapping.</p>

<p style="margin-top: 1em">lat_ops basic processor
operations, such as integer XOR, ADD, SUB, MUL, DIV, and
MOD, and float ADD, MUL, DIV, and double ADD, MUL, DIV.</p>

<p style="margin-top: 1em">lat_pipe &lsquo;&lsquo;hot
potato&rsquo;&rsquo; transaction through a Unix pipe.</p>

<p style="margin-top: 1em">lat_proc process creation times
(various sorts).</p>

<p style="margin-top: 1em">lat_rpc &lsquo;&lsquo;hot
potato&rsquo;&rsquo; transaction through Sun RPC over UDP or
TCP.</p>

<p style="margin-top: 1em">lat_select select latency</p>

<p style="margin-top: 1em">lat_sig signal installation and
catch latencies. Also protection fault signal latency.</p>

<p style="margin-top: 1em">lat_syscall non trivial entry
into the system.</p>

<p style="margin-top: 1em">lat_tcp &lsquo;&lsquo;hot
potato&rsquo;&rsquo; transaction through TCP.</p>

<p style="margin-top: 1em">lat_udp &lsquo;&lsquo;hot
potato&rsquo;&rsquo; transaction through UDP.</p>

<p style="margin-top: 1em">lat_unix &lsquo;&lsquo;hot
potato&rsquo;&rsquo; transaction through UNIX sockets.</p>

<p style="margin-top: 1em">lat_unix_connect <br>
the time it takes to establish a UNIX socket connection.</p>

<p style="margin-top: 1em">OTHER MEASUREMENTS <br>
mhz processor cycle time</p>

<p style="margin-top: 1em">tlb TLB size and TLB miss
latency</p>

<p style="margin-top: 1em">line cache line size (in
bytes)</p>

<p style="margin-top: 1em">cache cache statistics, such as
line size, cache sizes, memory parallelism.</p>

<p style="margin-top: 1em">stream John McCalpin&rsquo;s
stream benchmark</p>

<p style="margin-top: 1em">par_mem memory subsystem
parallelism. How many requests can the memory subsystem
service in parallel, which may depend on the location of the
data in the memory hierarchy.</p>

<p style="margin-top: 1em">par_ops basic processor
operation parallelism.</p>

<p style="margin-top: 1em">SEE ALSO <br>
bargraph(1), graph(1), lmbench(3), results(3), timing(3),
bw_file_rd(8), bw_mem_cp(8), bw_mem_wr(8), bw_mmap_rd(8),
bw_pipe(8), bw_tcp(8), bw_unix(8), lat_connect(8),
lat_ctx(8), <br>
lat_fcntl(8), lat_fifo(8), lat_fs(8), lat_http(8),
lat_mem_rd(8), lat_mmap(8), lat_ops(8), lat_pagefault(8),
lat_pipe(8), lat_proc(8), lat_rpc(8), lat_select(8),
lat_sig(8), <br>
lat_syscall(8), lat_tcp(8), lat_udp(8), lmdd(8), par_ops(8),
par_mem(8), mhz(8), tlb(8), line(8), cache(8), stream(8)</p>

<p style="margin-top: 1em">ACKNOWLEDGEMENT <br>
Funding for the development of these tools was provided by
Sun Microsystems Computer Corporation.</p>

<p style="margin-top: 1em">A large number of people have
contributed to the testing and development of lmbench.</p>

<p style="margin-top: 1em">COPYING <br>
The benchmarking code is distributed under the GPL with
additional restrictions, see the COPYING file.</p>

<p style="margin-top: 1em">AUTHOR <br>
Carl Staelin and Larry McVoy</p>

<p style="margin-top: 1em">Comments, suggestions, and bug
reports are always welcome.</p>

<p style="margin-top: 1em">(c)1994-2000 Larry McVoy and
Carl Staelin $Date$ LMBENCH(8)</p>
<hr>
</body>
</html>
