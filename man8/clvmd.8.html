<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 19:09:34 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>CLVMD(8) System Manager&rsquo;s Manual CLVMD(8)</p>

<p style="margin-top: 1em">NAME <br>
clvmd &acirc; cluster LVM daemon</p>

<p style="margin-top: 1em">SYNOPSIS <br>
clvmd [-C] [-d [value]] [-E lock_uuid] [-f] [-h] [-I
cluster_manager] [-R] [-S] [-t timeout] [-T start_timeout]
[-V]</p>

<p style="margin-top: 1em">DESCRIPTION <br>
clvmd is the daemon that distributes LVM metadata updates
around a cluster. It must be running on all nodes in the
cluster and will give an error if a node in the cluster does
<br>
not have this daemon running.</p>

<p style="margin-top: 1em">OPTIONS <br>
-C <br>
Only valid if -d is also specified. Tells all clvmds in a
cluster to enable/disable debug logging. Without this
switch, only the local clvmd will change its debug level
<br>
to that given with -d. <br>
This does not work correctly if specified on the
command-line that starts clvmd. If you want to start clvmd
and enable cluster-wide logging then the command needs to be
<br>
issued twice, eg: <br>
clvmd <br>
clvmd -d2</p>

<p style="margin-top: 1em">-d [value] <br>
Set debug logging level. If -d is specified without a value
then 1 is assumed. Value can be: <br>
0 &acirc; Disabled <br>
1 &acirc; Sends debug logs to stderr (implies -f) <br>
2 &acirc; Sends debug logs to syslog(3)</p>

<p style="margin-top: 1em">-E lock_uuid <br>
Pass lock uuid to be reacquired exclusively when clvmd is
restarted.</p>

<p style="margin-top: 1em">-f <br>
Don&rsquo;t fork, run in the foreground.</p>

<p style="margin-top: 1em">-h <br>
Show help information.</p>

<p style="margin-top: 1em">-I cluster_manager <br>
Selects the cluster manager to use for locking and internal
communications. As it is quite possible to have multiple
managers available on the same system you might have <br>
to manually specify this option to override the search.</p>

<p style="margin-top: 1em">By default, omit -I is
equivalent to -Iauto. Clvmd will use the first cluster
manager that succeeds, and it checks them in a predefined
order cman, corosync, openais. <br>
The available managers will be listed by order as part of
the clvmd -h output.</p>

<p style="margin-top: 1em">-R <br>
Tells all the running instance of clvmd in the cluster to
reload their device cache and re-read the lvm configuration
file lvm.conf(5). This command should be run whenever <br>
the devices on a cluster system are changed.</p>

<p style="margin-top: 1em">-S <br>
Tells the running clvmd to exit and reexecute itself, for
example at the end of a package upgrade. The new instance is
instructed to reacquire any locks in the same state <br>
as they were previously held. (Alternative methods of
restarting the daemon have the side effect of changing
exclusive LV locks into shared locks.)</p>

<p style="margin-top: 1em">-t timeout <br>
Specifies the timeout for commands to run around the
cluster. This should not be so small that commands with many
disk updates to do will fail, so you may need to increase
<br>
this on systems with very large disk farms. The default is
60 seconds.</p>

<p style="margin-top: 1em">-T start_timeout <br>
Specifies the start timeout for clvmd daemon startup. If the
daemon does not report that it has started up within this
time then the parent command will exit with status <br>
of 5. This does NOT mean that clvmd has not started! What it
means is that the startup has been delayed for some reason;
the most likely cause of this is an inquorate <br>
cluster though it could be due to locking latencies on a
cluster with large numbers of logical volumes. If you get
the return code of 5 it is usually not necessary to <br>
restart clvmd it will start as soon as that blockage has
cleared. This flag is to allow startup scripts to exit in a
timely fashion even if the cluster is stalled for <br>
some reason.</p>

<p style="margin-top: 1em">The default is 0 (no timeout)
and the value is in seconds. Don&rsquo;t set this too small
or you will experience spurious errors. 10 or 20 seconds
might be sensible.</p>

<p style="margin-top: 1em">This timeout will be ignored if
you start clvmd with the -d.</p>

<p style="margin-top: 1em">-V <br>
Display the version of the cluster LVM daemon.</p>

<p style="margin-top: 1em">ENVIRONMENT VARIABLES <br>
LVM_CLVMD_BINARY <br>
The CLVMD binary to use when clvmd restart is requested.
Defaults to /usr/sbin/clvmd.</p>

<p style="margin-top: 1em">LVM_BINARY <br>
The LVM2 binary to use. Defaults to /usr/sbin/lvm.</p>

<p style="margin-top: 1em">FILES <br>
/usr/sbin/clvmd <br>
/usr/sbin/lvm</p>

<p style="margin-top: 1em">SEE ALSO <br>
syslog(3), lvm.conf(5), lvm(8)</p>

<p style="margin-top: 1em">Red Hat Inc LVM TOOLS
2.02.166(2)-RHEL7 (2016-11-16) CLVMD(8)</p>
<hr>
</body>
</html>
