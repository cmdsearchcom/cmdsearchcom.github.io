<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
  </style>
  <title>PCS(8)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">PCS(8)</td>
    <td class="head-vol">System Administration Utilities</td>
    <td class="head-rtitle">PCS(8)</td>
  </tr>
</table>
<div class="manual-text">
<h1 class="Sh" title="Sh" id="NAME"><a class="selflink" href="#NAME">NAME</a></h1>
pcs - pacemaker/corosync configuration system
<h1 class="Sh" title="Sh" id="SYNOPSIS"><a class="selflink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<b>pcs</b> [ <i>-f file</i>] [<i>-h</i>] [<i>commands</i>]...
<h1 class="Sh" title="Sh" id="DESCRIPTION"><a class="selflink" href="#DESCRIPTION">DESCRIPTION</a></h1>
Control and configure pacemaker and corosync.
<h1 class="Sh" title="Sh" id="OPTIONS"><a class="selflink" href="#OPTIONS">OPTIONS</a></h1>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-h</b>, <b>--help</b></dt>
  <dd class="It-tag">Display usage and exit.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-f</b> file</dt>
  <dd class="It-tag">Perform actions on file instead of active CIB.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--debug</b></dt>
  <dd class="It-tag">Print all network traffic and external commands run.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--version</b></dt>
  <dd class="It-tag">Print pcs version information.</dd>
</dl>
<h2 class="Ss" title="Ss" id="Commands:"><a class="selflink" href="#Commands:">Commands:</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">cluster</dt>
  <dd class="It-tag">Configure cluster options and nodes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">resource</dt>
  <dd class="It-tag">Manage cluster resources.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">stonith</dt>
  <dd class="It-tag">Configure fence devices.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">constraint</dt>
  <dd class="It-tag">Set resource constraints.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">property</dt>
  <dd class="It-tag">Set pacemaker properties.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">acl</dt>
  <dd class="It-tag">Set pacemaker access control lists.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">qdevice</dt>
  <dd class="It-tag">Manage quorum device provider on the local host.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">quorum</dt>
  <dd class="It-tag">Manage cluster quorum settings.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">booth</dt>
  <dd class="It-tag">Manage booth (cluster ticket manager).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">status</dt>
  <dd class="It-tag">View cluster status.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">config</dt>
  <dd class="It-tag">View and manage cluster configuration.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">pcsd</dt>
  <dd class="It-tag">Manage pcs daemon.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">node</dt>
  <dd class="It-tag">Manage cluster nodes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">alert</dt>
  <dd class="It-tag">Manage pacemaker alerts.</dd>
</dl>
<h2 class="Ss" title="Ss" id="resource"><a class="selflink" href="#resource">resource</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">[show [&lt;resource id&gt;] | <b>--full</b> |
    <b>--groups</b> | <b>--hide-inactive</b>]</dt>
  <dd class="It-tag">Show all currently configured resources or if a resource is
      specified show the options for the configured resource. If <b>--full</b>
      is specified, all configured resource options will be displayed. If
      <b>--groups</b> is specified, only show groups (and their resources). If
      <b>--hide-inactive</b> is specified, only show active resources.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">list [&lt;standard|provider|type&gt;]
    [<b>--nodesc</b>]</dt>
  <dd class="It-tag">Show list of all available resources, optionally filtered
      by specified type, standard or provider. If <b>--nodesc</b> is used then
      descriptions of resources are not printed.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">describe &lt;standard:provider:type|type&gt;</dt>
  <dd class="It-tag">Show options for the specified resource.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">create &lt;resource id&gt;
    &lt;standard:provider:type|type&gt; [resource options] [op &lt;operation
    action&gt; &lt;operation options&gt; [&lt;operation action&gt; &lt;operation
    options&gt;]...] [meta &lt;meta options&gt;...] [ <b>--clone</b> &lt;clone
    options&gt; | <b>--master</b> &lt;master options&gt; | <b>--group</b>
    &lt;group id&gt; [ <b>--before</b> &lt;resource id&gt; | <b>--after</b>
    &lt;resource id&gt;]] [ <b>--disabled</b>] [<b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Create specified resource. If <b>--clone</b> is used a
      clone resource is created. If <b>--master</b> is specified a master/slave
      resource is created. If <b>--group</b> is specified the resource is added
      to the group named. You can use <b>--before</b> or <b>--after</b> to
      specify the position of the added resource relatively to some resource
      already existing in the group. If <b>--disabled</b> is specified the
      resource is not started automatically. If <b>--wait</b> is specified, pcs
      will wait up to 'n' seconds for the resource to start and then return 0 if
      the resource is started, or 1 if the resource has not yet started. If 'n'
      is not specified it defaults to 60 minutes.
    <div style="height: 1.00em;">&#x00A0;</div>
    Example: Create a new resource called 'VirtualIP' with IP address
      192.168.0.99, netmask of 32, monitored everything 30 seconds, on eth2: pcs
      resource create VirtualIP ocf:heartbeat:IPaddr2 ip=192.168.0.99
      cidr_netmask=32 nic=eth2 op monitor interval=30s</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">delete &lt;resource id|group id|master id|clone id&gt;</dt>
  <dd class="It-tag">Deletes the resource, group, master or clone (and all
      resources within the group/master/clone).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">enable &lt;resource id&gt; [<b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Allow the cluster to start the resource. Depending on the
      rest of the configuration (constraints, options, failures, etc), the
      resource may remain stopped. If <b>--wait</b> is specified, pcs will wait
      up to 'n' seconds for the resource to start and then return 0 if the
      resource is started, or 1 if the resource has not yet started. If 'n' is
      not specified it defaults to 60 minutes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">disable &lt;resource id&gt; [<b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Attempt to stop the resource if it is running and forbid
      the cluster from starting it again. Depending on the rest of the
      configuration (constraints, options, failures, etc), the resource may
      remain started. If <b>--wait</b> is specified, pcs will wait up to 'n'
      seconds for the resource to stop and then return 0 if the resource is
      stopped or 1 if the resource has not stopped. If 'n' is not specified it
      defaults to 60 minutes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">restart &lt;resource id&gt; [node] [<b>--wait</b>=n]</dt>
  <dd class="It-tag">Restart the resource specified. If a node is specified and
      if the resource is a clone or master/slave it will be restarted only on
      the node specified. If <b>--wait</b> is specified, then we will wait up to
      'n' seconds for the resource to be restarted and return 0 if the restart
      was successful or 1 if it was not.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">debug-start &lt;resource id&gt; [<b>--full</b>]</dt>
  <dd class="It-tag">This command will force the specified resource to start on
      this node ignoring the cluster recommendations and print the output from
      starting the resource. Using <b>--full</b> will give more detailed output.
      This is mainly used for debugging resources that fail to start.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">debug-stop &lt;resource id&gt; [<b>--full</b>]</dt>
  <dd class="It-tag">This command will force the specified resource to stop on
      this node ignoring the cluster recommendations and print the output from
      stopping the resource. Using <b>--full</b> will give more detailed output.
      This is mainly used for debugging resources that fail to stop.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">debug-promote &lt;resource id&gt; [<b>--full</b>]</dt>
  <dd class="It-tag">This command will force the specified resource to be
      promoted on this node ignoring the cluster recommendations and print the
      output from promoting the resource. Using <b>--full</b> will give more
      detailed output. This is mainly used for debugging resources that fail to
      promote.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">debug-demote &lt;resource id&gt; [<b>--full</b>]</dt>
  <dd class="It-tag">This command will force the specified resource to be
      demoted on this node ignoring the cluster recommendations and print the
      output from demoting the resource. Using <b>--full</b> will give more
      detailed output. This is mainly used for debugging resources that fail to
      demote.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">debug-monitor &lt;resource id&gt; [<b>--full</b>]</dt>
  <dd class="It-tag">This command will force the specified resource to be
      moniored on this node ignoring the cluster recommendations and print the
      output from monitoring the resource. Using <b>--full</b> will give more
      detailed output. This is mainly used for debugging resources that fail to
      be monitored.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">move &lt;resource id&gt; [destination node]
    [<b>--master</b>] [lifetime=&lt;lifetime&gt;] [ <b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Move the resource off the node it is currently running on
      by creating a -INFINITY location constraint to ban the node. If
      destination node is specified the resource will be moved to that node by
      creating an INFINITY location constraint to prefer the destination node.
      If <b>--master</b> is used the scope of the command is limited to the
      master role and you must use the master id (instead of the resource id).
      If lifetime is specified then the constraint will expire after that time,
      otherwise it defaults to infinity and the constraint can be cleared
      manually with 'pcs resource clear' or 'pcs constraint delete'. If
      <b>--wait</b> is specified, pcs will wait up to 'n' seconds for the
      resource to move and then return 0 on success or 1 on error. If 'n' is not
      specified it defaults to 60 minutes. If you want the resource to
      preferably avoid running on some nodes but be able to failover to them use
      'pcs location avoids'.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ban &lt;resource id&gt; [node] [<b>--master</b>]
    [lifetime=&lt;lifetime&gt;] [ <b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Prevent the resource id specified from running on the node
      (or on the current node it is running on if no node is specified) by
      creating a -INFINITY location constraint. If <b>--master</b> is used the
      scope of the command is limited to the master role and you must use the
      master id (instead of the resource id). If lifetime is specified then the
      constraint will expire after that time, otherwise it defaults to infinity
      and the constraint can be cleared manually with 'pcs resource clear' or
      'pcs constraint delete'. If <b>--wait</b> is specified, pcs will wait up
      to 'n' seconds for the resource to move and then return 0 on success or 1
      on error. If 'n' is not specified it defaults to 60 minutes. If you want
      the resource to preferably avoid running on some nodes but be able to
      failover to them use 'pcs location avoids'.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">clear &lt;resource id&gt; [node] [<b>--master</b>]
    [<b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Remove constraints created by move and/or ban on the
      specified resource (and node if specified). If <b>--master</b> is used the
      scope of the command is limited to the master role and you must use the
      master id (instead of the resource id). If <b>--wait</b> is specified, pcs
      will wait up to 'n' seconds for the operation to finish (including
      starting and/or moving resources if appropriate) and then return 0 on
      success or 1 on error. If 'n' is not specified it defaults to 60
    minutes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">standards</dt>
  <dd class="It-tag">List available resource agent standards supported by this
      installation (OCF, LSB, etc.).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">providers</dt>
  <dd class="It-tag">List available OCF resource agent providers.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">agents [standard[:provider]]</dt>
  <dd class="It-tag">List available agents optionally filtered by standard and
      provider.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">update &lt;resource id&gt; [resource options] [op
    [&lt;operation action&gt; &lt;operation options&gt;]...] [meta &lt;meta
    operations&gt;...] [ <b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Add/Change options to specified resource, clone or
      multi-state resource. If an operation (op) is specified it will update the
      first found operation with the same action on the specified resource, if
      no operation with that action exists then a new operation will be created.
      (WARNING: all existing options on the updated operation will be reset if
      not specified.) If you want to create multiple monitor operations you
      should use the 'op add' &amp; 'op remove' commands. If <b>--wait</b> is
      specified, pcs will wait up to 'n' seconds for the changes to take effect
      and then return 0 if the changes have been processed or 1 otherwise. If
      'n' is not specified it defaults to 60 minutes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">op add &lt;resource id&gt; &lt;operation action&gt;
    [operation properties]</dt>
  <dd class="It-tag">Add operation for specified resource.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">op remove &lt;resource id&gt; &lt;operation action&gt;
    [&lt;operation properties&gt;...]</dt>
  <dd class="It-tag">Remove specified operation (note: you must specify the
      exact operation properties to properly remove an existing operation).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">op remove &lt;operation id&gt;</dt>
  <dd class="It-tag">Remove the specified operation id.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">op defaults [options]</dt>
  <dd class="It-tag">Set default values for operations, if no options are
      passed, lists currently configured defaults.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">meta &lt;resource id | group id | master id | clone id&gt;
    &lt;meta options&gt; [ <b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Add specified options to the specified resource, group,
      master/slave or clone. Meta options should be in the format of name=value,
      options may be removed by setting an option without a value. If
      <b>--wait</b> is specified, pcs will wait up to 'n' seconds for the
      changes to take effect and then return 0 if the changes have been
      processed or 1 otherwise. If 'n' is not specified it defaults to 60
      minutes. Example: pcs resource meta TestResource failure-timeout=50
      stickiness=</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">group add &lt;group id&gt; &lt;resource id&gt; [resource
    id] ... [resource id] [ <b>--before</b> &lt;resource id&gt; | <b>--after</b>
    &lt;resource id&gt;] [ <b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Add the specified resource to the group, creating the group
      if it does not exist. If the resource is present in another group it is
      moved to the new group. You can use <b>--before</b> or <b>--after</b> to
      specify the position of the added resources relatively to some resource
      already existing in the group. If <b>--wait</b> is specified, pcs will
      wait up to 'n' seconds for the operation to finish (including moving
      resources if appropriate) and then return 0 on success or 1 on error. If
      'n' is not specified it defaults to 60 minutes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">group remove &lt;group id&gt; &lt;resource id&gt; [resource
    id] ... [resource id] [ <b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Remove the specified resource(s) from the group, removing
      the group if it no resources remain. If <b>--wait</b> is specified, pcs
      will wait up to 'n' seconds for the operation to finish (including moving
      resources if appropriate) and then return 0 on success or 1 on error. If
      'n' is not specified it defaults to 60 minutes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ungroup &lt;group id&gt; [resource id] ... [resource id]
    [<b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Remove the group (note: this does not remove any resources
      from the cluster) or if resources are specified, remove the specified
      resources from the group. If <b>--wait</b> is specified, pcs will wait up
      to 'n' seconds for the operation to finish (including moving resources if
      appropriate) and the return 0 on success or 1 on error. If 'n' is not
      specified it defaults to 60 minutes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">clone &lt;resource id | group id&gt; [clone options]...
    [<b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Setup up the specified resource or group as a clone. If
      <b>--wait</b> is specified, pcs will wait up to 'n' seconds for the
      operation to finish (including starting clone instances if appropriate)
      and then return 0 on success or 1 on error. If 'n' is not specified it
      defaults to 60 minutes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">unclone &lt;resource id | group id&gt;
    [<b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Remove the clone which contains the specified group or
      resource (the resource or group will not be removed). If <b>--wait</b> is
      specified, pcs will wait up to 'n' seconds for the operation to finish
      (including stopping clone instances if appropriate) and then return 0 on
      success or 1 on error. If 'n' is not specified it defaults to 60
    minutes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">master [&lt;master/slave id&gt;] &lt;resource id | group
    id&gt; [options] [ <b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Configure a resource or group as a multi-state
      (master/slave) resource. If <b>--wait</b> is specified, pcs will wait up
      to 'n' seconds for the operation to finish (including starting and
      promoting resource instances if appropriate) and then return 0 on success
      or 1 on error. If 'n' is not specified it defaults to 60 minutes. Note: to
      remove a master you must remove the resource/group it contains.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">manage &lt;resource id&gt; ... [resource n]</dt>
  <dd class="It-tag">Set resources listed to managed mode (default).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">unmanage &lt;resource id&gt; ... [resource n]</dt>
  <dd class="It-tag">Set resources listed to unmanaged mode.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">defaults [options]</dt>
  <dd class="It-tag">Set default values for resources, if no options are passed,
      lists currently configured defaults.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">cleanup [&lt;resource id&gt;] [<b>--node</b>
    &lt;node&gt;]</dt>
  <dd class="It-tag">Cleans up the resource in the lrmd (useful to reset the
      resource status and failcount). This tells the cluster to forget the
      operation history of a resource and re-detect its current state. This can
      be useful to purge knowledge of past failures that have since been
      resolved. If a resource id is not specified then all resources/stonith
      devices will be cleaned up. If a node is not specified then resources on
      all nodes will be cleaned up.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">failcount show &lt;resource id&gt; [node]</dt>
  <dd class="It-tag">Show current failcount for specified resource from all
      nodes or only on specified node.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">failcount reset &lt;resource id&gt; [node]</dt>
  <dd class="It-tag">Reset failcount for specified resource on all nodes or only
      on specified node. This tells the cluster to forget how many times a
      resource has failed in the past. This may allow the resource to be started
      or moved to a more preferred location.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">relocate dry-run [resource1] [resource2] ...</dt>
  <dd class="It-tag">The same as 'relocate run' but has no effect on the
      cluster.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">relocate run [resource1] [resource2] ...</dt>
  <dd class="It-tag">Relocate specified resources to their preferred nodes. If
      no resources are specified, relocate all resources. This command
      calculates the preferred node for each resource while ignoring resource
      stickiness. Then it creates location constraints which will cause the
      resources to move to their preferred nodes. Once the resources have been
      moved the constraints are deleted automatically. Note that the preferred
      node is calculated based on current cluster status, constraints, location
      of resources and other settings and thus it might change over time.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">relocate show</dt>
  <dd class="It-tag">Display current status of resources and their optimal node
      ignoring resource stickiness.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">relocate clear</dt>
  <dd class="It-tag">Remove all constraints created by the 'relocate run'
      command.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">utilization [&lt;resource id&gt;
    [&lt;name&gt;=&lt;value&gt; ...]]</dt>
  <dd class="It-tag">Add specified utilization options to specified resource. If
      resource is not specified, shows utilization of all resources. If
      utilization options are not specified, shows utilization of specified
      resource. Utilization option should be in format name=value, value has to
      be integer. Options may be removed by setting an option without a value.
      Example: pcs resource utilization TestResource cpu= ram=20</dd>
</dl>
<h2 class="Ss" title="Ss" id="cluster"><a class="selflink" href="#cluster">cluster</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">auth [node] [...] [<b>-u</b> username] [<b>-p</b> password]
    [ <b>--force</b>] [<b>--local</b>]</dt>
  <dd class="It-tag">Authenticate pcs to pcsd on nodes specified, or on all
      nodes configured in corosync.conf if no nodes are specified (authorization
      tokens are stored in ~/.pcs/tokens or /var/lib/pcsd/tokens for root). By
      default all nodes are also authenticated to each other, using
      <b>--local</b> only authenticates the local node (and does not
      authenticate the remote nodes with each other). Using <b>--force</b>
      forces re-authentication to occur.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">setup [<b>--start</b> [<b>--wait</b>[=&lt;n&gt;]]]
    [<b>--local</b>] [ <b>--enable</b>] <b>--name</b> &lt;cluster name&gt;
    &lt;node1[,node1-altaddr]&gt; [&lt;node2[,node2-altaddr]&gt;] [...] [
    <b>--transport</b> udpu|udp] [ <b>--rrpmode</b> active|passive]
    [<b>--addr0</b> &lt;addr/net&gt; [[[ <b>--mcast0</b> &lt;address&gt;]
    [<b>--mcastport0</b> &lt;port&gt;] [ <b>--ttl0</b> &lt;ttl&gt;]] |
    [<b>--broadcast0</b>]] [ <b>--addr1</b> &lt;addr/net&gt; [[[<b>--mcast1</b>
    &lt;address&gt;] [ <b>--mcastport1</b> &lt;port&gt;] [<b>--ttl1</b>
    &lt;ttl&gt;]] | [ <b>--broadcast1</b>]]]]
    [<b>--wait_for_all</b>=&lt;0|1&gt;] [ <b>--auto_tie_breaker</b>=&lt;0|1&gt;]
    [ <b>--last_man_standing</b>=&lt;0|1&gt;
    [<b>--last_man_standing_window</b>=&lt;time in ms&gt;]] [ <b>--ipv6</b>]
    [<b>--token</b> &lt;timeout&gt;] [<b>--token_coefficient</b>
    &lt;timeout&gt;] [ <b>--join</b> &lt;timeout&gt;] [<b>--consensus</b>
    &lt;timeout&gt;] [ <b>--miss_count_const</b> &lt;count&gt;]
    [<b>--fail_recv_const</b> &lt;failures&gt;]</dt>
  <dd class="It-tag">Configure corosync and sync configuration out to listed
      nodes. <b>--local</b> will only perform changes on the local node,
      <b>--start</b> will also start the cluster on the specified nodes,
      <b>--wait</b> will wait up to 'n' seconds for the nodes to start,
      <b>--enable</b> will enable corosync and pacemaker on node startup,
      <b>--transport</b> allows specification of corosync transport (default:
      udpu; udp for RHEL 6 clusters), <b>--rrpmode</b> allows you to set the RRP
      mode of the system. Currently only 'passive' is supported or tested (using
      'active' is not recommended). The <b>--wait_for_all</b>,
      <b>--auto_tie_breaker</b>, <b>--last_man_standing</b>,
      <b>--last_man_standing_window</b> options are all documented in corosync's
      votequorum(5) man page. These options are not supported on RHEL 6
      clusters.
    <div style="height: 1.00em;">&#x00A0;</div>
     <b>--ipv6</b> will configure corosync to use ipv6 (instead of ipv4). This
      option is not supported on RHEL 6 clusters.
    <div style="height: 1.00em;">&#x00A0;</div>
     <b>--token</b> &lt;timeout&gt; sets time in milliseconds until a token loss
      is declared after not receiving a token (default 1000 ms)
    <div style="height: 1.00em;">&#x00A0;</div>
     <b>--token_coefficient</b> &lt;timeout&gt; sets time in milliseconds used
      for clusters with at least 3 nodes as a coefficient for real token timeout
      calculation (token + (number_of_nodes - 2) * token_coefficient) (default
      650 ms) This option is not supported on RHEL 6 clusters.
    <div style="height: 1.00em;">&#x00A0;</div>
     <b>--join</b> &lt;timeout&gt; sets time in milliseconds to wait for join
      messages (default 50 ms)
    <div style="height: 1.00em;">&#x00A0;</div>
     <b>--consensus</b> &lt;timeout&gt; sets time in milliseconds to wait for
      consensus to be achieved before starting a new round of membership
      configuration (default 1200 ms)
    <div style="height: 1.00em;">&#x00A0;</div>
     <b>--miss_count_const</b> &lt;count&gt; sets the maximum number of times on
      receipt of a token a message is checked for retransmission before a
      retransmission occurs (default 5 messages)
    <div style="height: 1.00em;">&#x00A0;</div>
     <b>--fail_recv_const</b> &lt;failures&gt; specifies how many rotations of
      the token without receiving any messages when messages should be received
      may occur before a new configuration is formed (default 2500 failures)
    <div style="height: 1.00em;">&#x00A0;</div>
    <div style="height: 1.00em;">&#x00A0;</div>
    Configuring Redundant Ring Protocol (RRP)
    <div style="height: 1.00em;">&#x00A0;</div>
    When using udpu specifying nodes, specify the ring 0 address first followed
      by a ',' and then the ring 1 address.
    <div style="height: 1.00em;">&#x00A0;</div>
    Example: pcs cluster setup --name cname nodeA-0,nodeA-1 nodeB-0,nodeB-1
    <div style="height: 1.00em;">&#x00A0;</div>
    When using udp, using <b>--addr0</b> and <b>--addr1</b> will allow you to
      configure rrp mode for corosync. It's recommended to use a network
      (instead of IP address) for <b>--addr0</b> and <b>--addr1</b> so the same
      corosync.conf file can be used around the cluster. <b>--mcast0</b>
      defaults to 239.255.1.1 and <b>--mcast1</b> defaults to 239.255.2.1,
      <b>--mcastport0/1</b> default to 5405 and ttl defaults to 1. If
      <b>--broadcast</b> is specified, <b>--mcast0/1</b>, <b>--mcastport0/1</b>
      &amp; <b>--ttl0/1</b> are ignored.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">start [<b>--all</b>] [node] [...]
    [<b>--wait</b>[=&lt;n&gt;]]</dt>
  <dd class="It-tag">Start corosync &amp; pacemaker on specified node(s), if a
      node is not specified then corosync &amp; pacemaker are started on the
      local node. If <b>--all</b> is specified then corosync &amp; pacemaker are
      started on all nodes. If <b>--wait</b> is specified, wait up to 'n'
      seconds for nodes to start.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">stop [<b>--all</b>] [node] [...]</dt>
  <dd class="It-tag">Stop corosync &amp; pacemaker on specified node(s), if a
      node is not specified then corosync &amp; pacemaker are stopped on the
      local node. If <b>--all</b> is specified then corosync &amp; pacemaker are
      stopped on all nodes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">kill</dt>
  <dd class="It-tag">Force corosync and pacemaker daemons to stop on the local
      node (performs kill -9). Note that init system (e.g. systemd) can detect
      that cluster is not running and start it again. If you want to stop
      cluster on a node, run pcs cluster stop on that node.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">enable [<b>--all</b>] [node] [...]</dt>
  <dd class="It-tag">Configure corosync &amp; pacemaker to run on node boot on
      specified node(s), if node is not specified then corosync &amp; pacemaker
      are enabled on the local node. If <b>--all</b> is specified then corosync
      &amp; pacemaker are enabled on all nodes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">disable [<b>--all</b>] [node] [...]</dt>
  <dd class="It-tag">Configure corosync &amp; pacemaker to not run on node boot
      on specified node(s), if node is not specified then corosync &amp;
      pacemaker are disabled on the local node. If <b>--all</b> is specified
      then corosync &amp; pacemaker are disabled on all nodes. Note: this is the
      default after installation.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">remote-node add &lt;hostname&gt; &lt;resource id&gt;
    [options]</dt>
  <dd class="It-tag">Enables the specified resource as a remote-node resource on
      the specified hostname (hostname should be the same as 'uname -n').</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">remote-node remove &lt;hostname&gt;</dt>
  <dd class="It-tag">Disables any resources configured to be remote-node
      resource on the specified hostname (hostname should be the same as 'uname
      -n').</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">status</dt>
  <dd class="It-tag">View current cluster status (an alias of 'pcs status
      cluster').</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">pcsd-status [node] [...]</dt>
  <dd class="It-tag">Get current status of pcsd on nodes specified, or on all
      nodes configured in corosync.conf if no nodes are specified.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">sync</dt>
  <dd class="It-tag">Sync corosync configuration to all nodes found from current
      corosync.conf file (cluster.conf on systems running Corosync 1.x).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">cib [filename] [scope=&lt;scope&gt; | <b>--config</b>]</dt>
  <dd class="It-tag">Get the raw xml from the CIB (Cluster Information Base). If
      a filename is provided, we save the CIB to that file, otherwise the CIB is
      printed. Specify scope to get a specific section of the CIB. Valid values
      of the scope are: configuration, nodes, resources, constraints,
      crm_config, rsc_defaults, op_defaults, status. <b>--config</b> is the same
      as scope=configuration. Do not specify a scope if you want to edit the
      saved CIB using pcs (pcs -f &lt;command&gt;).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">cib-push &lt;filename&gt;
    [diff-against=&lt;filename_original&gt; | scope=&lt;scope&gt; |
    <b>--config</b>] [ <b>--wait</b>[=&lt;n&gt;]]</dt>
  <dd class="It-tag">Push the raw xml from &lt;filename&gt; to the CIB (Cluster
      Information Base). You can obtain the CIB by running the 'pcs cluster cib'
      command, which is recommended first step when you want to perform desired
      modifications (pcs <b>-f</b> &lt;command&gt;) for the one-off push. If
      diff-against is specified, pcs diffs contents of filename against contents
      of filename_original and pushes the result to the CIB. Specify scope to
      push a specific section of the CIB. Valid values of the scope are:
      configuration, nodes, resources, constraints, crm_config, rsc_defaults,
      op_defaults. <b>--config</b> is the same as scope=configuration. Use of
      <b>--config</b> is recommended. Do not specify a scope if you need to push
      the whole CIB or be warned in the case of outdated CIB. If --wait is
      specified wait up to 'n' seconds for changes to be applied. WARNING: the
      selected scope of the CIB will be overwritten by the current content of
      the specified file.
    <div style="height: 1.00em;">&#x00A0;</div>
    Example:
    <br/>
     pcs cluster cib &gt; original.xml
    <br/>
     cp original.xml new.xml
    <br/>
     pcs -f new.xml constraint location apache prefers node2
    <br/>
     pcs cluster cib-push new.xml diff-against=original.xml</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">cib-upgrade</dt>
  <dd class="It-tag">Upgrade the CIB to conform to the latest version of the
      document schema.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">edit [scope=&lt;scope&gt; | <b>--config</b>]</dt>
  <dd class="It-tag">Edit the cib in the editor specified by the $EDITOR
      environment variable and push out any changes upon saving. Specify scope
      to edit a specific section of the CIB. Valid values of the scope are:
      configuration, nodes, resources, constraints, crm_config, rsc_defaults,
      op_defaults. <b>--config</b> is the same as scope=configuration. Use of
      <b>--config</b> is recommended. Do not specify a scope if you need to edit
      the whole CIB or be warned in the case of outdated CIB.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">node add &lt;node[,node-altaddr]&gt; [<b>--start</b>
    [<b>--wait</b>[=&lt;n&gt;]]] [ <b>--enable</b>]
    [<b>--watchdog</b>=&lt;watchdog-path&gt;]</dt>
  <dd class="It-tag">Add the node to corosync.conf and corosync on all nodes in
      the cluster and sync the new corosync.conf to the new node. If
      <b>--start</b> is specified also start corosync/pacemaker on the new node,
      if <b>--wait</b> is sepcified wait up to 'n' seconds for the new node to
      start. If <b>--enable</b> is specified enable corosync/pacemaker on new
      node. When using Redundant Ring Protocol (RRP) with udpu transport,
      specify the ring 0 address first followed by a ',' and then the ring 1
      address. Use <b>--watchdog</b> to specify path to watchdog on newly added
      node, when SBD is enabled in cluster.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">node remove &lt;node&gt;</dt>
  <dd class="It-tag">Shutdown specified node and remove it from pacemaker and
      corosync on all other nodes in the cluster.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">uidgid</dt>
  <dd class="It-tag">List the current configured uids and gids of users allowed
      to connect to corosync.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">uidgid add [uid=&lt;uid&gt;] [gid=&lt;gid&gt;]</dt>
  <dd class="It-tag">Add the specified uid and/or gid to the list of
      users/groups allowed to connect to corosync.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">uidgid rm [uid=&lt;uid&gt;] [gid=&lt;gid&gt;]</dt>
  <dd class="It-tag">Remove the specified uid and/or gid from the list of
      users/groups allowed to connect to corosync.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">corosync [node]</dt>
  <dd class="It-tag">Get the corosync.conf from the specified node or from the
      current node if node not specified.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">reload corosync</dt>
  <dd class="It-tag">Reload the corosync configuration on the current node.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">destroy [<b>--all</b>]</dt>
  <dd class="It-tag">Permanently destroy the cluster on the current node,
      killing all corosync/pacemaker processes removing all cib files and the
      corosync.conf file. Using <b>--all</b> will attempt to destroy the cluster
      on all nodes configure in the corosync.conf file. WARNING: This command
      permantly removes any cluster configuration that has been created. It is
      recommended to run 'pcs cluster stop' before destroying the cluster.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">verify [<b>-V</b>] [filename]</dt>
  <dd class="It-tag">Checks the pacemaker configuration (cib) for syntax and
      common conceptual errors. If no filename is specified the check is
      performed on the currently running cluster. If <b>-V</b> is used more
      verbose output will be printed.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">report [<b>--from</b> &quot;YYYY-M-D H:M:S&quot;
    [<b>--to</b> &quot;YYYY-M-D&quot; H:M:S&quot;]] dest</dt>
  <dd class="It-tag">Create a tarball containing everything needed when
      reporting cluster problems. If <b>--from</b> and <b>--to</b> are not used,
      the report will include the past 24 hours.</dd>
</dl>
<h2 class="Ss" title="Ss" id="stonith"><a class="selflink" href="#stonith">stonith</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">[show [stonith id]] [<b>--full</b>]</dt>
  <dd class="It-tag">Show all currently configured stonith devices or if a
      stonith id is specified show the options for the configured stonith
      device. If <b>--full</b> is specified all configured stonith options will
      be displayed.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">list [filter] [<b>--nodesc</b>]</dt>
  <dd class="It-tag">Show list of all available stonith agents (if filter is
      provided then only stonith agents matching the filter will be shown). If
      <b>--nodesc</b> is used then descriptions of stonith agents are not
      printed.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">describe &lt;stonith agent&gt;</dt>
  <dd class="It-tag">Show options for specified stonith agent.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">create &lt;stonith id&gt; &lt;stonith device type&gt;
    [stonith device options] [op &lt;operation action&gt; &lt;operation
    options&gt; [&lt;operation action&gt; &lt;operation options&gt;]...] [meta
    &lt;meta options&gt;...]</dt>
  <dd class="It-tag">Create stonith device with specified type and options.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">update &lt;stonith id&gt; [stonith device options]</dt>
  <dd class="It-tag">Add/Change options to specified stonith id.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">delete &lt;stonith id&gt;</dt>
  <dd class="It-tag">Remove stonith id from configuration.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">cleanup [&lt;stonith id&gt;] [<b>--node</b>
    &lt;node&gt;]</dt>
  <dd class="It-tag">Cleans up the stonith device in the lrmd (useful to reset
      the status and failcount). This tells the cluster to forget the operation
      history of a stonith device and re-detect its current state. This can be
      useful to purge knowledge of past failures that have since been resolved.
      If a stonith id is not specified then all resources/stonith devices will
      be cleaned up. If a node is not specified then resources on all nodes will
      be cleaned up.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">level</dt>
  <dd class="It-tag">Lists all of the fencing levels currently configured.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">level add &lt;level&gt; &lt;node&gt; &lt;devices&gt;</dt>
  <dd class="It-tag">Add the fencing level for the specified node with a comma
      separated list of devices (stonith ids) to attempt for that node at that
      level. Fence levels are attempted in numerical order (starting with 1) if
      a level succeeds (meaning all devices are successfully fenced in that
      level) then no other levels are tried, and the node is considered
    fenced.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">level remove &lt;level&gt; [node id] [stonith id] ...
    [stonith id]</dt>
  <dd class="It-tag">Removes the fence level for the level, node and/or devices
      specified. If no nodes or devices are specified then the fence level is
      removed.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">level clear [node|stonith id(s)]</dt>
  <dd class="It-tag">Clears the fence levels on the node (or stonith id)
      specified or clears all fence levels if a node/stonith id is not
      specified. If more than one stonith id is specified they must be separated
      by a comma and no spaces. Example: pcs stonith level clear
    dev_a,dev_b</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">level verify</dt>
  <dd class="It-tag">Verifies all fence devices and nodes specified in fence
      levels exist.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">fence &lt;node&gt; [<b>--off</b>]</dt>
  <dd class="It-tag">Fence the node specified (if <b>--off</b> is specified, use
      the 'off' API call to stonith which will turn the node off instead of
      rebooting it).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">confirm &lt;node&gt; [<b>--force</b>]</dt>
  <dd class="It-tag">Confirm that the host specified is currently down. This
      command should <b>ONLY</b> be used when the node specified has already
      been confirmed to be powered off and to have no access to shared
      resources.
    <div style="height: 1.00em;">&#x00A0;</div>
    <b>WARNING: If this node is not actually powered off or it does have access
      to shared resources, data corruption/cluster failure can occur. To prevent
      accidental running of this command, --force or interactive user response
      is required in order to proceed.</b></dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">sbd enable [<b>--watchdog</b>=&lt;path&gt;[@&lt;node&gt;]]
    ... [&lt;SBD_OPTION&gt;=&lt;value&gt;] ...</dt>
  <dd class="It-tag">Enable SBD in cluster. Default path for watchdog device is
      /dev/watchdog. Allowed SBD options: SBD_WATCHDOG_TIMEOUT (default: 5),
      SBD_DELAY_START (default: no) and SBD_STARTMODE (default: clean).
    <div style="height: 1.00em;">&#x00A0;</div>
    <b>WARNING: Cluster has to be restarted in order to apply these changes.</b>
    <div style="height: 1.00em;">&#x00A0;</div>
    Example of enabling SBD in cluster with watchdogs on node1 will be
      /dev/watchdog2, on node2 /dev/watchdog1, /dev/watchdog0 on all other nodes
      and watchdog timeout will bet set to 10 seconds:
    <div style="height: 1.00em;">&#x00A0;</div>
    pcs stonith sbd enable --watchdog=/dev/watchdog2@node1
      --watchdog=/dev/watchdog1@node2 --watchdog=/dev/watchdog0
      SBD_WATCHDOG_TIMEOUT=10
    <div style="height: 1.00em;">&#x00A0;</div>
  </dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">sbd disable</dt>
  <dd class="It-tag">Disable SBD in cluster.
    <div style="height: 1.00em;">&#x00A0;</div>
    <b>WARNING: Cluster has to be restarted in order to apply these
    changes.</b></dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">sbd status</dt>
  <dd class="It-tag">Show status of SBD services in cluster.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">sbd config</dt>
  <dd class="It-tag">Show SBD configuration in cluster.</dd>
</dl>
<h2 class="Ss" title="Ss" id="acl"><a class="selflink" href="#acl">acl</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">[show]</dt>
  <dd class="It-tag">List all current access control lists.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">enable</dt>
  <dd class="It-tag">Enable access control lists.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">disable</dt>
  <dd class="It-tag">Disable access control lists.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">role create &lt;role id&gt;
    [description=&lt;description&gt;] [((read | write | deny) (xpath
    &lt;query&gt; | id &lt;id&gt;))...]</dt>
  <dd class="It-tag">Create a role with the id and (optional) description
      specified. Each role can also have an unlimited number of permissions
      (read/write/deny) applied to either an xpath query or the id of a specific
      element in the cib.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">role delete &lt;role id&gt;</dt>
  <dd class="It-tag">Delete the role specified and remove it from any
      users/groups it was assigned to.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">role assign &lt;role id&gt; [to]
    &lt;username/group&gt;</dt>
  <dd class="It-tag">Assign a role to a user or group already created with 'pcs
      acl user/group create'.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">role unassign &lt;role id&gt; [from]
    &lt;username/group&gt;</dt>
  <dd class="It-tag">Remove a role from the specified user.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">user create &lt;username&gt; &lt;role id&gt; [&lt;role
    id&gt;]...</dt>
  <dd class="It-tag">Create an ACL for the user specified and assign roles to
      the user.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">user delete &lt;username&gt;</dt>
  <dd class="It-tag">Remove the user specified (and roles assigned will be
      unassigned for the specified user).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">group create &lt;group&gt; &lt;role id&gt; [&lt;role
    id&gt;]...</dt>
  <dd class="It-tag">Create an ACL for the group specified and assign roles to
      the group.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">group delete &lt;group&gt;</dt>
  <dd class="It-tag">Remove the group specified (and roles assigned will be
      unassigned for the specified group).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">permission add &lt;role id&gt; ((read | write | deny)
    (xpath &lt;query&gt; | id &lt;id&gt;))...</dt>
  <dd class="It-tag">Add the listed permissions to the role specified.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">permission delete &lt;permission id&gt;</dt>
  <dd class="It-tag">Remove the permission id specified (permission id's are
      listed in parenthesis after permissions in 'pcs acl' output).</dd>
</dl>
<h2 class="Ss" title="Ss" id="property"><a class="selflink" href="#property">property</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">[list|show [&lt;property&gt; | <b>--all</b> |
    <b>--defaults</b>]] | [ <b>--all</b> | <b>--defaults</b>]</dt>
  <dd class="It-tag">List property settings (default: lists configured
      properties). If <b>--defaults</b> is specified will show all property
      defaults, if <b>--all</b> is specified, current configured properties will
      be shown with unset properties and their defaults. Run 'man pengine' and
      'man crmd' to get a description of the properties.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">set [<b>--force</b> | <b>--node</b> &lt;nodename&gt;]
    &lt;property&gt;=[&lt;value&gt;] [&lt;property&gt;=[&lt;value&gt;] ...]</dt>
  <dd class="It-tag">Set specific pacemaker properties (if the value is blank
      then the property is removed from the configuration). If a property is not
      recognized by pcs the property will not be created unless the
      <b>--force</b> is used. If <b>--node</b> is used a node attribute is set
      on the specified node. Run 'man pengine' and 'man crmd' to get a
      description of the properties.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">unset [<b>--node</b> &lt;nodename&gt;]
    &lt;property&gt;</dt>
  <dd class="It-tag">Remove property from configuration (or remove attribute
      from specified node if <b>--node</b> is used). Run 'man pengine' and 'man
      crmd' to get a description of the properties.</dd>
</dl>
<h2 class="Ss" title="Ss" id="constraint"><a class="selflink" href="#constraint">constraint</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">[list|show] <b>--full</b></dt>
  <dd class="It-tag">List all current location, order and colocation
      constraints, if <b>--full</b> is specified also list the constraint
    ids.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">location &lt;resource id&gt; prefers
    &lt;node[=score]&gt;...</dt>
  <dd class="It-tag">Create a location constraint on a resource to prefer the
      specified node and score (default score: INFINITY).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">location &lt;resource id&gt; avoids
    &lt;node[=score]&gt;...</dt>
  <dd class="It-tag">Create a location constraint on a resource to avoid the
      specified node and score (default score: INFINITY).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">location &lt;resource id&gt; rule [id=&lt;rule id&gt;]
    [resource-discovery=&lt;option&gt;] [role=master|slave]
    [constraint-id=&lt;id&gt;]
    [score=&lt;score&gt;|score-attribute=&lt;attribute&gt;]
    &lt;expression&gt;</dt>
  <dd class="It-tag">Creates a location rule on the specified resource where the
      expression looks like one of the following:
    <div>&#x00A0;</div>
    <br/>
     defined|not_defined &lt;attribute&gt;
    <div>&#x00A0;</div>
    <br/>
     &lt;attribute&gt; lt|gt|lte|gte|eq|ne [string|integer|version]
      &lt;value&gt;
    <div>&#x00A0;</div>
    <br/>
     date gt|lt &lt;date&gt;
    <div>&#x00A0;</div>
    <br/>
     date in_range &lt;date&gt; to &lt;date&gt;
    <div>&#x00A0;</div>
    <br/>
     date in_range &lt;date&gt; to duration &lt;duration options&gt;...
    <div>&#x00A0;</div>
    <br/>
     date-spec &lt;date spec options&gt;...
    <div>&#x00A0;</div>
    <br/>
     &lt;expression&gt; and|or &lt;expression&gt;
    <div>&#x00A0;</div>
    <br/>
     ( &lt;expression&gt; )
    <div>&#x00A0;</div>
    where duration options and date spec options are: hours, monthdays,
      weekdays, yeardays, months, weeks, years, weekyears, moon. If score is
      omitted it defaults to INFINITY. If id is omitted one is generated from
      the resource id. If resource-discovery is omitted it defaults to
    'always'.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">location [show [resources|nodes [node id|resource id]...]
    [<b>--full</b>]]</dt>
  <dd class="It-tag">List all the current location constraints, if 'resources'
      is specified location constraints are displayed per resource (default), if
      'nodes' is specified location constraints are displayed per node. If
      specific nodes or resources are specified then we only show information
      about them. If <b>--full</b> is specified show the internal constraint
      id's as well.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">location add &lt;id&gt; &lt;resource id&gt; &lt;node&gt;
    &lt;score&gt; [resource-discovery=&lt;option&gt;]</dt>
  <dd class="It-tag">Add a location constraint with the appropriate id, resource
      id, node name and score. (For more advanced pacemaker usage.)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">location remove &lt;id&gt; [&lt;resource id&gt;
    &lt;node&gt; &lt;score&gt;]</dt>
  <dd class="It-tag">Remove a location constraint with the appropriate id,
      resource id, node name and score. (For more advanced pacemaker
    usage.)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">order [show] [<b>--full</b>]</dt>
  <dd class="It-tag">List all current ordering constraints (if <b>--full</b> is
      specified show the internal constraint id's as well).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">order [action] &lt;resource id&gt; then [action]
    &lt;resource id&gt; [options]</dt>
  <dd class="It-tag">Add an ordering constraint specifying actions (start, stop,
      promote, demote) and if no action is specified the default action will be
      start. Available options are kind=Optional/Mandatory/Serialize,
      symmetrical=true/false, require-all=true/false and
      id=&lt;constraint-id&gt;.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">order set &lt;resource1&gt; [resourceN]... [options] [set
    &lt;resourceX&gt; ... [options]] [setoptions [constraint_options]]</dt>
  <dd class="It-tag">Create an ordered set of resources. Available options are
      sequential=true/false, require-all=true/false,
      action=start/promote/demote/stop and role=Stopped/Started/Master/Slave.
      Available constraint_options are id=&lt;constraint-id&gt;,
      kind=Optional/Mandatory/Serialize and symmetrical=true/false.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">order remove &lt;resource1&gt; [resourceN]...</dt>
  <dd class="It-tag">Remove resource from any ordering constraint</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">colocation [show] [<b>--full</b>]</dt>
  <dd class="It-tag">List all current colocation constraints (if <b>--full</b>
      is specified show the internal constraint id's as well).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">colocation add [master|slave] &lt;source resource id&gt;
    with [master|slave] &lt;target resource id&gt; [score] [options]
    [id=constraint-id]</dt>
  <dd class="It-tag">Request &lt;source resource&gt; to run on the same node
      where pacemaker has determined &lt;target resource&gt; should run.
      Positive values of score mean the resources should be run on the same
      node, negative values mean the resources should not be run on the same
      node. Specifying 'INFINITY' (or '-INFINITY') for the score forces
      &lt;source resource&gt; to run (or not run) with &lt;target resource&gt;
      (score defaults to &quot;INFINITY&quot;). A role can be master or slave
      (if no role is specified, it defaults to 'started').</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">colocation set &lt;resource1&gt; [resourceN]... [options]
    [set &lt;resourceX&gt; ... [options]] [setoptions [constraint_options]]</dt>
  <dd class="It-tag">Create a colocation constraint with a resource set.
      Available options are sequential=true/false, require-all=true/false,
      action=start/promote/demote/stop and role=Stopped/Started/Master/Slave.
      Available constraint_options are id, score, score-attribute and
      score-attribute-mangle.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">colocation remove &lt;source resource id&gt; &lt;target
    resource id&gt;</dt>
  <dd class="It-tag">Remove colocation constraints with specified
    resources.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ticket [show] [<b>--full</b>]</dt>
  <dd class="It-tag">List all current ticket constraints (if <b>--full</b> is
      specified show the internal constraint id's as well).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ticket add &lt;ticket&gt; [&lt;role&gt;] &lt;resource
    id&gt; [&lt;options&gt;] [id=&lt;constraint-id&gt;]</dt>
  <dd class="It-tag">Create a ticket constraint for &lt;resource id&gt;.
      Available option is loss-policy=fence/stop/freeze/demote. A role can be
      master, slave, started or stopped.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ticket set &lt;resource1&gt; [&lt;resourceN&gt;]...
    [&lt;options&gt;] [set &lt;resourceX&gt; ... [&lt;options&gt;]] setoptions
    &lt;constraint_options&gt;</dt>
  <dd class="It-tag">Create a ticket constraint with a resource set. Available
      options are sequential=true/false, require-all=true/false,
      action=start/promote/demote/stop and role=Stopped/Started/Master/Slave.
      Required constraint option is ticket=&lt;ticket&gt;. Optional constraint
      options are id=&lt;constraint-id&gt; and
      loss-policy=fence/stop/freeze/demote.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ticket remove &lt;ticket&gt; &lt;resource id&gt;</dt>
  <dd class="It-tag">Remove all ticket constraints with &lt;ticket&gt; from
      &lt;resource id&gt;.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">remove [constraint id]...</dt>
  <dd class="It-tag">Remove constraint(s) or constraint rules with the specified
      id(s).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ref &lt;resource&gt;...</dt>
  <dd class="It-tag">List constraints referencing specified resource.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">rule add &lt;constraint id&gt; [id=&lt;rule id&gt;]
    [role=master|slave] [score=&lt;score&gt;|score-attribute=&lt;attribute&gt;]
    &lt;expression&gt;</dt>
  <dd class="It-tag">Add a rule to a constraint where the expression looks like
      one of the following:
    <div>&#x00A0;</div>
    <br/>
     defined|not_defined &lt;attribute&gt;
    <div>&#x00A0;</div>
    <br/>
     &lt;attribute&gt; lt|gt|lte|gte|eq|ne [string|integer|version]
      &lt;value&gt;
    <div>&#x00A0;</div>
    <br/>
     date gt|lt &lt;date&gt;
    <div>&#x00A0;</div>
    <br/>
     date in_range &lt;date&gt; to &lt;date&gt;
    <div>&#x00A0;</div>
    <br/>
     date in_range &lt;date&gt; to duration &lt;duration options&gt;...
    <div>&#x00A0;</div>
    <br/>
     date-spec &lt;date spec options&gt;...
    <div>&#x00A0;</div>
    <br/>
     &lt;expression&gt; and|or &lt;expression&gt;
    <div>&#x00A0;</div>
    <br/>
     ( &lt;expression&gt; )
    <div>&#x00A0;</div>
    where duration options and date spec options are: hours, monthdays,
      weekdays, yeardays, months, weeks, years, weekyears, moon If score is
      ommited it defaults to INFINITY. If id is ommited one is generated from
      the constraint id.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">rule remove &lt;rule id&gt;</dt>
  <dd class="It-tag">Remove a rule if a rule id is specified, if rule is last
      rule in its constraint, the constraint will be removed.</dd>
</dl>
<h2 class="Ss" title="Ss" id="qdevice"><a class="selflink" href="#qdevice">qdevice</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">status &lt;device model&gt; [<b>--full</b>] [&lt;cluster
    name&gt;]</dt>
  <dd class="It-tag">Show runtime status of specified model of quorum device
      provider. Using <b>--full</b> will give more detailed output. If
      &lt;cluster name&gt; is specified, only information about the specified
      cluster will be displayed.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">setup model &lt;device model&gt; [<b>--enable</b>]
    [<b>--start</b>]</dt>
  <dd class="It-tag">Configure specified model of quorum device provider. Quorum
      device then can be added to clusters by running &quot;pcs quorum device
      add&quot; command in a cluster. <b>--start</b> will also start the
      provider. <b>--enable</b> will configure the provider to start on
    boot.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">destroy &lt;device model&gt;</dt>
  <dd class="It-tag">Disable and stop specified model of quorum device provider
      and delete its configuration files.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">start &lt;device model&gt;</dt>
  <dd class="It-tag">Start specified model of quorum device provider.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">stop &lt;device model&gt;</dt>
  <dd class="It-tag">Stop specified model of quorum device provider.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">kill &lt;device model&gt;</dt>
  <dd class="It-tag">Force specified model of quorum device provider to stop
      (performs kill -9). Note that init system (e.g. systemd) can detect that
      the qdevice is not running and start it again. If you want to stop the
      qdevice, run &quot;pcs qdevice stop&quot; command.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">enable &lt;device model&gt;</dt>
  <dd class="It-tag">Configure specified model of quorum device provider to
      start on boot.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">disable &lt;device model&gt;</dt>
  <dd class="It-tag">Configure specified model of quorum device provider to not
      start on boot.</dd>
</dl>
<h2 class="Ss" title="Ss" id="quorum"><a class="selflink" href="#quorum">quorum</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">[config]</dt>
  <dd class="It-tag">Show quorum configuration.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">status</dt>
  <dd class="It-tag">Show quorum runtime status.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">device add [&lt;generic options&gt;] model &lt;device
    model&gt; [&lt;model options&gt;]</dt>
  <dd class="It-tag">Add a quorum device to the cluster. Quorum device needs to
      be created first by &quot;pcs qdevice setup&quot; command. It is not
      possible to use more than one quorum device in a cluster simultaneously.
      Generic options, model and model options are all documented in corosync's
      corosync-qdevice(8) man page.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">device remove</dt>
  <dd class="It-tag">Remove a quorum device from the cluster.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">device status [<b>--full</b>]</dt>
  <dd class="It-tag">Show quorum device runtime status. Using <b>--full</b> will
      give more detailed output.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">device update [&lt;generic options&gt;] [model &lt;model
    options&gt;]</dt>
  <dd class="It-tag">Add/Change quorum device options. Generic options and model
      options are all documented in corosync's corosync-qdevice(8) man page.
      Requires the cluster to be stopped.
    <div style="height: 1.00em;">&#x00A0;</div>
    WARNING: If you want to change &quot;host&quot; option of qdevice model net,
      use &quot;pcs quorum device remove&quot; and &quot;pcs quorum device
      add&quot; commands to set up configuration properly unless old and new
      host is the same machine.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">expected-votes &lt;votes&gt;</dt>
  <dd class="It-tag">Set expected votes in the live cluster to specified value.
      This only affects the live cluster, not changes any configuration
    files.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">unblock [<b>--force</b>]</dt>
  <dd class="It-tag">Cancel waiting for all nodes when establishing quorum.
      Useful in situations where you know the cluster is inquorate, but you are
      confident that the cluster should proceed with resource management
      regardless. This command should ONLY be used when nodes which the cluster
      is waiting for have been confirmed to be powered off and to have no access
      to shared resources.
    <div style="height: 1.00em;">&#x00A0;</div>
    <b>WARNING: If the nodes are not actually powered off or they do have access
      to shared resources, data corruption/cluster failure can occur. To prevent
      accidental running of this command, --force or interactive user response
      is required in order to proceed.</b></dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">update [auto_tie_breaker=[0|1]] [last_man_standing=[0|1]]
    [last_man_standing_window=[&lt;time in ms&gt;]] [wait_for_all=[0|1]]</dt>
  <dd class="It-tag">Add/Change quorum options. At least one option must be
      specified. Options are documented in corosync's votequorum(5) man page.
      Requires the cluster to be stopped.</dd>
</dl>
<h2 class="Ss" title="Ss" id="booth"><a class="selflink" href="#booth">booth</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">setup sites &lt;address&gt; &lt;address&gt;
    [&lt;address&gt;...] [arbitrators &lt;address&gt; ...] [
    <b>--force</b>]</dt>
  <dd class="It-tag">Write new booth configuration with specified sites and
      arbitrators. Total number of peers (sites and arbitrators) must be odd.
      When the configuration file already exists, command fails unless
      <b>--force</b> is specified.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">destroy</dt>
  <dd class="It-tag">Remove booth configuration files.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ticket add &lt;ticket&gt; [&lt;name&gt;=&lt;value&gt;
    ...]</dt>
  <dd class="It-tag">Add new ticket to the current configuration. Ticket options
      are specified in booth manpage.
    <div style="height: 1.00em;">&#x00A0;</div>
  </dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ticket remove &lt;ticket&gt;</dt>
  <dd class="It-tag">Remove the specified ticket from the current
    configuration.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">config [&lt;node&gt;]</dt>
  <dd class="It-tag">Show booth configuration from the specified node or from
      the current node if node not specified.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">create ip &lt;address&gt;</dt>
  <dd class="It-tag">Make the cluster run booth service on the specified ip
      address as a cluster resource. Typically this is used to run booth
    site.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">remove</dt>
  <dd class="It-tag">Remove booth resources created by the &quot;pcs booth
      create&quot; command.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">restart</dt>
  <dd class="It-tag">Restart booth resources created by the &quot;pcs booth
      create&quot; command.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ticket grant &lt;ticket&gt; [&lt;site address&gt;]</dt>
  <dd class="It-tag">Grant the ticket for the site specified by address. Site
      address which has been specified with 'pcs booth create' command is used
      if 'site address' is omitted. Specifying site address is mandatory when
      running this command on an arbitrator.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ticket revoke &lt;ticket&gt; [&lt;site address&gt;]</dt>
  <dd class="It-tag">Revoke the ticket for the site specified by address. Site
      address which has been specified with 'pcs booth create' command is used
      if 'site address' is omitted. Specifying site address is mandatory when
      running this command on an arbitrator.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">status</dt>
  <dd class="It-tag">Print current status of booth on the local node.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">pull &lt;node&gt;</dt>
  <dd class="It-tag">Pull booth configuration from the specified node.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">sync [<b>--skip-offline</b>]</dt>
  <dd class="It-tag">Send booth configuration from the local node to all nodes
      in the cluster.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">enable</dt>
  <dd class="It-tag">Enable booth arbitrator service.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">disable</dt>
  <dd class="It-tag">Disable booth arbitrator service.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">start</dt>
  <dd class="It-tag">Start booth arbitrator service.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">stop</dt>
  <dd class="It-tag">Stop booth arbitrator service.</dd>
</dl>
<h2 class="Ss" title="Ss" id="status"><a class="selflink" href="#status">status</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">[status] [<b>--full</b> | <b>--hide-inactive</b>]</dt>
  <dd class="It-tag">View all information about the cluster and resources
      (<b>--full</b> provides more details, <b>--hide-inactive</b> hides
      inactive resources).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">resources [&lt;resource id&gt; | <b>--full</b> |
    <b>--groups</b> | <b>--hide-inactive</b>]</dt>
  <dd class="It-tag">Show all currently configured resources or if a resource is
      specified show the options for the configured resource. If <b>--full</b>
      is specified, all configured resource options will be displayed. If
      <b>--groups</b> is specified, only show groups (and their resources). If
      <b>--hide-inactive</b> is specified, only show active resources.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">groups</dt>
  <dd class="It-tag">View currently configured groups and their resources.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">cluster</dt>
  <dd class="It-tag">View current cluster status.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">corosync</dt>
  <dd class="It-tag">View current membership information as seen by
    corosync.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">quorum</dt>
  <dd class="It-tag">View current quorum status.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">qdevice &lt;device model&gt; [<b>--full</b>] [&lt;cluster
    name&gt;]</dt>
  <dd class="It-tag">Show runtime status of specified model of quorum device
      provider. Using <b>--full</b> will give more detailed output. If
      &lt;cluster name&gt; is specified, only information about the specified
      cluster will be displayed.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">nodes [corosync|both|config]</dt>
  <dd class="It-tag">View current status of nodes from pacemaker. If 'corosync'
      is specified, print nodes currently configured in corosync, if 'both' is
      specified, print nodes from both corosync &amp; pacemaker. If 'config' is
      specified, print nodes from corosync &amp; pacemaker configuration.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">pcsd [&lt;node&gt;] ...</dt>
  <dd class="It-tag">Show the current status of pcsd on the specified nodes.
      When no nodes are specified, status of all nodes is displayed.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">xml</dt>
  <dd class="It-tag">View xml version of status (output from crm_mon <b>-r</b>
      <b>-1</b> <b>-X</b>).</dd>
</dl>
<h2 class="Ss" title="Ss" id="config"><a class="selflink" href="#config">config</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">[show]</dt>
  <dd class="It-tag">View full cluster configuration.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">backup [filename]</dt>
  <dd class="It-tag">Creates the tarball containing the cluster configuration
      files. If filename is not specified the standard output will be used.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">restore [<b>--local</b>] [filename]</dt>
  <dd class="It-tag">Restores the cluster configuration files on all nodes from
      the backup. If filename is not specified the standard input will be used.
      If <b>--local</b> is specified only the files on the current node will be
      restored.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">checkpoint</dt>
  <dd class="It-tag">List all available configuration checkpoints.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">checkpoint view &lt;checkpoint_number&gt;</dt>
  <dd class="It-tag">Show specified configuration checkpoint.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">checkpoint restore &lt;checkpoint_number&gt;</dt>
  <dd class="It-tag">Restore cluster configuration to specified checkpoint.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">import-cman output=&lt;filename&gt;
    [input=&lt;filename&gt;] [ <b>--interactive</b>]
    [output-format=corosync.conf|cluster.conf] [dist=&lt;dist&gt;]</dt>
  <dd class="It-tag">Converts RHEL 6 (CMAN) cluster configuration to Pacemaker
      cluster configuration. Converted configuration will be saved to 'output'
      file. To send the configuration to the cluster nodes the 'pcs config
      restore' command can be used. If <b>--interactive</b> is specified you
      will be prompted to solve incompatibilities manually. If no input is
      specified /etc/cluster/cluster.conf will be used. You can force to create
      output containing either cluster.conf or corosync.conf using the
      output-format option. Optionally you can specify output version by setting
      'dist' option e. g. rhel,6.8 or redhat,7.3 or debian,7 or ubuntu,trusty.
      You can get the list of supported dist values by running the &quot;clufter
      <b>--list-dists</b>&quot; command. If 'dist' is not specified, it defaults
      to this node's version if that matches output-format, otherwise redhat,6.7
      is used for cluster.conf and redhat,7.1 is used for corosync.conf.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">import-cman output=&lt;filename&gt;
    [input=&lt;filename&gt;] [ <b>--interactive</b>]
    output-format=pcs-commands|pcs-commands-verbose [dist=&lt;dist&gt;]</dt>
  <dd class="It-tag">Converts RHEL 6 (CMAN) cluster configuration to a list of
      pcs commands which recreates the same cluster as Pacemaker cluster when
      executed. Commands will be saved to 'output' file. For other options see
      above.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">export pcs-commands|pcs-commands-verbose
    [output=&lt;filename&gt;] [dist=&lt;dist&gt;]</dt>
  <dd class="It-tag">Creates a list of pcs commands which upon execution
      recreates the current cluster running on this node. Commands will be saved
      to 'output' file or written to stdout if 'output' is not specified. Use
      pcs-commands to get a simple list of commands, whereas
      pcs-commands-verbose creates a list including comments and debug messages.
      Optionally specify output version by setting 'dist' option e. g. rhel,6.8
      or redhat,7.3 or debian,7 or ubuntu,trusty. You can get the list of
      supported dist values by running the &quot;clufter
      <b>--list-dists</b>&quot; command. If 'dist' is not specified, it defaults
      to this node's version.</dd>
</dl>
<h2 class="Ss" title="Ss" id="pcsd"><a class="selflink" href="#pcsd">pcsd</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">certkey &lt;certificate file&gt; &lt;key file&gt;</dt>
  <dd class="It-tag">Load custom certificate and key files for use in pcsd.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">sync-certificates</dt>
  <dd class="It-tag">Sync pcsd certificates to all nodes found from current
      corosync.conf file (cluster.conf on systems running Corosync 1.x).
      WARNING: This will restart pcsd daemon on the nodes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">clear-auth [<b>--local</b>] [<b>--remote</b>]</dt>
  <dd class="It-tag">Removes all system tokens which allow pcs/pcsd on the
      current system to authenticate with remote pcs/pcsd instances and
      vice-versa. After this command is run this node will need to be
      re-authenticated with other nodes (using 'pcs cluster auth'). Using
      <b>--local</b> only removes tokens used by local pcs (and pcsd if root) to
      connect to other pcsd instances, using <b>--remote</b> clears
      authentication tokens used by remote systems to connect to the local pcsd
      instance.</dd>
</dl>
<h2 class="Ss" title="Ss" id="node"><a class="selflink" href="#node">node</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">attribute [[&lt;node&gt;] [<b>--name</b> &lt;name&gt;] |
    &lt;node&gt; &lt;name&gt;=&lt;value&gt; ...]</dt>
  <dd class="It-tag">Manage node attributes. If no parameters are specified,
      show attributes of all nodes. If one parameter is specified, show
      attributes of specified node. If <b>--name</b> is specified, show
      specified attribute's value from all nodes. If more parameters are
      specified, set attributes of specified node. Attributes can be removed by
      setting an attribute without a value.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">maintenance [<b>--all</b>] | [&lt;node&gt;]...</dt>
  <dd class="It-tag">Put specified node(s) into maintenance mode, if no node or
      options are specified the current node will be put into maintenance mode,
      if <b>--all</b> is specified all nodes will be put into maintenace
    mode.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">unmaintenance [<b>--all</b>] | [&lt;node&gt;]...</dt>
  <dd class="It-tag">Remove node(s) from maintenance mode, if no node or options
      are specified the current node will be removed from maintenance mode, if
      <b>--all</b> is specified all nodes will be removed from maintenance
    mode.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">standby [<b>--all</b> | &lt;node&gt;]
    [<b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Put specified node into standby mode (the node specified
      will no longer be able to host resources), if no node or options are
      specified the current node will be put into standby mode, if <b>--all</b>
      is specified all nodes will be put into standby mode. If <b>--wait</b> is
      specified, pcs will wait up to 'n' seconds for the node(s) to be put into
      standby mode and then return 0 on success or 1 if the operation not
      succeeded yet. If 'n' is not specified it defaults to 60 minutes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">unstandby [<b>--all</b> | &lt;node&gt;]
    [<b>--wait</b>[=n]]</dt>
  <dd class="It-tag">Remove node from standby mode (the node specified will now
      be able to host resources), if no node or options are specified the
      current node will be removed from standby mode, if <b>--all</b> is
      specified all nodes will be removed from standby mode. If <b>--wait</b> is
      specified, pcs will wait up to 'n' seconds for the node(s) to be removed
      from standby mode and then return 0 on success or 1 if the operation not
      succeeded yet. If 'n' is not specified it defaults to 60 minutes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">utilization [[&lt;node&gt;] [<b>--name</b> &lt;name&gt;] |
    &lt;node&gt; &lt;name&gt;=&lt;value&gt; ...]</dt>
  <dd class="It-tag">Add specified utilization options to specified node. If
      node is not specified, shows utilization of all nodes. If <b>--name</b> is
      specified, shows specified utilization value from all nodes. If
      utilization options are not specified, shows utilization of specified
      node. Utilization option should be in format name=value, value has to be
      integer. Options may be removed by setting an option without a value.
      Example: pcs node utilization node1 cpu=4 ram=</dd>
</dl>
<h2 class="Ss" title="Ss" id="alert"><a class="selflink" href="#alert">alert</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">[config|show]</dt>
  <dd class="It-tag">Show all configured alerts.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">create path=&lt;path&gt; [id=&lt;alert-id&gt;]
    [description=&lt;description&gt;] [options
    [&lt;option&gt;=&lt;value&gt;]...] [meta
    [&lt;meta-option&gt;=&lt;value&gt;]...]</dt>
  <dd class="It-tag">Define an alert handler with specified path. Id will be
      automatically generated if it is not specified.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">update &lt;alert-id&gt; [path=&lt;path&gt;]
    [description=&lt;description&gt;] [options
    [&lt;option&gt;=&lt;value&gt;]...] [meta
    [&lt;meta-option&gt;=&lt;value&gt;]...]</dt>
  <dd class="It-tag">Update existing alert handler with specified id.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">remove &lt;alert-id&gt;</dt>
  <dd class="It-tag">Remove alert handler with specified id.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">recipient add &lt;alert-id&gt;
    value=&lt;recipient-value&gt; [id=&lt;recipient-id&gt;]
    [description=&lt;description&gt;] [options
    [&lt;option&gt;=&lt;value&gt;]...] [meta
    [&lt;meta-option&gt;=&lt;value&gt;]...]</dt>
  <dd class="It-tag">Add new recipient to specified alert handler.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">recipient update &lt;recipient-id&gt;
    [value=&lt;recipient-value&gt;] [description=&lt;description&gt;] [options
    [&lt;option&gt;=&lt;value&gt;]...] [meta
    [&lt;meta-option&gt;=&lt;value&gt;]...]</dt>
  <dd class="It-tag">Update existing recipient identified by it's id.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">recipient remove &lt;recipient-id&gt;</dt>
  <dd class="It-tag">Remove specified recipient.</dd>
</dl>
<h1 class="Sh" title="Sh" id="EXAMPLES"><a class="selflink" href="#EXAMPLES">EXAMPLES</a></h1>
<dl class="Bl-tag">
  <dt class="It-tag">Show all resources</dt>
  <dd class="It-tag"><b># pcs resource show</b></dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">Show options specific to the 'VirtualIP' resource</dt>
  <dd class="It-tag"><b># pcs resource show VirtualIP</b></dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">Create a new resource called 'VirtualIP' with options</dt>
  <dd class="It-tag"><b># pcs resource create VirtualIP ocf:heartbeat:IPaddr2
      ip=192.168.0.99 cidr_netmask=32 nic=eth2 op monitor interval=30s</b></dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">Create a new resource called 'VirtualIP' with options</dt>
  <dd class="It-tag"><b># pcs resource create VirtualIP IPaddr2 ip=192.168.0.99
      cidr_netmask=32 nic=eth2 op monitor interval=30s</b></dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">Change the ip address of VirtualIP and remove the nic
    option</dt>
  <dd class="It-tag"><b># pcs resource update VirtualIP ip=192.168.0.98
    nic=</b></dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">Delete the VirtualIP resource</dt>
  <dd class="It-tag"><b># pcs resource delete VirtualIP</b></dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">Create the MyStonith stonith fence_virt device which can
    fence host 'f1'</dt>
  <dd class="It-tag"><b># pcs stonith create MyStonith fence_virt
      pcmk_host_list=f1</b></dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">Set the stonith-enabled property to false on the cluster
    (which disables stonith)</dt>
  <dd class="It-tag"><b># pcs property set stonith-enabled=false</b></dd>
</dl>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">June 2016</td>
    <td class="foot-os">pcs 0.9.152</td>
  </tr>
</table>
</body>
</html>
