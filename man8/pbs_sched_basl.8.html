<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 19:14:30 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>pbs_scheduler_basl(8B) PBS pbs_scheduler_basl(8B)</p>

<p style="margin-top: 1em">NAME <br>
pbs_sched_basl - pbs BASL scheduler</p>

<p style="margin-top: 1em">SYNOPSIS <br>
pbs_sched [-d home] [-L logfile] [-p print_file] [-a alarm]
[-S port] [-c configfile]</p>

<p style="margin-top: 1em">DESCRIPTION <br>
The pbs_sched command starts the operation of a batch
scheduler on the local host. It runs in conjunction with the
PBS server. It queries the server about the state of PBS and
<br>
communicates with pbs_mom to get information about the
status of running jobs, memory available etc. It then makes
decisions as to what jobs to run.</p>

<p style="margin-top: 1em">Typically, this command will be
in a local boot file such as /etc/rc.local .</p>

<p style="margin-top: 1em">pbs_sched must be executed with
root permission.</p>

<p style="margin-top: 1em">OPTIONS <br>
-d home <br>
Specifies the name of the PBS home directory, PBS_HOME. If
not specified, the value of $PBS_SERVER_HOME as defined at
compile time is used. Also see the -L option.</p>

<p style="margin-top: 1em">-L logfile <br>
Specifies an absolute path name of the file to use as the
log file. If not specified, the scheduler will open a file
named for the current date in the PBS_HOME/sched_logs <br>
directory. See the -d option.</p>

<p style="margin-top: 1em">-p print_file <br>
This specifies the &quot;print&quot; file. Any output from
the scheduler code which is written to standard out or
standard error will be written to this file. If this option
is not <br>
given, the file used will be $PBS_HOME/sched_priv/sched_out.
See the -d option.</p>

<p style="margin-top: 1em">-a alarm <br>
This specifies the time in seconds to wait for a schedule
run to finish. If a scheduling iteration takes too long to
finish, an alarm signal is sent, and the scheduler is <br>
restarted. If a core file does not exist in the current
directory, abort() is called and a core file is generated.
The default for alarm is 180 seconds.</p>

<p style="margin-top: 1em">-S port <br>
Specifies a port on which to talk to the server. This option
is not required. It merely overides the default PBS
scheduler port.</p>

<p style="margin-top: 1em">-c configfile <br>
Specify a configuration file, see description below. If this
is a relative file name it will be relative to
PBS_HOME/sched_priv, see the -d option. If the -c option is
not <br>
supplied, pbs_sched will not attempt to open a configuration
file. In BASL, this config file is almost always needed
because it is where the list of servers, nodes, and host
<br>
resource queries are specified by the administrator.</p>

<p style="margin-top: 1em">USAGE <br>
This version of the scheduler requires knowledge of the BASL
language. The site must first write a function called
sched_main() (and all functions supporting it) using BASL
con&acirc; <br>
structs, and then translate the functions into C using the
BASL compiler basl2c , which would also attach a main
program to the resulting code. This main program performs
gen&acirc; <br>
eral initialization and housekeeping chores such as setting
up local socket to communicate with the server running on
the same machine, cd-ing to the priv directory, opening log
<br>
files, opening configuration file (if any), setting up
locks, forking the child to become a daemon, initializing a
scheduling cycle (i.e. get node attributes that are static
in <br>
nature), setting up the signal handlers, executing global
initialization assignment statements specified by the
scheduler writer, and finally sitting on a loop waiting for
a <br>
scheduling command from the server. When the server sends
the scheduler an appropriate scheduling command
{SCH_SCHEDULE_NEW, SCH_SCHEDULE_TERM, SCH_SCHEDULE_TIME,
SCH_SCHED&acirc; <br>
ULE_RECYC, SCH_SCHEDULE_CMD, SCH_SCHEDULE_FIRST},
information about server(s), jobs, queues, and execution
host(s) are obtained, and then sched_main() is called.</p>

<p style="margin-top: 1em">SCHEDULING LANGUAGE <br>
The BAtch Scheduling Language (BASL) is a C-like procedural
language. It provides a number of constructs and predefined
functions that facilitate dealing with scheduling issues.
<br>
Information about a PBS server, the queues that it owns,
jobs residing on each queue, and the computational nodes
where jobs can be run, are accessed via the BASL data types
<br>
Server, Que, Job, CNode, Set Server, Set Que, Set Job, and
Set CNode.</p>

<p style="margin-top: 1em">The following simple
sched_main() will cause the server to run all queued jobs on
the local server:</p>

<p style="margin-top: 1em">sched_main() <br>
{ <br>
Server s; <br>
Que q; <br>
Job j; <br>
Set Que queues; <br>
Set Job jobs;</p>

<p style="margin-top: 1em">s = AllServersLocalHostGet(); //
get local server <br>
queues = ServerQueuesGet(s);</p>

<p style="margin-top: 1em">foreach( q in queues ) { <br>
jobs = QueJobsGet(q); <br>
foreach( j in jobs ) { <br>
JobAction(j, SYNCRUN, NULLSTR); <br>
} <br>
}</p>

<p style="margin-top: 1em">}</p>

<p style="margin-top: 1em">For a more complete discussion
of the Batch Scheduler Language, see basl2c(1B) .</p>

<p style="margin-top: 1em">CONFIGURATION FILE <br>
A configuration file may be specified with the -c option.
This file is used to specify the (1) hosts which are allowed
to connect to pbs_sched, (2) the list of server hosts for
<br>
which the scheduler writer wishes the system to periodically
check for status, queues, and jobs info, (3) list of
execution hosts for which the scheduler writer wants the
system <br>
to periodically check for information like state, property,
and so on, and (4) various queries to send to each execution
host.</p>

<p style="margin-top: 1em">(1) specifying client hosts:
<br>
The hosts allowed to connect to pbs_sched are specified in
the configuration file in a manner identical to that used in
pbs_mom. There is one line per host using the syn&acirc;
<br>
tax:</p>

<p style="margin-top: 1em">$clienthost hostname</p>

<p style="margin-top: 1em">where clienthost and hostname
are separated by white space. Two host names are always
allowed to connection to pbs_sched: &quot;localhost&quot;
and the name returned to pbs_sched by <br>
the system call gethostname(). These names need not be
specified in the configuration file.</p>

<p style="margin-top: 1em">(2) specifying list of servers:
<br>
The list of servers is specified in a one host per line
manner, using the syntax:</p>

<p style="margin-top: 1em">$serverhost hostname port_number
<br>
or where $server_host, hostname, and port_number are
separated by white space.</p>

<p style="margin-top: 1em">If port_number is 0, then the
default PBS server port will be used.</p>

<p style="margin-top: 1em">Regardless of what has been
specified in the file, the list of servers will always
include the local server - one running on the same host
where the scheduler is running.</p>

<p style="margin-top: 1em">Within the BASL code, access to
data of the list of servers is done by calling
AllServersGet(), or AllServersLocalHostGet() which returns
the local server on the list.</p>

<p style="margin-top: 1em">(3) specifying the list of
execution hosts: <br>
The list of execution hosts (nodes), whose MOMs are to be
queried from the scheduler, is specified in a one host per
line manner, using the syntax:</p>

<p style="margin-top: 1em">$momhost hostname
port_number</p>

<p style="margin-top: 1em">where $momhost, hostname, and
port_number are separated by white space.</p>

<p style="margin-top: 1em">If port_number is 0, then the
default PBS MOM port will be used.</p>

<p style="margin-top: 1em">The BASL function AllNodesGet()
, or ServerNodesGet(AllServersLocalHostGet()) is available
for getting the list of nodes known to the local system.</p>

<p style="margin-top: 1em">(4) specifying the list of host
resources: <br>
For specifying the list of host resource queries to send to
each execution host&rsquo;s MOM, the following syntax is
used:</p>

<p style="margin-top: 1em">$node node_name CNode..Get
host_resource</p>

<p style="margin-top: 1em">node_name should be the same
hostname string that was specified in a $momhost line. A
node_name value of &quot;*&quot; (wildcard) means to match
any node.</p>

<p style="margin-top: 1em">Please consult section 9 of the
PBS ERS (Resource Monitor/Resources) for a list of possible
values to host_resource parameter.</p>

<p style="margin-top: 1em">CNode..Get refers to the actual
function name that is called from the scheduler code to
obtain the return values to host resource queries. The list
of CNode..Get function <br>
names that can appear in the configuration file are: <br>
STATIC: <br>
================================ <br>
CNodePropertiesGet <br>
CNodeVendorGet <br>
CNodeNumCpusGet <br>
CNodeOsGet <br>
CNodeMemTotalGet[type] <br>
CNodeNetworkBwGet[type] <br>
CNodeSwapSpaceTotalGet[name] <br>
CNodeDiskSpaceTotalGet[name] <br>
CNodeDiskInBwGet[name] <br>
CNodeDiskOutBwGet[name] <br>
CNodeTapeSpaceTotalGet[name] <br>
CNodeTapeInBwGet[name] <br>
CNodeTapeOutBwGet[name] <br>
CNodeSrfsSpaceTotalGet[name] <br>
CNodeSrfsInBwGet[name] <br>
CNodeSrfsOutBwGet[name]</p>

<p style="margin-top: 1em">DYNAMIC: <br>
================================ <br>
CNodeIdletimeGet <br>
CNodeLoadAveGet <br>
CNodeMemAvailGet[type] <br>
CNodeSwapSpaceAvailGet[name] <br>
CNodeSwapInBwGet[name] <br>
CNodeSwapOutBwGet[name] <br>
CNodeDiskSpaceReservedGet[name] <br>
CNodeDiskSpaceAvailGet[name] <br>
CNodeTapeSpaceAvailGet[name] <br>
CNodeSrfsSpaceReservedGet[name] <br>
CNodeSrfsSpaceAvailGet[name] <br>
CNodeCpuPercentIdleGet <br>
CNodeCpuPercentSysGet <br>
CNodeCpuPercentUserGet <br>
CNodeCpuPercentGuestGet</p>

<p style="margin-top: 1em">STATIC function names return
values that are obtained only during the first scheduling
cycle, or when the scheduler is instructed to reconfig;
whereas, DYNAMIC function <br>
names return attribute values that are taken at every
subsequent scheduling cycle.</p>

<p style="margin-top: 1em">name and type are arbitrarily
defined. For example, you can choose to have name defined as
&quot;$FASTDIR&quot; for the CNodeSrfs* calls, and a sample
configuration file entry would <br>
look like:</p>

<p style="margin-top: 1em">$node unicos8
CNodeSrfsSpaceAvailGet[$FASTDIR] <br>
quota[type=ares_avail,dir=$FASTDIR]</p>

<p style="margin-top: 1em">So in a BASL code, if you call
CNodeSrfsSpaceAvailGet(node, &quot;$FASTDIR&quot;), then it
will return the value to the query
&quot;quota[type=ares_avail,dir=$FASTDIR]&quot; (3rd
parameter) as <br>
sent to the node&rsquo;s MOM.</p>

<p style="margin-top: 1em">By default, the scheduler has
already internally defined the following mappings, which can
be overriden in the configuration file:</p>

<p style="margin-top: 1em">keyword node_name CNode..Get
host_resource <br>
======= ========= ================ ============= <br>
$node * CNodeOsGet arch <br>
$node * CNodeLoadAveGet loadave <br>
$node * CNodeIdletimeGet idletime</p>

<p style="margin-top: 1em">The above means that for all
declared nodes (via $momhost), the host queries arch,
loadave, and idletime will be sent to each node&rsquo;s MOM.
The value to arch is obtained <br>
internally by the system during the first scheduling cycle
because it falls under STATIC category, while values to
loadave and idletime are taken at every scheduling
itera&acirc; <br>
tion because they fall under the DYNAMIC category. Access to
the return values is done by calling CNodeOsGet(node),
CNodeLoadAveGet(node), and CNodeIdletimeGet(node), <br>
respectively. The following are some sample $node arguments
that you may put in the configuration file. <br>
node_name CNode..Get host res <br>
================== ========================= ========== <br>
&lt;sunos4_nodename&gt; CNodeIdletimeGet idletime <br>
&lt;sunos4_nodename&gt; CNodeLoadAveGet loadave <br>
&lt;sunos4_nodename&gt; CNodeMemTotalGet[real] physmem <br>
&lt;sunos4_nodename&gt; CNodeMemTotalGet[virtual] totmem
<br>
&lt;sunos4_nodename&gt; CNodeMemAvailGet[virtual]
availmem</p>

<p style="margin-top: 1em">&lt;irix5_nodename&gt;
CNodeNumCpusGet ncpus <br>
&lt;irix5_nodename&gt; CNodeMemTotalGet[real] physmem <br>
&lt;irix5_nodename&gt; CNodeMemTotalGet[virtual] totmem <br>
&lt;irix5_nodename&gt; CNodeIdletimeGet idletime <br>
&lt;irix5_nodename&gt; CNodeLoadAveGet loadave <br>
&lt;irix5_nodename&gt; CNodeMemAvailGet[virtual]
availmem</p>

<p style="margin-top: 1em">&lt;linux_nodename&gt;
CNodeNumCpusGet ncpus <br>
&lt;linux_nodename&gt; CNodeMemTotalGet[real] physmem <br>
&lt;linux_nodename&gt; CNodeMemTotalGet[virtual] totmem <br>
&lt;linux_nodename&gt; CNodeIdletimeGet idletime <br>
&lt;linux_nodename&gt; CNodeLoadAveGet loadave <br>
&lt;linux_nodename&gt; CNodeMemAvailGet[virtual]
availmem</p>

<p style="margin-top: 1em">&lt;solaris5_nodename&gt;
CNodeIdletimeGet idletime <br>
&lt;solaris5_nodename&gt; CNodeLoadAveGet loadave <br>
&lt;solaris5_nodename&gt; CNodeNumCpusGet ncpus <br>
&lt;solaris5_nodename&gt; CNodeMemTotalGet[real] physmem</p>

<p style="margin-top: 1em">&lt;aix4_nodename&gt;
CNodeIdletimeGet idletime <br>
&lt;aix4_nodename&gt; CNodeLoadAveGet loadave <br>
&lt;aix4_nodename&gt; CNodeMemTotalGet[virtual] totmem <br>
&lt;aix4_nodename&gt; CNodeMemAvailGet[virtual] availmem</p>

<p style="margin-top: 1em">&lt;unicos8_nodename&gt;
CNodeIdletimeGet idletime <br>
&lt;unicos8_nodename&gt; CNodeLoadAveGet loadave <br>
&lt;unicos8_nodename&gt; CNodeNumCpusGet ncpus <br>
&lt;unicos8_nodename&gt; CNodeMemTotalGet[real] physme <br>
&lt;unicos8_nodename&gt; CNodeMemAvailGet[virtual] availmem
<br>
&lt;unicos8_nodename&gt; CNodeSwapSpaceTotalGet[primary]
swaptotal <br>
&lt;unicos8_nodename&gt; CNodeSwapSpaceAvailGet[primary]
swapavail <br>
&lt;unicos8_nodename&gt; CNodeSwapInBwGet[primary]
swapinrate <br>
&lt;unicos8_nodename&gt; CNodeSwapOutBwGet[primary]
swapoutrate <br>
&lt;unicos8_nodename&gt; CNodePercentIdleGet cpuidle <br>
&lt;unicos8_nodename&gt; CNodePercentSysGet cpuunix <br>
&lt;unicos8_nodename&gt; CNodePercentGuestGet cpuguest <br>
&lt;unicos8_nodename&gt; CNodePercentUsrGet cpuuser <br>
&lt;unicos8_nodename&gt; CNodeSrfsSpaceAvailGet[$FASTDIR]
quota[type <br>
=ares_avail, <br>
dir=$FASTDIR]</p>

<p style="margin-top: 1em">&lt;unicos8_nodename&gt;
CNodeSrfsSpaceAvailGet[$BIGDIR] quota[type <br>
=ares_avail, <br>
dir=$BIGDIR]</p>

<p style="margin-top: 1em">&lt;unicos8_nodename&gt;
CNodeSrfsSpaceAvailGet[$WRKDIR] quota[type <br>
=ares_avail, <br>
dir=$WRKDIR]</p>

<p style="margin-top: 1em">&lt;sp2_nodename&gt;
CNodeLoadAveGet loadave</p>

<p style="margin-top: 1em">Suppose you have an execution
host that is of irix5 os type, then the
&lt;irix5_node_name&gt; entries will be consulted by the
scheduler. The initial scheduling cycle would <br>
involve sending the STATIC queries ncpus, physmem, totmem to
the execution host&rsquo;s MOM, and access to return values
of the queries is done via CNodeNumCpusGet(node),
CNode&acirc; <br>
MemTotalGet(node, &quot;real&quot;), CNodeMemTotalGet(node,
&quot;virtual&quot;) respectively, where node is the CNode
representation of the execution host. The subsequent
scheduling cycles <br>
will only send DYNAMIC queries idletime, loadave, and
availmem, and access to the return values of the queries is
done via CNodeIdleTimeGet(node), CNodeLoadAveGet(node), <br>
CNodeMemAvailGet(node, &quot;virtual&quot;).
respectively.</p>

<p style="margin-top: 1em">&quot;Later&quot; entries in the
config file take precedence.</p>

<p style="margin-top: 1em">The configuration file must be
&quot;secure&quot;. It must be owned by a user id and group
id less than 10 and not be world writable.</p>

<p style="margin-top: 1em">On receipt of a SIGHUP signal,
the scheduler will close and reopen its log file and reread
its configuration file (if any).</p>

<p style="margin-top: 1em">FILES <br>
$PBS_SERVER_HOME/sched_priv <br>
the default directory for configuration files, typically
(/usr/spool/pbs)/sched_priv.</p>

<p style="margin-top: 1em">Signal Handling <br>
A C based scheduler will handle the following signals:</p>

<p style="margin-top: 1em">SIGHUP The server will close and
reopen its log file and reread the config file if one
exists.</p>

<p style="margin-top: 1em">SIGALRM <br>
If the site supplied scheduling module exceeds the time
limit, the Alarm will cause the scheduler to attempt to core
dump and restart itself.</p>

<p style="margin-top: 1em">SIGINT and SIGTERM <br>
Will result in an orderly shutdown of the scheduler.</p>

<p style="margin-top: 1em">All other signals have the
default action installed.</p>

<p style="margin-top: 1em">EXIT STATUS <br>
Upon normal termination, an exit status of zero is
returned.</p>

<p style="margin-top: 1em">SEE ALSO <br>
basl2c(1B), pbs_sched_tcl(8B), pbs_server(8B), and
pbs_mom(8B). <br>
PBS Internal Design Specification</p>

<p style="margin-top: 1em">Local pbs_scheduler_basl(8B)</p>
<hr>
</body>
</html>
