<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 19:16:16 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>SSM(8) System Storage Manager SSM(8)</p>

<p style="margin-top: 1em">NAME <br>
ssm - System Storage Manager: a single tool to manage your
storage</p>

<p style="margin-top: 1em">SYNOPSIS <br>
ssm [-h] [--version] [-v] [-f] [-b BACKEND] [-n]
{check,resize,create,list,add,remove,snapshot,mount} ...</p>

<p style="margin-top: 1em">ssm create [-h] [-s SIZE] [-n
NAME] [--fstype FSTYPE] [-r LEVEL] [-I STRIPESIZE] [-i
STRIPES] [-p POOL] [-e [{luks,plain}]] [-o MNT_OPTIONS] [-v
VIRTUAL_SIZE] [device [device <br>
...]] [mount]</p>

<p style="margin-top: 1em">ssm list [-h]
[{volumes,vol,dev,devices,pool,pools,fs,filesystems,snap,snapshots}]</p>

<p style="margin-top: 1em">ssm remove [-h] [-a] [items
[items ...]]</p>

<p style="margin-top: 1em">ssm resize [-h] [-s SIZE] volume
[device [device ...]]</p>

<p style="margin-top: 1em">ssm check [-h] device [device
...]</p>

<p style="margin-top: 1em">ssm snapshot [-h] [-s SIZE] [-d
DEST | -n NAME] volume</p>

<p style="margin-top: 1em">ssm add [-h] [-p POOL] device
[device ...]</p>

<p style="margin-top: 1em">ssm mount [-h] [-o OPTIONS]
volume directory</p>

<p style="margin-top: 1em">DESCRIPTION <br>
System Storage Manager provides an easy to use command line
interface to manage your storage using various technologies
like lvm, btrfs, encrypted volumes and more.</p>

<p style="margin-top: 1em">In more sophisticated enterprise
storage environments, management with Device Mapper (dm),
Logical Volume Manager (LVM), or Multiple Devices (md) is
becoming increasingly more <br>
difficult. With file systems added to the mix, the number of
tools needed to configure and manage storage has grown so
large that it is simply not user friendly. With so many <br>
options for a system administrator to consider, the
opportunity for errors and problems is large.</p>

<p style="margin-top: 1em">The btrfs administration tools
have shown us that storage management can be simplified, and
we are working to bring that ease of use to Linux
filesystems in general.</p>

<p style="margin-top: 1em">OPTIONS <br>
-h, --help <br>
show this help message and exit</p>

<p style="margin-top: 1em">--version <br>
show program&rsquo;s version number and exit</p>

<p style="margin-top: 1em">-v, --verbose <br>
Show aditional information while executing.</p>

<p style="margin-top: 1em">-f, --force <br>
Force execution in the case where ssm has some doubts or
questions.</p>

<p style="margin-top: 1em">-b BACKEND, --backend BACKEND
<br>
Choose backend to use. Currently you can choose from
(lvm,btrfs,crypt).</p>

<p style="margin-top: 1em">-n, --dry-run <br>
Dry run. Do not do anything, just parse the command line
options and gather system information if necessary. Note
that with this option ssm will not perform all the check
<br>
as some of them are done by the backends themselves. This
option is mainly used for debugging purposes, but still
requires root privileges.</p>

<p style="margin-top: 1em">SYSTEM STORAGE MANAGER COMMANDS
<br>
Introduction <br>
System Storage Manager has several commands that you can
specify on the command line as a first argument to ssm. They
all have a specific use and their own arguments, but global
<br>
ssm arguments are propagated to all commands.</p>

<p style="margin-top: 1em">Create command <br>
ssm create [-h] [-s SIZE] [-n NAME] [--fstype FSTYPE] [-r
LEVEL] [-I STRIPESIZE] [-i STRIPES] [-p POOL] [-e
[{luks,plain}]] [-o MNT_OPTIONS] [-v VIRTUAL_SIZE] [device
[device <br>
...]] [mount]</p>

<p style="margin-top: 1em">This command creates a new
volume with defined parameters. If a device is provided it
will be used to create the volume, hence it will be added
into the pool prior to volume cre&acirc; <br>
ation (See Add command section). More than one device can be
used to create a volume.</p>

<p style="margin-top: 1em">If the device is already being
used in a different pool, then ssm will ask you whether you
want to remove it from the original pool. If you decline, or
the removal fails, then <br>
the volume creation fails if the SIZE was not provided. On
the other hand, if the SIZE is provided and some devices can
not be added to the pool, the volume creation might still
<br>
succeed if there is enough space in the pool.</p>

<p style="margin-top: 1em">In addition to specifying size
of the volume directly, percentage can be specified as well.
Specify --size 70% to indicate the volume size to be 70% of
total pool size. Addition&acirc; <br>
ally, percentage of the used, or free pool space can be
specified as well using keywords FREE, or USED
respectively.</p>

<p style="margin-top: 1em">The POOL name can be specified
as well. If the pool exists, a new volume will be created
from that pool (optionally adding device into the pool).
However if the POOL does not <br>
exist, then ssm will attempt to create a new pool with the
provided device, and then create a new volume from this
pool. If the --backend argument is omitted, the default ssm
<br>
backend will be used. The default backend is lvm.</p>

<p style="margin-top: 1em">ssm also supports creating a
RAID configuration, however some back-ends might not support
all RAID levels, or may not even support RAID at all. In
this case, volume creation will <br>
fail.</p>

<p style="margin-top: 1em">If a mount point is provided,
ssm will attempt to mount the volume after it is created.
However it will fail if mountable file system is not present
on the volume.</p>

<p style="margin-top: 1em">If the backend allows it
(currently only supported with lvm backend), ssm can be used
to create thinly provisioned volumes by specifying
--virtual-size option. This will automat&acirc; <br>
ically create a thin pool of a given size provided with
--size option and thin volume of a given size provided with
--virtual-size option and name provided with --name option.
<br>
Virtual size can be much bigger than available space in the
pool.</p>

<p style="margin-top: 1em">-h, --help <br>
show this help message and exit</p>

<p style="margin-top: 1em">-s SIZE, --size SIZE <br>
Gives the size to allocate for the new logical volume. A
size suffix K|k, M|m, G|g, T|t, P|p, E|e can be used to
define &rsquo;power of two&rsquo; units. If no unit is
provided, it <br>
defaults to kilobytes. This is optional and if not given,
maximum possible size will be used. Additionally the new
size can be specified as a percentage of the total pool <br>
size (50%), as a percentage of free pool space (50%FREE), or
as a percentage of used pool space (50%USED).</p>

<p style="margin-top: 1em">-n NAME, --name NAME <br>
The name for the new logical volume. This is optional and if
omitted, name will be generated by the corresponding
backend.</p>

<p style="margin-top: 1em">--fstype FSTYPE <br>
Gives the file system type to create on the new logical
volume. Supported file systems are (ext3, ext4, xfs, btrfs).
This is optional and if not given file system will not <br>
be created.</p>

<p style="margin-top: 1em">-r LEVEL, --raid LEVEL <br>
Specify a RAID level you want to use when creating a new
volume. Note that some backends might not implement all
supported RAID levels. This is optional and if no
speci&acirc; <br>
fied, linear volume will be created. You can choose from the
following list of supported levels (0,1,10).</p>

<p style="margin-top: 1em">-I STRIPESIZE, --stripesize
STRIPESIZE <br>
Gives the number of kilobytes for the granularity of
stripes. This is optional and if not given, backend default
will be used. Note that you have to specify RAID level as
<br>
well.</p>

<p style="margin-top: 1em">-i STRIPES, --stripes STRIPES
<br>
Gives the number of stripes. This is equal to the number of
physical volumes to scatter the logical volume. This is
optional and if stripesize is set and multiple devices <br>
are provided stripes is determined automatically from the
number of devices. Note that you have to specify RAID level
as well.</p>

<p style="margin-top: 1em">-p POOL, --pool POOL <br>
Pool to use to create the new volume.</p>

<p style="margin-top: 1em">-e [{luks,plain}], --encrypt
[{luks,plain}] <br>
Create encrpted volume. Extension to use can be
specified.</p>

<p style="margin-top: 1em">-o MNT_OPTIONS, --mnt-options
MNT_OPTIONS <br>
Mount options are specified with a -o flag followed by a
comma separated string of options. This option is equivalent
to the -o mount(8) option.</p>

<p style="margin-top: 1em">-v VIRTUAL_SIZE, --virtual-size
VIRTUAL_SIZE <br>
Gives the virtual size for the new thinly provisioned
volume. A size suffix K|k, M|m, G|g, T|t, P|p, E|e can be
used to define &rsquo;power of two&rsquo; units. If no unit
is pro&acirc; <br>
vided, it defaults to kilobytes.</p>

<p style="margin-top: 1em">List command <br>
ssm list [-h]
[{volumes,vol,dev,devices,pool,pools,fs,filesystems,snap,snapshots}]</p>

<p style="margin-top: 1em">Lists information about all
detected devices, pools, volumes and snapshots found on the
system. The list command can be used either alone to list
all of the information, or you <br>
can request specific sections only.</p>

<p style="margin-top: 1em">The following sections can be
specified:</p>

<p style="margin-top: 1em">{volumes | vol} <br>
List information about all volumes found in the system.</p>

<p style="margin-top: 1em">{devices | dev} <br>
List information about all devices found on the system. Some
devices are intentionally hidden, like for example cdrom or
DM/MD devices since those are actually listed as <br>
volumes.</p>

<p style="margin-top: 1em">{pools | pool} <br>
List information about all pools found in the system.</p>

<p style="margin-top: 1em">{filesystems | fs} <br>
List information about all volumes containing filesystems
found in the system.</p>

<p style="margin-top: 1em">{snapshots | snap} <br>
List information about all snapshots found in the system.
Note that some back-ends do not support snapshotting and
some cannot distinguish snapshot from regular volumes. <br>
In this case, ssm will try to recognize the volume name in
order to identify a snapshot, but if the ssm regular
expression does not match the snapshot pattern, the
prob&acirc; <br>
lematic snapshot will not be recognized.</p>

<p style="margin-top: 1em">-h, --help <br>
show this help message and exit</p>

<p style="margin-top: 1em">Remove command <br>
ssm remove [-h] [-a] [items [items ...]]</p>

<p style="margin-top: 1em">This command removes an item
from the system. Multiple items can be specified. If the
item cannot be removed for some reason, it will be
skipped.</p>

<p style="margin-top: 1em">An item can be any of the
following:</p>

<p style="margin-top: 1em">device Remove a device from the
pool. Note that this cannot be done in some cases where the
device is being used by the pool. You can use the -f
argument to force removal. If the <br>
device does not belong to any pool, it will be skipped.</p>

<p style="margin-top: 1em">pool Remove a pool from the
system. This will also remove all volumes created from that
pool.</p>

<p style="margin-top: 1em">volume Remove a volume from the
system. Note that this will fail if the volume is mounted
and cannot be forced with -f.</p>

<p style="margin-top: 1em">-h, --help <br>
show this help message and exit</p>

<p style="margin-top: 1em">-a, --all <br>
Remove all pools in the system.</p>

<p style="margin-top: 1em">Resize command <br>
ssm resize [-h] [-s SIZE] volume [device [device ...]]</p>

<p style="margin-top: 1em">Change size of the volume and
file system. If there is no file system, only the volume
itself will be resized. You can specify a device to add into
the volume pool prior the <br>
resize. Note that the device will only be added into the
pool if the volume size is going to grow.</p>

<p style="margin-top: 1em">If the device is already used in
a different pool, then ssm will ask you whether or not you
want to remove it from the original pool.</p>

<p style="margin-top: 1em">In some cases, the file system
has to be mounted in order to resize. This will be handled
by ssm automatically by mounting the volume temporarily.</p>

<p style="margin-top: 1em">In addition to specifying new
size of the volume directly, percentage can be specified as
well. Specify --size 70% to resize the volume to 70% of
it&rsquo;s original size. Addition&acirc; <br>
ally, percentage of the used, or free pool space can be
specified as well using keywords FREE, or USED
respectively.</p>

<p style="margin-top: 1em">Note that resizing btrfs
subvolume is not supported, only the whole file system can
be resized.</p>

<p style="margin-top: 1em">-h, --help <br>
show this help message and exit</p>

<p style="margin-top: 1em">-s SIZE, --size SIZE <br>
New size of the volume. With the + or - sign the value is
added to or subtracted from the actual size of the volume
and without it, the value will be set as the new volume <br>
size. A size suffix of [k|K] for kilobytes, [m|M] for
megabytes, [g|G] for gigabytes, [t|T] for terabytes or [p|P]
for petabytes is optional. If no unit is provided the <br>
default is kilobytes. Additionally the new size can be
specified as a percentage of the original volume size
([+][-]50%), as a percentage of free pool space <br>
([+][-]50%FREE), or as a percentage of used pool space
([+][-]50%USED).</p>

<p style="margin-top: 1em">Check command <br>
ssm check [-h] device [device ...]</p>

<p style="margin-top: 1em">Check the file system
consistency on the volume. You can specify multiple volumes
to check. If there is no file system on the volume, this
volume will be skipped.</p>

<p style="margin-top: 1em">In some cases the file system
has to be mounted in order to check the file system. This
will be handled by ssm automatically by mounting the volume
temporarily.</p>

<p style="margin-top: 1em">-h, --help <br>
show this help message and exit</p>

<p style="margin-top: 1em">Snapshot command <br>
ssm snapshot [-h] [-s SIZE] [-d DEST | -n NAME] volume</p>

<p style="margin-top: 1em">Take a snapshot of an existing
volume. This operation will fail if the back-end to which
the volume belongs to does not support snapshotting. Note
that you cannot specify both <br>
NAME and DEST since those options are mutually
exclusive.</p>

<p style="margin-top: 1em">In addition to specifying new
size of the volume directly, percentage can be specified as
well. Specify --size 70% to indicate the new snapshot size
to be 70% of the origin vol&acirc; <br>
ume size. Additionally, percentage of the used, or free pool
space can be specified as well using keywords FREE, or USED
respectively.</p>

<p style="margin-top: 1em">In some cases the file system
has to be mounted in order to take a snapshot of the volume.
This will be handled by ssm automatically by mounting the
volume temporarily.</p>

<p style="margin-top: 1em">-h, --help <br>
show this help message and exit</p>

<p style="margin-top: 1em">-s SIZE, --size SIZE <br>
Gives the size to allocate for the new snapshot volume. A
size suffix K|k, M|m, G|g, T|t, P|p, E|e can be used to
define &rsquo;power of two&rsquo; units. If no unit is
provided, it <br>
defaults to kilobytes. This is optional and if not given,
the size will be determined automatically. Additionally the
new size can be specified as a percentage of the <br>
original volume size (50%), as a percentage of free pool
space (50%FREE), or as a percentage of used pool space
(50%USED).</p>

<p style="margin-top: 1em">-d DEST, --dest DEST <br>
Destination of the snapshot specified with absolute path to
be used for the new snapshot. This is optional and if not
specified default backend policy will be performed.</p>

<p style="margin-top: 1em">-n NAME, --name NAME <br>
Name of the new snapshot. This is optional and if not
specified default backend policy will be performed.</p>

<p style="margin-top: 1em">Add command <br>
ssm add [-h] [-p POOL] device [device ...]</p>

<p style="margin-top: 1em">This command adds a device into
the pool. By default, the device will not be added if
it&rsquo;s already a part of a different pool, but the user
will be asked whether or not to remove <br>
the device from its pool. When multiple devices are
provided, all of them are added into the pool. If one of the
devices cannot be added into the pool for any reason, the
add <br>
command will fail. If no pool is specified, the default pool
will be chosen. In the case of a non existing pool, it will
be created using the provided devices.</p>

<p style="margin-top: 1em">-h, --help <br>
show this help message and exit</p>

<p style="margin-top: 1em">-p POOL, --pool POOL <br>
Pool to add device into. If not specified the default pool
is used.</p>

<p style="margin-top: 1em">Mount command <br>
ssm mount [-h] [-o OPTIONS] volume directory</p>

<p style="margin-top: 1em">This command will mount the
volume at the specified directory. The volume can be
specified in the same way as with mount(8), however in
addition, one can also specify a volume in <br>
the format as it appears in the ssm list table.</p>

<p style="margin-top: 1em">For example, instead of finding
out what the device and subvolume id of the btrfs subvolume
&quot;btrfs_pool:vol001&quot; is in order to mount it, one
can simply call ssm mount <br>
btrfs_pool:vol001 /mnt/test.</p>

<p style="margin-top: 1em">One can also specify OPTIONS in
the same way as with mount(8).</p>

<p style="margin-top: 1em">-h, --help <br>
show this help message and exit</p>

<p style="margin-top: 1em">-o OPTIONS, --options OPTIONS
<br>
Options are specified with a -o flag followed by a comma
separated string of options. This option is equivalent to
the same mount(8) option.</p>

<p style="margin-top: 1em">BACK-ENDS <br>
Introduction <br>
Ssm aims to create a unified user interface for various
technologies like Device Mapper (dm), Btrfs file system,
Multiple Devices (md) and possibly more. In order to do so
we <br>
have a core abstraction layer in ssmlib/main.py. This
abstraction layer should ideally know nothing about the
underlying technology, but rather comply with device, pool
and vol&acirc; <br>
ume abstractions.</p>

<p style="margin-top: 1em">Various backends can be
registered in ssmlib/main.py in order to handle specific
storage technology, implementing methods like create,
snapshot, or remove volumes and pools. The <br>
core will then call these methods to manage the storage
without needing to know what lies underneath it. There are
already several backends registered in ssm.</p>

<p style="margin-top: 1em">Btrfs backend <br>
Btrfs is the file system with many advanced features
including volume management. This is the reason why btrfs is
handled differently than other conventional file systems in
ssm. <br>
It is used as a volume management back-end.</p>

<p style="margin-top: 1em">Pools, volumes and snapshots can
be created with btrfs backend and here is what it means from
the btrfs point of view:</p>

<p style="margin-top: 1em">pool A pool is actually a btrfs
file system itself, because it can be extended by adding
more devices, or shrunk by removing devices from it.
Subvolumes and snapshots can also <br>
be created. When the new btrfs pool should be created, ssm
simply creates a btrfs file system, which means that every
new btrfs pool has one volume of the same name as the <br>
pool itself which can not be removed without removing the
entire pool. The default btrfs pool name is btrfs_pool.</p>

<p style="margin-top: 1em">When creating a new btrfs pool,
the name of the pool is used as the file system label. If
there is an already existing btrfs file system in the system
without a label, a <br>
btrfs pool name will be generated for internal use in the
following format &quot;btrfs_{device base name}&quot;.</p>

<p style="margin-top: 1em">A btrfs pool is created when the
create or add command is used with specified devices and non
existing pool name.</p>

<p style="margin-top: 1em">volume A volume in the btrfs
back-end is actually just btrfs subvolume with the exception
of the first volume created on btrfs pool creation, which is
the file system itself. <br>
Subvolumes can only be created on the btrfs file system when
it is mounted, but the user does not have to worry about
that since ssm will automatically mount the file sys&acirc;
<br>
tem temporarily in order to create a new subvolume.</p>

<p style="margin-top: 1em">The volume name is used as
subvolume path in the btrfs file system and every object in
this path must exist in order to create a volume. The volume
name for internal <br>
tracking and that is visible to the user is generated in the
format &quot;{pool_name}:{volume name}&quot;, but volumes
can be also referenced by its mount point.</p>

<p style="margin-top: 1em">The btrfs volumes are only shown
in the list output, when the file system is mounted, with
the exception of the main btrfs volume - the file system
itself.</p>

<p style="margin-top: 1em">Also note that btrfs volumes and
subvolumes cannot be resized. This is mainly limitation of
the btrfs tools which currently do not work reliably.</p>

<p style="margin-top: 1em">A new btrfs volume can be
created with the create command.</p>

<p style="margin-top: 1em">snapshot <br>
The btrfs file system supports subvolume snapshotting, so
you can take a snapshot of any btrfs volume in the system
with ssm. However btrfs does not distinguish between <br>
subvolumes and snapshots, because a snapshot is actually
just a subvolume with some blocks shared with a different
subvolume. This means, that ssm is not able to directly <br>
recognize a btrfs snapshot. Instead, ssm will try to
recognize a special name format of the btrfs volume that
denotes it is a snapshot. However, if the NAME is specified
<br>
when creating snapshot which does not match the special
pattern, snapshot will not be recognized by the ssm and it
will be listed as regular btrfs volume.</p>

<p style="margin-top: 1em">A new btrfs snapshot can be
created with the snapshot command.</p>

<p style="margin-top: 1em">device Btrfs does not require a
special device to be created on.</p>

<p style="margin-top: 1em">Lvm backend <br>
Pools, volumes and snapshots can be created with lvm, which
pretty much match the lvm abstraction.</p>

<p style="margin-top: 1em">pool An lvm pool is just a
volume group in lvm language. It means that it is grouping
devices and new logical volumes can be created out of the
lvm pool. The default lvm pool <br>
name is lvm_pool.</p>

<p style="margin-top: 1em">An lvm pool is created when the
create or add commands are used with specified devices and a
non existing pool name.</p>

<p style="margin-top: 1em">Alternatively a thin pool can be
created as a result of using --virtual-size option to create
thin volume.</p>

<p style="margin-top: 1em">volume An lvm volume is just a
logical volume in lvm language. An lvm volume can be created
with the create command.</p>

<p style="margin-top: 1em">snapshot <br>
Lvm volumes can be snapshotted as well. When a snapshot is
created from the lvm volume, a new snapshot volume is
created, which can be handled as any other lvm volume. <br>
Unlike btrfs lvm is able to distinguish snapshot from
regular volume, so there is no need for a snapshot name to
match special pattern.</p>

<p style="margin-top: 1em">device Lvm requires a physical
device to be created on the device, but with ssm this is
transparent for the user.</p>

<p style="margin-top: 1em">Crypt backend <br>
The crypt backend in ssm uses cryptsetup and dm-crypt target
to manage encrypted volumes. The crypt backend can be used
as a regular backend for creating encrypted volumes on top
<br>
of regular block devices, or even other volumes (lvm or md
volumes for example). Or it can be used to create encrypted
lvm volumes right away in a single step.</p>

<p style="margin-top: 1em">Only volumes can be created with
crypt backend. This backend does not support pooling and
does not require special devices.</p>

<p style="margin-top: 1em">pool The crypt backend does not
support pooling, and it is not possible to create crypt pool
or add a device into a pool.</p>

<p style="margin-top: 1em">volume A volume in the crypt
backend is the volume created by dm-crypt which represents
the data on the original encrypted device in unencrypted
form. The crypt backend does not <br>
support pooling, so only one device can be used to create
crypt volume. It also does not support raid or any device
concatenation.</p>

<p style="margin-top: 1em">Currently two modes, or
extensions are supported: luks and plain. Luks is used by
default. For more information about the extensions, please
see cryptsetup manual page.</p>

<p style="margin-top: 1em">snapshot <br>
The crypt backend does not support snapshotting, however if
the encrypted volume is created on top of an lvm volume, the
lvm volume itself can be snapshotted. The snapshot <br>
can be then opened by using cryptsetup. It is possible that
this might change in the future so that ssm will be able to
activate the volume directly without the extra <br>
step.</p>

<p style="margin-top: 1em">device The crypt backend does
not require a special device to be created on.</p>

<p style="margin-top: 1em">MD backend <br>
MD backend in ssm is currently limited to only gather the
information about MD volumes in the system. You can not
create or manage MD volumes or pools, but this functionality
<br>
will be extended in the future.</p>

<p style="margin-top: 1em">EXAMPLES <br>
List system storage information:</p>

<p style="margin-top: 1em"># ssm list</p>

<p style="margin-top: 1em">List all pools in the
system:</p>

<p style="margin-top: 1em"># ssm list pools</p>

<p style="margin-top: 1em">Create a new 100GB volume with
the default lvm backend using /dev/sda and /dev/sdb with xfs
file system:</p>

<p style="margin-top: 1em"># ssm create --size 100G --fs
xfs /dev/sda /dev/sdb</p>

<p style="margin-top: 1em">Create a new volume with a btrfs
backend using /dev/sda and /dev/sdb and let the volume to be
RAID 1:</p>

<p style="margin-top: 1em"># ssm -b btrfs create --raid 1
/dev/sda /dev/sdb</p>

<p style="margin-top: 1em">Using the lvm backend create a
RAID 0 volume with devices /dev/sda and /dev/sdb with 128kB
stripe size, ext4 file system and mount it on /home:</p>

<p style="margin-top: 1em"># ssm create --raid 0
--stripesize 128k /dev/sda /dev/sdb /home</p>

<p style="margin-top: 1em">Create a new thinly provisioned
volume with a lvm backend using devices /dev/sda and
/dev/sdb using --virtual-size option:</p>

<p style="margin-top: 1em"># ssm create --virtual-size 1T
/dev/sda /dev/sdb</p>

<p style="margin-top: 1em">Create a new thinly provisioned
volume with a defined thin pool size and devices /dev/sda
and /dev/sdb:</p>

<p style="margin-top: 1em"># ssm create --size 50G
--virtual-size 1T /dev/sda /dev/sdb</p>

<p style="margin-top: 1em">Extend btrfs volume btrfs_pool
by 500GB and use /dev/sdc and /dev/sde to cover the
resize:</p>

<p style="margin-top: 1em"># ssm resize -s +500G btrfs_pool
/dev/sdc /dev/sde</p>

<p style="margin-top: 1em">Shrink volume
/dev/lvm_pool/lvol001 by 1TB:</p>

<p style="margin-top: 1em"># ssm resize -s-1t
/dev/lvm_pool/lvol001</p>

<p style="margin-top: 1em">Remove /dev/sda device from the
pool, remove the btrfs_pool pool and also remove the volume
/dev/lvm_pool/lvol001:</p>

<p style="margin-top: 1em"># ssm remove /dev/sda btrfs_pool
/dev/lvm_pool/lvol001</p>

<p style="margin-top: 1em">Take a snapshot of the btrfs
volume btrfs_pool:my_volume:</p>

<p style="margin-top: 1em"># ssm snapshot
btrfs_pool:my_volume</p>

<p style="margin-top: 1em">Add devices /dev/sda and
/dev/sdb into the btrfs_pool pool:</p>

<p style="margin-top: 1em"># ssm add -p btrfs_pool /dev/sda
/dev/sdb</p>

<p style="margin-top: 1em">Mount btrfs subvolume
btrfs_pool:vol001 on /mnt/test:</p>

<p style="margin-top: 1em"># ssm mount btrfs_pool:vol001
/mnt/test</p>

<p style="margin-top: 1em">ENVIRONMENT VARIABLES <br>
SSM_DEFAULT_BACKEND <br>
Specify which backend will be used by default. This can be
overridden by specifying the -b or --backend argument.
Currently only lvm and btrfs are supported.</p>

<p style="margin-top: 1em">SSM_LVM_DEFAULT_POOL <br>
Name of the default lvm pool to be used if the -p or --pool
argument is omitted.</p>

<p style="margin-top: 1em">SSM_BTRFS_DEFAULT_POOL <br>
Name of the default btrfs pool to be used if the -p or
--pool argument is omitted.</p>

<p style="margin-top: 1em">SSM_PREFIX_FILTER <br>
When this is set, ssm will filter out all devices, volumes
and pools whose name does not start with this prefix. It is
used mainly in the ssm test suite to make sure that <br>
we do not scramble the local system configuration.</p>

<p style="margin-top: 1em">LICENCE <br>
(C)2011 Red Hat, Inc., Lukas Czerner
&lt;lczerner@redhat.com&gt;</p>

<p style="margin-top: 1em">This program is free software:
you can redistribute it and/or modify it under the terms of
the GNU General Public License as published by the Free
Software Foundation, either <br>
version 2 of the License, or (at your option) any later
version.</p>

<p style="margin-top: 1em">This program is distributed in
the hope that it will be useful, but WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PUR&acirc; <br>
POSE. See the GNU General Public License for more
details.</p>

<p style="margin-top: 1em">You should have received a copy
of the GNU General Public License along with this program.
If not, see &lt;http://www.gnu.org/licenses/&gt;.</p>

<p style="margin-top: 1em">REQUIREMENTS <br>
Python 2.6 or higher is required to run this tool. System
Storage Manager can only be run as root since most of the
commands require root privileges.</p>

<p style="margin-top: 1em">There are other requirements
listed below, but note that you do not necessarily need all
dependencies for all backends. However if some of the tools
required by a backend are <br>
missing, that backend will not work.</p>

<p style="margin-top: 1em">Python modules <br>
&Acirc;&middot; os</p>

<p style="margin-top: 1em">&Acirc;&middot; re</p>

<p style="margin-top: 1em">&Acirc;&middot; sys</p>

<p style="margin-top: 1em">&Acirc;&middot; stat</p>

<p style="margin-top: 1em">&Acirc;&middot; argparse</p>

<p style="margin-top: 1em">&Acirc;&middot; datetime</p>

<p style="margin-top: 1em">&Acirc;&middot; threading</p>

<p style="margin-top: 1em">&Acirc;&middot; subprocess</p>

<p style="margin-top: 1em">System tools <br>
&Acirc;&middot; tune2fs</p>

<p style="margin-top: 1em">&Acirc;&middot;
fsck.SUPPORTED_FS</p>

<p style="margin-top: 1em">&Acirc;&middot; resize2fs</p>

<p style="margin-top: 1em">&Acirc;&middot; xfs_db</p>

<p style="margin-top: 1em">&Acirc;&middot; xfs_check</p>

<p style="margin-top: 1em">&Acirc;&middot; xfs_growfs</p>

<p style="margin-top: 1em">&Acirc;&middot;
mkfs.SUPPORTED_FS</p>

<p style="margin-top: 1em">&Acirc;&middot; which</p>

<p style="margin-top: 1em">&Acirc;&middot; mount</p>

<p style="margin-top: 1em">&Acirc;&middot; blkid</p>

<p style="margin-top: 1em">&Acirc;&middot; wipefs</p>

<p style="margin-top: 1em">Lvm backend <br>
&Acirc;&middot; lvm2 binaries</p>

<p style="margin-top: 1em">Btrfs backend <br>
&Acirc;&middot; btrfs progs</p>

<p style="margin-top: 1em">Crypt backend <br>
&Acirc;&middot; dmsetup</p>

<p style="margin-top: 1em">&Acirc;&middot; cryptsetup</p>

<p style="margin-top: 1em">AVAILABILITY <br>
System storage manager is available from
http://storagemanager.sourceforge.net. You can subscribe to
storagemanager-devel@lists.sourceforge.net to follow the
current development.</p>

<p style="margin-top: 1em">AUTHOR <br>
Luk&Atilde;&Acirc;&iexcl;&Atilde;&Acirc;&iexcl; Czerner
&lt;lczerner@redhat.com&gt;</p>

<p style="margin-top: 1em">COPYRIGHT <br>
2015, Red Hat, Inc.,
Luk&Atilde;&Acirc;&iexcl;&Atilde;&Acirc;&iexcl; Czerner
&lt;lczerner@redhat.com&gt;</p>

<p style="margin-top: 1em">0.4 July 01, 2016 SSM(8)</p>
<hr>
</body>
</html>
