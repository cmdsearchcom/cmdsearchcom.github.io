<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 16:02:42 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>DBMAPREDUCE(1) User Contributed Perl Documentation
DBMAPREDUCE(1)</p>

<p style="margin-top: 1em">NAME <br>
dbmapreduce - reduce all input rows with the same key</p>

<p style="margin-top: 1em">SYNOPSIS <br>
dbmapreduce [-dMS] [-k KeyField] [-f CodeFile] [-C
Filtercode] [--] [ReduceCommand [ReduceArguments...]]</p>

<p style="margin-top: 1em">DESCRIPTION <br>
Group input data by KeyField, then apply a function (the
&quot;reducer&quot;) to each group. The reduce function can
be an external program given by ReduceCommand and
ReduceArguments, or <br>
an Perl subroutine given in CodeFile or FilterCode.</p>

<p style="margin-top: 1em">If a &quot;--&quot; appears
before reduce command, arguments after the -- passed the the
command.</p>

<p style="margin-top: 1em">Grouping (The Mapper) <br>
By default the KeyField is the first field in the row.
Unlike Hadoop streaming, the -k KeyField option can
explicitly name where the key is in any column of each input
row.</p>

<p style="margin-top: 1em">By default, we sort the data to
make sure data is grouped by key. If the input is already
grouped, the &quot;-S&quot; option avoids this cost.</p>

<p style="margin-top: 1em">The Reducer <br>
Reduce functions default to be shell commands. However, with
&quot;-C&quot;, one can use arbitrary Perl code</p>

<p style="margin-top: 1em">(see the &quot;-C&quot; option
below for details). the &quot;-f&quot; option is useful to
specify complex Perl code somewhere other than the command
line.</p>

<p style="margin-top: 1em">Finally, as a special case, if
there are no rows of input, the reducer will be invoked once
with the empty value (if it&rsquo;s an external reducer) or
with undef (if it&rsquo;s a <br>
subroutine). It is expected to generate the output header,
and it may generate no data rows itself, or a null data row
of its choosing.</p>

<p style="margin-top: 1em">Output <br>
For non-multi-key-aware reducers, we add the KeyField use
for each Reduce is in the output stream. (If the reducer
passes the key we trust that it gives a correct value.) We
<br>
also insure that the output field separator is the same as
the input field separator.</p>

<p style="margin-top: 1em">Adding the key and adjusting the
output field separator is not possible for
non-multi-key-aware reducers.</p>

<p style="margin-top: 1em">Comparison to Related Work <br>
This program thus implements Google-style map/reduce, but
executed sequentially.</p>

<p style="margin-top: 1em">For input, these systems include
a map function and apply it to input data to generate the
key. We assume this key generation (the map function) has
occurred head of time.</p>

<p style="margin-top: 1em">We also allow the grouping key
to be in any column. Hadoop Streaming requires it to be in
the first column.</p>

<p style="margin-top: 1em">By default, the reducer gets
exactly (and only) one key. This invariant is stronger than
Google and Hadoop. They both pass multiple keys to the
reducer, insuring that each key <br>
is grouped together. With the &quot;-M&quot; option, we also
pass multiple multiple groups to the reducer.</p>

<p style="margin-top: 1em">Unlike those systems, with the
&quot;-S&quot; option we do not require the groups arrive in
any particular order, just that they be grouped together.
(They guarantees they arrive in <br>
lexically sorted order). However, with &quot;-S&quot; we
create lexical ordering.</p>

<p style="margin-top: 1em">With &quot;--prepend-key&quot;
we insure that the KeyField is in the output stream; other
systems do not enforce this.</p>

<p style="margin-top: 1em">Assumptions and requirements
<br>
By default, data can be provided in arbitrary order and the
program consumes O(number of unique tags) memory, and O(size
of data) disk space.</p>

<p style="margin-top: 1em">With the &quot;-S&quot; option,
data must arrive group by tags (not necessarily sorted), and
the program consumes O(number of tags) memory and no disk
space. The program will check and <br>
abort if this precondition is not met.</p>

<p style="margin-top: 1em">With two &quot;-S&quot;&rsquo;s,
program consumes O(1) memory, but doesn&rsquo;t verify that
the data-arrival precondition is met.</p>

<p style="margin-top: 1em">The field separators of the
input and the output can now be different (early versions of
this tool prohibited such variation.) With
&quot;--copy-fs&quot; we copy the input field separator <br>
to the output, but only for non-multi-key-aware reducers.
(this used to be done automatically).</p>

<p style="margin-top: 1em">Known bugs <br>
As of 2013-09-21, we don&rsquo;t verify key order with
options &quot;-M -S&quot;.</p>

<p style="margin-top: 1em">OPTIONS <br>
-k or --key KeyField <br>
specify which column is the key for grouping (default: the
first column)</p>

<p style="margin-top: 1em">-S or --pre-sorted <br>
Assume data is already grouped by tag. Provided twice, it
removes the validation of this assertion.</p>

<p style="margin-top: 1em">-M or --multiple-ok <br>
Assume the ReduceCommand can handle multiple grouped keys,
and the ReduceCommand is responsible for outputting the with
each output row. (By default, a separate <br>
ReduceCommand is run for each key, and dbmapreduce adds the
key to each output row.)</p>

<p style="margin-top: 1em">-K or --pass-current-key <br>
Pass the current key as an argument to the external,
non-map-aware ReduceCommand. This is only done optionally
since some external commands do not expect an extra
argument. <br>
(Internal, non-map-aware Perl reducers are always given the
current key as an argument.)</p>

<p style="margin-top: 1em">--prepend-key <br>
Add the current key into the reducer output for
non-multi-key-aware reducers only. Not done by default.</p>

<p style="margin-top: 1em">--copy-fs or
--copy-fieldseparator <br>
Change the field separator of a non-multi-key-aware reducers
to match the input&rsquo;s field separator. Not done by
default.</p>

<p style="margin-top: 1em">--parallelism=N or -j N <br>
Allow up to N reducers to run in parallel. Default is the
number of CPUs in the machine.</p>

<p style="margin-top: 1em">-C FILTER-CODE or
--filter-code=FILTER-CODE <br>
Provide FILTER-CODE, Perl code that generates and returns a
Fsdb::Filter object that implements the reduce function. The
provided code should be an anonymous sub that <br>
creates a Fsdb Filter that implements the reduce object.</p>

<p style="margin-top: 1em">The reduce object will then be
called with --input and --output parameters that hook it
into a the reduce with queues.</p>

<p style="margin-top: 1em">One sample fragment that works
is just:</p>

<p style="margin-top: 1em">dbcolstats(qw(--nolog
duration))</p>

<p style="margin-top: 1em">So this command:</p>

<p style="margin-top: 1em">cat DATA/stats.fsdb |
dbmapreduce -k experiment -C &rsquo;dbcolstats(qw(--nolog
duration))&rsquo;</p>

<p style="margin-top: 1em">is the same as the example</p>

<p style="margin-top: 1em">cat DATA/stats.fsdb |
dbmapreduce -k experiment -- dbcolstats duration</p>

<p style="margin-top: 1em">except that with &quot;-C&quot;
there is no forking and so things run faster.</p>

<p style="margin-top: 1em">If &quot;dbmapreduce&quot; is
invoked from within Perl, then one can use a code SUB as
well: <br>
dbmapreduce(-k =&gt; &rsquo;experiment&rsquo;, -C =&gt; sub
{ dbcolstats(qw(--nolong duration)) });</p>

<p style="margin-top: 1em">The reduce object must consume
all input as a Fsdb stream, and close the output Fsdb
stream. (If this assumption is not met the map/reduce will
be aborted.)</p>

<p style="margin-top: 1em">For non-map-reduce-aware
filters, when the filter-generator code runs, $_[0] will be
the current key.</p>

<p style="margin-top: 1em">-f CODE-FILE or
--code-file=CODE-FILE <br>
Includes CODE-FILE in the program. This option is useful for
more complicated perl reducer functions.</p>

<p style="margin-top: 1em">Thus, if reducer.pl has the
code.</p>

<p style="margin-top: 1em">sub make_reducer { <br>
my($current_key) = @_; <br>
dbcolstats(qw(--nolog duration)); <br>
}</p>

<p style="margin-top: 1em">Then the command</p>

<p style="margin-top: 1em">cat DATA/stats.fsdb |
dbmapreduce -k experiment -f reducer.pl -C make_reducer</p>

<p style="margin-top: 1em">does the same thing as the
example.</p>

<p style="margin-top: 1em">-w or --warnings <br>
Enable warnings in user supplied code. Warnings are issued
if an external reducer fails to consume all input. (Default
to include warnings.)</p>

<p style="margin-top: 1em">-T TmpDir <br>
where to put tmp files. Also uses environment variable
TMPDIR, if -T is not specified. Default is /tmp.</p>

<p style="margin-top: 1em">This module also supports the
standard fsdb options:</p>

<p style="margin-top: 1em">-d Enable debugging output.</p>

<p style="margin-top: 1em">-i or --input InputSource <br>
Read from InputSource, typically a file name, or
&quot;-&quot; for standard input, or (if in Perl) a
IO::Handle, Fsdb::IO or Fsdb::BoundedQueue objects.</p>

<p style="margin-top: 1em">-o or --output OutputDestination
<br>
Write to OutputDestination, typically a file name, or
&quot;-&quot; for standard output, or (if in Perl) a
IO::Handle, Fsdb::IO or Fsdb::BoundedQueue objects.</p>

<p style="margin-top: 1em">--autorun or --noautorun <br>
By default, programs process automatically, but Fsdb::Filter
objects in Perl do not run until you invoke the run()
method. The &quot;--(no)autorun&quot; option controls that
behavior <br>
within Perl.</p>

<p style="margin-top: 1em">--header H <br>
Use H as the full Fsdb header, rather than reading a header
from then input.</p>

<p style="margin-top: 1em">--help <br>
Show help.</p>

<p style="margin-top: 1em">--man <br>
Show full manual.</p>

<p style="margin-top: 1em">SAMPLE USAGE <br>
Input: <br>
#fsdb experiment duration <br>
ufs_mab_sys 37.2 <br>
ufs_mab_sys 37.3 <br>
ufs_rcp_real 264.5 <br>
ufs_rcp_real 277.9</p>

<p style="margin-top: 1em">Command: <br>
cat DATA/stats.fsdb | dbmapreduce --prepend-key -k
experiment -- dbcolstats duration</p>

<p style="margin-top: 1em">Output: <br>
#fsdb experiment mean stddev pct_rsd conf_range conf_low
conf_high conf_pct sum sum_squared min max n <br>
ufs_mab_sys 37.25 0.070711 0.18983 0.6353 36.615 37.885 0.95
74.5 2775.1 37.2 37.3 2 <br>
ufs_rcp_real 271.2 9.4752 3.4938 85.13 186.07 356.33 0.95
542.4 1.4719e+05 264.5 277.9 2 <br>
# | dbmapreduce -k experiment dbstats duration</p>

<p style="margin-top: 1em">SEE ALSO <br>
Fsdb. dbmultistats dbrowsplituniq</p>

<p style="margin-top: 1em">AUTHOR and COPYRIGHT <br>
Copyright (C) 1991-2016 by John Heidemann
&lt;johnh@isi.edu&gt;</p>

<p style="margin-top: 1em">This program is distributed
under terms of the GNU general public license, version 2.
See the file COPYING with the distribution for details.</p>

<p style="margin-top: 1em">perl v5.24.1 2017-05-26
DBMAPREDUCE(1)</p>
<hr>
</body>
</html>
