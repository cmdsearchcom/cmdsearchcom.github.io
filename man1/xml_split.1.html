<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 16:44:15 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>XML_SPLIT(1) User Contributed Perl Documentation
XML_SPLIT(1)</p>

<p style="margin-top: 1em">NAME <br>
xml_split - cut a big XML file into smaller chunks</p>

<p style="margin-top: 1em">DESCRIPTION <br>
&quot;xml_split&quot; takes a (presumably big) XML file and
split it in several smaller files. The memory used is the
memory needed for the biggest chunk (ie memory is reused for
each new <br>
chunk).</p>

<p style="margin-top: 1em">It can split at a given level in
the tree (the default, splits children of the root), or on a
condition (using the subset of XPath understood by
XML::Twig, so &quot;section&quot; or <br>
&quot;/doc/section&quot;).</p>

<p style="margin-top: 1em">Each generated file is replaced
by a processing instruction that will allow
&quot;xml_merge&quot; to rebuild the original document. The
processing instruction format is &quot;&lt;?merge <br>
subdocs=[01] :&lt;filename&gt; ?&gt;&quot;</p>

<p style="margin-top: 1em">File names are
&lt;file&gt;-&lt;nb&gt;.xml, with &lt;file&gt;-00.xml
holding the main document.</p>

<p style="margin-top: 1em">OPTIONS <br>
-l &lt;level&gt; <br>
level to cut at: 1 generates a file for each child of the
root, 2 for each grand child</p>

<p style="margin-top: 1em">defaults to 1</p>

<p style="margin-top: 1em">-c &lt;condition&gt; <br>
generate a file for each element that passes the
condition</p>

<p style="margin-top: 1em">xml_split -c &lt;section&gt;
will put each &quot;section&quot; element in its own file
(nested sections are handled too)</p>

<p style="margin-top: 1em">Note that at the moment this
option is a lot slower than using &quot;-l&quot;</p>

<p style="margin-top: 1em">-s &lt;size&gt; <br>
generates files of (approximately) &lt;size&gt;. The content
of each file is enclosed in a new element
(&quot;xml_split::root&quot;), so it&rsquo;s well-formed
XML. The size can be given in <br>
bytes, Kb, Mb or Gb.</p>

<p style="margin-top: 1em">-g &lt;nb&gt; <br>
groups &lt;nb&gt; elements in a single file. The content of
each file is enclosed in a new element
(&quot;xml_split::root&quot;), so it&rsquo;s well-formed
XML.</p>

<p style="margin-top: 1em">-b &lt;name&gt; <br>
base name for the output, files will be named
&lt;base&gt;-&lt;nb&gt;&lt;.ext&gt;</p>

<p style="margin-top: 1em">&lt;nb&gt; is a sequence number,
see below &quot;--nb_digits&quot; &lt;ext&gt; is an
extension, see below &quot;--extension&quot;</p>

<p style="margin-top: 1em">defaults to the original file
name (if available) or &quot;out&quot; (if input comes from
the standard input)</p>

<p style="margin-top: 1em">-n &lt;nb&gt; <br>
number of digits in the sequence number for each file</p>

<p style="margin-top: 1em">if more digits than &lt;nb&gt;
are needed, then they are used: if &quot;--nb_digits 2&quot;
is used and 112 files are generated they will be named
&quot;&lt;file&gt;-01.xml&quot; to
&quot;&lt;file&gt;-112.xml&quot;</p>

<p style="margin-top: 1em">defaults to 2</p>

<p style="margin-top: 1em">-e &lt;ext&gt; <br>
extension to use for generated files</p>

<p style="margin-top: 1em">defaults to the original file
extension or &quot;.xml&quot;</p>

<p style="margin-top: 1em">-i use XInclude elements instead
of Processing Instructions to mark where sub files need to
be included</p>

<p style="margin-top: 1em">-v verbose output</p>

<p style="margin-top: 1em">Note that this option can slow
down processing considerably (by an order of magnitude) when
generating lots of small documents</p>

<p style="margin-top: 1em">-V outputs version and exit</p>

<p style="margin-top: 1em">-h short help</p>

<p style="margin-top: 1em">-m man (requires pod2text to be
in the path)</p>

<p style="margin-top: 1em">EXAMPLES <br>
xml_split foo.xml # split at level 1 <br>
xml_split -l 2 foo.xml # split at level 2 <br>
xml_split -c section foo.xml # a file is generated for each
section element <br>
# nested sections are split properly</p>

<p style="margin-top: 1em">SEE ALSO <br>
XML::Twig, xml_merge</p>

<p style="margin-top: 1em">TODO <br>
optimize the code <br>
any idea welcome! I have already implemented most of what I
thought would improve performances.</p>

<p style="margin-top: 1em">provide other methods that PIs
to keep merge information <br>
XInclude is a good candidate (alpha support added in
0.04).</p>

<p style="margin-top: 1em">using entities, which would seem
the natural way to do it, doesn&rsquo;t work, as they make
it impossible to have both the main document and the sub
docs to be well-formed if the <br>
sub docs include sub-sub docs (you can&rsquo;t have entity
declarations in an entity)</p>

<p style="margin-top: 1em">AUTHOR <br>
Michel Rodriguez &lt;mirod@cpan.org&gt;</p>

<p style="margin-top: 1em">LICENSE <br>
This tool is free software; you can redistribute it and/or
modify it under the same terms as Perl itself.</p>

<p style="margin-top: 1em">perl v5.16.3 2012-05-17
XML_SPLIT(1)</p>
<hr>
</body>
</html>
