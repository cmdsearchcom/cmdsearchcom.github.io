<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
  </style>
  <title>MPIEXEC(1)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">MPIEXEC(1)</td>
    <td class="head-vol">LAM COMMANDS</td>
    <td class="head-rtitle">MPIEXEC(1)</td>
  </tr>
</table>
<div class="manual-text">
<h1 class="Sh" title="Sh" id="NAME"><a class="selflink" href="#NAME">NAME</a></h1>
mpiexec - Run MPI programs on LAM nodes.
<h1 class="Sh" title="Sh" id="SYNOPSIS"><a class="selflink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<div class="Pp" style="margin-left: 5.00ex; text-indent: -5.00ex;">mpiexec
  [global_args] local_args1 [: local_args2 [...]]</div>
<div class="Pp"></div>
<div class="Pp" style="margin-left: 5.00ex; text-indent: -5.00ex;">mpiexec
  [global_args] -configfile filename</div>
<h1 class="Sh" title="Sh" id="OPTIONS"><a class="selflink" href="#OPTIONS">OPTIONS</a></h1>
Global arguments apply to all commands that will be launched by <i>mpiexec</i>.
  They come at the beginning of the command line.
<dl class="Bl-tag">
  <dt class="It-tag"><b>-boot</b></dt>
  <dd class="It-tag">Boot the LAM run-time environment before running the MPI
      program. If <b>-machinefile</b> is not specified, use the default boot
      schema. When the MPI processes finish, the LAM run-time environment will
      be shut down.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-boot-args args</b></dt>
  <dd class="It-tag">Pass arguments to the back-end <i>lamboot</i> command when
      booting the LAM run-time environment. Implies <i>-boot</i>.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-d</b></dt>
  <dd class="It-tag">Enable lots of debugging output. Implies <b>-v</b>.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-machinefile hostfile</b></dt>
  <dd class="It-tag">Enable &quot;one shot&quot; MPI executions; boot the LAM
      run-time environment with the boot schema specified by hostfile (see
      bhost(5)), run the MPI program, and then shut down the LAM run-time
      environment. Implies <b>-boot</b>.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-prefix lam/install/path</b></dt>
  <dd class="It-tag">Use the LAM installation specified in /lam/install/path/.
      Not compatible with LAM/MPI versions prior to 7.1.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-ssi key value</b></dt>
  <dd class="It-tag">Set the SSI parameter key to the value value.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-tv</b></dt>
  <dd class="It-tag">Launch the MPI processes under the TotalView debugger.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-v</b></dt>
  <dd class="It-tag">Be verbose</dd>
</dl>
<div class="Pp"></div>
One or more sets of local arguments must be specified (or a config file; see
  below). Local arguments essentially include everything allowed in an
  appschema(5) as well as the following options specified by the MPI-2 standard
  (note that the options listed below must be specified <i>before</i> appschema
  arguments):
<dl class="Bl-tag">
  <dt class="It-tag"><b>-n numprocs</b></dt>
  <dd class="It-tag">Number of copies of the process to start.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-host hostname</b></dt>
  <dd class="It-tag">Specify the hostname to start the MPI process on. The
      hostname must be resolvable by the <i>lamnodes</i> command after the LAM
      run-time environment is booted (see lamnodes(1)).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-arch architecture</b></dt>
  <dd class="It-tag">Specify the architecture to start the MPI process on.
      <i>mpiexec</i> essentially uses the provided architecture as a pattern
      match against the output of the GNU <i>config.guess</i> utility on each
      machine in the LAM run-time environment. Any subset will match. See
      EXAMPLES, below.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-wdir directory</b></dt>
  <dd class="It-tag">Set the working directory of the executable.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-soft</b></dt>
  <dd class="It-tag">Not yet supported.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-path</b></dt>
  <dd class="It-tag">Not yet supported.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-file</b></dt>
  <dd class="It-tag">Not yet supported.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>other_arguments</b></dt>
  <dd class="It-tag">When <i>mpiexec</i> first encounters an argument that it
      doesn't recognize (such as an appschema(5) argument, or the MPI executable
      name), the remainder of the arguments will be passed back to <i>mpirun</i>
      to actually start the process. As such, all of <i>mpiexec</i>'s arguments
      that are described above must come <b>before</b> appschema arguments
      and/or the MPI executable name. Similarly, all arguments after the MPI
      executable name will be transparently passed as command line argument to
      the MPI process and will be will be effectively ignored by
    <i>mpirun</i>.</dd>
</dl>
<h1 class="Sh" title="Sh" id="DESCRIPTION"><a class="selflink" href="#DESCRIPTION">DESCRIPTION</a></h1>
<i>mpiexec</i> is loosely defined in the Miscellany chapter of the MPI-2
  standard (see http://www.mpi-forum.org/). It is meant to be a portable
  mechanism for starting MPI processes. The MPI-2 standard recommends several
  command line options, but does not mandate any. LAM's <i>mpiexec</i> currently
  supports several of these options, but not all.
<div class="Pp"></div>
LAM's <i>mpiexec</i> is actually a perl script that is a wrapper around several
  underlying LAM commands, most notably <i>lamboot</i>, <i>mpirun</i>, and
  <i>lamhalt</i>. As such, the functionality provided by <i>mpiexec</i> can
  always be performed manually. Unless otherwise specified in arguments that are
  passed back to <i>mpirun</i>, <i>mpiexec</i> will use the per-CPU scheduling
  as described in mpirun(1) (i.e., the &quot;cX&quot; and &quot;C&quot;
  notation).
<div class="Pp"></div>
<i>mpiexec</i> can either use an already-existing LAM universe (i.e., a booted
  LAM run-time environment), similar to <i>mpirun</i>, or can be used for
  &quot;one-shot&quot; MPI executions where it boots the LAM run-time
  environment, runs the MPI executable(s), and then shuts down the LAM run-time
  environment.
<div class="Pp"></div>
<i>mpiexec</i> can also be used to launch MPMD MPI jobs from the command line.
  <i>mpirun</i> also supports launching MPMD MPI jobs, but the user must make a
  text file appschema(5) first.
<div class="Pp"></div>
Perhaps one of <i>mpiexec</i>'s most useful features is the command-line ability
  to launch different executables on different architectures using the
  <i>-arch</i> flag (see EXAMPLES, below). Essentially, the string argument that
  is given to <i>-arch</i> is used as a pattern match against the output of the
  GNU <i>config.guess</i> utility on each node. If the user-provided
  architecture string matches any subset of the output of <i>config.guess</i>,
  it is ruled a match. Wildcards are not possible. The GNU <i>config.guess</i>
  utility is available both in the LAM/MPI source code distribution (in the
  config subdirectory) and at ftp://ftp.gnu.org/gnu/config/config.guess.
<div class="Pp"></div>
Some sample outputs from <i>config.guess include:</i>
<dl class="Bl-tag">
  <dt class="It-tag">sparc-sun-solaris2.8</dt>
  <dd class="It-tag">Solaris 2.8 running on a SPARC platform.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">i686-pc-linux-gnu</dt>
  <dd class="It-tag">Linux running on an i686 architecture.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">mips-sgi-irix6.5</dt>
  <dd class="It-tag">IRIX 6.5 running on an SGI/MIPS architecture.</dd>
</dl>
<div class="Pp"></div>
You might want to run the <i>laminfo</i> command on your available platforms to
  see what string <i>config.guess</i> reported. See laminfo(1) for more details
  (e.g., the <b>-arch</b> flag to <i>laminfo</i>).
<h2 class="Ss" title="Ss" id="Configfile_option"><a class="selflink" href="#Configfile_option">Configfile
  option</a></h2>
It is possible to specify any set of local parameters in a configuration file
  rather than on the command line using the <i>-configfile</i> option. This
  option is typically used when the number of command line options is too large
  for some shells, or when automated processes generate the command line
  arguments and it is simply more convenient to put them in a file for later
  processing by <b>mpiexec</b>.
<div class="Pp"></div>
The config file can contain both comments and one or more sets of local
  arguments. Lines beginning with &quot;#&quot; are considered comments and are
  ignored. Other lines are considered to be one or more groups of local
  arguments. Each group must be separated by either a newline or a colon
  (&quot;:&quot;). For example:
<div class="Pp"></div>
<pre>
  # Sample mpiexec config file
  # Launch foo on two nodes
  -host node1.example.com foo : -host node2.example.com foo
  # Launch two copies of bar on a third node
  -host node3.example.com -np 2 bar
</pre>
<h1 class="Sh" title="Sh" id="ERRORS"><a class="selflink" href="#ERRORS">ERRORS</a></h1>
In the event of an error, <i>mpiexec</i> will do its best to shut everything
  down and return to the state before it was executed. For example, if
  <i>mpiexec</i> was used to boot a LAM run-time environment, <i>mpiexec</i>
  will do its best to take down whatever successfully booted of the run-time
  environment (to include invoking <i>lamhalt</i> and/or <i>lamwipe</i>).
<h1 class="Sh" title="Sh" id="EXAMPLES"><a class="selflink" href="#EXAMPLES">EXAMPLES</a></h1>
The following are some examples of how to use <i>mpiexec</i>. Note that all
  examples assume the CPU-based scheduling (which does <i>NOT</i> map to
  physical CPUs) as described in mpirun(1).
<dl class="Bl-tag">
  <dt class="It-tag">mpiexec -n 4 my_mpi_program</dt>
  <dd class="It-tag">Launch 4 copies of <i>my_mpi_program</i> in an
      already-existing LAM universe.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">mpiexec -n 4 my_mpi_program arg1 arg2</dt>
  <dd class="It-tag">Similar to the previous example, but pass &quot;arg1&quot;
      and &quot;arg2&quot; as command line arguments to each copy of
      my_mpi_program.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">mpiexec -ssi rpi gm -n 4 my_mpi_program</dt>
  <dd class="It-tag">Similar to the previous example, but pass &quot;-ssi rpi
      gm&quot; back to <i>mpirun</i> to tell the MPI processes to use the
      Myrinet (gm) RPI for MPI message passing.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">mpiexec -n 4 program1 : -n 4 program2</dt>
  <dd class="It-tag">Launch 4 copies of <i>program1</i> and 4 copies of
      <i>program2</i> in an already-existing LAM universe. All 8 resulting
      processes will share a common MPI_COMM_WORLD.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">mpiexec -machinefile hostfile -n 4 my_mpi_program</dt>
  <dd class="It-tag">Boot the LAM run-time environment with the nodes listed in
      the hostfile, run 4 copies of my_mpi_program in the resulting LAM
      universe, and then shut down the LAM universe.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">mpiexec -machinefile hostfile my_mpi_program</dt>
  <dd class="It-tag">Similar to above, but run my_mpi_program on all available
      CPUs in the LAM universe.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">mpiexec -arch solaris2.8 sol_program : -arch linux
    linux_program</dt>
  <dd class="It-tag">Run as many copies of sol_program as there are CPUs on
      Solaris machines in the current LAM universe, and as many copies of
      linux_program as there are CPUs on linux machines in the current LAM
      universe. All resulting processes will share a common MPI_COMM_WORLD.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">mpiexec -arch solaris2.8 sol2.8_prog : -arch solaris2.9
    sol2.9_program</dt>
  <dd class="It-tag">Similar to the above example, except distinguish between
      Solaris 2.8 and 2.9 (since they may have different shared libraries,
      etc.).</dd>
</dl>
<h1 class="Sh" title="Sh" id="SEE_ALSO"><a class="selflink" href="#SEE_ALSO">SEE
  ALSO</a></h1>
appschema(5), bhost(5), lamboot(1), lamexec(1), mpirun(1)</div>
<table class="foot">
  <tr>
    <td class="foot-date">July, 2007</td>
    <td class="foot-os">LAM 7.1.4</td>
  </tr>
</table>
</body>
</html>
