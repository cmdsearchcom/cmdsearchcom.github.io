<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
  </style>
  <title>JULIUS(1)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">JULIUS(1)</td>
    <td class="head-vol"></td>
    <td class="head-rtitle">JULIUS(1)</td>
  </tr>
</table>
<div class="manual-text">
<br/>
 julius
<div style="height: 1.00em;">&#x00A0;</div>
<h1 class="Sh" title="Sh" id="NAME"><a class="selflink" href="#NAME">NAME</a></h1>
<br/>
 julius
<br/>
 - open source multi-purpose LVCSR engine
<h1 class="Sh" title="Sh" id="SYNOPSIS"><a class="selflink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<div class="Pp" style="margin-left: 7.00ex; text-indent: -7.00ex;"><b>julius</b>
  [-C&#x00A0; <i>jconffile</i>] [<i>options</i>...]</div>
<h1 class="Sh" title="Sh" id="DESCRIPTION"><a class="selflink" href="#DESCRIPTION">DESCRIPTION</a></h1>
<b>julius</b> is a high-performance, multi-purpose, open-source speech
  recognition engine for researchers and developers. It is capable of performing
  almost real-time recognition of continuous speech with over 60k-word 3-gram
  language model and triphone HMM model, on most current PCs. <b>julius</b> can
  perform recognition on audio files, live microphone input, network input and
  feature parameter files.
<div class="Pp"></div>
The core recognition module is implemented as C library called
  &quot;JuliusLib&quot;. It can also be extended by plug-in facility.
<h2 class="Ss" title="Ss" id="Supported_Models"><a class="selflink" href="#Supported_Models">Supported
  Models</a></h2>
<b>julius</b> needs a language model and an acoustic model to run as a speech
  recognizer. <b>julius</b> supports the following models.
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Acoustic model</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
Sub-word HMM (Hidden Markov Model) in HTK ascii format are supported. Phoneme
  models (monophone), context dependent phoneme models (triphone), tied-mixture
  and phonetic tied-mixture models of any unit can be used. When using context
  dependent models, inter-word context dependency is also handled. Multi-stream
  feature and MSD-HMM is also supported. You can further use a tool
  <b>mkbinhmm</b> to convert the ascii HMM file to a compact binary format for
  faster loading.
<div class="Pp"></div>
Note that <b>julius</b> itself can only extract MFCC features from speech data.
  If you use acoustic HMM trained for other feature, you should give the input
  in HTK parameter file of the same feature type.</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Language model: word N-gram</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
Word N-gram language model, up to 10-gram, is supported. Julius uses different
  N-gram for each pass: left-to-right 2-gram on 1st pass, and right-to-left
  N-gram on 2nd pass. It is recommended to use both LR 2-gram and RL N-gram for
  Julius. However, you can use only single LR N-gram or RL N-gram. In such case,
  approximated LR 2-gram computed from the given N-gram will be applied at the
  first pass.
<div class="Pp"></div>
The Standard ARPA format is supported. In addition, a binary format is also
  supported for efficiency. The tool <b>mkbingram</b>(1) can convert ARPA format
  N-gram to binary format.</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Language model: grammar</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
The grammar format is an original one, and tools to create a recognirion grammar
  are included in the distribution. A grammar consists of two files: one is a
  'grammar' file that describes sentence structures in a BNF style, using word
  'category' name as terminate symbols. Another is a 'voca' file that defines
  words with its pronunciations (i.e. phoneme sequences) for each category. They
  should be converted by <b>mkdfa</b>(1) to a deterministic finite automaton
  file (.dfa) and a dictionary file (.dict), respectively. You can also use
  multiple grammars.</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Language model: isolated word</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
You can perform isolated word recognition using only word dictionary. With this
  model type, Julius will perform rapid one pass recognition with static context
  handling. Silence models will be added at both head and tail of each word. You
  can also use multiple dictionaries in a process.</div>
<h2 class="Ss" title="Ss" id="Search_Algorithm"><a class="selflink" href="#Search_Algorithm">Search
  Algorithm</a></h2>
Recognition algorithm of <b>julius</b> is based on a two-pass strategy. Word
  2-gram and reverse word 3-gram is used on the respective passes. The entire
  input is processed on the first pass, and again the final searching process is
  performed again for the input, using the result of the first pass to narrow
  the search space. Specifically, the recognition algorithm is based on a
  tree-trellis heuristic search combined with left-to-right frame-synchronous
  beam search and right-to-left stack decoding search.
<div class="Pp"></div>
When using context dependent phones (triphones), interword contexts are taken
  into consideration. For tied-mixture and phonetic tied-mixture models,
  high-speed acoustic likelihood calculation is possible using gaussian pruning.
<div class="Pp"></div>
For more details, see the related documents.
<h1 class="Sh" title="Sh" id="OPTIONS"><a class="selflink" href="#OPTIONS">OPTIONS</a></h1>
These options specify the models, system behaviors and various search parameters
  to Julius. These option can be set at the command line, but it is recommended
  that you write them in a text file as a &quot;jconf file&quot;, and specify it
  by &quot;-C&quot; option.
<div class="Pp"></div>
Applications incorporating JuliusLib also use these options to set the
  parameters of core recognition engine. For example, a jconf file can be loaded
  to the enine by calling <b>j_config_load_file_new()</b> with the jconf file
  name as argument.
<div class="Pp"></div>
Please note that relative paths in a jconf file should be relative to the jconf
  file itself, not the current working directory.
<div class="Pp"></div>
Below are the details of all options, gathered by group.
<h2 class="Ss" title="Ss" id="Julius_application_option"><a class="selflink" href="#Julius_application_option">Julius
  application option</a></h2>
These are application options of Julius, outside of JuliusLib. It contains
  parameters and switches for result output, character set conversion, log
  level, and module mode options. These option are specific to Julius, and
  cannot be used at applications using JuliusLib other than Julius.
<div class="Pp"></div>
<b> -outfile </b>
<div style="margin-left: 3.00ex;">On file input, this option write the
  recognition result of each file to a separate file. The output file of an
  input file will be the same name but the suffix will be changed to
  &quot;.out&quot;. (rev.4.0)</div>
<div class="Pp"></div>
<b> -separatescore </b>
<div style="margin-left: 3.00ex;">Output the language and acoustic scores
  separately.</div>
<div class="Pp"></div>
<b> -callbackdebug </b>
<div style="margin-left: 3.00ex;">Print the callback names at each call for
  debug. (rev.4.0)</div>
<div class="Pp"></div>
<b> -charconv </b> <i>from</i> <i>to</i>
<div style="margin-left: 3.00ex;">Print with character set conversion.
  <i>from</i> is the source character set used in the language model, and
  <i>to</i> is the target character set you want to get.
<div style="height: 1.00em;">&#x00A0;</div>
On Linux, the arguments should be a code name. You can obtain the list of
  available code names by invoking the command &quot;iconv --list&quot;. On
  Windows, the arguments should be a code name or codepage number. Code name
  should be one of &quot;ansi&quot;, &quot;mac&quot;, &quot;oem&quot;,
  &quot;utf-7&quot;, &quot;utf-8&quot;, &quot;sjis&quot;, &quot;euc&quot;. Or
  you can specify any codepage number supported at your environment.</div>
<div class="Pp"></div>
<b> -nocharconv </b>
<div style="margin-left: 3.00ex;">Disable character conversion.</div>
<div class="Pp"></div>
<b> -module </b> [port]
<div style="margin-left: 3.00ex;">Run Julius on &quot;Server Module Mode&quot;.
  After startup, Julius waits for tcp/ip connection from client. Once connection
  is established, Julius start communication with the client to process incoming
  commands from the client, or to output recognition results, input trigger
  information and other system status to the client. The default port number is
  10500.</div>
<div class="Pp"></div>
<b> -record </b> <i>dir</i>
<div style="margin-left: 3.00ex;">Auto-save all input speech data into the
  specified directory. Each segmented inputs are recorded each by one. The file
  name of the recorded data is generated from system time when the input ends,
  in a style of YYYY.MMDD.HHMMSS.wav. File format is 16bit monoral WAV. Invalid
  for mfcfile input.
<div style="height: 1.00em;">&#x00A0;</div>
With input rejection by <b>-rejectshort</b>, the rejected input will also be
  recorded even if they are rejected.</div>
<div class="Pp"></div>
<b> -logfile </b> <i>file</i>
<div style="margin-left: 3.00ex;">Save all log output to a file instead of
  standard output. (Rev.4.0)</div>
<div class="Pp"></div>
<b> -nolog </b>
<div style="margin-left: 3.00ex;">Disable all log output. (Rev.4.0)</div>
<div class="Pp"></div>
<b> -help </b>
<div style="margin-left: 3.00ex;">Output help message and exit.</div>
<h2 class="Ss" title="Ss" id="Global_options"><a class="selflink" href="#Global_options">Global
  options</a></h2>
These are model-/search-dependent options relating audio input, sound detection,
  GMM, decoding algorithm, plugin facility, and others. Global options should be
  placed before any instance declaration ( <b>-AM</b>, <b>-LM</b>, or
  <b>-SR</b>), or just after &quot; <b>-GLOBAL</b>&quot; option.
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Audio input</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -input </b> {mic|rawfile|mfcfile|adinnet|stdin|netaudio|alsa|oss|esd}
<div style="margin-left: 3.00ex;">Choose speech input source. Specify 'file' or
  'rawfile' for waveform file, 'htkparam' or 'mfcfile' for HTK parameter file.
  On file input, users will be prompted to enter the file name from stdin, or
  you can use <b>-filelist</b> option to specify list of files to process.
<div style="height: 1.00em;">&#x00A0;</div>
&#x00B4;mic' is to get audio input from a default live microphone device, and
  'adinnet' means receiving waveform data via tcpip network from an adinnet
  client. 'netaudio' is from DatLink/NetAudio input, and 'stdin' means data
  input from standard input.
<div style="height: 1.00em;">&#x00A0;</div>
For waveform file input, only WAV (no compression) and RAW (noheader, 16bit, big
  endian) are supported by default. Other format can be read when compiled with
  libsnd library. To see what format is actually supported, see the help message
  using option <b>-help</b>. For stdin input, only WAV and RAW is supported.
  (default: mfcfile)
<div style="height: 1.00em;">&#x00A0;</div>
At Linux, you can choose API at run time by specifying alsa, oss and esd.</div>
<div class="Pp"></div>
<b> -chunk_size </b> <i>samples</i>
<div style="margin-left: 3.00ex;">Audio fragment size in number of samples.
  (default: 1000)</div>
<div class="Pp"></div>
<b> -filelist </b> <i>filename</i>
<div style="margin-left: 3.00ex;">(With <b>-input rawfile|mfcfile</b>) perform
  recognition on all files listed in the file. The file should contain input
  file per line. Engine will end when all of the files are processed.</div>
<div class="Pp"></div>
<b> -notypecheck </b>
<div style="margin-left: 3.00ex;">By default, Julius checks the input parameter
  type whether it matches the AM or not. This option will disable the check and
  force engine to use the input vector as is.</div>
<div class="Pp"></div>
<b> -48 </b>
<div style="margin-left: 3.00ex;">Record input with 48kHz sampling, and
  down-sample it to 16kHz on-the-fly. This option is valid for 16kHz model only.
  The down-sampling routine was ported from sptk. (Rev. 4.0)</div>
<div class="Pp"></div>
<b> -NA </b> <i>devicename</i>
<div style="margin-left: 3.00ex;">Host name for DatLink server input (<b>-input
  netaudio</b>).</div>
<div class="Pp"></div>
<b> -adport </b> <i>port_number</i>
<div style="margin-left: 3.00ex;">With <b>-input adinnet</b>, specify adinnet
  port number to listen. (default: 5530)</div>
<div class="Pp"></div>
<b> -nostrip </b>
<div style="margin-left: 3.00ex;">Julius by default removes successive zero
  samples in input speech data. This option inhibits the removal.</div>
<div class="Pp"></div>
<b> -zmean </b>, <b> -nozmean </b>
<div style="margin-left: 3.00ex;">This option enables/disables DC offset removal
  of input waveform. Offset will be estimated from the whole input. For
  microphone / network input, zero mean of the first 48000 samples (3 seconds in
  16kHz sampling) will be used for the estimation. (default: disabled)
<div style="height: 1.00em;">&#x00A0;</div>
This option uses static offset for the channel. See also <b>-zmeansource</b> for
  frame-wise offset removal.</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Speech detection by level and zero-cross</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -cutsilence </b>, <b> -nocutsilence </b>
<div style="margin-left: 3.00ex;">Turn on / off the speech detection by level
  and zero-cross. Default is on for mic / adinnet input, and off for
  files.</div>
<div class="Pp"></div>
<b> -lv </b> <i>thres</i>
<div style="margin-left: 3.00ex;">Level threshold for speech input detection.
  Values should be in range from 0 to 32767. (default: 2000)</div>
<div class="Pp"></div>
<b> -zc </b> <i>thres</i>
<div style="margin-left: 3.00ex;">Zero crossing threshold per second. Only input
  that goes over the level threshold ( <b>-lv</b>) will be counted. (default:
  60)</div>
<div class="Pp"></div>
<b> -headmargin </b> <i>msec</i>
<div style="margin-left: 3.00ex;">Silence margin at the start of speech segment
  in milliseconds. (default: 300)</div>
<div class="Pp"></div>
<b> -tailmargin </b> <i>msec</i>
<div style="margin-left: 3.00ex;">Silence margin at the end of speech segment in
  milliseconds. (default: 400)</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Input rejection</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
Two simple front-end input rejection methods are implemented, based on input
  length and average power of detected segment. The rejection by average power
  is experimental, and can be enabled by --enable-power-reject on compilation.
  Valid for MFCC feature with power coefficient and real-time input only.
<div class="Pp"></div>
For GMM-based input rejection see the GMM section below.
<div class="Pp"></div>
<b> -rejectshort </b> <i>msec</i>
<div style="margin-left: 3.00ex;">Reject input shorter than specified
  milliseconds. Search will be terminated and no result will be output.</div>
<div class="Pp"></div>
<b> -powerthres </b> <i>thres</i>
<div style="margin-left: 3.00ex;">Reject the inputted segment by its average
  energy. If the average energy of the last recognized input is below the
  threshold, Julius will reject the input. (Rev.4.0)
<div style="height: 1.00em;">&#x00A0;</div>
This option is valid when --enable-power-reject is specified at compilation
  time.</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Gaussian mixture model / GMM-VAD</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
GMM will be used for input rejection by accumulated score, or for front-end
  GMM-based VAD when --enable-gmm-vad is specified.
<div class="Pp"></div>
NOTE: You should also set the proper MFCC parameters required for the GMM,
  specifying the acoustic parameters described in AM section <b>-AM_GMM</b>.
<div class="Pp"></div>
When GMM-based VAD is enabled, the voice activity score will be calculated at
  each frame as front-end processing. The value will be computed as \[ \max_{m
  \in M_v} p(x|m) - \max_{m \in M_n} p(x|m) \] where $M_v$ is a set of voice
  GMM, and $M_n$ is a set of noise GMM whose names should be specified by
  <b>-gmmreject</b>. The activity score will be then averaged for the last N
  frames, where N is specified by <b>-gmmmargin</b>. Julius updates the averaged
  activity score at each frame, and detect speech up-trigger when the value gets
  higher than a value specified by <b>-gmmup</b>, and detecgt down-trigger when
  it gets lower than a value of <b>-gmmdown</b>.
<div class="Pp"></div>
<b> -gmm </b> <i>hmmdefs_file</i>
<div style="margin-left: 3.00ex;">GMM definition file in HTK format. If
  specified, GMM-based input verification will be performed concurrently with
  the 1st pass, and you can reject the input according to the result as
  specified by <b>-gmmreject</b>. The GMM should be defined as one-state
  HMMs.</div>
<div class="Pp"></div>
<b> -gmmnum </b> <i>number</i>
<div style="margin-left: 3.00ex;">Number of Gaussian components to be computed
  per frame on GMM calculation. Only the N-best Gaussians will be computed for
  rapid calculation. The default is 10 and specifying smaller value will speed
  up GMM calculation, but too small value (1 or 2) may cause degradation of
  identification performance.</div>
<div class="Pp"></div>
<b> -gmmreject </b> <i>string</i>
<div style="margin-left: 3.00ex;">Comma-separated list of GMM names to be
  rejected as invalid input. When recognition, the log likelihoods of GMMs
  accumulated for the entire input will be computed concurrently with the 1st
  pass. If the GMM name of the maximum score is within this string, the 2nd pass
  will not be executed and the input will be rejected.</div>
<div class="Pp"></div>
<b> -gmmmargin </b> <i>frames</i>
<div style="margin-left: 3.00ex;">(GMM_VAD) Head margin in frames. When a speech
  trigger detected by GMM, recognition will start from current frame minus this
  value. (Rev.4.0)
<div style="height: 1.00em;">&#x00A0;</div>
This option will be valid only if compiled with --enable-gmm-vad.</div>
<div class="Pp"></div>
<b> -gmmup </b> <i>value</i>
<div style="margin-left: 3.00ex;">(GMM_VAD) Up trigger threshold of voice
  activity score. (Rev.4.1)
<div style="height: 1.00em;">&#x00A0;</div>
This option will be valid only if compiled with --enable-gmm-vad.</div>
<div class="Pp"></div>
<b> -gmmdown </b> <i>value</i>
<div style="margin-left: 3.00ex;">(GMM_VAD) Down trigger threshold of voice
  activity score. (Rev.4.1)
<div style="height: 1.00em;">&#x00A0;</div>
This option will be valid only if compiled with --enable-gmm-vad.</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Decoding option</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
Real-time processing means concurrent processing of MFCC computation 1st pass
  decoding. By default, real-time processing on the pass is on for microphone /
  adinnet / netaudio input, and for others.
<div class="Pp"></div>
<b> -realtime </b>, <b> -norealtime </b>
<div style="margin-left: 3.00ex;">Explicitly switch on / off real-time
  (pipe-line) processing on the first pass. The default is off for file input,
  and on for microphone, adinnet and NetAudio input. This option relates to the
  way CMN and energy normalization is performed: if off, they will be done using
  average features of whole input. If on, MAP-CMN and energy normalization to do
  real-time processing.</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Misc. options</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -C </b> <i>jconffile</i>
<div style="margin-left: 3.00ex;">Load a jconf file at here. The content of the
  jconffile will be expanded at this point.</div>
<div class="Pp"></div>
<b> -version </b>
<div style="margin-left: 3.00ex;">Print version information to standard error,
  and exit.</div>
<div class="Pp"></div>
<b> -setting </b>
<div style="margin-left: 3.00ex;">Print engine setting information to standard
  error, and exit.</div>
<div class="Pp"></div>
<b> -quiet </b>
<div style="margin-left: 3.00ex;">Output less log. For result, only the best
  word sequence will be printed.</div>
<div class="Pp"></div>
<b> -debug </b>
<div style="margin-left: 3.00ex;">(For debug) output enormous internal message
  and debug information to log.</div>
<div class="Pp"></div>
<b> -check </b> {wchmm|trellis|triphone}
<div style="margin-left: 3.00ex;">For debug, enter interactive check mode.</div>
<div class="Pp"></div>
<b> -plugindir </b> <i>dirlist</i>
<div style="margin-left: 3.00ex;">Specify directory to load plugin. If several
  direcotries exist, specify them by colon-separated list.</div>
</div>
<h2 class="Ss" title="Ss" id="Instance_declaration_for_multi_decoding"><a class="selflink" href="#Instance_declaration_for_multi_decoding">Instance
  declaration for multi decoding</a></h2>
The following arguments will create a new configuration set with default
  parameters, and switch current set to it. Jconf parameters specified after the
  option will be set into the current set.
<div class="Pp"></div>
To do multi-model decoding, these argument should be specified at the first of
  each model / search instances with different names. Any options before the
  first instance definition will be IGNORED.
<div class="Pp"></div>
When no instance definition is found (as older version of Julius), all the
  options are assigned to a default instance named _default.
<div class="Pp"></div>
Please note that decoding with a single LM and multiple AMs is not fully
  supported. For example, you may want to construct the jconf file as following.
<div style="height: 1.00em;">&#x00A0;</div>
This type of model sharing is not supported yet, since some part of LM
  processing depends on the assigned AM. Instead, you can get the same result by
  defining the same LMs for each AM, like this:
<div style="height: 1.00em;">&#x00A0;</div>
<div class="Pp"></div>
<b> -AM </b> <i>name</i>
<div style="margin-left: 3.00ex;">Create a new AM configuration set, and switch
  current to the new one. You should give a unique name. (Rev.4.0)</div>
<div class="Pp"></div>
<b> -LM </b> <i>name</i>
<div style="margin-left: 3.00ex;">Create a new LM configuration set, and switch
  current to the new one. You should give a unique name. (Rev.4.0)</div>
<div class="Pp"></div>
<b> -SR </b> <i>name</i> <i>am_name</i> <i>lm_name</i>
<div style="margin-left: 3.00ex;">Create a new search configuration set, and
  switch current to the new one. The specified AM and LM will be assigned to it.
  The <i>am_name</i> and <i>lm_name</i> can be either name or ID number. You
  should give a unique name. (Rev.4.0)</div>
<div class="Pp"></div>
<b> -AM_GMM </b>
<div style="margin-left: 3.00ex;">When using GMM for front-end processing, you
  can specify GMM-specific acoustic parameters after this option. If you does
  not specify <b>-AM_GMM</b> with GMM, the GMM will share the same parameter
  vector as the last AM. The current AM will be switched to the GMM one, so be
  careful not to confuse with normal AM configurations. (Rev.4.0)</div>
<div class="Pp"></div>
<b> -GLOBAL </b>
<div style="margin-left: 3.00ex;">Start a global section. The global options
  should be placed before any instance declaration, or after this option on
  multiple model recognition. This can be used multiple times. (Rev.4.1)</div>
<div class="Pp"></div>
<b> -nosectioncheck </b>, <b> -sectioncheck </b>
<div style="margin-left: 3.00ex;">Disable / enable option location check in
  multi-model decoding. When enabled, the options between instance declaration
  is treated as &quot;sections&quot; and only the belonging option types can be
  written. For example, when an option <b>-AM</b> is specified, only the AM
  related option can be placed after the option until other declaration is
  found. Also, global options should be placed at top, before any instance
  declarataion. This is enabled by default. (Rev.4.1)</div>
<h2 class="Ss" title="Ss" id="Language_model_(-LM)"><a class="selflink" href="#Language_model_(-LM)">Language
  model ( <b>-LM</b>)</a></h2>
This group contains options for model definition of each language model type.
  When using multiple LM, one instance can have only one LM.
<div class="Pp"></div>
Only one type of LM can be specified for a LM configuration. If you want to use
  multi model, you should define them one as a new LM.
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>N-gram</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -d </b> <i>bingram_file</i>
<div style="margin-left: 3.00ex;">Use binary format N-gram. An ARPA N-gram file
  can be converted to Julius binary format by mkbingram.</div>
<div class="Pp"></div>
<b> -nlr </b> <i>arpa_ngram_file</i>
<div style="margin-left: 3.00ex;">A forward, left-to-right N-gram language model
  in standard ARPA format. When both a forward N-gram and backward N-gram are
  specified, Julius uses this forward 2-gram for the 1st pass, and the backward
  N-gram for the 2nd pass.
<div style="height: 1.00em;">&#x00A0;</div>
Since ARPA file often gets huge and requires a lot of time to load, it may be
  better to convert the ARPA file to Julius binary format by mkbingram. Note
  that if both forward and backward N-gram is used for recognition, they
  together will be converted to a single binary.
<div style="height: 1.00em;">&#x00A0;</div>
When only a forward N-gram is specified by this option and no backward N-gram
  specified by <b>-nrl</b>, Julius performs recognition with only the forward
  N-gram. The 1st pass will use the 2-gram entry in the given N-gram, and The
  2nd pass will use the given N-gram, with converting forward probabilities to
  backward probabilities by Bayes rule. (Rev.4.0)</div>
<div class="Pp"></div>
<b> -nrl </b> <i>arpa_ngram_file</i>
<div style="margin-left: 3.00ex;">A backward, right-to-left N-gram language
  model in standard ARPA format. When both a forward N-gram and backward N-gram
  are specified, Julius uses the forward 2-gram for the 1st pass, and this
  backward N-gram for the 2nd pass.
<div style="height: 1.00em;">&#x00A0;</div>
Since ARPA file often gets huge and requires a lot of time to load, it may be
  better to convert the ARPA file to Julius binary format by mkbingram. Note
  that if both forward and backward N-gram is used for recognition, they
  together will be converted to a single binary.
<div style="height: 1.00em;">&#x00A0;</div>
When only a backward N-gram is specified by this option and no forward N-gram
  specified by <b>-nlr</b>, Julius performs recognition with only the backward
  N-gram. The 1st pass will use the forward 2-gram probability computed from the
  backward 2-gram using Bayes rule. The 2nd pass fully use the given backward
  N-gram. (Rev.4.0)</div>
<div class="Pp"></div>
<b> -v </b> <i>dict_file</i>
<div style="margin-left: 3.00ex;">Word dictionary file.</div>
<div class="Pp"></div>
<b> -silhead </b> <i>word_string</i> <b> -siltail </b> <i>word_string</i>
<div style="margin-left: 3.00ex;">Silence word defined in the dictionary, for
  silences at the beginning of sentence and end of sentence. (default:
  &quot;&lt;s&gt;&quot;, &quot;&lt;/s&gt;&quot;)</div>
<div class="Pp"></div>
<b> -mapunk </b> <i>word_string</i>
<div style="margin-left: 3.00ex;">Specify unknown word. Default is
  &quot;&lt;unk&gt;&quot; or &quot;&lt;UNK&gt;&quot;. This will be used to
  assign word probability on unknown words, i.e. words in dictionary that are
  not in N-gram vocabulary.</div>
<div class="Pp"></div>
<b> -iwspword </b>
<div style="margin-left: 3.00ex;">Add a word entry to the dictionary that should
  correspond to inter-word pauses. This may improve recognition accuracy in some
  language model that has no explicit inter-word pause modeling. The word entry
  to be added can be changed by <b>-iwspentry</b>.</div>
<div class="Pp"></div>
<b> -iwspentry </b> <i>word_entry_string</i>
<div style="margin-left: 3.00ex;">Specify the word entry that will be added by
  <b>-iwspword</b>. (default: &quot;&lt;UNK&gt; [sp] sp sp&quot;)</div>
<div class="Pp"></div>
<b> -sepnum </b> <i>number</i>
<div style="margin-left: 3.00ex;">Number of high frequency words to be isolated
  from the lexicon tree, to ease approximation error that may be caused by the
  one-best approximation on 1st pass. (default: 150)</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Grammar</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
Multiple grammars can be specified by repeating <b>-gram</b> and
  <b>-gramlist</b>. Note that this is unusual behavior from other options (in
  normal Julius option, last one will override previous ones). You can use
  <b>-nogram</b> to reset the grammars already specified before the point.
<div class="Pp"></div>
<b> -gram </b> gramprefix1[,gramprefix2[,gramprefix3,...]]
<div style="margin-left: 3.00ex;">Comma-separated list of grammars to be used.
  the argument should be a prefix of a grammar, i.e. if you have <i>foo.dfa</i>
  and <i>foo.dict</i>, you should specify them with a single argument foo.
  Multiple grammars can be specified at a time as a comma-separated list.</div>
<div class="Pp"></div>
<b> -gramlist </b> <i>list_file</i>
<div style="margin-left: 3.00ex;">Specify a grammar list file that contains list
  of grammars to be used. The list file should contain the prefixes of grammars,
  each per line. A relative path in the list file will be treated as relative to
  the file, not the current path or configuration file.</div>
<div class="Pp"></div>
<b> -dfa </b> <i>dfa_file</i> <b> -v </b> <i>dict_file</i>
<div style="margin-left: 3.00ex;">An old way of specifying grammar files
  separately. This is bogus, and should not be used any more.</div>
<div class="Pp"></div>
<b> -nogram </b>
<div style="margin-left: 3.00ex;">Remove the current list of grammars already
  specified by <b>-gram</b>, <b>-gramlist</b>, <b>-dfa</b> and <b>-v</b>.</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Isolated word</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
Dictionary can be specified by using <b>-w</b> and <b>-wlist</b>. When you
  specify multiple times, all of them will be read at startup. You can use
  <b>-nogram</b> to reset the already specified dictionaries at that point.
<div class="Pp"></div>
<b> -w </b> <i>dict_file</i>
<div style="margin-left: 3.00ex;">Word dictionary for isolated word recognition.
  File format is the same as other LM. (Rev.4.0)</div>
<div class="Pp"></div>
<b> -wlist </b> <i>list_file</i>
<div style="margin-left: 3.00ex;">Specify a dictionary list file that contains
  list of dictionaries to be used. The list file should contain the file name of
  dictionaries, each per line. A relative path in the list file will be treated
  as relative to the list file, not the current path or configuration file.
  (Rev.4.0)</div>
<div class="Pp"></div>
<b> -nogram </b>
<div style="margin-left: 3.00ex;">Remove the current list of dictionaries
  already specified by <b>-w</b> and <b>-wlist</b>.</div>
<div class="Pp"></div>
<b> -wsil </b> <i>head_sil_model_name</i> <i>tail_sil_model_name</i>
  <i>sil_context_name</i>
<div style="margin-left: 3.00ex;">On isolated word recognition, silence models
  will be appended to the head and tail of each word at recognition. This option
  specifies the silence models to be appended. <i>sil_context_name</i> is the
  name of the head sil model and tail sil model as a context of word head phone
  and tail phone. For example, if you specify -wsil silB silE sp, a word with
  phone sequence b eh t will be translated as silB sp-b+eh b-eh+t eh-t+sp silE.
  (Rev.4.0)</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>User-defined LM</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -userlm </b>
<div style="margin-left: 3.00ex;">Declare to use user LM functions in the
  program. This option should be specified if you use user-defined LM functions.
  (Rev.4.0)</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Misc. LM options</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -forcedict </b>
<div style="margin-left: 3.00ex;">Skip error words in dictionary and force
  running.</div>
</div>
<h2 class="Ss" title="Ss" id="Acoustic_model_and_feature_analysis_(-AM)_(-AM_GMM)"><a class="selflink" href="#Acoustic_model_and_feature_analysis_(-AM)_(-AM_GMM)">Acoustic
  model and feature analysis ( <b>-AM</b>) (<b>-AM_GMM</b>)</a></h2>
This section is about options for acoustic model, feature extraction, feature
  normalizations and spectral subtraction.
<div class="Pp"></div>
After -AM name, an acoustic model and related specification should be written.
  You can use multiple AMs trained with different MFCC types. For GMM, the
  required parameter condition should be specified just as same as AMs after
  <b>-AM_GMM</b>.
<div class="Pp"></div>
When using multiple AMs, the values of <b>-smpPeriod</b>, <b>-smpFreq</b>,
  <b>-fsize</b> and <b>-fshift</b> should be the same among all AMs.
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Acoustic HMM</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -h </b> <i>hmmdef_file</i>
<div style="margin-left: 3.00ex;">Acoustic HMM definition file. It should be in
  HTK ascii format, or Julius binary format. You can convert HTK ascii format to
  Julius binary format using mkbinhmm.</div>
<div class="Pp"></div>
<b> -hlist </b> <i>hmmlist_file</i>
<div style="margin-left: 3.00ex;">HMMList file for phone mapping. This file
  provides mapping between logical triphone names generated in the dictionary
  and the defined HMM names in hmmdefs. This option should be specified for
  context-dependent model.</div>
<div class="Pp"></div>
<b> -tmix </b> <i>number</i>
<div style="margin-left: 3.00ex;">Specify the number of top Gaussians to be
  calculated in a mixture codebook. Small number will speed up the acoustic
  computation, but AM accuracy may get worse with too small value. See also
  <b>-gprune</b>. (default: 2)</div>
<div class="Pp"></div>
<b> -spmodel </b> <i>name</i>
<div style="margin-left: 3.00ex;">Specify HMM model name that corresponds to
  short-pause in an utterance. The short-pause model name will be used in
  recognition: short-pause skipping on grammar recognition, word-end short-pause
  model insertion with <b>-iwsp</b> on N-gram, or short-pause segmentation (
  <b>-spsegment</b>). (default: &quot;sp&quot;)</div>
<div class="Pp"></div>
<b> -multipath </b>
<div style="margin-left: 3.00ex;">Enable multi-path mode. To make decoding
  faster, Julius by default impose a limit on HMM transitions that each model
  should have only one transition from initial state and to end state. On
  multi-path mode, Julius does extra handling on inter-model transition to
  allows model-skipping transition and multiple output/input transitions. Note
  that specifying this option will make Julius a bit slower, and the larger beam
  width may be required.
<div style="height: 1.00em;">&#x00A0;</div>
This function was a compilation-time option on Julius 3.x, and now becomes a
  run-time option. By default (without this option), Julius checks the
  transition type of specified HMMs, and enable the multi-path mode if required.
  You can force multi-path mode with this option. (rev.4.0)</div>
<div class="Pp"></div>
<b> -gprune </b> {safe|heuristic|beam|none|default}
<div style="margin-left: 3.00ex;">Set Gaussian pruning algorithm to use. For
  tied-mixture model, Julius performs Gaussian pruning to reduce acoustic
  computation, by calculating only the top N Gaussians in each codebook at each
  frame. The default setting will be set according to the model type and engine
  setting. default will force accepting the default setting. Set this to none to
  disable pruning and perform full computation. safe guarantees the top N
  Gaussians to be computed. heuristic and beam do more aggressive computational
  cost reduction, but may result in small loss of accuracy model (default: safe
  (standard), beam (fast) for tied mixture model, none for non tied-mixture
  model).</div>
<div class="Pp"></div>
<b> -iwcd1 </b> {max|avg|best number}
<div style="margin-left: 3.00ex;">Select method to approximate inter-word
  triphone on the head and tail of a word in the first pass.
<div style="height: 1.00em;">&#x00A0;</div>
<div style="height: 1.00em;">&#x00A0;</div>
max will apply the maximum likelihood of the same context triphones. avg will
  apply the average likelihood of the same context triphones. best number will
  apply the average of top N-best likelihoods of the same context triphone.
<div style="height: 1.00em;">&#x00A0;</div>
Default is best 3 for use with N-gram, and avg for grammar and word. When this
  AM is shared by LMs of both type, latter one will be chosen.</div>
<div class="Pp"></div>
<b> -iwsppenalty </b> <i>float</i>
<div style="margin-left: 3.00ex;">Insertion penalty for word-end short pauses
  appended by <b>-iwsp</b>.</div>
<div class="Pp"></div>
<b> -gshmm </b> <i>hmmdef_file</i>
<div style="margin-left: 3.00ex;">If this option is specified, Julius performs
  Gaussian Mixture Selection for efficient decoding. The hmmdefs should be a
  monophone model generated from an ordinary monophone HMM model, using
  mkgshmm.</div>
<div class="Pp"></div>
<b> -gsnum </b> <i>number</i>
<div style="margin-left: 3.00ex;">On GMS, specify number of monophone states to
  compute corresponding triphones in detail. (default: 24)</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Speech analysis</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
Only MFCC feature extraction is supported in current Julius. Thus when
  recognizing a waveform input from file or microphone, AM must be trained by
  MFCC. The parameter condition should also be set as exactly the same as the
  training condition by the options below.
<div class="Pp"></div>
When you give an input in HTK Parameter file, you can use any parameter type for
  AM. In this case Julius does not care about the type of input feature and AM,
  just read them as vector sequence and match them to the given AM. Julius only
  checks whether the parameter types are the same. If it does not work well, you
  can disable this checking by <b>-notypecheck</b>.
<div class="Pp"></div>
In Julius, the parameter kind and qualifiers (as TARGETKIND in HTK) and the
  number of cepstral parameters (NUMCEPS) will be set automatically from the
  content of the AM header, so you need not specify them by options.
<div class="Pp"></div>
Other parameters should be set exactly the same as training condition. You can
  also give a HTK Config file which you used to train AM to Julius by
  <b>-htkconf</b>. When this option is applied, Julius will parse the Config
  file and set appropriate parameter.
<div class="Pp"></div>
You can further embed those analysis parameter settings to a binary HMM file
  using mkbinhmm.
<div class="Pp"></div>
If options specified in several ways, they will be evaluated in the order below.
  The AM embedded parameter will be loaded first if any. Then, the HTK config
  file given by <b>-htkconf</b> will be parsed. If a value already set by AM
  embedded value, HTK config will override them. At last, the direct options
  will be loaded, which will override settings loaded before. Note that, when
  the same options are specified several times, later will override previous,
  except that <b>-htkconf</b> will be evaluated first as described above.
<div class="Pp"></div>
<b> -smpPeriod </b> <i>period</i>
<div style="margin-left: 3.00ex;">Sampling period of input speech, in unit of
  100 nanoseconds. Sampling rate can also be specified by <b>-smpFreq</b>.
  Please note that the input frequency should be set equal to the training
  conditions of AM. (default: 625, corresponds to 16,000Hz)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option SOURCERATE. The same value can be
  given to this option.
<div style="height: 1.00em;">&#x00A0;</div>
When using multiple AM, this value should be the same among all AMs.</div>
<div class="Pp"></div>
<b> -smpFreq </b> <i>Hz</i>
<div style="margin-left: 3.00ex;">Set sampling frequency of input speech in Hz.
  Sampling rate can also be specified using <b>-smpPeriod</b>. Please note that
  this frequency should be set equal to the training conditions of AM. (default:
  16,000)
<div style="height: 1.00em;">&#x00A0;</div>
When using multiple AM, this value should be the same among all AMs.</div>
<div class="Pp"></div>
<b> -fsize </b> <i>sample_num</i>
<div style="margin-left: 3.00ex;">Window size in number of samples. (default:
  400)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option WINDOWSIZE, but value should be in
  samples (HTK value / smpPeriod).
<div style="height: 1.00em;">&#x00A0;</div>
When using multiple AM, this value should be the same among all AMs.</div>
<div class="Pp"></div>
<b> -fshift </b> <i>sample_num</i>
<div style="margin-left: 3.00ex;">Frame shift in number of samples. (default:
  160)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option TARGETRATE, but value should be in
  samples (HTK value / smpPeriod).
<div style="height: 1.00em;">&#x00A0;</div>
When using multiple AM, this value should be the same among all AMs.</div>
<div class="Pp"></div>
<b> -preemph </b> <i>float</i>
<div style="margin-left: 3.00ex;">Pre-emphasis coefficient. (default: 0.97)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option PREEMCOEF. The same value can be given
  to this option.</div>
<div class="Pp"></div>
<b> -fbank </b> <i>num</i>
<div style="margin-left: 3.00ex;">Number of filterbank channels. (default: 24)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option NUMCHANS. The same value can be given
  to this option. Be aware that the default value not the same as in HTK
  (22).</div>
<div class="Pp"></div>
<b> -ceplif </b> <i>num</i>
<div style="margin-left: 3.00ex;">Cepstral liftering coefficient. (default: 22)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option CEPLIFTER. The same value can be given
  to this option.</div>
<div class="Pp"></div>
<b> -rawe </b>, <b> -norawe </b>
<div style="margin-left: 3.00ex;">Enable/disable using raw energy before
  pre-emphasis (default: disabled)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option RAWENERGY. Be aware that the default
  value differs from HTK (enabled at HTK, disabled at Julius).</div>
<div class="Pp"></div>
<b> -enormal </b>, <b> -noenormal </b>
<div style="margin-left: 3.00ex;">Enable/disable normalizing log energy. On live
  input, this normalization will be approximated from the average of last input.
  (default: disabled)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option ENORMALISE. Be aware that the default
  value differs from HTK (enabled at HTK, disabled at Julius).</div>
<div class="Pp"></div>
<b> -escale </b> <i>float_scale</i>
<div style="margin-left: 3.00ex;">Scaling factor of log energy when normalizing
  log energy. (default: 1.0)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option ESCALE. Be aware that the default
  value differs from HTK (0.1).</div>
<div class="Pp"></div>
<b> -silfloor </b> <i>float</i>
<div style="margin-left: 3.00ex;">Energy silence floor in dB when normalizing
  log energy. (default: 50.0)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option SILFLOOR.</div>
<div class="Pp"></div>
<b> -delwin </b> <i>frame</i>
<div style="margin-left: 3.00ex;">Delta window size in number of frames.
  (default: 2)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option DELTAWINDOW. The same value can be
  given to this option.</div>
<div class="Pp"></div>
<b> -accwin </b> <i>frame</i>
<div style="margin-left: 3.00ex;">Acceleration window size in number of frames.
  (default: 2)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option ACCWINDOW. The same value can be given
  to this option.</div>
<div class="Pp"></div>
<b> -hifreq </b> <i>Hz</i>
<div style="margin-left: 3.00ex;">Enable band-limiting for MFCC filterbank
  computation: set upper frequency cut-off. Value of -1 will disable it.
  (default: -1)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option HIFREQ. The same value can be given to
  this option.</div>
<div class="Pp"></div>
<b> -lofreq </b> <i>Hz</i>
<div style="margin-left: 3.00ex;">Enable band-limiting for MFCC filterbank
  computation: set lower frequency cut-off. Value of -1 will disable it.
  (default: -1)
<div style="height: 1.00em;">&#x00A0;</div>
This option corresponds to the HTK Option LOFREQ. The same value can be given to
  this option.</div>
<div class="Pp"></div>
<b> -zmeanframe </b>, <b> -nozmeanframe </b>
<div style="margin-left: 3.00ex;">With speech input, this option
  enables/disables frame-wise DC offset removal. This corresponds to HTK
  configuration ZMEANSOURCE. This cannot be used together with <b>-zmean</b>.
  (default: disabled)</div>
<div class="Pp"></div>
<b> -usepower </b>
<div style="margin-left: 3.00ex;">Use power instead of magnitude on filterbank
  analysis. (default: disabled)</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Normalization</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
Julius can perform cepstral mean normalization (CMN) for inputs. CMN will be
  activated when the given AM was trained with CMN (i.e. has &quot;_Z&quot;
  qualifier in the header).
<div class="Pp"></div>
The cepstral mean will be estimated in different way according to the input
  type. On file input, the mean will be computed from the whole input. On live
  input such as microphone and network input, the ceptral mean of the input is
  unknown at the start. So MAP-CMN will be used. On MAP-CMN, an initial mean
  vector will be applied at the beginning, and the mean vector will be smeared
  to the mean of the incrementing input vector as input goes. Options below can
  control the behavior of MAP-CMN.
<div class="Pp"></div>
<b> -cvn </b>
<div style="margin-left: 3.00ex;">Enable cepstral variance normalization. At
  file input, the variance of whole input will be calculated and then applied.
  At live microphone input, variance of the last input will be applied. CVN is
  only supported for an audio input.</div>
<div class="Pp"></div>
<b> -vtln </b> <i>alpha</i> <i>lowcut</i> <i>hicut</i>
<div style="margin-left: 3.00ex;">Do frequency warping, typically for a vocal
  tract length normalization (VTLN). Arguments are warping factor, high
  frequency cut-off and low freq. cut-off. They correspond to HTK Config values,
  WARPFREQ, WARPHCUTOFF and WARPLCUTOFF.</div>
<div class="Pp"></div>
<b> -cmnload </b> <i>file</i>
<div style="margin-left: 3.00ex;">Load initial cepstral mean vector from file on
  startup. The <i>file</i> should be one saved by <b>-cmnsave</b>. Loading an
  initial cepstral mean enables Julius to better recognize the first utterance
  on a real-time input. When used together with <b>-cmnnoupdate</b>, this
  initial value will be used for all input.</div>
<div class="Pp"></div>
<b> -cmnsave </b> <i>file</i>
<div style="margin-left: 3.00ex;">Save the calculated cepstral mean vector into
  <i>file</i>. The parameters will be saved at each input end. If the output
  file already exists, it will be overridden.</div>
<div class="Pp"></div>
<b> -cmnupdate </b> <b> -cmnnoupdate </b>
<div style="margin-left: 3.00ex;">Control whether to update the cepstral mean at
  each input on real-time input. Disabling this and specifying <b>-cmnload</b>
  will make engine to always use the loaded static initial cepstral mean.</div>
<div class="Pp"></div>
<b> -cmnmapweight </b> <i>float</i>
<div style="margin-left: 3.00ex;">Specify the weight of initial cepstral mean
  for MAP-CMN. Specify larger value to retain the initial cepstral mean for a
  longer period, and smaller value to make the cepstral mean rely more on the
  current input. (default: 100.0)</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Front-end processing</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
Julius can perform spectral subtraction to reduce some stationary noise from
  audio input. Though it is not a powerful method, but it may work on some
  situation. Julius has two ways to estimate noise spectrum. One way is to
  assume that the first short segment of an speech input is noise segment, and
  estimate the noise spectrum as the average of the segment. Another way is to
  calculate average spectrum from noise-only input using other tool mkss, and
  load it in Julius. The former one is popular for speech file input, and latter
  should be used in live input. The options below will switch / control the
  behavior.
<div class="Pp"></div>
<b> -sscalc </b>
<div style="margin-left: 3.00ex;">Perform spectral subtraction using head part
  of each file as silence part. The head part length should be specified by
  <b>-sscalclen</b>. Valid only for file input. Conflict with
  <b>-ssload</b>.</div>
<div class="Pp"></div>
<b> -sscalclen </b> <i>msec</i>
<div style="margin-left: 3.00ex;">With <b>-sscalc</b>, specify the length of
  head silence for noise spectrum estimation in milliseconds. (default:
  300)</div>
<div class="Pp"></div>
<b> -ssload </b> <i>file</i>
<div style="margin-left: 3.00ex;">Perform spectral subtraction for speech input
  using pre-estimated noise spectrum loaded from <i>file</i>. The noise spectrum
  file can be made by mkss. Valid for all speech input. Conflict with
  <b>-sscalc</b>.</div>
<div class="Pp"></div>
<b> -ssalpha </b> <i>float</i>
<div style="margin-left: 3.00ex;">Alpha coefficient of spectral subtraction for
  <b>-sscalc</b> and <b>-ssload</b>. Noise will be subtracted stronger as this
  value gets larger, but distortion of the resulting signal also becomes
  remarkable. (default: 2.0)</div>
<div class="Pp"></div>
<b> -ssfloor </b> <i>float</i>
<div style="margin-left: 3.00ex;">Flooring coefficient of spectral subtraction.
  The spectral power that goes below zero after subtraction will be substituted
  by the source signal with this coefficient multiplied. (default: 0.5)</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Misc. AM options</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -htkconf </b> <i>file</i>
<div style="margin-left: 3.00ex;">Parse the given HTK Config file, and set
  corresponding parameters to Julius. When using this option, the default
  parameter values are switched from Julius defaults to HTK defaults.</div>
</div>
<h2 class="Ss" title="Ss" id="Recognition_process_and_search_(-SR)"><a class="selflink" href="#Recognition_process_and_search_(-SR)">Recognition
  process and search ( <b>-SR</b>)</a></h2>
This section contains options for search parameters on the 1st / 2nd pass such
  as beam width and LM weights, configurations for short-pause segmentation,
  switches for word lattice output and confusion network output, forced
  alignments, and other options relating recognition process and result output.
<div class="Pp"></div>
Default values for beam width and LM weights will change according to
  compile-time setup of JuliusLib , AM model type, and LM size. Please see the
  startup log for the actual values.
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>1st pass parameters</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -lmp </b> <i>weight</i> <i>penalty</i>
<div style="margin-left: 3.00ex;">(N-gram) Language model weights and word
  insertion penalties for the first pass.</div>
<div class="Pp"></div>
<b> -penalty1 </b> <i>penalty</i>
<div style="margin-left: 3.00ex;">(Grammar) word insertion penalty for the first
  pass. (default: 0.0)</div>
<div class="Pp"></div>
<b> -b </b> <i>width</i>
<div style="margin-left: 3.00ex;">Beam width in number of HMM nodes for rank
  beaming on the first pass. This value defines search width on the 1st pass,
  and has dominant effect on the total processing time. Smaller width will speed
  up the decoding, but too small value will result in a substantial increase of
  recognition errors due to search failure. Larger value will make the search
  stable and will lead to failure-free search, but processing time will grow in
  proportion to the width.
<div style="height: 1.00em;">&#x00A0;</div>
The default value is dependent on acoustic model type: 400 (monophone), 800
  (triphone), or 1000 (triphone, setup=v2.1)</div>
<div class="Pp"></div>
<b> -nlimit </b> <i>num</i>
<div style="margin-left: 3.00ex;">Upper limit of token per node. This option is
  valid when --enable-wpair and --enable-wpair-nlimit are enabled at compilation
  time.</div>
<div class="Pp"></div>
<b> -progout </b>
<div style="margin-left: 3.00ex;">Enable progressive output of the partial
  results on the first pass.</div>
<div class="Pp"></div>
<b> -proginterval </b> <i>msec</i>
<div style="margin-left: 3.00ex;">Set the time interval for <b>-progout</b> in
  milliseconds. (default: 300)</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>2nd pass parameters</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -lmp2 </b> <i>weight</i> <i>penalty</i>
<div style="margin-left: 3.00ex;">(N-gram) Language model weights and word
  insertion penalties for the second pass.</div>
<div class="Pp"></div>
<b> -penalty2 </b> <i>penalty</i>
<div style="margin-left: 3.00ex;">(Grammar) word insertion penalty for the
  second pass. (default: 0.0)</div>
<div class="Pp"></div>
<b> -b2 </b> <i>width</i>
<div style="margin-left: 3.00ex;">Envelope beam width (number of hypothesis) at
  the second pass. If the count of word expansion at a certain hypothesis length
  reaches this limit while search, shorter hypotheses are not expanded further.
  This prevents search to fall in breadth-first-like situation stacking on the
  same position, and improve search failure mostly for large vocabulary
  condition. (default: 30)</div>
<div class="Pp"></div>
<b> -sb </b> <i>float</i>
<div style="margin-left: 3.00ex;">Score envelope width for enveloped scoring.
  When calculating hypothesis score for each generated hypothesis, its trellis
  expansion and Viterbi operation will be pruned in the middle of the speech if
  score on a frame goes under the width. Giving small value makes the second
  pass faster, but computation error may occur. (default: 80.0)</div>
<div class="Pp"></div>
<b> -s </b> <i>num</i>
<div style="margin-left: 3.00ex;">Stack size, i.e. the maximum number of
  hypothesis that can be stored on the stack during the search. A larger value
  may give more stable results, but increases the amount of memory required.
  (default: 500)</div>
<div class="Pp"></div>
<b> -m </b> <i>count</i>
<div style="margin-left: 3.00ex;">Number of expanded hypotheses required to
  discontinue the search. If the number of expanded hypotheses is greater then
  this threshold then, the search is discontinued at that point. The larger this
  value is, The longer Julius gets to give up search. (default: 2000)</div>
<div class="Pp"></div>
<b> -n </b> <i>num</i>
<div style="margin-left: 3.00ex;">The number of candidates Julius tries to find.
  The search continues till this number of sentence hypotheses have been found.
  The obtained sentence hypotheses are sorted by score, and final result is
  displayed in the order (see also the <b>-output</b>). The possibility that the
  optimum hypothesis is correctly found increases as this value gets increased,
  but the processing time also becomes longer. The default value depends on the
  engine setup on compilation time: 10 (standard) or 1 (fast or v2.1)</div>
<div class="Pp"></div>
<b> -output </b> <i>num</i>
<div style="margin-left: 3.00ex;">The top N sentence hypothesis to be output at
  the end of search. Use with <b>-n</b> (default: 1)</div>
<div class="Pp"></div>
<b> -lookuprange </b> <i>frame</i>
<div style="margin-left: 3.00ex;">Set the number of frames before and after to
  look up next word hypotheses in the word trellis on the second pass. This
  prevents the omission of short words, but with a large value, the number of
  expanded hypotheses increases and system becomes slow. (default: 5)</div>
<div class="Pp"></div>
<b> -looktrellis </b>
<div style="margin-left: 3.00ex;">(Grammar) Expand only the words survived on
  the first pass instead of expanding all the words predicted by grammar. This
  option makes second pass decoding faster especially for large vocabulary
  condition, but may increase deletion error of short words. (default:
  disabled)</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Short-pause segmentation / decoder-VAD</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
When compiled with --enable-decoder-vad, the short-pause segmentation will be
  extended to support decoder-based VAD.
<div class="Pp"></div>
<b> -spsegment </b>
<div style="margin-left: 3.00ex;">Enable short-pause segmentation mode. Input
  will be segmented when a short pause word (word with only silence model in
  pronunciation) gets the highest likelihood at certain successive frames on the
  first pass. When detected segment end, Julius stop the 1st pass at the point,
  perform 2nd pass, and continue with next segment. The word context will be
  considered among segments. (Rev.4.0)
<div style="height: 1.00em;">&#x00A0;</div>
When compiled with --enable-decoder-vad, this option enables decoder-based VAD,
  to skip long silence.</div>
<div class="Pp"></div>
<b> -spdur </b> <i>frame</i>
<div style="margin-left: 3.00ex;">Short pause duration length to detect end of
  input segment, in number of frames. (default: 10)</div>
<div class="Pp"></div>
<b> -pausemodels </b> <i>string</i>
<div style="margin-left: 3.00ex;">A comma-separated list of pause model names to
  be used at short-pause segmentation. The word whose pronunciation consists of
  only the pause models will be treated as &quot;pause word&quot; and used for
  pause detection. If not specified, name of <b>-spmodel</b>, <b>-silhead</b>
  and <b>-siltail</b> will be used. (Rev.4.0)</div>
<div class="Pp"></div>
<b> -spmargin </b> <i>frame</i>
<div style="margin-left: 3.00ex;">Back step margin at trigger up for
  decoder-based VAD. When speech up-trigger found by decoder-VAD, Julius will
  rewind the input parameter by this value, and start recognition at the point.
  (Rev.4.0)
<div style="height: 1.00em;">&#x00A0;</div>
This option will be valid only if compiled with --enable-decoder-vad.</div>
<div class="Pp"></div>
<b> -spdelay </b> <i>frame</i>
<div style="margin-left: 3.00ex;">Trigger decision delay frame at trigger up for
  decoder-based VAD. (Rev.4.0)
<div style="height: 1.00em;">&#x00A0;</div>
This option will be valid only if compiled with --enable-decoder-vad.</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Word lattice / confusion network output</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -lattice </b>, <b> -nolattice </b>
<div style="margin-left: 3.00ex;">Enable / disable generation of word graph.
  Search algorithm also has changed to optimize for better word graph
  generation, so the sentence result may not be the same as normal N-best
  recognition. (Rev.4.0)</div>
<div class="Pp"></div>
<b> -confnet </b>, <b> -noconfnet </b>
<div style="margin-left: 3.00ex;">Enable / disable generation of confusion
  network. Enabling this will also activates <b>-lattice</b> internally.
  (Rev.4.0)</div>
<div class="Pp"></div>
<b> -graphrange </b> <i>frame</i>
<div style="margin-left: 3.00ex;">Merge same words at neighbor position at graph
  generation. If the beginning time and ending time of two word candidates of
  the same word is within the specified range, they will be merged. The default
  is 0 (allow merging same words on exactly the same location) and specifying
  larger value will result in smaller graph output. Setting this value to -1
  will disable merging, in that case same words on the same location of
  different scores will be left as they are. (default: 0)</div>
<div class="Pp"></div>
<b> -graphcut </b> <i>depth</i>
<div style="margin-left: 3.00ex;">Cut the resulting graph by its word depth at
  post-processing stage. The depth value is the number of words to be allowed at
  a frame. Setting to -1 disables this feature. (default: 80)</div>
<div class="Pp"></div>
<b> -graphboundloop </b> <i>count</i>
<div style="margin-left: 3.00ex;">Limit the number of boundary adjustment loop
  at post-processing stage. This parameter prevents Julius from blocking by
  infinite adjustment loop by short word oscillation. (default: 20)</div>
<div class="Pp"></div>
<b> -graphsearchdelay </b>, <b> -nographsearchdelay </b>
<div style="margin-left: 3.00ex;">When this option is enabled, Julius modifies
  its graph generation algorithm on the 2nd pass not to terminate search by
  graph merging, until the first sentence candidate is found. This option may
  improve graph accuracy, especially when you are going to generate a huge word
  graph by setting broad search. Namely, it may result in better graph accuracy
  when you set wide beams on both 1st pass <b>-b</b> and 2nd pass <b>-b2</b>,
  and large number for <b>-n</b>. (default: disabled)</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Multi-gram / multi-dic recognition</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -multigramout </b>, <b> -nomultigramout </b>
<div style="margin-left: 3.00ex;">On grammar recognition using multiple
  grammars, Julius will output only the best result among all grammars. Enabling
  this option will make Julius to output result for each grammar. (default:
  disabled)</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Forced alignment</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -walign </b>
<div style="margin-left: 3.00ex;">Do viterbi alignment per word units for the
  recognition result. The word boundary frames and the average acoustic scores
  per frame will be calculated.</div>
<div class="Pp"></div>
<b> -palign </b>
<div style="margin-left: 3.00ex;">Do viterbi alignment per phone units for the
  recognition result. The phone boundary frames and the average acoustic scores
  per frame will be calculated.</div>
<div class="Pp"></div>
<b> -salign </b>
<div style="margin-left: 3.00ex;">Do viterbi alignment per state for the
  recognition result. The state boundary frames and the average acoustic scores
  per frame will be calculated.</div>
</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<b>Misc. search options</b>
<div>&#x00A0;</div>
<div style="margin-left: 5.00ex;">
<div class="Pp"></div>
<b> -inactive </b>
<div style="margin-left: 3.00ex;">Start this recognition process instance with
  inactive state. (Rev.4.0)</div>
<div class="Pp"></div>
<b> -1pass </b>
<div style="margin-left: 3.00ex;">Perform only the first pass.</div>
<div class="Pp"></div>
<b> -fallback1pass </b>
<div style="margin-left: 3.00ex;">When 2nd pass fails, Julius finish the
  recognition with no result. This option tell Julius to output the 1st pass
  result as a final result when the 2nd pass fails. Note that some score output
  (confidence etc.) may not be useful. This was the default behavior of
  Julius-3.x.</div>
<div class="Pp"></div>
<b> -no_ccd </b>, <b> -force_ccd </b>
<div style="margin-left: 3.00ex;">Explicitly switch phone context handling at
  search. Normally Julius determines whether the using AM is a context-dependent
  model or not from the model names, i.e., whether the names contain character +
  and -. This option will override the automatic detection.</div>
<div class="Pp"></div>
<b> -cmalpha </b> <i>float</i>
<div style="margin-left: 3.00ex;">Smoothing parameter for confidence scoring.
  (default: 0.05)</div>
<div class="Pp"></div>
<b> -iwsp </b>
<div style="margin-left: 3.00ex;">(Multi-path mode only) Enable inter-word
  context-free short pause insertion. This option appends a skippable short
  pause model for every word end. The short-pause model can be specified by
  <b>-spmodel</b>.</div>
<div class="Pp"></div>
<b> -transp </b> <i>float</i>
<div style="margin-left: 3.00ex;">Additional insertion penalty for transparent
  words. (default: 0.0)</div>
<div class="Pp"></div>
<b> -demo </b>
<div style="margin-left: 3.00ex;">Equivalent to <b>-progout -quiet</b>.</div>
</div>
<h1 class="Sh" title="Sh" id="ENVIRONMENT_VARIABLES"><a class="selflink" href="#ENVIRONMENT_VARIABLES">ENVIRONMENT
  VARIABLES</a></h1>
<b> </b><b></b><b>ALSADEV</b><b> </b>
<div style="margin-left: 3.00ex;">(using mic input with alsa device) specify a
  capture device name. If not specified, &quot;default&quot; will be used.</div>
<div class="Pp"></div>
<b> </b><b></b><b>AUDIODEV</b><b> </b>
<div style="margin-left: 3.00ex;">(using mic input with oss device) specify a
  capture device path. If not specified, &quot; <i>/dev/dsp</i>&quot; will be
  used.</div>
<div class="Pp"></div>
<b> </b><b></b><b>LATENCY_MSEC</b><b> </b>
<div style="margin-left: 3.00ex;">Try to set input latency of microphone input
  in milliseconds. Smaller value will shorten latency but sometimes make process
  unstable. Default value will depend on the running OS.</div>
<h1 class="Sh" title="Sh" id="EXAMPLES"><a class="selflink" href="#EXAMPLES">EXAMPLES</a></h1>
For examples of system usage, refer to the tutorial section in the Julius
  documents.
<h1 class="Sh" title="Sh" id="NOTICE"><a class="selflink" href="#NOTICE">NOTICE</a></h1>
Note about jconf files: relative paths in a jconf file are interpreted as
  relative to the jconf file itself, not to the current directory.
<h1 class="Sh" title="Sh" id="SEE_ALSO"><a class="selflink" href="#SEE_ALSO">SEE
  ALSO</a></h1>
<b>julian</b>(1), <b>jcontrol</b>(1), <b>adinrec</b>(1), <b>adintool</b>(1),
  <b>mkbingram</b>(1), <b>mkbinhmm</b>(1), <b>mkgsmm</b>(1), wav2<b>mfcc</b>(1),
  <b>mkss</b>(1)
<div class="Pp"></div>
<i>http://julius.sourceforge.jp/en/</i>
<h1 class="Sh" title="Sh" id="DIAGNOSTICS"><a class="selflink" href="#DIAGNOSTICS">DIAGNOSTICS</a></h1>
Julius normally will return the exit status 0. If an error occurs, Julius exits
  abnormally with exit status 1. If an input file cannot be found or cannot be
  loaded for some reason then Julius will skip processing for that file.
<h1 class="Sh" title="Sh" id="BUGS"><a class="selflink" href="#BUGS">BUGS</a></h1>
There are some restrictions to the type and size of the models Julius can use.
  For a detailed explanation refer to the Julius documentation. For bug-reports,
  inquires and comments please contact julius-info at lists.sourceforge.jp.
<h1 class="Sh" title="Sh" id="COPYRIGHT"><a class="selflink" href="#COPYRIGHT">COPYRIGHT</a></h1>
Copyright (c) 1991-2008 Kawahara Lab., Kyoto University
<div class="Pp"></div>
Copyright (c) 1997-2000 Information-technology Promotion Agency, Japan
<div class="Pp"></div>
Copyright (c) 2000-2008 Shikano Lab., Nara Institute of Science and Technology
<div class="Pp"></div>
Copyright (c) 2005-2008 Julius project team, Nagoya Institute of Technology
<h1 class="Sh" title="Sh" id="AUTHORS"><a class="selflink" href="#AUTHORS">AUTHORS</a></h1>
Rev.1.0 (1998/02/20)
<div style="margin-left: 3.00ex;">Designed by Tatsuya KAWAHARA and Akinobu LEE
  (Kyoto University)
<div style="height: 1.00em;">&#x00A0;</div>
Development by Akinobu LEE (Kyoto University)</div>
<div class="Pp"></div>
Rev.1.1 (1998/04/14), Rev.1.2 (1998/10/31), Rev.2.0 (1999/02/20), Rev.2.1
  (1999/04/20), Rev.2.2 (1999/10/04), Rev.3.0 (2000/02/14), Rev.3.1 (2000/05/11)
<div style="margin-left: 3.00ex;">Development of above versions by Akinobu LEE
  (Kyoto University)</div>
<div class="Pp"></div>
Rev.3.2 (2001/08/15), Rev.3.3 (2002/09/11), Rev.3.4 (2003/10/01), Rev.3.4.1
  (2004/02/25), Rev.3.4.2 (2004/04/30)
<div style="margin-left: 3.00ex;">Development of above versions by Akinobu LEE
  (Nara Institute of Science and Technology)</div>
<div class="Pp"></div>
Rev.3.5 (2005/11/11), Rev.3.5.1 (2006/03/31), Rev.3.5.2 (2006/07/31), Rev.3.5.3
  (2006/12/29), Rev.4.0 (2007/12/19), Rev.4.1 (2008/10/03)
<div style="margin-left: 3.00ex;">Development of above versions by Akinobu LEE
  (Nagoya Institute of Technology)</div>
<h1 class="Sh" title="Sh" id="THANKS_TO"><a class="selflink" href="#THANKS_TO">THANKS
  TO</a></h1>
From rev.3.2, Julius is released by the &quot;Information Processing Society,
  Continuous Speech Consortium&quot;.
<div class="Pp"></div>
The Windows DLL version was developed and released by Hideki BANNO (Nagoya
  University).
<div class="Pp"></div>
The Windows Microsoft Speech API compatible version was developed by Takashi
  SUMIYOSHI (Kyoto University).</div>
<table class="foot">
  <tr>
    <td class="foot-date">02/11/2009</td>
    <td class="foot-os"></td>
  </tr>
</table>
</body>
</html>
