<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 16:20:08 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>julius</p>

<p style="margin-top: 1em">JULIUS(1) JULIUS(1)</p>

<p style="margin-top: 1em">NAME <br>
julius <br>
- open source multi-purpose LVCSR engine</p>

<p style="margin-top: 1em">SYNOPSIS <br>
julius [-C jconffile] [options...]</p>

<p style="margin-top: 1em">DESCRIPTION <br>
julius is a high-performance, multi-purpose, open-source
speech recognition engine for researchers and developers. It
is capable of performing almost real-time recognition of
<br>
continuous speech with over 60k-word 3-gram language model
and triphone HMM model, on most current PCs. julius can
perform recognition on audio files, live microphone input,
<br>
network input and feature parameter files.</p>

<p style="margin-top: 1em">The core recognition module is
implemented as C library called &quot;JuliusLib&quot;. It
can also be extended by plug-in facility.</p>

<p style="margin-top: 1em">Supported Models <br>
julius needs a language model and an acoustic model to run
as a speech recognizer. julius supports the following
models.</p>

<p style="margin-top: 1em">Acoustic model <br>
Sub-word HMM (Hidden Markov Model) in HTK ascii format are
supported. Phoneme models (monophone), context dependent
phoneme models (triphone), tied-mixture and phonetic <br>
tied-mixture models of any unit can be used. When using
context dependent models, inter-word context dependency is
also handled. Multi-stream feature and MSD-HMM is also <br>
supported. You can further use a tool mkbinhmm to convert
the ascii HMM file to a compact binary format for faster
loading.</p>

<p style="margin-top: 1em">Note that julius itself can only
extract MFCC features from speech data. If you use acoustic
HMM trained for other feature, you should give the input in
HTK parameter file <br>
of the same feature type.</p>

<p style="margin-top: 1em">Language model: word N-gram <br>
Word N-gram language model, up to 10-gram, is supported.
Julius uses different N-gram for each pass: left-to-right
2-gram on 1st pass, and right-to-left N-gram on 2nd <br>
pass. It is recommended to use both LR 2-gram and RL N-gram
for Julius. However, you can use only single LR N-gram or RL
N-gram. In such case, approximated LR 2-gram <br>
computed from the given N-gram will be applied at the first
pass.</p>

<p style="margin-top: 1em">The Standard ARPA format is
supported. In addition, a binary format is also supported
for efficiency. The tool mkbingram(1) can convert ARPA
format N-gram to binary <br>
format.</p>

<p style="margin-top: 1em">Language model: grammar <br>
The grammar format is an original one, and tools to create a
recognirion grammar are included in the distribution. A
grammar consists of two files: one is a
&rsquo;grammar&rsquo; file <br>
that describes sentence structures in a BNF style, using
word &rsquo;category&rsquo; name as terminate symbols.
Another is a &rsquo;voca&rsquo; file that defines words with
its pronunciations <br>
(i.e. phoneme sequences) for each category. They should be
converted by mkdfa(1) to a deterministic finite automaton
file (.dfa) and a dictionary file (.dict), <br>
respectively. You can also use multiple grammars.</p>

<p style="margin-top: 1em">Language model: isolated word
<br>
You can perform isolated word recognition using only word
dictionary. With this model type, Julius will perform rapid
one pass recognition with static context handling. <br>
Silence models will be added at both head and tail of each
word. You can also use multiple dictionaries in a
process.</p>

<p style="margin-top: 1em">Search Algorithm <br>
Recognition algorithm of julius is based on a two-pass
strategy. Word 2-gram and reverse word 3-gram is used on the
respective passes. The entire input is processed on the
first <br>
pass, and again the final searching process is performed
again for the input, using the result of the first pass to
narrow the search space. Specifically, the recognition <br>
algorithm is based on a tree-trellis heuristic search
combined with left-to-right frame-synchronous beam search
and right-to-left stack decoding search.</p>

<p style="margin-top: 1em">When using context dependent
phones (triphones), interword contexts are taken into
consideration. For tied-mixture and phonetic tied-mixture
models, high-speed acoustic <br>
likelihood calculation is possible using gaussian
pruning.</p>

<p style="margin-top: 1em">For more details, see the
related documents.</p>

<p style="margin-top: 1em">OPTIONS <br>
These options specify the models, system behaviors and
various search parameters to Julius. These option can be set
at the command line, but it is recommended that you write
them <br>
in a text file as a &quot;jconf file&quot;, and specify it
by &quot;-C&quot; option.</p>

<p style="margin-top: 1em">Applications incorporating
JuliusLib also use these options to set the parameters of
core recognition engine. For example, a jconf file can be
loaded to the enine by calling <br>
j_config_load_file_new() with the jconf file name as
argument.</p>

<p style="margin-top: 1em">Please note that relative paths
in a jconf file should be relative to the jconf file itself,
not the current working directory.</p>

<p style="margin-top: 1em">Below are the details of all
options, gathered by group.</p>

<p style="margin-top: 1em">Julius application option <br>
These are application options of Julius, outside of
JuliusLib. It contains parameters and switches for result
output, character set conversion, log level, and module mode
<br>
options. These option are specific to Julius, and cannot be
used at applications using JuliusLib other than Julius.</p>

<p style="margin-top: 1em">-outfile <br>
On file input, this option write the recognition result of
each file to a separate file. The output file of an input
file will be the same name but the suffix will be changed
<br>
to &quot;.out&quot;. (rev.4.0)</p>

<p style="margin-top: 1em">-separatescore <br>
Output the language and acoustic scores separately.</p>

<p style="margin-top: 1em">-callbackdebug <br>
Print the callback names at each call for debug.
(rev.4.0)</p>

<p style="margin-top: 1em">-charconv from to <br>
Print with character set conversion. from is the source
character set used in the language model, and to is the
target character set you want to get.</p>

<p style="margin-top: 1em">On Linux, the arguments should
be a code name. You can obtain the list of available code
names by invoking the command &quot;iconv --list&quot;. On
Windows, the arguments should be a <br>
code name or codepage number. Code name should be one of
&quot;ansi&quot;, &quot;mac&quot;, &quot;oem&quot;,
&quot;utf-7&quot;, &quot;utf-8&quot;, &quot;sjis&quot;,
&quot;euc&quot;. Or you can specify any codepage number
supported at your <br>
environment.</p>

<p style="margin-top: 1em">-nocharconv <br>
Disable character conversion.</p>

<p style="margin-top: 1em">-module [port] <br>
Run Julius on &quot;Server Module Mode&quot;. After startup,
Julius waits for tcp/ip connection from client. Once
connection is established, Julius start communication with
the client <br>
to process incoming commands from the client, or to output
recognition results, input trigger information and other
system status to the client. The default port number is <br>
10500.</p>

<p style="margin-top: 1em">-record dir <br>
Auto-save all input speech data into the specified
directory. Each segmented inputs are recorded each by one.
The file name of the recorded data is generated from system
time <br>
when the input ends, in a style of YYYY.MMDD.HHMMSS.wav.
File format is 16bit monoral WAV. Invalid for mfcfile
input.</p>

<p style="margin-top: 1em">With input rejection by
-rejectshort, the rejected input will also be recorded even
if they are rejected.</p>

<p style="margin-top: 1em">-logfile file <br>
Save all log output to a file instead of standard output.
(Rev.4.0)</p>

<p style="margin-top: 1em">-nolog <br>
Disable all log output. (Rev.4.0)</p>

<p style="margin-top: 1em">-help <br>
Output help message and exit.</p>

<p style="margin-top: 1em">Global options <br>
These are model-/search-dependent options relating audio
input, sound detection, GMM, decoding algorithm, plugin
facility, and others. Global options should be placed before
any <br>
instance declaration (-AM, -LM, or -SR), or just after
&quot;-GLOBAL&quot; option.</p>

<p style="margin-top: 1em">Audio input <br>
-input
{mic|rawfile|mfcfile|adinnet|stdin|netaudio|alsa|oss|esd}
<br>
Choose speech input source. Specify &rsquo;file&rsquo; or
&rsquo;rawfile&rsquo; for waveform file,
&rsquo;htkparam&rsquo; or &rsquo;mfcfile&rsquo; for HTK
parameter file. On file input, users will be prompted to
<br>
enter the file name from stdin, or you can use -filelist
option to specify list of files to process.</p>

<p style="margin-top: 1em">&Acirc;&acute;mic&rsquo; is to
get audio input from a default live microphone device, and
&rsquo;adinnet&rsquo; means receiving waveform data via
tcpip network from an adinnet client. &rsquo;netaudio&rsquo;
is <br>
from DatLink/NetAudio input, and &rsquo;stdin&rsquo; means
data input from standard input.</p>

<p style="margin-top: 1em">For waveform file input, only
WAV (no compression) and RAW (noheader, 16bit, big endian)
are supported by default. Other format can be read when
compiled with libsnd <br>
library. To see what format is actually supported, see the
help message using option -help. For stdin input, only WAV
and RAW is supported. (default: mfcfile)</p>

<p style="margin-top: 1em">At Linux, you can choose API at
run time by specifying alsa, oss and esd.</p>

<p style="margin-top: 1em">-chunk_size samples <br>
Audio fragment size in number of samples. (default:
1000)</p>

<p style="margin-top: 1em">-filelist filename <br>
(With -input rawfile|mfcfile) perform recognition on all
files listed in the file. The file should contain input file
per line. Engine will end when all of the files <br>
are processed.</p>

<p style="margin-top: 1em">-notypecheck <br>
By default, Julius checks the input parameter type whether
it matches the AM or not. This option will disable the check
and force engine to use the input vector as is.</p>

<p style="margin-top: 1em">-48 <br>
Record input with 48kHz sampling, and down-sample it to
16kHz on-the-fly. This option is valid for 16kHz model only.
The down-sampling routine was ported from sptk. <br>
(Rev. 4.0)</p>

<p style="margin-top: 1em">-NA devicename <br>
Host name for DatLink server input (-input netaudio).</p>

<p style="margin-top: 1em">-adport port_number <br>
With -input adinnet, specify adinnet port number to listen.
(default: 5530)</p>

<p style="margin-top: 1em">-nostrip <br>
Julius by default removes successive zero samples in input
speech data. This option inhibits the removal.</p>

<p style="margin-top: 1em">-zmean , -nozmean <br>
This option enables/disables DC offset removal of input
waveform. Offset will be estimated from the whole input. For
microphone / network input, zero mean of the first <br>
48000 samples (3 seconds in 16kHz sampling) will be used for
the estimation. (default: disabled)</p>

<p style="margin-top: 1em">This option uses static offset
for the channel. See also -zmeansource for frame-wise offset
removal.</p>

<p style="margin-top: 1em">Speech detection by level and
zero-cross <br>
-cutsilence , -nocutsilence <br>
Turn on / off the speech detection by level and zero-cross.
Default is on for mic / adinnet input, and off for
files.</p>

<p style="margin-top: 1em">-lv thres <br>
Level threshold for speech input detection. Values should be
in range from 0 to 32767. (default: 2000)</p>

<p style="margin-top: 1em">-zc thres <br>
Zero crossing threshold per second. Only input that goes
over the level threshold (-lv) will be counted. (default:
60)</p>

<p style="margin-top: 1em">-headmargin msec <br>
Silence margin at the start of speech segment in
milliseconds. (default: 300)</p>

<p style="margin-top: 1em">-tailmargin msec <br>
Silence margin at the end of speech segment in milliseconds.
(default: 400)</p>

<p style="margin-top: 1em">Input rejection <br>
Two simple front-end input rejection methods are
implemented, based on input length and average power of
detected segment. The rejection by average power is
experimental, <br>
and can be enabled by --enable-power-reject on compilation.
Valid for MFCC feature with power coefficient and real-time
input only.</p>

<p style="margin-top: 1em">For GMM-based input rejection
see the GMM section below.</p>

<p style="margin-top: 1em">-rejectshort msec <br>
Reject input shorter than specified milliseconds. Search
will be terminated and no result will be output.</p>

<p style="margin-top: 1em">-powerthres thres <br>
Reject the inputted segment by its average energy. If the
average energy of the last recognized input is below the
threshold, Julius will reject the input. (Rev.4.0)</p>

<p style="margin-top: 1em">This option is valid when
--enable-power-reject is specified at compilation time.</p>

<p style="margin-top: 1em">Gaussian mixture model / GMM-VAD
<br>
GMM will be used for input rejection by accumulated score,
or for front-end GMM-based VAD when --enable-gmm-vad is
specified.</p>

<p style="margin-top: 1em">NOTE: You should also set the
proper MFCC parameters required for the GMM, specifying the
acoustic parameters described in AM section -AM_GMM.</p>

<p style="margin-top: 1em">When GMM-based VAD is enabled,
the voice activity score will be calculated at each frame as
front-end processing. The value will be computed as x_{m in
M_v} p(x|m) <br>
- x_{m in M_n} p(x|m) ] where $M_v$ is a set of voice GMM,
and $M_n$ is a set of noise GMM whose names should be
specified by -gmmreject. The activity score will be <br>
then averaged for the last N frames, where N is specified by
-gmmmargin. Julius updates the averaged activity score at
each frame, and detect speech up-trigger when the <br>
value gets higher than a value specified by -gmmup, and
detecgt down-trigger when it gets lower than a value of
-gmmdown.</p>

<p style="margin-top: 1em">-gmm hmmdefs_file <br>
GMM definition file in HTK format. If specified, GMM-based
input verification will be performed concurrently with the
1st pass, and you can reject the input according <br>
to the result as specified by -gmmreject. The GMM should be
defined as one-state HMMs.</p>

<p style="margin-top: 1em">-gmmnum number <br>
Number of Gaussian components to be computed per frame on
GMM calculation. Only the N-best Gaussians will be computed
for rapid calculation. The default is 10 and <br>
specifying smaller value will speed up GMM calculation, but
too small value (1 or 2) may cause degradation of
identification performance.</p>

<p style="margin-top: 1em">-gmmreject string <br>
Comma-separated list of GMM names to be rejected as invalid
input. When recognition, the log likelihoods of GMMs
accumulated for the entire input will be computed <br>
concurrently with the 1st pass. If the GMM name of the
maximum score is within this string, the 2nd pass will not
be executed and the input will be rejected.</p>

<p style="margin-top: 1em">-gmmmargin frames <br>
(GMM_VAD) Head margin in frames. When a speech trigger
detected by GMM, recognition will start from current frame
minus this value. (Rev.4.0)</p>

<p style="margin-top: 1em">This option will be valid only
if compiled with --enable-gmm-vad.</p>

<p style="margin-top: 1em">-gmmup value <br>
(GMM_VAD) Up trigger threshold of voice activity score.
(Rev.4.1)</p>

<p style="margin-top: 1em">This option will be valid only
if compiled with --enable-gmm-vad.</p>

<p style="margin-top: 1em">-gmmdown value <br>
(GMM_VAD) Down trigger threshold of voice activity score.
(Rev.4.1)</p>

<p style="margin-top: 1em">This option will be valid only
if compiled with --enable-gmm-vad.</p>

<p style="margin-top: 1em">Decoding option <br>
Real-time processing means concurrent processing of MFCC
computation 1st pass decoding. By default, real-time
processing on the pass is on for microphone / adinnet / <br>
netaudio input, and for others.</p>

<p style="margin-top: 1em">-realtime , -norealtime <br>
Explicitly switch on / off real-time (pipe-line) processing
on the first pass. The default is off for file input, and on
for microphone, adinnet and NetAudio input. <br>
This option relates to the way CMN and energy normalization
is performed: if off, they will be done using average
features of whole input. If on, MAP-CMN and energy <br>
normalization to do real-time processing.</p>

<p style="margin-top: 1em">Misc. options <br>
-C jconffile <br>
Load a jconf file at here. The content of the jconffile will
be expanded at this point.</p>

<p style="margin-top: 1em">-version <br>
Print version information to standard error, and exit.</p>

<p style="margin-top: 1em">-setting <br>
Print engine setting information to standard error, and
exit.</p>

<p style="margin-top: 1em">-quiet <br>
Output less log. For result, only the best word sequence
will be printed.</p>

<p style="margin-top: 1em">-debug <br>
(For debug) output enormous internal message and debug
information to log.</p>

<p style="margin-top: 1em">-check {wchmm|trellis|triphone}
<br>
For debug, enter interactive check mode.</p>

<p style="margin-top: 1em">-plugindir dirlist <br>
Specify directory to load plugin. If several direcotries
exist, specify them by colon-separated list.</p>

<p style="margin-top: 1em">Instance declaration for multi
decoding <br>
The following arguments will create a new configuration set
with default parameters, and switch current set to it. Jconf
parameters specified after the option will be set into <br>
the current set.</p>

<p style="margin-top: 1em">To do multi-model decoding,
these argument should be specified at the first of each
model / search instances with different names. Any options
before the first instance <br>
definition will be IGNORED.</p>

<p style="margin-top: 1em">When no instance definition is
found (as older version of Julius), all the options are
assigned to a default instance named _default.</p>

<p style="margin-top: 1em">Please note that decoding with a
single LM and multiple AMs is not fully supported. For
example, you may want to construct the jconf file as
following. <br>
This type of model sharing is not supported yet, since some
part of LM processing depends on the assigned AM. Instead,
you can get the same result by defining the same LMs for
<br>
each AM, like this:</p>

<p style="margin-top: 1em">-AM name <br>
Create a new AM configuration set, and switch current to the
new one. You should give a unique name. (Rev.4.0)</p>

<p style="margin-top: 1em">-LM name <br>
Create a new LM configuration set, and switch current to the
new one. You should give a unique name. (Rev.4.0)</p>

<p style="margin-top: 1em">-SR name am_name lm_name <br>
Create a new search configuration set, and switch current to
the new one. The specified AM and LM will be assigned to it.
The am_name and lm_name can be either name or ID <br>
number. You should give a unique name. (Rev.4.0)</p>

<p style="margin-top: 1em">-AM_GMM <br>
When using GMM for front-end processing, you can specify
GMM-specific acoustic parameters after this option. If you
does not specify -AM_GMM with GMM, the GMM will share the
<br>
same parameter vector as the last AM. The current AM will be
switched to the GMM one, so be careful not to confuse with
normal AM configurations. (Rev.4.0)</p>

<p style="margin-top: 1em">-GLOBAL <br>
Start a global section. The global options should be placed
before any instance declaration, or after this option on
multiple model recognition. This can be used multiple <br>
times. (Rev.4.1)</p>

<p style="margin-top: 1em">-nosectioncheck , -sectioncheck
<br>
Disable / enable option location check in multi-model
decoding. When enabled, the options between instance
declaration is treated as &quot;sections&quot; and only the
belonging option <br>
types can be written. For example, when an option -AM is
specified, only the AM related option can be placed after
the option until other declaration is found. Also, global
<br>
options should be placed at top, before any instance
declarataion. This is enabled by default. (Rev.4.1)</p>

<p style="margin-top: 1em">Language model (-LM) <br>
This group contains options for model definition of each
language model type. When using multiple LM, one instance
can have only one LM.</p>

<p style="margin-top: 1em">Only one type of LM can be
specified for a LM configuration. If you want to use multi
model, you should define them one as a new LM.</p>

<p style="margin-top: 1em">N-gram <br>
-d bingram_file <br>
Use binary format N-gram. An ARPA N-gram file can be
converted to Julius binary format by mkbingram.</p>

<p style="margin-top: 1em">-nlr arpa_ngram_file <br>
A forward, left-to-right N-gram language model in standard
ARPA format. When both a forward N-gram and backward N-gram
are specified, Julius uses this forward 2-gram <br>
for the 1st pass, and the backward N-gram for the 2nd
pass.</p>

<p style="margin-top: 1em">Since ARPA file often gets huge
and requires a lot of time to load, it may be better to
convert the ARPA file to Julius binary format by mkbingram.
Note that if both <br>
forward and backward N-gram is used for recognition, they
together will be converted to a single binary.</p>

<p style="margin-top: 1em">When only a forward N-gram is
specified by this option and no backward N-gram specified by
-nrl, Julius performs recognition with only the forward
N-gram. The 1st pass <br>
will use the 2-gram entry in the given N-gram, and The 2nd
pass will use the given N-gram, with converting forward
probabilities to backward probabilities by Bayes <br>
rule. (Rev.4.0)</p>

<p style="margin-top: 1em">-nrl arpa_ngram_file <br>
A backward, right-to-left N-gram language model in standard
ARPA format. When both a forward N-gram and backward N-gram
are specified, Julius uses the forward 2-gram <br>
for the 1st pass, and this backward N-gram for the 2nd
pass.</p>

<p style="margin-top: 1em">Since ARPA file often gets huge
and requires a lot of time to load, it may be better to
convert the ARPA file to Julius binary format by mkbingram.
Note that if both <br>
forward and backward N-gram is used for recognition, they
together will be converted to a single binary.</p>

<p style="margin-top: 1em">When only a backward N-gram is
specified by this option and no forward N-gram specified by
-nlr, Julius performs recognition with only the backward
N-gram. The 1st pass <br>
will use the forward 2-gram probability computed from the
backward 2-gram using Bayes rule. The 2nd pass fully use the
given backward N-gram. (Rev.4.0)</p>

<p style="margin-top: 1em">-v dict_file <br>
Word dictionary file.</p>

<p style="margin-top: 1em">-silhead word_string -siltail
word_string <br>
Silence word defined in the dictionary, for silences at the
beginning of sentence and end of sentence. (default:
&quot;&lt;s&gt;&quot;, &quot;&lt;/s&gt;&quot;)</p>

<p style="margin-top: 1em">-mapunk word_string <br>
Specify unknown word. Default is &quot;&lt;unk&gt;&quot; or
&quot;&lt;UNK&gt;&quot;. This will be used to assign word
probability on unknown words, i.e. words in dictionary that
are not in N-gram <br>
vocabulary.</p>

<p style="margin-top: 1em">-iwspword <br>
Add a word entry to the dictionary that should correspond to
inter-word pauses. This may improve recognition accuracy in
some language model that has no explicit <br>
inter-word pause modeling. The word entry to be added can be
changed by -iwspentry.</p>

<p style="margin-top: 1em">-iwspentry word_entry_string
<br>
Specify the word entry that will be added by -iwspword.
(default: &quot;&lt;UNK&gt; [sp] sp sp&quot;)</p>

<p style="margin-top: 1em">-sepnum number <br>
Number of high frequency words to be isolated from the
lexicon tree, to ease approximation error that may be caused
by the one-best approximation on 1st pass. (default: <br>
150)</p>

<p style="margin-top: 1em">Grammar <br>
Multiple grammars can be specified by repeating -gram and
-gramlist. Note that this is unusual behavior from other
options (in normal Julius option, last one will override
<br>
previous ones). You can use -nogram to reset the grammars
already specified before the point.</p>

<p style="margin-top: 1em">-gram
gramprefix1[,gramprefix2[,gramprefix3,...]] <br>
Comma-separated list of grammars to be used. the argument
should be a prefix of a grammar, i.e. if you have foo.dfa
and foo.dict, you should specify them with a single <br>
argument foo. Multiple grammars can be specified at a time
as a comma-separated list.</p>

<p style="margin-top: 1em">-gramlist list_file <br>
Specify a grammar list file that contains list of grammars
to be used. The list file should contain the prefixes of
grammars, each per line. A relative path in the list <br>
file will be treated as relative to the file, not the
current path or configuration file.</p>

<p style="margin-top: 1em">-dfa dfa_file -v dict_file <br>
An old way of specifying grammar files separately. This is
bogus, and should not be used any more.</p>

<p style="margin-top: 1em">-nogram <br>
Remove the current list of grammars already specified by
-gram, -gramlist, -dfa and -v.</p>

<p style="margin-top: 1em">Isolated word <br>
Dictionary can be specified by using -w and -wlist. When you
specify multiple times, all of them will be read at startup.
You can use -nogram to reset the already <br>
specified dictionaries at that point.</p>

<p style="margin-top: 1em">-w dict_file <br>
Word dictionary for isolated word recognition. File format
is the same as other LM. (Rev.4.0)</p>

<p style="margin-top: 1em">-wlist list_file <br>
Specify a dictionary list file that contains list of
dictionaries to be used. The list file should contain the
file name of dictionaries, each per line. A relative path
<br>
in the list file will be treated as relative to the list
file, not the current path or configuration file.
(Rev.4.0)</p>

<p style="margin-top: 1em">-nogram <br>
Remove the current list of dictionaries already specified by
-w and -wlist.</p>

<p style="margin-top: 1em">-wsil head_sil_model_name
tail_sil_model_name sil_context_name <br>
On isolated word recognition, silence models will be
appended to the head and tail of each word at recognition.
This option specifies the silence models to be appended.
<br>
sil_context_name is the name of the head sil model and tail
sil model as a context of word head phone and tail phone.
For example, if you specify -wsil silB silE sp, a <br>
word with phone sequence b eh t will be translated as silB
sp-b+eh b-eh+t eh-t+sp silE. (Rev.4.0)</p>

<p style="margin-top: 1em">User-defined LM <br>
-userlm <br>
Declare to use user LM functions in the program. This option
should be specified if you use user-defined LM functions.
(Rev.4.0)</p>

<p style="margin-top: 1em">Misc. LM options <br>
-forcedict <br>
Skip error words in dictionary and force running.</p>

<p style="margin-top: 1em">Acoustic model and feature
analysis (-AM) (-AM_GMM) <br>
This section is about options for acoustic model, feature
extraction, feature normalizations and spectral
subtraction.</p>

<p style="margin-top: 1em">After -AM name, an acoustic
model and related specification should be written. You can
use multiple AMs trained with different MFCC types. For GMM,
the required parameter <br>
condition should be specified just as same as AMs after
-AM_GMM.</p>

<p style="margin-top: 1em">When using multiple AMs, the
values of -smpPeriod, -smpFreq, -fsize and -fshift should be
the same among all AMs.</p>

<p style="margin-top: 1em">Acoustic HMM <br>
-h hmmdef_file <br>
Acoustic HMM definition file. It should be in HTK ascii
format, or Julius binary format. You can convert HTK ascii
format to Julius binary format using mkbinhmm.</p>

<p style="margin-top: 1em">-hlist hmmlist_file <br>
HMMList file for phone mapping. This file provides mapping
between logical triphone names generated in the dictionary
and the defined HMM names in hmmdefs. This option <br>
should be specified for context-dependent model.</p>

<p style="margin-top: 1em">-tmix number <br>
Specify the number of top Gaussians to be calculated in a
mixture codebook. Small number will speed up the acoustic
computation, but AM accuracy may get worse with too <br>
small value. See also -gprune. (default: 2)</p>

<p style="margin-top: 1em">-spmodel name <br>
Specify HMM model name that corresponds to short-pause in an
utterance. The short-pause model name will be used in
recognition: short-pause skipping on grammar <br>
recognition, word-end short-pause model insertion with -iwsp
on N-gram, or short-pause segmentation (-spsegment).
(default: &quot;sp&quot;)</p>

<p style="margin-top: 1em">-multipath <br>
Enable multi-path mode. To make decoding faster, Julius by
default impose a limit on HMM transitions that each model
should have only one transition from initial state <br>
and to end state. On multi-path mode, Julius does extra
handling on inter-model transition to allows model-skipping
transition and multiple output/input transitions. <br>
Note that specifying this option will make Julius a bit
slower, and the larger beam width may be required.</p>

<p style="margin-top: 1em">This function was a
compilation-time option on Julius 3.x, and now becomes a
run-time option. By default (without this option), Julius
checks the transition type of <br>
specified HMMs, and enable the multi-path mode if required.
You can force multi-path mode with this option.
(rev.4.0)</p>

<p style="margin-top: 1em">-gprune
{safe|heuristic|beam|none|default} <br>
Set Gaussian pruning algorithm to use. For tied-mixture
model, Julius performs Gaussian pruning to reduce acoustic
computation, by calculating only the top N Gaussians <br>
in each codebook at each frame. The default setting will be
set according to the model type and engine setting. default
will force accepting the default setting. Set <br>
this to none to disable pruning and perform full
computation. safe guarantees the top N Gaussians to be
computed. heuristic and beam do more aggressive
computational <br>
cost reduction, but may result in small loss of accuracy
model (default: safe (standard), beam (fast) for tied
mixture model, none for non tied-mixture model).</p>

<p style="margin-top: 1em">-iwcd1 {max|avg|best number}
<br>
Select method to approximate inter-word triphone on the head
and tail of a word in the first pass.</p>

<p style="margin-top: 1em">max will apply the maximum
likelihood of the same context triphones. avg will apply the
average likelihood of the same context triphones. best
number will apply the <br>
average of top N-best likelihoods of the same context
triphone.</p>

<p style="margin-top: 1em">Default is best 3 for use with
N-gram, and avg for grammar and word. When this AM is shared
by LMs of both type, latter one will be chosen.</p>

<p style="margin-top: 1em">-iwsppenalty float <br>
Insertion penalty for word-end short pauses appended by
-iwsp.</p>

<p style="margin-top: 1em">-gshmm hmmdef_file <br>
If this option is specified, Julius performs Gaussian
Mixture Selection for efficient decoding. The hmmdefs should
be a monophone model generated from an ordinary <br>
monophone HMM model, using mkgshmm.</p>

<p style="margin-top: 1em">-gsnum number <br>
On GMS, specify number of monophone states to compute
corresponding triphones in detail. (default: 24)</p>

<p style="margin-top: 1em">Speech analysis <br>
Only MFCC feature extraction is supported in current Julius.
Thus when recognizing a waveform input from file or
microphone, AM must be trained by MFCC. The parameter <br>
condition should also be set as exactly the same as the
training condition by the options below.</p>

<p style="margin-top: 1em">When you give an input in HTK
Parameter file, you can use any parameter type for AM. In
this case Julius does not care about the type of input
feature and AM, just read <br>
them as vector sequence and match them to the given AM.
Julius only checks whether the parameter types are the same.
If it does not work well, you can disable this <br>
checking by -notypecheck.</p>

<p style="margin-top: 1em">In Julius, the parameter kind
and qualifiers (as TARGETKIND in HTK) and the number of
cepstral parameters (NUMCEPS) will be set automatically from
the content of the AM <br>
header, so you need not specify them by options.</p>

<p style="margin-top: 1em">Other parameters should be set
exactly the same as training condition. You can also give a
HTK Config file which you used to train AM to Julius by
-htkconf. When this <br>
option is applied, Julius will parse the Config file and set
appropriate parameter.</p>

<p style="margin-top: 1em">You can further embed those
analysis parameter settings to a binary HMM file using
mkbinhmm.</p>

<p style="margin-top: 1em">If options specified in several
ways, they will be evaluated in the order below. The AM
embedded parameter will be loaded first if any. Then, the
HTK config file given by <br>
-htkconf will be parsed. If a value already set by AM
embedded value, HTK config will override them. At last, the
direct options will be loaded, which will override <br>
settings loaded before. Note that, when the same options are
specified several times, later will override previous,
except that -htkconf will be evaluated first as <br>
described above.</p>

<p style="margin-top: 1em">-smpPeriod period <br>
Sampling period of input speech, in unit of 100 nanoseconds.
Sampling rate can also be specified by -smpFreq. Please note
that the input frequency should be set equal <br>
to the training conditions of AM. (default: 625, corresponds
to 16,000Hz)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option SOURCERATE. The same value can be given to this
option.</p>

<p style="margin-top: 1em">When using multiple AM, this
value should be the same among all AMs.</p>

<p style="margin-top: 1em">-smpFreq Hz <br>
Set sampling frequency of input speech in Hz. Sampling rate
can also be specified using -smpPeriod. Please note that
this frequency should be set equal to the training <br>
conditions of AM. (default: 16,000)</p>

<p style="margin-top: 1em">When using multiple AM, this
value should be the same among all AMs.</p>

<p style="margin-top: 1em">-fsize sample_num <br>
Window size in number of samples. (default: 400)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option WINDOWSIZE, but value should be in samples (HTK
value / smpPeriod).</p>

<p style="margin-top: 1em">When using multiple AM, this
value should be the same among all AMs.</p>

<p style="margin-top: 1em">-fshift sample_num <br>
Frame shift in number of samples. (default: 160)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option TARGETRATE, but value should be in samples (HTK
value / smpPeriod).</p>

<p style="margin-top: 1em">When using multiple AM, this
value should be the same among all AMs.</p>

<p style="margin-top: 1em">-preemph float <br>
Pre-emphasis coefficient. (default: 0.97)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option PREEMCOEF. The same value can be given to this
option.</p>

<p style="margin-top: 1em">-fbank num <br>
Number of filterbank channels. (default: 24)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option NUMCHANS. The same value can be given to this
option. Be aware that the default value not the same as in
HTK (22).</p>

<p style="margin-top: 1em">-ceplif num <br>
Cepstral liftering coefficient. (default: 22)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option CEPLIFTER. The same value can be given to this
option.</p>

<p style="margin-top: 1em">-rawe , -norawe <br>
Enable/disable using raw energy before pre-emphasis
(default: disabled)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option RAWENERGY. Be aware that the default value
differs from HTK (enabled at HTK, disabled at Julius).</p>

<p style="margin-top: 1em">-enormal , -noenormal <br>
Enable/disable normalizing log energy. On live input, this
normalization will be approximated from the average of last
input. (default: disabled)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option ENORMALISE. Be aware that the default value
differs from HTK (enabled at HTK, disabled at Julius).</p>

<p style="margin-top: 1em">-escale float_scale <br>
Scaling factor of log energy when normalizing log energy.
(default: 1.0)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option ESCALE. Be aware that the default value differs
from HTK (0.1).</p>

<p style="margin-top: 1em">-silfloor float <br>
Energy silence floor in dB when normalizing log energy.
(default: 50.0)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option SILFLOOR.</p>

<p style="margin-top: 1em">-delwin frame <br>
Delta window size in number of frames. (default: 2)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option DELTAWINDOW. The same value can be given to this
option.</p>

<p style="margin-top: 1em">-accwin frame <br>
Acceleration window size in number of frames. (default:
2)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option ACCWINDOW. The same value can be given to this
option.</p>

<p style="margin-top: 1em">-hifreq Hz <br>
Enable band-limiting for MFCC filterbank computation: set
upper frequency cut-off. Value of -1 will disable it.
(default: -1)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option HIFREQ. The same value can be given to this
option.</p>

<p style="margin-top: 1em">-lofreq Hz <br>
Enable band-limiting for MFCC filterbank computation: set
lower frequency cut-off. Value of -1 will disable it.
(default: -1)</p>

<p style="margin-top: 1em">This option corresponds to the
HTK Option LOFREQ. The same value can be given to this
option.</p>

<p style="margin-top: 1em">-zmeanframe , -nozmeanframe <br>
With speech input, this option enables/disables frame-wise
DC offset removal. This corresponds to HTK configuration
ZMEANSOURCE. This cannot be used together with <br>
-zmean. (default: disabled)</p>

<p style="margin-top: 1em">-usepower <br>
Use power instead of magnitude on filterbank analysis.
(default: disabled)</p>

<p style="margin-top: 1em">Normalization <br>
Julius can perform cepstral mean normalization (CMN) for
inputs. CMN will be activated when the given AM was trained
with CMN (i.e. has &quot;_Z&quot; qualifier in the
header).</p>

<p style="margin-top: 1em">The cepstral mean will be
estimated in different way according to the input type. On
file input, the mean will be computed from the whole input.
On live input such as <br>
microphone and network input, the ceptral mean of the input
is unknown at the start. So MAP-CMN will be used. On
MAP-CMN, an initial mean vector will be applied at the <br>
beginning, and the mean vector will be smeared to the mean
of the incrementing input vector as input goes. Options
below can control the behavior of MAP-CMN.</p>

<p style="margin-top: 1em">-cvn <br>
Enable cepstral variance normalization. At file input, the
variance of whole input will be calculated and then applied.
At live microphone input, variance of the last <br>
input will be applied. CVN is only supported for an audio
input.</p>

<p style="margin-top: 1em">-vtln alpha lowcut hicut <br>
Do frequency warping, typically for a vocal tract length
normalization (VTLN). Arguments are warping factor, high
frequency cut-off and low freq. cut-off. They <br>
correspond to HTK Config values, WARPFREQ, WARPHCUTOFF and
WARPLCUTOFF.</p>

<p style="margin-top: 1em">-cmnload file <br>
Load initial cepstral mean vector from file on startup. The
file should be one saved by -cmnsave. Loading an initial
cepstral mean enables Julius to better recognize <br>
the first utterance on a real-time input. When used together
with -cmnnoupdate, this initial value will be used for all
input.</p>

<p style="margin-top: 1em">-cmnsave file <br>
Save the calculated cepstral mean vector into file. The
parameters will be saved at each input end. If the output
file already exists, it will be overridden.</p>

<p style="margin-top: 1em">-cmnupdate -cmnnoupdate <br>
Control whether to update the cepstral mean at each input on
real-time input. Disabling this and specifying -cmnload will
make engine to always use the loaded static <br>
initial cepstral mean.</p>

<p style="margin-top: 1em">-cmnmapweight float <br>
Specify the weight of initial cepstral mean for MAP-CMN.
Specify larger value to retain the initial cepstral mean for
a longer period, and smaller value to make the <br>
cepstral mean rely more on the current input. (default:
100.0)</p>

<p style="margin-top: 1em">Front-end processing <br>
Julius can perform spectral subtraction to reduce some
stationary noise from audio input. Though it is not a
powerful method, but it may work on some situation. Julius
has <br>
two ways to estimate noise spectrum. One way is to assume
that the first short segment of an speech input is noise
segment, and estimate the noise spectrum as the average <br>
of the segment. Another way is to calculate average spectrum
from noise-only input using other tool mkss, and load it in
Julius. The former one is popular for speech file <br>
input, and latter should be used in live input. The options
below will switch / control the behavior.</p>

<p style="margin-top: 1em">-sscalc <br>
Perform spectral subtraction using head part of each file as
silence part. The head part length should be specified by
-sscalclen. Valid only for file input. Conflict <br>
with -ssload.</p>

<p style="margin-top: 1em">-sscalclen msec <br>
With -sscalc, specify the length of head silence for noise
spectrum estimation in milliseconds. (default: 300)</p>

<p style="margin-top: 1em">-ssload file <br>
Perform spectral subtraction for speech input using
pre-estimated noise spectrum loaded from file. The noise
spectrum file can be made by mkss. Valid for all speech <br>
input. Conflict with -sscalc.</p>

<p style="margin-top: 1em">-ssalpha float <br>
Alpha coefficient of spectral subtraction for -sscalc and
-ssload. Noise will be subtracted stronger as this value
gets larger, but distortion of the resulting signal <br>
also becomes remarkable. (default: 2.0)</p>

<p style="margin-top: 1em">-ssfloor float <br>
Flooring coefficient of spectral subtraction. The spectral
power that goes below zero after subtraction will be
substituted by the source signal with this coefficient <br>
multiplied. (default: 0.5)</p>

<p style="margin-top: 1em">Misc. AM options <br>
-htkconf file <br>
Parse the given HTK Config file, and set corresponding
parameters to Julius. When using this option, the default
parameter values are switched from Julius defaults to <br>
HTK defaults.</p>

<p style="margin-top: 1em">Recognition process and search
(-SR) <br>
This section contains options for search parameters on the
1st / 2nd pass such as beam width and LM weights,
configurations for short-pause segmentation, switches for
word <br>
lattice output and confusion network output, forced
alignments, and other options relating recognition process
and result output.</p>

<p style="margin-top: 1em">Default values for beam width
and LM weights will change according to compile-time setup
of JuliusLib , AM model type, and LM size. Please see the
startup log for the actual <br>
values.</p>

<p style="margin-top: 1em">1st pass parameters <br>
-lmp weight penalty <br>
(N-gram) Language model weights and word insertion penalties
for the first pass.</p>

<p style="margin-top: 1em">-penalty1 penalty <br>
(Grammar) word insertion penalty for the first pass.
(default: 0.0)</p>

<p style="margin-top: 1em">-b width <br>
Beam width in number of HMM nodes for rank beaming on the
first pass. This value defines search width on the 1st pass,
and has dominant effect on the total processing <br>
time. Smaller width will speed up the decoding, but too
small value will result in a substantial increase of
recognition errors due to search failure. Larger value will
<br>
make the search stable and will lead to failure-free search,
but processing time will grow in proportion to the
width.</p>

<p style="margin-top: 1em">The default value is dependent
on acoustic model type: 400 (monophone), 800 (triphone), or
1000 (triphone, setup=v2.1)</p>

<p style="margin-top: 1em">-nlimit num <br>
Upper limit of token per node. This option is valid when
--enable-wpair and --enable-wpair-nlimit are enabled at
compilation time.</p>

<p style="margin-top: 1em">-progout <br>
Enable progressive output of the partial results on the
first pass.</p>

<p style="margin-top: 1em">-proginterval msec <br>
Set the time interval for -progout in milliseconds.
(default: 300)</p>

<p style="margin-top: 1em">2nd pass parameters <br>
-lmp2 weight penalty <br>
(N-gram) Language model weights and word insertion penalties
for the second pass.</p>

<p style="margin-top: 1em">-penalty2 penalty <br>
(Grammar) word insertion penalty for the second pass.
(default: 0.0)</p>

<p style="margin-top: 1em">-b2 width <br>
Envelope beam width (number of hypothesis) at the second
pass. If the count of word expansion at a certain hypothesis
length reaches this limit while search, shorter <br>
hypotheses are not expanded further. This prevents search to
fall in breadth-first-like situation stacking on the same
position, and improve search failure mostly for <br>
large vocabulary condition. (default: 30)</p>

<p style="margin-top: 1em">-sb float <br>
Score envelope width for enveloped scoring. When calculating
hypothesis score for each generated hypothesis, its trellis
expansion and Viterbi operation will be pruned <br>
in the middle of the speech if score on a frame goes under
the width. Giving small value makes the second pass faster,
but computation error may occur. (default: 80.0)</p>

<p style="margin-top: 1em">-s num <br>
Stack size, i.e. the maximum number of hypothesis that can
be stored on the stack during the search. A larger value may
give more stable results, but increases the <br>
amount of memory required. (default: 500)</p>

<p style="margin-top: 1em">-m count <br>
Number of expanded hypotheses required to discontinue the
search. If the number of expanded hypotheses is greater then
this threshold then, the search is discontinued <br>
at that point. The larger this value is, The longer Julius
gets to give up search. (default: 2000)</p>

<p style="margin-top: 1em">-n num <br>
The number of candidates Julius tries to find. The search
continues till this number of sentence hypotheses have been
found. The obtained sentence hypotheses are sorted <br>
by score, and final result is displayed in the order (see
also the -output). The possibility that the optimum
hypothesis is correctly found increases as this value gets
<br>
increased, but the processing time also becomes longer. The
default value depends on the engine setup on compilation
time: 10 (standard) or 1 (fast or v2.1)</p>

<p style="margin-top: 1em">-output num <br>
The top N sentence hypothesis to be output at the end of
search. Use with -n (default: 1)</p>

<p style="margin-top: 1em">-lookuprange frame <br>
Set the number of frames before and after to look up next
word hypotheses in the word trellis on the second pass. This
prevents the omission of short words, but with a <br>
large value, the number of expanded hypotheses increases and
system becomes slow. (default: 5)</p>

<p style="margin-top: 1em">-looktrellis <br>
(Grammar) Expand only the words survived on the first pass
instead of expanding all the words predicted by grammar.
This option makes second pass decoding faster <br>
especially for large vocabulary condition, but may increase
deletion error of short words. (default: disabled)</p>

<p style="margin-top: 1em">Short-pause segmentation /
decoder-VAD <br>
When compiled with --enable-decoder-vad, the short-pause
segmentation will be extended to support decoder-based
VAD.</p>

<p style="margin-top: 1em">-spsegment <br>
Enable short-pause segmentation mode. Input will be
segmented when a short pause word (word with only silence
model in pronunciation) gets the highest likelihood at <br>
certain successive frames on the first pass. When detected
segment end, Julius stop the 1st pass at the point, perform
2nd pass, and continue with next segment. The <br>
word context will be considered among segments.
(Rev.4.0)</p>

<p style="margin-top: 1em">When compiled with
--enable-decoder-vad, this option enables decoder-based VAD,
to skip long silence.</p>

<p style="margin-top: 1em">-spdur frame <br>
Short pause duration length to detect end of input segment,
in number of frames. (default: 10)</p>

<p style="margin-top: 1em">-pausemodels string <br>
A comma-separated list of pause model names to be used at
short-pause segmentation. The word whose pronunciation
consists of only the pause models will be treated as <br>
&quot;pause word&quot; and used for pause detection. If not
specified, name of -spmodel, -silhead and -siltail will be
used. (Rev.4.0)</p>

<p style="margin-top: 1em">-spmargin frame <br>
Back step margin at trigger up for decoder-based VAD. When
speech up-trigger found by decoder-VAD, Julius will rewind
the input parameter by this value, and start <br>
recognition at the point. (Rev.4.0)</p>

<p style="margin-top: 1em">This option will be valid only
if compiled with --enable-decoder-vad.</p>

<p style="margin-top: 1em">-spdelay frame <br>
Trigger decision delay frame at trigger up for decoder-based
VAD. (Rev.4.0)</p>

<p style="margin-top: 1em">This option will be valid only
if compiled with --enable-decoder-vad.</p>

<p style="margin-top: 1em">Word lattice / confusion network
output <br>
-lattice , -nolattice <br>
Enable / disable generation of word graph. Search algorithm
also has changed to optimize for better word graph
generation, so the sentence result may not be the same as
<br>
normal N-best recognition. (Rev.4.0)</p>

<p style="margin-top: 1em">-confnet , -noconfnet <br>
Enable / disable generation of confusion network. Enabling
this will also activates -lattice internally. (Rev.4.0)</p>

<p style="margin-top: 1em">-graphrange frame <br>
Merge same words at neighbor position at graph generation.
If the beginning time and ending time of two word candidates
of the same word is within the specified range, <br>
they will be merged. The default is 0 (allow merging same
words on exactly the same location) and specifying larger
value will result in smaller graph output. Setting <br>
this value to -1 will disable merging, in that case same
words on the same location of different scores will be left
as they are. (default: 0)</p>

<p style="margin-top: 1em">-graphcut depth <br>
Cut the resulting graph by its word depth at post-processing
stage. The depth value is the number of words to be allowed
at a frame. Setting to -1 disables this <br>
feature. (default: 80)</p>

<p style="margin-top: 1em">-graphboundloop count <br>
Limit the number of boundary adjustment loop at
post-processing stage. This parameter prevents Julius from
blocking by infinite adjustment loop by short word <br>
oscillation. (default: 20)</p>

<p style="margin-top: 1em">-graphsearchdelay ,
-nographsearchdelay <br>
When this option is enabled, Julius modifies its graph
generation algorithm on the 2nd pass not to terminate search
by graph merging, until the first sentence candidate <br>
is found. This option may improve graph accuracy, especially
when you are going to generate a huge word graph by setting
broad search. Namely, it may result in better <br>
graph accuracy when you set wide beams on both 1st pass -b
and 2nd pass -b2, and large number for -n. (default:
disabled)</p>

<p style="margin-top: 1em">Multi-gram / multi-dic
recognition <br>
-multigramout , -nomultigramout <br>
On grammar recognition using multiple grammars, Julius will
output only the best result among all grammars. Enabling
this option will make Julius to output result for <br>
each grammar. (default: disabled)</p>

<p style="margin-top: 1em">Forced alignment <br>
-walign <br>
Do viterbi alignment per word units for the recognition
result. The word boundary frames and the average acoustic
scores per frame will be calculated.</p>

<p style="margin-top: 1em">-palign <br>
Do viterbi alignment per phone units for the recognition
result. The phone boundary frames and the average acoustic
scores per frame will be calculated.</p>

<p style="margin-top: 1em">-salign <br>
Do viterbi alignment per state for the recognition result.
The state boundary frames and the average acoustic scores
per frame will be calculated.</p>

<p style="margin-top: 1em">Misc. search options <br>
-inactive <br>
Start this recognition process instance with inactive state.
(Rev.4.0)</p>

<p style="margin-top: 1em">-1pass <br>
Perform only the first pass.</p>

<p style="margin-top: 1em">-fallback1pass <br>
When 2nd pass fails, Julius finish the recognition with no
result. This option tell Julius to output the 1st pass
result as a final result when the 2nd pass fails. Note <br>
that some score output (confidence etc.) may not be useful.
This was the default behavior of Julius-3.x.</p>

<p style="margin-top: 1em">-no_ccd , -force_ccd <br>
Explicitly switch phone context handling at search. Normally
Julius determines whether the using AM is a
context-dependent model or not from the model names, i.e.,
<br>
whether the names contain character + and -. This option
will override the automatic detection.</p>

<p style="margin-top: 1em">-cmalpha float <br>
Smoothing parameter for confidence scoring. (default:
0.05)</p>

<p style="margin-top: 1em">-iwsp <br>
(Multi-path mode only) Enable inter-word context-free short
pause insertion. This option appends a skippable short pause
model for every word end. The short-pause model <br>
can be specified by -spmodel.</p>

<p style="margin-top: 1em">-transp float <br>
Additional insertion penalty for transparent words.
(default: 0.0)</p>

<p style="margin-top: 1em">-demo <br>
Equivalent to -progout -quiet.</p>

<p style="margin-top: 1em">ENVIRONMENT VARIABLES <br>
ALSADEV <br>
(using mic input with alsa device) specify a capture device
name. If not specified, &quot;default&quot; will be
used.</p>

<p style="margin-top: 1em">AUDIODEV <br>
(using mic input with oss device) specify a capture device
path. If not specified, &quot;/dev/dsp&quot; will be
used.</p>

<p style="margin-top: 1em">LATENCY_MSEC <br>
Try to set input latency of microphone input in
milliseconds. Smaller value will shorten latency but
sometimes make process unstable. Default value will depend
on the running <br>
OS.</p>

<p style="margin-top: 1em">EXAMPLES <br>
For examples of system usage, refer to the tutorial section
in the Julius documents.</p>

<p style="margin-top: 1em">NOTICE <br>
Note about jconf files: relative paths in a jconf file are
interpreted as relative to the jconf file itself, not to the
current directory.</p>

<p style="margin-top: 1em">SEE ALSO <br>
julian(1), jcontrol(1), adinrec(1), adintool(1),
mkbingram(1), mkbinhmm(1), mkgsmm(1), wav2mfcc(1),
mkss(1)</p>


<p style="margin-top: 1em">http://julius.sourceforge.jp/en/</p>

<p style="margin-top: 1em">DIAGNOSTICS <br>
Julius normally will return the exit status 0. If an error
occurs, Julius exits abnormally with exit status 1. If an
input file cannot be found or cannot be loaded for some <br>
reason then Julius will skip processing for that file.</p>

<p style="margin-top: 1em">BUGS <br>
There are some restrictions to the type and size of the
models Julius can use. For a detailed explanation refer to
the Julius documentation. For bug-reports, inquires and <br>
comments please contact julius-info at
lists.sourceforge.jp.</p>

<p style="margin-top: 1em">COPYRIGHT <br>
Copyright (c) 1991-2008 Kawahara Lab., Kyoto University</p>

<p style="margin-top: 1em">Copyright (c) 1997-2000
Information-technology Promotion Agency, Japan</p>

<p style="margin-top: 1em">Copyright (c) 2000-2008 Shikano
Lab., Nara Institute of Science and Technology</p>

<p style="margin-top: 1em">Copyright (c) 2005-2008 Julius
project team, Nagoya Institute of Technology</p>

<p style="margin-top: 1em">AUTHORS <br>
Rev.1.0 (1998/02/20) <br>
Designed by Tatsuya KAWAHARA and Akinobu LEE (Kyoto
University)</p>

<p style="margin-top: 1em">Development by Akinobu LEE
(Kyoto University)</p>

<p style="margin-top: 1em">Rev.1.1 (1998/04/14), Rev.1.2
(1998/10/31), Rev.2.0 (1999/02/20), Rev.2.1 (1999/04/20),
Rev.2.2 (1999/10/04), Rev.3.0 (2000/02/14), Rev.3.1
(2000/05/11) <br>
Development of above versions by Akinobu LEE (Kyoto
University)</p>

<p style="margin-top: 1em">Rev.3.2 (2001/08/15), Rev.3.3
(2002/09/11), Rev.3.4 (2003/10/01), Rev.3.4.1 (2004/02/25),
Rev.3.4.2 (2004/04/30) <br>
Development of above versions by Akinobu LEE (Nara Institute
of Science and Technology)</p>

<p style="margin-top: 1em">Rev.3.5 (2005/11/11), Rev.3.5.1
(2006/03/31), Rev.3.5.2 (2006/07/31), Rev.3.5.3
(2006/12/29), Rev.4.0 (2007/12/19), Rev.4.1 (2008/10/03)
<br>
Development of above versions by Akinobu LEE (Nagoya
Institute of Technology)</p>

<p style="margin-top: 1em">THANKS TO <br>
From rev.3.2, Julius is released by the &quot;Information
Processing Society, Continuous Speech Consortium&quot;.</p>

<p style="margin-top: 1em">The Windows DLL version was
developed and released by Hideki BANNO (Nagoya
University).</p>

<p style="margin-top: 1em">The Windows Microsoft Speech API
compatible version was developed by Takashi SUMIYOSHI (Kyoto
University).</p>

<p style="margin-top: 1em">02/11/2009 JULIUS(1)</p>
<hr>
</body>
</html>
