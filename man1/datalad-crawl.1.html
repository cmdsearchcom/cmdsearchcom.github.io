<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
  </style>
  <title>datalad-crawl(1)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">datalad-crawl(1)</td>
    <td class="head-vol">General Commands Manual</td>
    <td class="head-rtitle">datalad-crawl(1)</td>
  </tr>
</table>
<div class="manual-text">
<h1 class="Sh" title="Sh" id="SYNOPSIS"><a class="selflink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<br/>
 <b>datalad-crawl</b> [--version] [-h] [-l LEVEL] [-p {condor}] [--is-pipeline]
  [-t]
<br/>
 [-r] [-C CHDIR]
<br/>
 [file]
<div style="height: 1.00em;">&#x00A0;</div>
<div style="height: 1.00em;">&#x00A0;</div>
<h1 class="Sh" title="Sh" id="DESCRIPTION"><a class="selflink" href="#DESCRIPTION">DESCRIPTION</a></h1>
Crawl online resource to create or update a dataset.
<div>&#x00A0;</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
Examples:
<div>&#x00A0;</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div>&#x00A0;</div>
<br/>
 $ datalad crawl # within a dataset having .datalad/crawl/crawl.cfg
<h1 class="Sh" title="Sh" id="OPTIONS"><a class="selflink" href="#OPTIONS">OPTIONS</a></h1>
<br/>
 file configuration (or pipeline if --is-pipeline) file
<br/>
 defining crawling, or a directory of a dataset on
<br/>
 which to perform crawling using its standard crawling
<br/>
 specification. Constraints: value must be a string
<br/>
 [Default: None]
<div style="height: 1.00em;">&#x00A0;</div>
<br/>
 <b>--version</b> show the program's version and license information
<br/>
 <b>-h</b>, <b>--help</b>, <b>--help-np</b>
<br/>
 show this help message. --help-np forcefully disables
<br/>
 the use of a pager for displaying the help message
<br/>
 <b>-l</b> LEVEL, <b>--log-level</b> LEVEL
<br/>
 set logging verbosity level. Choose among critical,
<br/>
 error, warning, info, debug. Also you can specify an
<br/>
 integer &lt;10 to provide even more debugging information
<br/>
 <b>-p</b> {condor}, <b>--pbs-runner</b> {condor}
<br/>
 execute command by scheduling it via available PBS.
<br/>
 For settings, config file will be consulted
<br/>
 <b>--is-pipeline</b> flag if provided file is a Python script which defines
<br/>
 pipeline(). [Default: False]
<br/>
 <b>-t</b>, <b>--is-template</b>
<br/>
 flag if provided value is the name of the template to
<br/>
 use. [Default: False]
<br/>
 <b>-r</b>, <b>--recursive</b>
<br/>
 flag to crawl subdatasets as well (for now serially).
<br/>
 [Default: False]
<br/>
 <b>-C</b> <i>CHDIR</i>, <b>--chdir</b> <i>CHDIR</i>
<br/>
 directory to chdir to for crawling. Constraints: value
<br/>
 must be a string [Default: None]
<h1 class="Sh" title="Sh" id="AUTHORS"><a class="selflink" href="#AUTHORS">AUTHORS</a></h1>
<br/>
 datalad is developed by The DataLad Team and Contributors
  &lt;team@datalad.org&gt;.</div>
<table class="foot">
  <tr>
    <td class="foot-date">2016-12-18</td>
    <td class="foot-os">datalad-crawl 0.4.1</td>
  </tr>
</table>
</body>
</html>
