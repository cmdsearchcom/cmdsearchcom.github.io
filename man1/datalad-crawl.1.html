<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 16:02:16 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>datalad-crawl(1) General Commands Manual
datalad-crawl(1)</p>

<p style="margin-top: 1em">SYNOPSIS <br>
datalad-crawl [--version] [-h] [-l LEVEL] [-p {condor}]
[--is-pipeline] [-t] <br>
[-r] [-C CHDIR] <br>
[file]</p>

<p style="margin-top: 1em">DESCRIPTION <br>
Crawl online resource to create or update a dataset.</p>

<p style="margin-top: 1em">Examples:</p>

<p style="margin-top: 1em">$ datalad crawl # within a
dataset having .datalad/crawl/crawl.cfg</p>

<p style="margin-top: 1em">OPTIONS <br>
file configuration (or pipeline if --is-pipeline) file <br>
defining crawling, or a directory of a dataset on <br>
which to perform crawling using its standard crawling <br>
specification. Constraints: value must be a string <br>
[Default: None]</p>

<p style="margin-top: 1em">--version show the
program&rsquo;s version and license information <br>
-h, --help, --help-np <br>
show this help message. --help-np forcefully disables <br>
the use of a pager for displaying the help message <br>
-l LEVEL, --log-level LEVEL <br>
set logging verbosity level. Choose among critical, <br>
error, warning, info, debug. Also you can specify an <br>
integer &lt;10 to provide even more debugging information
<br>
-p {condor}, --pbs-runner {condor} <br>
execute command by scheduling it via available PBS. <br>
For settings, config file will be consulted <br>
--is-pipeline flag if provided file is a Python script which
defines <br>
pipeline(). [Default: False] <br>
-t, --is-template <br>
flag if provided value is the name of the template to <br>
use. [Default: False] <br>
-r, --recursive <br>
flag to crawl subdatasets as well (for now serially). <br>
[Default: False] <br>
-C CHDIR, --chdir CHDIR <br>
directory to chdir to for crawling. Constraints: value <br>
must be a string [Default: None]</p>

<p style="margin-top: 1em">AUTHORS <br>
datalad is developed by The DataLad Team and Contributors
&lt;team@datalad.org&gt;.</p>

<p style="margin-top: 1em">datalad-crawl 0.4.1 2016-12-18
datalad-crawl(1)</p>
<hr>
</body>
</html>
