<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 16:26:11 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>mprof-report(1) General Commands Manual
mprof-report(1)</p>

<p style="margin-top: 1em">The Mono log profiler <br>
The Mono log profiler can be used to collect a lot of
information about a program running in the Mono runtime.
This data can be used (both while the process is running and
<br>
later) to do analyses of the program behaviour, determine
resource usage, performance issues or even look for
particular execution patterns.</p>

<p style="margin-top: 1em">This is accomplished by logging
the events provided by the Mono runtime through the
profiling interface and periodically writing them to a file
which can be later inspected with <br>
the command line mprof-report program or with a GUI (not
developed yet).</p>

<p style="margin-top: 1em">The events collected include
(among others):</p>

<p style="margin-top: 1em">&Acirc;&middot; method enter and
leave</p>

<p style="margin-top: 1em">&Acirc;&middot; object
allocation</p>

<p style="margin-top: 1em">&Acirc;&middot; garbage
collection</p>

<p style="margin-top: 1em">&Acirc;&middot; JIT
compilation</p>

<p style="margin-top: 1em">&Acirc;&middot; metadata
loading</p>

<p style="margin-top: 1em">&Acirc;&middot; lock
contention</p>

<p style="margin-top: 1em">&Acirc;&middot; exceptions</p>

<p style="margin-top: 1em">In addition, the profiler can
periodically collect info about all the objects present in
the heap at the end of a garbage collection (this is called
heap shot and currently <br>
implemented only for the sgen garbage collector). Another
available profiler mode is the sampling or statistical mode:
periodically the program is sampled and the information <br>
about what the program was busy with is saved. This allows
to get information about the program behaviour without
degrading its performance too much (usually less than
10%).</p>

<p style="margin-top: 1em">Basic profiler usage <br>
The simpler way to use the profiler is the following:</p>

<p style="margin-top: 1em">mono --profile=log
program.exe</p>

<p style="margin-top: 1em">At the end of the execution the
file output.mlpd will be found in the current directory. A
summary report of the data can be printed by running:</p>

<p style="margin-top: 1em">mprof-report output.mlpd</p>

<p style="margin-top: 1em">With this invocation a huge
amount of data is collected about the program execution and
collecting and saving this data can significantly slow down
program execution. If saving <br>
the profiling data is not needed, a report can be generated
directly with:</p>

<p style="margin-top: 1em">mono --profile=log:report
program.exe</p>

<p style="margin-top: 1em">If the information about
allocations is not of interest, it can be excluded:</p>

<p style="margin-top: 1em">mono --profile=log:noalloc
program.exe</p>

<p style="margin-top: 1em">On the other hand, if method
call timing is not important, while allocations are, the
needed info can be gathered with:</p>

<p style="margin-top: 1em">mono --profile=log:nocalls
program.exe</p>

<p style="margin-top: 1em">You will still be able to
inspect information about the sequence of calls that lead to
each allocation because at each object allocation a stack
trace is collected if full <br>
enter/leave information is not available.</p>

<p style="margin-top: 1em">To periodically collect heap
shots (and exclude method and allocation events) use the
following options (making sure you run with the sgen garbage
collector):</p>

<p style="margin-top: 1em">mono --gc=sgen
--profile=log:heapshot program.exe</p>

<p style="margin-top: 1em">To perform a sampling profiler
run, use the sample option:</p>

<p style="margin-top: 1em">mono --profile=log:sample
program.exe</p>

<p style="margin-top: 1em">Profiler option documentation
<br>
By default the log profiler will gather all the events
provided by the Mono runtime and write them to a file named
output.mlpd. When no option is specified, it is equivalent
to <br>
using:</p>


<p style="margin-top: 1em">--profile=log:calls,alloc,output=output.mlpd,maxframes=32,calldepth=100</p>

<p style="margin-top: 1em">The following options can be
used to modify this default behaviour. Each option is
separated from the next by a , character, with no spaces and
all the options are included <br>
after the log: profile module specifier.</p>

<p style="margin-top: 1em">&Acirc;&middot; help: display
concise help info about each available option</p>

<p style="margin-top: 1em">&Acirc;&middot; [no]alloc:
noalloc disables collecting object allocation info, alloc
enables it if it was disabled by another option like
heapshot.</p>

<p style="margin-top: 1em">&Acirc;&middot; [no]calls:
nocalls disables collecting method enter and leave events.
When this option is used at each object allocation and at
some other events (like lock contentions and <br>
exception throws) a stack trace is collected by default. See
the maxframes option to control this behaviour. calls
enables method enter/leave events if they were disabled by
<br>
another option like heapshot.</p>

<p style="margin-top: 1em">&Acirc;&middot; heapshot[=MODE]:
collect heap shot data at each major collection. The
frequency of the heap shots can be changed with the MODE
parameter. When this option is used allocation <br>
events and method enter/leave events are not recorded by
default: if they are needed, they need to be enabled
explicitly. The optional parameter MODE can modify the
default <br>
heap shot frequency. heapshot can be used multiple times
with different modes: in that case a heap shot is taken if
either of the conditions are met. MODE can be one of:</p>

<p style="margin-top: 1em">&Acirc;&middot; NUMms: perform a
heap shot if at least NUM milliseconds passed since the last
one.</p>

<p style="margin-top: 1em">&Acirc;&middot; NUMgc: perform a
heap shot every NUM major garbage collections</p>

<p style="margin-top: 1em">&Acirc;&middot; ondemand:
perform a heap shot when such a command is sent to the
control port</p>

<p style="margin-top: 1em">&Acirc;&middot; sample[=FREQ]:
collect statistical samples of the program behaviour. The
default is to collect a 100 times per second (100 Hz) the
instruction pointer. This is equivalent to <br>
the value &acirc;100&acirc;. A value of zero for FREQ
effectively disables sampling.</p>

<p style="margin-top: 1em">&Acirc;&middot; maxframes=NUM:
when a stack trace needs to be performed, collect NUM frames
at the most. The default is 32.</p>

<p style="margin-top: 1em">&Acirc;&middot; maxsamples=NUM:
stop allocating reusable sample events once NUM events have
been allocated (a value of zero for all intents and purposes
means unlimited). By default, the value <br>
of this setting is the number of CPU cores multiplied by
1000. This is usually a good enough value for typical
desktop and mobile apps. If you&rsquo;re losing too many
samples due <br>
to this default (which is possible in apps with an unusually
high amount of threads), you may want to tinker with this
value to find a good balance between sample hit rate and
<br>
performance impact on the app. The way it works is that
sample events are enqueued for reuse after they&rsquo;re
flushed to the output file; if a thread gets a sampling
signal but <br>
there are no sample events in the reuse queue and the
profiler has reached the maximum number of sample
allocations, the sample gets dropped. So a higher number for
this set&acirc; <br>
ting will increase the chance that a thread is able to
collect a sample, but also necessarily means that there will
be more work done by the profiler. You can run Mono with the
<br>
--stats option to see statistics about sample events.</p>

<p style="margin-top: 1em">&Acirc;&middot; calldepth=NUM:
ignore method enter/leave events when the call chain depth
is bigger than NUM.</p>

<p style="margin-top: 1em">&Acirc;&middot; zip:
automatically compress the output data in gzip format.</p>

<p style="margin-top: 1em">&Acirc;&middot; output=OUTSPEC:
instead of writing the profiling data to the output.mlpd
file, substitute %p in OUTSPEC with the current process id
and %t with the current date and time, then <br>
do according to OUTSPEC:</p>

<p style="margin-top: 1em">&Acirc;&middot; if OUTSPEC
begins with a | character, execute the rest as a program and
feed the data to its standard input</p>

<p style="margin-top: 1em">&Acirc;&middot; if OUTSPEC
begins with a - character, use the rest of OUTSPEC as the
filename, but force overwrite any existing file by that
name</p>

<p style="margin-top: 1em">&Acirc;&middot; otherwise write
the data the the named file: note that is a file by that
name already exists, a warning is issued and profiling is
disabled.</p>

<p style="margin-top: 1em">&Acirc;&middot; report: the
profiling data is sent to mprof-report, which will print a
summary report. This is equivalent to the option:
output=mprof-report -. If the output option is speci&acirc;
<br>
fied as well, the report will be written to the output file
instead of the console.</p>

<p style="margin-top: 1em">&Acirc;&middot; port=PORT:
specify the tcp/ip port to use for the listening command
server. Currently not available for windows. This server is
started for example when heapshot=ondemand is <br>
used: it will read commands line by line. The following
commands are available:</p>

<p style="margin-top: 1em">&Acirc;&middot; heapshot:
perform a heapshot as soon as possible</p>

<p style="margin-top: 1em">&Acirc;&middot; nocounters:
disables sampling of runtime and performance counters, which
is normally done every 1 second.</p>

<p style="margin-top: 1em">&Acirc;&middot; coverage:
collect code coverage data. This implies enabling the calls
option.</p>

<p style="margin-top: 1em">&Acirc;&middot; onlycoverage:
can only be used with coverage. This disables most other
events so that the profiler mostly only collects coverage
data.</p>

<p style="margin-top: 1em">Analyzing the profile data <br>
Currently there is a command line program (mprof-report) to
analyze the data produced by the profiler. This is ran
automatically when the report profiler option is used.
Simply <br>
run:</p>

<p style="margin-top: 1em">mprof-report output.mlpd</p>

<p style="margin-top: 1em">to see a summary report of the
data included in the file.</p>

<p style="margin-top: 1em">Trace information for events
<br>
Often it is important for some events, like allocations,
lock contention and exception throws to know where they
happened. Or we may want to see what sequence of calls leads
to <br>
a particular method invocation. To see this info invoke
mprof-report as follows:</p>

<p style="margin-top: 1em">mprof-report --traces
output.mlpd</p>

<p style="margin-top: 1em">The maximum number of methods in
each stack trace can be specified with the --maxframes=NUM
option:</p>

<p style="margin-top: 1em">mprof-report --traces
--maxframes=4 output.mlpd</p>

<p style="margin-top: 1em">The stack trace info will be
available if method enter/leave events have been recorded or
if stack trace collection wasn&rsquo;t explicitly disabled
with the maxframes=0 profiler <br>
option.</p>

<p style="margin-top: 1em">The --traces option also
controls the reverse reference feature in the heapshot
report: for each class it reports how many references to
objects of that class come from other <br>
classes.</p>

<p style="margin-top: 1em">Sort order for methods and
allocations <br>
When a list of methods is printed the default sort order is
based on the total time spent in the method. This time is
wall clock time (that is, it includes the time spent, for
<br>
example, in a sleep call, even if actual cpu time would be
basically 0). Also, if the method has been ran on different
threads, the time will be a sum of the time used in each
<br>
thread.</p>

<p style="margin-top: 1em">To change the sort order, use
the option:</p>

<p style="margin-top: 1em">--method-sort=MODE</p>

<p style="margin-top: 1em">where MODE can be:</p>

<p style="margin-top: 1em">&Acirc;&middot; self: amount of
time spent in the method itself and not in its callees</p>

<p style="margin-top: 1em">&Acirc;&middot; calls: the
number of method invocations</p>

<p style="margin-top: 1em">&Acirc;&middot; total: the total
time spent in the method.</p>

<p style="margin-top: 1em">Object allocation lists are
sorted by default depending on the total amount of bytes
used by each type.</p>

<p style="margin-top: 1em">To change the sort order of
object allocations, use the option:</p>

<p style="margin-top: 1em">--alloc-sort=MODE</p>

<p style="margin-top: 1em">where MODE can be:</p>

<p style="margin-top: 1em">&Acirc;&middot; count: the
number of allocated objects of the given type</p>

<p style="margin-top: 1em">&Acirc;&middot; bytes: the total
number of bytes used by objects of the given type</p>

<p style="margin-top: 1em">To change the sort order of
counters, use the option:</p>

<p style="margin-top: 1em">--counters-sort=MODE</p>

<p style="margin-top: 1em">where MODE can be:</p>

<p style="margin-top: 1em">&Acirc;&middot; time: sort
values by time then category</p>

<p style="margin-top: 1em">&Acirc;&middot; category: sort
values by category then time</p>

<p style="margin-top: 1em">Selecting what data to report
<br>
The profiler by default collects data about many runtime
subsystems and mprof-report prints a summary of all the
subsystems that are found in the data file. It is possible
to <br>
tell mprof-report to only show information about some of
them with the following option:</p>

<p style="margin-top: 1em">--reports=R1[,R2...]</p>

<p style="margin-top: 1em">where the report names R1, R2
etc. can be:</p>

<p style="margin-top: 1em">&Acirc;&middot; header:
information about program startup and profiler version</p>

<p style="margin-top: 1em">&Acirc;&middot; jit: JIT
compiler information</p>

<p style="margin-top: 1em">&Acirc;&middot; sample:
statistical sampling information</p>

<p style="margin-top: 1em">&Acirc;&middot; gc: garbage
collection information</p>

<p style="margin-top: 1em">&Acirc;&middot; alloc: object
allocation information</p>

<p style="margin-top: 1em">&Acirc;&middot; call: method
profiling information</p>

<p style="margin-top: 1em">&Acirc;&middot; metadata:
metadata events like image loads</p>

<p style="margin-top: 1em">&Acirc;&middot; exception:
exception throw and handling information</p>

<p style="margin-top: 1em">&Acirc;&middot; monitor: lock
contention information</p>

<p style="margin-top: 1em">&Acirc;&middot; thread: thread
information</p>

<p style="margin-top: 1em">&Acirc;&middot; domain: app
domain information</p>

<p style="margin-top: 1em">&Acirc;&middot; context:
remoting context information</p>

<p style="margin-top: 1em">&Acirc;&middot; heapshot: live
heap usage at heap shots</p>

<p style="margin-top: 1em">&Acirc;&middot; counters:
counters samples</p>

<p style="margin-top: 1em">&Acirc;&middot; coverage: code
coverage data</p>

<p style="margin-top: 1em">&Acirc;&middot; stats: event
statistics</p>

<p style="margin-top: 1em">It is possible to limit some of
the data displayed to a timeframe of the program execution
with the option:</p>

<p style="margin-top: 1em">--time=FROM-TO</p>

<p style="margin-top: 1em">where FROM and TO are seconds
since application startup (they can be floating point
numbers).</p>

<p style="margin-top: 1em">Another interesting option is to
consider only events happening on a particular thread with
the following option:</p>

<p style="margin-top: 1em">--thread=THREADID</p>

<p style="margin-top: 1em">where THREADID is one of the
numbers listed in the thread summary report (or a thread
name when present).</p>

<p style="margin-top: 1em">By default long lists of methods
or other information like object allocations are limited to
the most important data. To increase the amount of
information printed you can use <br>
the option:</p>

<p style="margin-top: 1em">--verbose</p>

<p style="margin-top: 1em">Track individual objects <br>
Instead of printing the usual reports from the profiler
data, it is possible to track some interesting information
about some specific object addresses. The objects are
selected <br>
based on their address with the --track option as
follows:</p>


<p style="margin-top: 1em">--track=0xaddr1[,0xaddr2,...]</p>

<p style="margin-top: 1em">The reported info (if available
in the data file), will be class name, size, creation time,
stack trace of creation (with the --traces option), etc. If
heapshot data is avail&acirc; <br>
able it will be possible to also track what other objects
reference one of the listed addresses.</p>

<p style="margin-top: 1em">The object addresses can be
gathered either from the profiler report in some cases (like
in the monitor lock report), from the live application or
they can be selected with the <br>
--find=FINDSPEC option. FINDSPEC can be one of the
following:</p>

<p style="margin-top: 1em">&Acirc;&middot; S:SIZE: where
the object is selected if its size is at least SIZE</p>

<p style="margin-top: 1em">&Acirc;&middot; T:NAME: where
the object is selected if NAME partially matches its class
name</p>

<p style="margin-top: 1em">This option can be specified
multiple times with one of the different kinds of FINDSPEC.
For example, the following:</p>

<p style="margin-top: 1em">--find=S:10000
--find=T:Byte[]</p>

<p style="margin-top: 1em">will find all the byte arrays
that are at least 10000 bytes in size.</p>

<p style="margin-top: 1em">Note that with a moving garbage
collector the object address can change, so you may need to
track the changed address manually. It can also happen that
multiple objects are <br>
allocated at the same address, so the output from this
option can become large.</p>

<p style="margin-top: 1em">Saving a profiler report <br>
By default mprof-report will print the summary data to the
console. To print it to a file, instead, use the option:</p>

<p style="margin-top: 1em">--out=FILENAME</p>

<p style="margin-top: 1em">Processing code coverage data
<br>
If you ran the profiler with the coverage option, you can
process the collected coverage data into an XML file by
running mprof-report like this:</p>

<p style="margin-top: 1em">mprof-report
--coverage-out=coverage.xml output.mlpd</p>

<p style="margin-top: 1em">Dealing with profiler slowness
<br>
If the profiler needs to collect lots of data, the execution
of the program will slow down significantly, usually 10 to
20 times slower. There are several ways to reduce the <br>
impact of the profiler on the program execution.</p>

<p style="margin-top: 1em">Use the statistical sampling
mode</p>

<p style="margin-top: 1em">Statistical sampling allows
executing a program under the profiler with minimal
performance overhead (usually less than 10%). This mode
allows checking where the program is <br>
spending most of its execution time without significantly
perturbing its behaviour.</p>

<p style="margin-top: 1em">Collect less data</p>

<p style="margin-top: 1em">Collecting method enter/leave
events can be very expensive, especially in programs that
perform many millions of tiny calls. The profiler option
nocalls can be used to avoid <br>
collecting this data or it can be limited to only a few call
levels with the calldepth option.</p>

<p style="margin-top: 1em">Object allocation information is
expensive as well, though much less than method enter/leave
events. If it&rsquo;s not needed, it can be skipped with the
noalloc profiler option. <br>
Note that when method enter/leave events are discarded, by
default stack traces are collected at each allocation and
this can be expensive as well. The impact of stack trace
<br>
information can be reduced by setting a low value with the
maxframes option or by eliminating them completely, by
setting it to 0.</p>

<p style="margin-top: 1em">The other major source of data
is the heapshot profiler option: especially if the managed
heap is big, since every object needs to be inspected. The
MODE parameter of the <br>
heapshot option can be used to reduce the frequency of the
heap shots.</p>

<p style="margin-top: 1em">Dealing with the size of the
data files <br>
When collecting a lot of information about a profiled
program, huge data files can be generated. There are a few
ways to minimize the amount of data, for example by not
collect&acirc; <br>
ing some of the more space-consuming information or by
compressing the information on the fly or by just generating
a summary report.</p>

<p style="margin-top: 1em">Reducing the amount of data</p>

<p style="margin-top: 1em">Method enter/leave events can be
excluded completely with the nocalls option or they can be
limited to just a few levels of calls with the calldepth
option. For example, the <br>
option:</p>

<p style="margin-top: 1em">calldepth=10</p>

<p style="margin-top: 1em">will ignore the method events
when there are more than 10 managed stack frames. This is
very useful for programs that have deep recursion or for
programs that perform many <br>
millions of tiny calls deep enough in the call stack. The
optimal number for the calldepth option depends on the
program and it needs to be balanced between providing enough
<br>
profiling information and allowing fast execution speed.</p>

<p style="margin-top: 1em">Note that by default, if method
events are not recorded at all, the profiler will collect
stack trace information at events like allocations. To avoid
gathering this data, <br>
use the maxframes=0 profiler option.</p>

<p style="margin-top: 1em">Allocation events can be
eliminated with the noalloc option.</p>

<p style="margin-top: 1em">Heap shot data can also be huge:
by default it is collected at each major collection. To
reduce the frequency, you can specify a heapshot mode: for
example to collect every <br>
5 collections (including major and minor):</p>

<p style="margin-top: 1em">heapshot=5gc</p>

<p style="margin-top: 1em">or when at least 5 seconds
passed since the last heap shot:</p>

<p style="margin-top: 1em">heapshot=5000ms</p>

<p style="margin-top: 1em">Compressing the data</p>

<p style="margin-top: 1em">To reduce the amout of disk
space used by the data, the data can be compressed either
after it has been generated with the gzip command:</p>

<p style="margin-top: 1em">gzip -9 output.mlpd</p>

<p style="margin-top: 1em">or it can be compressed
automatically by using the zip profiler option. Note that in
this case there could be a significant slowdown of the
profiled program.</p>

<p style="margin-top: 1em">The mprof-report program will
tranparently deal with either compressed or uncompressed
data files.</p>

<p style="margin-top: 1em">Generating only a summary
report</p>

<p style="margin-top: 1em">Often it&rsquo;s enough to look
at the profiler summary report to diagnose an issue and in
this case it&rsquo;s possible to avoid saving the profiler
data file to disk. This can be <br>
accomplished with the report profiler option, which will
basically send the data to the mprof-report program for
display.</p>

<p style="margin-top: 1em">To have more control of what
summary information is reported (or to use a completely
different program to decode the profiler data), the output
profiler option can be used, <br>
with | as the first character: the rest of the output name
will be executed as a program with the data fed in on the
standard input.</p>

<p style="margin-top: 1em">For example, to print only the
Monitor summary with stack trace information, you could use
it like this:</p>

<p style="margin-top: 1em">output=|mprof-report
--reports=monitor --traces -</p>

<p style="margin-top: 1em">WEB SITE <br>

http://www.mono-project.com/docs/debug+profile/profile/profiler/</p>

<p style="margin-top: 1em">SEE ALSO <br>
mono(1)</p>

<p style="margin-top: 1em">AUTHORS <br>
Paolo Molaro, Alex R&Atilde;&cedil;nne Petersen</p>
 
<p style="margin-top: 1em">mprof-report(1)</p>
<hr>
</body>
</html>
