<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 16:41:57 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>VALGRIND(1) Release 3.11.0 VALGRIND(1)</p>

<p style="margin-top: 1em">NAME <br>
valgrind - a suite of tools for debugging and profiling
programs</p>

<p style="margin-top: 1em">SYNOPSIS <br>
valgrind [valgrind-options] [your-program]
[your-program-options]</p>

<p style="margin-top: 1em">DESCRIPTION <br>
Valgrind is a flexible program for debugging and profiling
Linux executables. It consists of a core, which provides a
synthetic CPU in software, and a series of debugging and
<br>
profiling tools. The architecture is modular, so that new
tools can be created easily and without disturbing the
existing structure.</p>

<p style="margin-top: 1em">Some of the options described
below work with all Valgrind tools, and some only work with
a few or one. The section MEMCHECK OPTIONS and those below
it describe tool-specific <br>
options.</p>

<p style="margin-top: 1em">This manual page covers only
basic usage and options. For more comprehensive information,
please see the HTML documentation on your system: <br>
$INSTALL/share/doc/valgrind/html/index.html, or online:
http://www.valgrind.org/docs/manual/index.html.</p>

<p style="margin-top: 1em">TOOL SELECTION OPTIONS <br>
The single most important option.</p>

<p style="margin-top: 1em">--tool=&lt;toolname&gt;
[default: memcheck] <br>
Run the Valgrind tool called toolname, e.g. memcheck,
cachegrind, callgrind, helgrind, drd, massif, lackey, none,
exp-sgcheck, exp-bbv, exp-dhat, etc.</p>

<p style="margin-top: 1em">BASIC OPTIONS <br>
These options work with all tools.</p>

<p style="margin-top: 1em">-h --help <br>
Show help for all options, both for the core and for the
selected tool. If the option is repeated it is equivalent to
giving --help-debug.</p>

<p style="margin-top: 1em">--help-debug <br>
Same as --help, but also lists debugging options which
usually are only of use to Valgrind&rsquo;s developers.</p>

<p style="margin-top: 1em">--version <br>
Show the version number of the Valgrind core. Tools can have
their own version numbers. There is a scheme in place to
ensure that tools only execute when the core version is <br>
one they are known to work with. This was done to minimise
the chances of strange problems arising from tool-vs-core
version incompatibilities.</p>

<p style="margin-top: 1em">-q, --quiet <br>
Run silently, and only print error messages. Useful if you
are running regression tests or have some other automated
test machinery.</p>

<p style="margin-top: 1em">-v, --verbose <br>
Be more verbose. Gives extra information on various aspects
of your program, such as: the shared objects loaded, the
suppressions used, the progress of the instrumentation <br>
and execution engines, and warnings about unusual behaviour.
Repeating the option increases the verbosity level.</p>

<p style="margin-top: 1em">--trace-children=&lt;yes|no&gt;
[default: no] <br>
When enabled, Valgrind will trace into sub-processes
initiated via the exec system call. This is necessary for
multi-process programs.</p>

<p style="margin-top: 1em">Note that Valgrind does trace
into the child of a fork (it would be difficult not to,
since fork makes an identical copy of a process), so this
option is arguably badly <br>
named. However, most children of fork calls immediately call
exec anyway.</p>


<p style="margin-top: 1em">--trace-children-skip=patt1,patt2,...
<br>
This option only has an effect when --trace-children=yes is
specified. It allows for some children to be skipped. The
option takes a comma separated list of patterns for the <br>
names of child executables that Valgrind should not trace
into. Patterns may include the metacharacters ? and *, which
have the usual meaning.</p>

<p style="margin-top: 1em">This can be useful for pruning
uninteresting branches from a tree of processes being run on
Valgrind. But you should be careful when using it. When
Valgrind skips tracing <br>
into an executable, it doesn&rsquo;t just skip tracing that
executable, it also skips tracing any of that
executable&rsquo;s child processes. In other words, the flag
doesn&rsquo;t merely <br>
cause tracing to stop at the specified executables -- it
skips tracing of entire process subtrees rooted at any of
the specified executables.</p>


<p style="margin-top: 1em">--trace-children-skip-by-arg=patt1,patt2,...
<br>
This is the same as --trace-children-skip, with one
difference: the decision as to whether to trace into a child
process is made by examining the arguments to the child <br>
process, rather than the name of its executable.</p>


<p style="margin-top: 1em">--child-silent-after-fork=&lt;yes|no&gt;
[default: no] <br>
When enabled, Valgrind will not show any debugging or
logging output for the child process resulting from a fork
call. This can make the output less confusing (although more
<br>
misleading) when dealing with processes that create
children. It is particularly useful in conjunction with
--trace-children=. Use of this option is also strongly
recommended <br>
if you are requesting XML output (--xml=yes), since
otherwise the XML from child and parent may become mixed up,
which usually makes it useless.</p>

<p style="margin-top: 1em">--vgdb=&lt;no|yes|full&gt;
[default: yes] <br>
Valgrind will provide &quot;gdbserver&quot; functionality
when --vgdb=yes or --vgdb=full is specified. This allows an
external GNU GDB debugger to control and debug your program
when <br>
it runs on Valgrind. --vgdb=full incurs significant
performance overheads, but provides more precise breakpoints
and watchpoints. See Debugging your program using
Valgrind&rsquo;s <br>
gdbserver and GDB for a detailed description.</p>

<p style="margin-top: 1em">If the embedded gdbserver is
enabled but no gdb is currently being used, the vgdb command
line utility can send &quot;monitor commands&quot; to
Valgrind from a shell. The Valgrind core <br>
provides a set of Valgrind monitor commands. A tool can
optionally provide tool specific monitor commands, which are
documented in the tool specific chapter.</p>

<p style="margin-top: 1em">--vgdb-error=&lt;number&gt;
[default: 999999999] <br>
Use this option when the Valgrind gdbserver is enabled with
--vgdb=yes or --vgdb=full. Tools that report errors will
wait for &quot;number&quot; errors to be reported before
freezing <br>
the program and waiting for you to connect with GDB. It
follows that a value of zero will cause the gdbserver to be
started before your program is executed. This is typically
<br>
used to insert GDB breakpoints before execution, and also
works with tools that do not report errors, such as
Massif.</p>

<p style="margin-top: 1em">--vgdb-stop-at=&lt;set&gt;
[default: none] <br>
Use this option when the Valgrind gdbserver is enabled with
--vgdb=yes or --vgdb=full. The Valgrind gdbserver will be
invoked for each error after --vgdb-error have been <br>
reported. You can additionally ask the Valgrind gdbserver to
be invoked for other events, specified in one of the
following ways:</p>

<p style="margin-top: 1em">&Acirc;&middot; a comma
separated list of one or more of startup exit
valgrindabexit.</p>

<p style="margin-top: 1em">The values
startupexitvalgrindabexit respectively indicate to invoke
gdbserver before your program is executed, after the last
instruction of your program, on Valgrind <br>
abnormal exit (e.g. internal error, out of memory, ...).</p>

<p style="margin-top: 1em">Note: startup and --vgdb-error=0
will both cause Valgrind gdbserver to be invoked before your
program is executed. The --vgdb-error=0 will in addition
cause your program <br>
to stop on all subsequent errors.</p>

<p style="margin-top: 1em">&Acirc;&middot; all to specify
the complete set. It is equivalent to
--vgdb-stop-at=startup,exit,valgrindabexit.</p>

<p style="margin-top: 1em">&Acirc;&middot; none for the
empty set.</p>

<p style="margin-top: 1em">--track-fds=&lt;yes|no&gt;
[default: no] <br>
When enabled, Valgrind will print out a list of open file
descriptors on exit or on request, via the gdbserver monitor
command v.info open_fds. Along with each file <br>
descriptor is printed a stack backtrace of where the file
was opened and any details relating to the file descriptor
such as the file name or socket details.</p>

<p style="margin-top: 1em">--time-stamp=&lt;yes|no&gt;
[default: no] <br>
When enabled, each message is preceded with an indication of
the elapsed wallclock time since startup, expressed as days,
hours, minutes, seconds and milliseconds.</p>

<p style="margin-top: 1em">--log-fd=&lt;number&gt;
[default: 2, stderr] <br>
Specifies that Valgrind should send all of its messages to
the specified file descriptor. The default, 2, is the
standard error channel (stderr). Note that this may
interfere <br>
with the client&rsquo;s own use of stderr, as
Valgrind&rsquo;s output will be interleaved with any output
that the client sends to stderr.</p>

<p style="margin-top: 1em">--log-file=&lt;filename&gt; <br>
Specifies that Valgrind should send all of its messages to
the specified file. If the file name is empty, it causes an
abort. There are three special format specifiers that <br>
can be used in the file name.</p>

<p style="margin-top: 1em">%p is replaced with the current
process ID. This is very useful for program that invoke
multiple processes. WARNING: If you use --trace-children=yes
and your program invokes <br>
multiple processes OR your program forks without calling
exec afterwards, and you don&rsquo;t use this specifier (or
the %q specifier below), the Valgrind output from all those
<br>
processes will go into one file, possibly jumbled up, and
possibly incomplete.</p>

<p style="margin-top: 1em">%q{FOO} is replaced with the
contents of the environment variable FOO. If the {FOO} part
is malformed, it causes an abort. This specifier is rarely
needed, but very useful in <br>
certain circumstances (eg. when running MPI programs). The
idea is that you specify a variable which will be set
differently for each process in the job, for example <br>
BPROC_RANK or whatever is applicable in your MPI setup. If
the named environment variable is not set, it causes an
abort. Note that in some shells, the { and } characters may
<br>
need to be escaped with a backslash.</p>

<p style="margin-top: 1em">%% is replaced with %.</p>

<p style="margin-top: 1em">If an % is followed by any other
character, it causes an abort.</p>

<p style="margin-top: 1em">If the file name specifies a
relative file name, it is put in the program&rsquo;s initial
working directory : this is the current directory when the
program started its execution <br>
after the fork or after the exec. If it specifies an
absolute file name (ie. starts with &rsquo;/&rsquo;) then it
is put there.</p>


<p style="margin-top: 1em">--log-socket=&lt;ip-address:port-number&gt;
<br>
Specifies that Valgrind should send all of its messages to
the specified port at the specified IP address. The port may
be omitted, in which case port 1500 is used. If a <br>
connection cannot be made to the specified socket, Valgrind
falls back to writing output to the standard error (stderr).
This option is intended to be used in conjunction <br>
with the valgrind-listener program. For further details, see
the commentary in the manual.</p>

<p style="margin-top: 1em">ERROR-RELATED OPTIONS <br>
These options are used by all tools that can report errors,
e.g. Memcheck, but not Cachegrind.</p>

<p style="margin-top: 1em">--xml=&lt;yes|no&gt; [default:
no] <br>
When enabled, the important parts of the output (e.g. tool
error messages) will be in XML format rather than plain
text. Furthermore, the XML output will be sent to a <br>
different output channel than the plain text output.
Therefore, you also must use one of --xml-fd, --xml-file or
--xml-socket to specify where the XML is to be sent.</p>

<p style="margin-top: 1em">Less important messages will
still be printed in plain text, but because the XML output
and plain text output are sent to different output channels
(the destination of the <br>
plain text output is still controlled by --log-fd,
--log-file and --log-socket) this should not cause
problems.</p>

<p style="margin-top: 1em">This option is aimed at making
life easier for tools that consume Valgrind&rsquo;s output
as input, such as GUI front ends. Currently this option
works with Memcheck, Helgrind, DRD <br>
and SGcheck. The output format is specified in the file
docs/internals/xml-output-protocol4.txt in the source tree
for Valgrind 3.5.0 or later.</p>

<p style="margin-top: 1em">The recommended options for a
GUI to pass, when requesting XML output, are: --xml=yes to
enable XML output, --xml-file to send the XML output to a
(presumably GUI-selected) <br>
file, --log-file to send the plain text output to a second
GUI-selected file, --child-silent-after-fork=yes, and -q to
restrict the plain text output to critical error <br>
messages created by Valgrind itself. For example, failure to
read a specified suppressions file counts as a critical
error message. In this way, for a successful run the text
<br>
output file will be empty. But if it isn&rsquo;t empty, then
it will contain important information which the GUI user
should be made aware of.</p>

<p style="margin-top: 1em">--xml-fd=&lt;number&gt;
[default: -1, disabled] <br>
Specifies that Valgrind should send its XML output to the
specified file descriptor. It must be used in conjunction
with --xml=yes.</p>

<p style="margin-top: 1em">--xml-file=&lt;filename&gt; <br>
Specifies that Valgrind should send its XML output to the
specified file. It must be used in conjunction with
--xml=yes. Any %p or %q sequences appearing in the filename
are <br>
expanded in exactly the same way as they are for --log-file.
See the description of --log-file for details.</p>


<p style="margin-top: 1em">--xml-socket=&lt;ip-address:port-number&gt;
<br>
Specifies that Valgrind should send its XML output the
specified port at the specified IP address. It must be used
in conjunction with --xml=yes. The form of the argument is
<br>
the same as that used by --log-socket. See the description
of --log-socket for further details.</p>


<p style="margin-top: 1em">--xml-user-comment=&lt;string&gt;
<br>
Embeds an extra user comment string at the start of the XML
output. Only works when --xml=yes is specified; ignored
otherwise.</p>

<p style="margin-top: 1em">--demangle=&lt;yes|no&gt;
[default: yes] <br>
Enable/disable automatic demangling (decoding) of C++ names.
Enabled by default. When enabled, Valgrind will attempt to
translate encoded C++ names back to something <br>
approaching the original. The demangler handles symbols
mangled by g++ versions 2.X, 3.X and 4.X.</p>

<p style="margin-top: 1em">An important fact about
demangling is that function names mentioned in suppressions
files should be in their mangled form. Valgrind does not
demangle function names when <br>
searching for applicable suppressions, because to do
otherwise would make suppression file contents dependent on
the state of Valgrind&rsquo;s demangling machinery, and also
slow <br>
down suppression matching.</p>

<p style="margin-top: 1em">--num-callers=&lt;number&gt;
[default: 12] <br>
Specifies the maximum number of entries shown in stack
traces that identify program locations. Note that errors are
commoned up using only the top four function locations <br>
(the place in the current function, and that of its three
immediate callers). So this doesn&rsquo;t affect the total
number of errors reported.</p>

<p style="margin-top: 1em">The maximum value for this is
500. Note that higher settings will make Valgrind run a bit
more slowly and take a bit more memory, but can be useful
when working with programs <br>
with deeply-nested call chains.</p>


<p style="margin-top: 1em">--unw-stack-scan-thresh=&lt;number&gt;
[default: 0] , --unw-stack-scan-frames=&lt;number&gt;
[default: 5] <br>
Stack-scanning support is available only on ARM targets.</p>

<p style="margin-top: 1em">These flags enable and control
stack unwinding by stack scanning. When the normal stack
unwinding mechanisms -- usage of Dwarf CFI records, and
frame-pointer following -- <br>
fail, stack scanning may be able to recover a stack
trace.</p>

<p style="margin-top: 1em">Note that stack scanning is an
imprecise, heuristic mechanism that may give very misleading
results, or none at all. It should be used only in
emergencies, when normal <br>
unwinding fails, and it is important to nevertheless have
stack traces.</p>

<p style="margin-top: 1em">Stack scanning is a simple
technique: the unwinder reads words from the stack, and
tries to guess which of them might be return addresses, by
checking to see if they point <br>
just after ARM or Thumb call instructions. If so, the word
is added to the backtrace.</p>

<p style="margin-top: 1em">The main danger occurs when a
function call returns, leaving its return address exposed,
and a new function is called, but the new function does not
overwrite the old <br>
address. The result of this is that the backtrace may
contain entries for functions which have already returned,
and so be very confusing.</p>

<p style="margin-top: 1em">A second limitation of this
implementation is that it will scan only the page (4KB,
normally) containing the starting stack pointer. If the
stack frames are large, this may <br>
result in only a few (or not even any) being present in the
trace. Also, if you are unlucky and have an initial stack
pointer near the end of its containing page, the scan <br>
may miss all interesting frames.</p>

<p style="margin-top: 1em">By default stack scanning is
disabled. The normal use case is to ask for it when a stack
trace would otherwise be very short. So, to enable it, use
<br>
--unw-stack-scan-thresh=number. This requests Valgrind to
try using stack scanning to &quot;extend&quot; stack traces
which contain fewer than number frames.</p>

<p style="margin-top: 1em">If stack scanning does take
place, it will only generate at most the number of frames
specified by --unw-stack-scan-frames. Typically, stack
scanning generates so many <br>
garbage entries that this value is set to a low value (5) by
default. In no case will a stack trace larger than the value
specified by --num-callers be created.</p>

<p style="margin-top: 1em">--error-limit=&lt;yes|no&gt;
[default: yes] <br>
When enabled, Valgrind stops reporting errors after
10,000,000 in total, or 1,000 different ones, have been
seen. This is to stop the error tracking machinery from
becoming a <br>
huge performance overhead in programs with many errors.</p>

<p style="margin-top: 1em">--error-exitcode=&lt;number&gt;
[default: 0] <br>
Specifies an alternative exit code to return if Valgrind
reported any errors in the run. When set to the default
value (zero), the return value from Valgrind will always be
<br>
the return value of the process being simulated. When set to
a nonzero value, that value is returned instead, if Valgrind
detects any errors. This is useful for using <br>
Valgrind as part of an automated test suite, since it makes
it easy to detect test cases for which Valgrind has reported
errors, just by inspecting return codes.</p>


<p style="margin-top: 1em">--error-markers=&lt;begin&gt;,&lt;end&gt;
[default: none] <br>
When errors are output as plain text (i.e. XML not used),
--error-markers instructs to output a line containing the
begin (end) string before (after) each error.</p>

<p style="margin-top: 1em">Such marker lines facilitate
searching for errors and/or extracting errors in an output
file that contain valgrind errors mixed with the program
output.</p>

<p style="margin-top: 1em">Note that empty markers are
accepted. So, only using a begin (or an end) marker is
possible.</p>


<p style="margin-top: 1em">--sigill-diagnostics=&lt;yes|no&gt;
[default: yes] <br>
Enable/disable printing of illegal instruction diagnostics.
Enabled by default, but defaults to disabled when --quiet is
given. The default can always be explicitly <br>
overridden by giving this option.</p>

<p style="margin-top: 1em">When enabled, a warning message
will be printed, along with some diagnostics, whenever an
instruction is encountered that Valgrind cannot decode or
translate, before the <br>
program is given a SIGILL signal. Often an illegal
instruction indicates a bug in the program or missing
support for the particular instruction in Valgrind. But some
programs <br>
do deliberately try to execute an instruction that might be
missing and trap the SIGILL signal to detect processor
features. Using this flag makes it possible to avoid the
<br>
diagnostic output that you would otherwise get in such
cases.</p>


<p style="margin-top: 1em">--show-below-main=&lt;yes|no&gt;
[default: no] <br>
By default, stack traces for errors do not show any
functions that appear beneath main because most of the time
it&rsquo;s uninteresting C library stuff and/or
gobbledygook. <br>
Alternatively, if main is not present in the stack trace,
stack traces will not show any functions below main-like
functions such as glibc&rsquo;s __libc_start_main.
Furthermore, <br>
if main-like functions are present in the trace, they are
normalised as (below main), in order to make the output more
deterministic.</p>

<p style="margin-top: 1em">If this option is enabled, all
stack trace entries will be shown and main-like functions
will not be normalised.</p>

<p style="margin-top: 1em">--fullpath-after=&lt;string&gt;
[default: don&rsquo;t show source paths] <br>
By default Valgrind only shows the filenames in stack
traces, but not full paths to source files. When using
Valgrind in large projects where the sources reside in
multiple <br>
different directories, this can be inconvenient.
--fullpath-after provides a flexible solution to this
problem. When this option is present, the path to each
source file is <br>
shown, with the following all-important caveat: if string is
found in the path, then the path up to and including string
is omitted, else the path is shown unmodified. Note <br>
that string is not required to be a prefix of the path.</p>

<p style="margin-top: 1em">For example, consider a file
named /home/janedoe/blah/src/foo/bar/xyzzy.c. Specifying
--fullpath-after=/home/janedoe/blah/src/ will cause Valgrind
to show the name as <br>
foo/bar/xyzzy.c.</p>

<p style="margin-top: 1em">Because the string is not
required to be a prefix, --fullpath-after=src/ will produce
the same output. This is useful when the path contains
arbitrary machine-generated <br>
characters. For example, the path
/my/build/dir/C32A1B47/blah/src/foo/xyzzy can be pruned to
foo/xyzzy using --fullpath-after=/blah/src/.</p>

<p style="margin-top: 1em">If you simply want to see the
full path, just specify an empty string: --fullpath-after=.
This isn&rsquo;t a special case, merely a logical
consequence of the above rules.</p>

<p style="margin-top: 1em">Finally, you can use
--fullpath-after multiple times. Any appearance of it causes
Valgrind to switch to producing full paths and applying the
above filtering rule. Each <br>
produced path is compared against all the
--fullpath-after-specified strings, in the order specified.
The first string to match causes the path to be truncated as
described <br>
above. If none match, the full path is shown. This
facilitates chopping off prefixes when the sources are drawn
from a number of unrelated directories.</p>


<p style="margin-top: 1em">--extra-debuginfo-path=&lt;path&gt;
[default: undefined and unused] <br>
By default Valgrind searches in several well-known paths for
debug objects, such as /usr/lib/debug/.</p>

<p style="margin-top: 1em">However, there may be scenarios
where you may wish to put debug objects at an arbitrary
location, such as external storage when running Valgrind on
a mobile device with <br>
limited local storage. Another example might be a situation
where you do not have permission to install debug object
packages on the system where you are running Valgrind.</p>

<p style="margin-top: 1em">In these scenarios, you may
provide an absolute path as an extra, final place for
Valgrind to search for debug objects by specifying <br>
--extra-debuginfo-path=/path/to/debug/objects. The given
path will be prepended to the absolute path name of the
searched-for object. For example, if Valgrind is looking for
<br>
the debuginfo for /w/x/y/zz.so and
--extra-debuginfo-path=/a/b/c is specified, it will look for
a debug object at /a/b/c/w/x/y/zz.so.</p>

<p style="margin-top: 1em">This flag should only be
specified once. If it is specified multiple times, only the
last instance is honoured.</p>

<p style="margin-top: 1em">--debuginfo-server=ipaddr:port
[default: undefined and unused] <br>
This is a new, experimental, feature introduced in version
3.9.0.</p>

<p style="margin-top: 1em">In some scenarios it may be
convenient to read debuginfo from objects stored on a
different machine. With this flag, Valgrind will query a
debuginfo server running on ipaddr <br>
and listening on port port, if it cannot find the debuginfo
object in the local filesystem.</p>

<p style="margin-top: 1em">The debuginfo server must accept
TCP connections on port port. The debuginfo server is
contained in the source file auxprogs/valgrind-di-server.c.
It will only serve from the <br>
directory it is started in. port defaults to 1500 in both
client and server if not specified.</p>

<p style="margin-top: 1em">If Valgrind looks for the
debuginfo for /w/x/y/zz.so by using the debuginfo server, it
will strip the pathname components and merely request zz.so
on the server. That in turn <br>
will look only in its current working directory for a
matching debuginfo object.</p>

<p style="margin-top: 1em">The debuginfo data is
transmitted in small fragments (8 KB) as requested by
Valgrind. Each block is compressed using LZO to reduce
transmission time. The implementation has <br>
been tuned for best performance over a single-stage 802.11g
(WiFi) network link.</p>

<p style="margin-top: 1em">Note that checks for matching
primary vs debug objects, using GNU debuglink CRC scheme,
are performed even when using the debuginfo server. To
disable such checking, you need <br>
to also specify --allow-mismatched-debuginfo=yes.</p>

<p style="margin-top: 1em">By default the Valgrind build
system will build valgrind-di-server for the target
platform, which is almost certainly not what you want. So
far we have been unable to find <br>
out how to get automake/autoconf to build it for the build
platform. If you want to use it, you will have to recompile
it by hand using the command shown at the top of <br>
auxprogs/valgrind-di-server.c.</p>


<p style="margin-top: 1em">--allow-mismatched-debuginfo=no|yes
[no] <br>
When reading debuginfo from separate debuginfo objects,
Valgrind will by default check that the main and debuginfo
objects match, using the GNU debuglink mechanism. This <br>
guarantees that it does not read debuginfo from out of date
debuginfo objects, and also ensures that Valgrind
can&rsquo;t crash as a result of mismatches.</p>

<p style="margin-top: 1em">This check can be overridden
using --allow-mismatched-debuginfo=yes. This may be useful
when the debuginfo and main objects have not been split in
the proper way. Be careful <br>
when using this, though: it disables all consistency
checking, and Valgrind has been observed to crash when the
main and debuginfo objects don&rsquo;t match.</p>

<p style="margin-top: 1em">--suppressions=&lt;filename&gt;
[default: $PREFIX/lib/valgrind/default.supp] <br>
Specifies an extra file from which to read descriptions of
errors to suppress. You may use up to 100 extra suppression
files.</p>


<p style="margin-top: 1em">--gen-suppressions=&lt;yes|no|all&gt;
[default: no] <br>
When set to yes, Valgrind will pause after every error shown
and print the line:</p>

<p style="margin-top: 1em">---- Print suppression ? ---
[Return/N/n/Y/y/C/c] ----</p>

<p style="margin-top: 1em">Pressing Ret, or N Ret or n Ret,
causes Valgrind continue execution without printing a
suppression for this error.</p>

<p style="margin-top: 1em">Pressing Y Ret or y Ret causes
Valgrind to write a suppression for this error. You can then
cut and paste it into a suppression file if you don&rsquo;t
want to hear about the error <br>
in the future.</p>

<p style="margin-top: 1em">When set to all, Valgrind will
print a suppression for every reported error, without
querying the user.</p>

<p style="margin-top: 1em">This option is particularly
useful with C++ programs, as it prints out the suppressions
with mangled names, as required.</p>

<p style="margin-top: 1em">Note that the suppressions
printed are as specific as possible. You may want to common
up similar ones, by adding wildcards to function names, and
by using frame-level <br>
wildcards. The wildcarding facilities are powerful yet
flexible, and with a bit of careful editing, you may be able
to suppress a whole family of related errors with only a
<br>
few suppressions.</p>

<p style="margin-top: 1em">Sometimes two different errors
are suppressed by the same suppression, in which case
Valgrind will output the suppression more than once, but you
only need to have one copy <br>
in your suppression file (but having more than one
won&rsquo;t cause problems). Also, the suppression name is
given as &lt;insert a suppression name here&gt;; the name
doesn&rsquo;t really <br>
matter, it&rsquo;s only used with the -v option which prints
out all used suppression records.</p>

<p style="margin-top: 1em">--input-fd=&lt;number&gt;
[default: 0, stdin] <br>
When using --gen-suppressions=yes, Valgrind will stop so as
to read keyboard input from you when each error occurs. By
default it reads from the standard input (stdin), which <br>
is problematic for programs which close stdin. This option
allows you to specify an alternative file descriptor from
which to read input.</p>

<p style="margin-top: 1em">--dsymutil=no|yes [yes] <br>
This option is only relevant when running Valgrind on Mac OS
X.</p>

<p style="margin-top: 1em">Mac OS X uses a deferred debug
information (debuginfo) linking scheme. When object files
containing debuginfo are linked into a .dylib or an
executable, the debuginfo is not <br>
copied into the final file. Instead, the debuginfo must be
linked manually by running dsymutil, a system-provided
utility, on the executable or .dylib. The resulting combined
<br>
debuginfo is placed in a directory alongside the executable
or .dylib, but with the extension .dSYM.</p>

<p style="margin-top: 1em">With --dsymutil=no, Valgrind
will detect cases where the .dSYM directory is either
missing, or is present but does not appear to match the
associated executable or .dylib, <br>
most likely because it is out of date. In these cases,
Valgrind will print a warning message but take no further
action.</p>

<p style="margin-top: 1em">With --dsymutil=yes, Valgrind
will, in such cases, automatically run dsymutil as necessary
to bring the debuginfo up to date. For all practical
purposes, if you always use <br>
--dsymutil=yes, then there is never any need to run dsymutil
manually or as part of your applications&rsquo;s build
system, since Valgrind will run it as necessary.</p>

<p style="margin-top: 1em">Valgrind will not attempt to run
dsymutil on any executable or library in /usr/, /bin/,
/sbin/, /opt/, /sw/, /System/, /Library/ or /Applications/
since dsymutil will always <br>
fail in such situations. It fails both because the debuginfo
for such pre-installed system components is not available
anywhere, and also because it would require write <br>
privileges in those directories.</p>

<p style="margin-top: 1em">Be careful when using
--dsymutil=yes, since it will cause pre-existing .dSYM
directories to be silently deleted and re-created. Also note
that dsymutil is quite slow, <br>
sometimes excessively so.</p>

<p style="margin-top: 1em">--max-stackframe=&lt;number&gt;
[default: 2000000] <br>
The maximum size of a stack frame. If the stack pointer
moves by more than this amount then Valgrind will assume
that the program is switching to a different stack.</p>

<p style="margin-top: 1em">You may need to use this option
if your program has large stack-allocated arrays. Valgrind
keeps track of your program&rsquo;s stack pointer. If it
changes by more than the <br>
threshold amount, Valgrind assumes your program is switching
to a different stack, and Memcheck behaves differently than
it would for a stack pointer change smaller than the <br>
threshold. Usually this heuristic works well. However, if
your program allocates large structures on the stack, this
heuristic will be fooled, and Memcheck will subsequently
<br>
report large numbers of invalid stack accesses. This option
allows you to change the threshold to a different value.</p>

<p style="margin-top: 1em">You should only consider use of
this option if Valgrind&rsquo;s debug output directs you to
do so. In that case it will tell you the new threshold you
should specify.</p>

<p style="margin-top: 1em">In general, allocating large
structures on the stack is a bad idea, because you can
easily run out of stack space, especially on systems with
limited memory or which expect <br>
to support large numbers of threads each with a small stack,
and also because the error checking performed by Memcheck is
more effective for heap-allocated data than for <br>
stack-allocated data. If you have to use this option, you
may wish to consider rewriting your code to allocate on the
heap rather than on the stack.</p>

<p style="margin-top: 1em">--main-stacksize=&lt;number&gt;
[default: use current &rsquo;ulimit&rsquo; value] <br>
Specifies the size of the main thread&rsquo;s stack.</p>

<p style="margin-top: 1em">To simplify its memory
management, Valgrind reserves all required space for the
main thread&rsquo;s stack at startup. That means it needs to
know the required stack size at <br>
startup.</p>

<p style="margin-top: 1em">By default, Valgrind uses the
current &quot;ulimit&quot; value for the stack size, or 16
MB, whichever is lower. In many cases this gives a stack
size in the range 8 to 16 MB, which <br>
almost never overflows for most applications.</p>

<p style="margin-top: 1em">If you need a larger total stack
size, use --main-stacksize to specify it. Only set it as
high as you need, since reserving far more space than you
need (that is, hundreds of <br>
megabytes more than you need) constrains Valgrind&rsquo;s
memory allocators and may reduce the total amount of memory
that Valgrind can use. This is only really of significance
on <br>
32-bit machines.</p>

<p style="margin-top: 1em">On Linux, you may request a
stack of size up to 2GB. Valgrind will stop with a
diagnostic message if the stack cannot be allocated.</p>

<p style="margin-top: 1em">--main-stacksize only affects
the stack size for the program&rsquo;s initial thread. It
has no bearing on the size of thread stacks, as Valgrind
does not allocate those.</p>

<p style="margin-top: 1em">You may need to use both
--main-stacksize and --max-stackframe together. It is
important to understand that --main-stacksize sets the
maximum total stack size, whilst <br>
--max-stackframe specifies the largest size of any one stack
frame. You will have to work out the --main-stacksize value
for yourself (usually, if your applications <br>
segfaults). But Valgrind will tell you the needed
--max-stackframe size, if necessary.</p>

<p style="margin-top: 1em">As discussed further in the
description of --max-stackframe, a requirement for a large
stack is a sign of potential portability problems. You are
best advised to place all <br>
large data in heap-allocated memory.</p>

<p style="margin-top: 1em">--max-threads=&lt;number&gt;
[default: 500] <br>
By default, Valgrind can handle to up to 500 threads.
Occasionally, that number is too small. Use this option to
provide a different limit. E.g. --max-threads=3000.</p>

<p style="margin-top: 1em">MALLOC()-RELATED OPTIONS <br>
For tools that use their own version of malloc (e.g.
Memcheck, Massif, Helgrind, DRD), the following options
apply.</p>

<p style="margin-top: 1em">--alignment=&lt;number&gt;
[default: 8 or 16, depending on the platform] <br>
By default Valgrind&rsquo;s malloc, realloc, etc, return a
block whose starting address is 8-byte aligned or 16-byte
aligned (the value depends on the platform and matches the
<br>
platform default). This option allows you to specify a
different alignment. The supplied value must be greater than
or equal to the default, less than or equal to 4096, and
<br>
must be a power of two.</p>

<p style="margin-top: 1em">--redzone-size=&lt;number&gt;
[default: depends on the tool] <br>
Valgrind&rsquo;s malloc, realloc, etc, add padding blocks
before and after each heap block allocated by the program
being run. Such padding blocks are called redzones. The
default <br>
value for the redzone size depends on the tool. For example,
Memcheck adds and protects a minimum of 16 bytes before and
after each block allocated by the client. This allows <br>
it to detect block underruns or overruns of up to 16
bytes.</p>

<p style="margin-top: 1em">Increasing the redzone size
makes it possible to detect overruns of larger distances,
but increases the amount of memory used by Valgrind.
Decreasing the redzone size will <br>
reduce the memory needed by Valgrind but also reduces the
chances of detecting over/underruns, so is not
recommended.</p>

<p style="margin-top: 1em">UNCOMMON OPTIONS <br>
These options apply to all tools, as they affect certain
obscure workings of the Valgrind core. Most people
won&rsquo;t need to use them.</p>


<p style="margin-top: 1em">--smc-check=&lt;none|stack|all|all-non-file&gt;
[default: all-non-file for x86/amd64/s390x, stack for other
archs] <br>
This option controls Valgrind&rsquo;s detection of
self-modifying code. If no checking is done, when a program
executes some code, then overwrites it with new code, and
executes <br>
the new code, Valgrind will continue to execute the
translations it made for the old code. This will likely lead
to incorrect behaviour and/or crashes.</p>

<p style="margin-top: 1em">For &quot;modern&quot;
architectures -- anything that&rsquo;s not x86, amd64 or
s390x -- the default is stack. This is because a correct
program must take explicit action to reestablish D-I <br>
cache coherence following code modification. Valgrind
observes and honours such actions, with the result that
self-modifying code is transparently handled with zero extra
<br>
cost.</p>

<p style="margin-top: 1em">For x86, amd64 and s390x, the
program is not required to notify the hardware of required
D-I coherence syncing. Hence the default is all-non-file,
which covers the normal <br>
case of generating code into an anonymous (non-file-backed)
mmap&rsquo;d area.</p>

<p style="margin-top: 1em">The meanings of the four
available settings are as follows. No detection (none),
detect self-modifying code on the stack (which is used by
GCC to implement nested functions) <br>
(stack), detect self-modifying code everywhere (all), and
detect self-modifying code everywhere except in file-backed
mappings (all-non-file).</p>

<p style="margin-top: 1em">Running with all will slow
Valgrind down noticeably. Running with none will rarely
speed things up, since very little code gets dynamically
generated in most programs. The <br>
VALGRIND_DISCARD_TRANSLATIONS client request is an
alternative to --smc-check=all and --smc-check=all-non-file
that requires more programmer effort but allows Valgrind to
run <br>
your program faster, by telling it precisely when
translations need to be re-made.</p>

<p style="margin-top: 1em">--smc-check=all-non-file
provides a cheaper but more limited version of
--smc-check=all. It adds checks to any translations that do
not originate from file-backed memory <br>
mappings. Typical applications that generate code, for
example JITs in web browsers, generate code into anonymous
mmaped areas, whereas the &quot;fixed&quot; code of the
browser always <br>
lives in file-backed mappings. --smc-check=all-non-file
takes advantage of this observation, limiting the overhead
of checking to code which is likely to be JIT generated.</p>


<p style="margin-top: 1em">--read-inline-info=&lt;yes|no&gt;
[default: see below] <br>
When enabled, Valgrind will read information about inlined
function calls from DWARF3 debug info. This slows Valgrind
startup and makes it use more memory (typically for each
<br>
inlined piece of code, 6 words and space for the function
name), but it results in more descriptive stacktraces. For
the 3.10.0 release, this functionality is enabled by <br>
default only for Linux, Android and Solaris targets and only
for the tools Memcheck, Helgrind and DRD. Here is an example
of some stacktraces with --read-inline-info=no:</p>

<p style="margin-top: 1em">==15380== Conditional jump or
move depends on uninitialised value(s) <br>
==15380== at 0x80484EA: main (inlinfo.c:6) <br>
==15380== <br>
==15380== Conditional jump or move depends on uninitialised
value(s) <br>
==15380== at 0x8048550: fun_noninline (inlinfo.c:6) <br>
==15380== by 0x804850E: main (inlinfo.c:34) <br>
==15380== <br>
==15380== Conditional jump or move depends on uninitialised
value(s) <br>
==15380== at 0x8048520: main (inlinfo.c:6)</p>

<p style="margin-top: 1em">And here are the same errors
with --read-inline-info=yes:</p>

<p style="margin-top: 1em">==15377== Conditional jump or
move depends on uninitialised value(s) <br>
==15377== at 0x80484EA: fun_d (inlinfo.c:6) <br>
==15377== by 0x80484EA: fun_c (inlinfo.c:14) <br>
==15377== by 0x80484EA: fun_b (inlinfo.c:20) <br>
==15377== by 0x80484EA: fun_a (inlinfo.c:26) <br>
==15377== by 0x80484EA: main (inlinfo.c:33) <br>
==15377== <br>
==15377== Conditional jump or move depends on uninitialised
value(s) <br>
==15377== at 0x8048550: fun_d (inlinfo.c:6) <br>
==15377== by 0x8048550: fun_noninline (inlinfo.c:41) <br>
==15377== by 0x804850E: main (inlinfo.c:34) <br>
==15377== <br>
==15377== Conditional jump or move depends on uninitialised
value(s) <br>
==15377== at 0x8048520: fun_d (inlinfo.c:6) <br>
==15377== by 0x8048520: main (inlinfo.c:35)</p>

<p style="margin-top: 1em">--read-var-info=&lt;yes|no&gt;
[default: no] <br>
When enabled, Valgrind will read information about variable
types and locations from DWARF3 debug info. This slows
Valgrind startup significantly and makes it use <br>
significantly more memory, but for the tools that can take
advantage of it (Memcheck, Helgrind, DRD) it can result in
more precise error messages. For example, here are some <br>
standard errors issued by Memcheck:</p>

<p style="margin-top: 1em">==15363== Uninitialised byte(s)
found during client check request <br>
==15363== at 0x80484A9: croak (varinfo1.c:28) <br>
==15363== by 0x8048544: main (varinfo1.c:55) <br>
==15363== Address 0x80497f7 is 7 bytes inside data symbol
&quot;global_i2&quot; <br>
==15363== <br>
==15363== Uninitialised byte(s) found during client check
request <br>
==15363== at 0x80484A9: croak (varinfo1.c:28) <br>
==15363== by 0x8048550: main (varinfo1.c:56) <br>
==15363== Address 0xbea0d0cc is on thread 1&rsquo;s stack
<br>
==15363== in frame #1, created by main (varinfo1.c:45)</p>

<p style="margin-top: 1em">And here are the same errors
with --read-var-info=yes:</p>

<p style="margin-top: 1em">==15370== Uninitialised byte(s)
found during client check request <br>
==15370== at 0x80484A9: croak (varinfo1.c:28) <br>
==15370== by 0x8048544: main (varinfo1.c:55) <br>
==15370== Location 0x80497f7 is 0 bytes inside global_i2[7],
<br>
==15370== a global variable declared at varinfo1.c:41 <br>
==15370== <br>
==15370== Uninitialised byte(s) found during client check
request <br>
==15370== at 0x80484A9: croak (varinfo1.c:28) <br>
==15370== by 0x8048550: main (varinfo1.c:56) <br>
==15370== Location 0xbeb4a0cc is 0 bytes inside local var
&quot;local&quot; <br>
==15370== declared at varinfo1.c:46, in frame #1 of thread
1</p>

<p style="margin-top: 1em">--vgdb-poll=&lt;number&gt;
[default: 5000] <br>
As part of its main loop, the Valgrind scheduler will poll
to check if some activity (such as an external command or
some input from a gdb) has to be handled by gdbserver. <br>
This activity poll will be done after having run the given
number of basic blocks (or slightly more than the given
number of basic blocks). This poll is quite cheap so the
<br>
default value is set relatively low. You might further
decrease this value if vgdb cannot use ptrace system call to
interrupt Valgrind if all threads are (most of the time)
<br>
blocked in a system call.</p>

<p style="margin-top: 1em">--vgdb-shadow-registers=no|yes
[default: no] <br>
When activated, gdbserver will expose the Valgrind shadow
registers to GDB. With this, the value of the Valgrind
shadow registers can be examined or changed using GDB. <br>
Exposing shadow registers only works with GDB version 7.1 or
later.</p>

<p style="margin-top: 1em">--vgdb-prefix=&lt;prefix&gt;
[default: /tmp/vgdb-pipe] <br>
To communicate with gdb/vgdb, the Valgrind gdbserver creates
3 files (2 named FIFOs and a mmap shared memory file). The
prefix option controls the directory and prefix for <br>
the creation of these files.</p>


<p style="margin-top: 1em">--run-libc-freeres=&lt;yes|no&gt;
[default: yes] <br>
This option is only relevant when running Valgrind on
Linux.</p>

<p style="margin-top: 1em">The GNU C library (libc.so),
which is used by all programs, may allocate memory for its
own uses. Usually it doesn&rsquo;t bother to free that
memory when the program ends&acirc;there <br>
would be no point, since the Linux kernel reclaims all
process resources when a process exits anyway, so it would
just slow things down.</p>

<p style="margin-top: 1em">The glibc authors realised that
this behaviour causes leak checkers, such as Valgrind, to
falsely report leaks in glibc, when a leak check is done at
exit. In order to avoid <br>
this, they provided a routine called __libc_freeres
specifically to make glibc release all memory it has
allocated. Memcheck therefore tries to run __libc_freeres at
exit.</p>

<p style="margin-top: 1em">Unfortunately, in some very old
versions of glibc, __libc_freeres is sufficiently buggy to
cause segmentation faults. This was particularly noticeable
on Red Hat 7.1. So this <br>
option is provided in order to inhibit the run of
__libc_freeres. If your program seems to run fine on
Valgrind, but segfaults at exit, you may find that <br>
--run-libc-freeres=no fixes that, although at the cost of
possibly falsely reporting space leaks in libc.so.</p>

<p style="margin-top: 1em">--sim-hints=hint1,hint2,... <br>
Pass miscellaneous hints to Valgrind which slightly modify
the simulated behaviour in nonstandard or dangerous ways,
possibly to help the simulation of strange features. By <br>
default no hints are enabled. Use with caution! Currently
known hints are:</p>

<p style="margin-top: 1em">&Acirc;&middot; lax-ioctls: Be
very lax about ioctl handling; the only assumption is that
the size is correct. Doesn&rsquo;t require the full buffer
to be initialised when writing. Without <br>
this, using some device drivers with a large number of
strange ioctl commands becomes very tiresome.</p>

<p style="margin-top: 1em">&Acirc;&middot; fuse-compatible:
Enable special handling for certain system calls that may
block in a FUSE file-system. This may be necessary when
running Valgrind on a multi-threaded <br>
program that uses one thread to manage a FUSE file-system
and another thread to access that file-system.</p>

<p style="margin-top: 1em">&Acirc;&middot; enable-outer:
Enable some special magic needed when the program being run
is itself Valgrind.</p>

<p style="margin-top: 1em">&Acirc;&middot; no-inner-prefix:
Disable printing a prefix &gt; in front of each stdout or
stderr output line in an inner Valgrind being run by an
outer Valgrind. This is useful when <br>
running Valgrind regression tests in an outer/inner setup.
Note that the prefix &gt; will always be printed in front of
the inner debug logging lines.</p>

<p style="margin-top: 1em">&Acirc;&middot;
no-nptl-pthread-stackcache: This hint is only relevant when
running Valgrind on Linux.</p>

<p style="margin-top: 1em">The GNU glibc pthread library
(libpthread.so), which is used by pthread programs,
maintains a cache of pthread stacks. When a pthread
terminates, the memory used for the <br>
pthread stack and some thread local storage related data
structure are not always directly released. This memory is
kept in a cache (up to a certain size), and is re-used <br>
if a new thread is started.</p>

<p style="margin-top: 1em">This cache causes the helgrind
tool to report some false positive race condition errors on
this cached memory, as helgrind does not understand the
internal glibc cache <br>
synchronisation primitives. So, when using helgrind,
disabling the cache helps to avoid false positive race
conditions, in particular when using thread local storage
<br>
variables (e.g. variables using the __thread qualifier).</p>

<p style="margin-top: 1em">When using the memcheck tool,
disabling the cache ensures the memory used by glibc to
handle __thread variables is directly released when a thread
terminates.</p>

<p style="margin-top: 1em">Note: Valgrind disables the
cache using some internal knowledge of the glibc stack cache
implementation and by examining the debug information of the
pthread library. <br>
This technique is thus somewhat fragile and might not work
for all glibc versions. This has been succesfully tested
with various glibc versions (e.g. 2.11, 2.16, 2.18) on <br>
various platforms.</p>

<p style="margin-top: 1em">&Acirc;&middot; lax-doors:
(Solaris only) Be very lax about door syscall handling over
unrecognised door file descriptors. Does not require that
full buffer is initialised when writing. <br>
Without this, programs using libdoor(3LIB) functionality
with completely proprietary semantics may report large
number of false positives.</p>

<p style="margin-top: 1em">--fair-sched=&lt;no|yes|try&gt;
[default: no] <br>
The --fair-sched option controls the locking mechanism used
by Valgrind to serialise thread execution. The locking
mechanism controls the way the threads are scheduled, and
<br>
different settings give different trade-offs between
fairness and performance. For more details about the
Valgrind thread serialisation scheme and its impact on
performance <br>
and thread scheduling, see Scheduling and Multi-Thread
Performance.</p>

<p style="margin-top: 1em">&Acirc;&middot; The value
--fair-sched=yes activates a fair scheduler. In short, if
multiple threads are ready to run, the threads will be
scheduled in a round robin fashion. This <br>
mechanism is not available on all platforms or Linux
versions. If not available, using --fair-sched=yes will
cause Valgrind to terminate with an error.</p>

<p style="margin-top: 1em">You may find this setting
improves overall responsiveness if you are running an
interactive multithreaded program, for example a web
browser, on Valgrind.</p>

<p style="margin-top: 1em">&Acirc;&middot; The value
--fair-sched=try activates fair scheduling if available on
the platform. Otherwise, it will automatically fall back to
--fair-sched=no.</p>

<p style="margin-top: 1em">&Acirc;&middot; The value
--fair-sched=no activates a scheduler which does not
guarantee fairness between threads ready to run, but which
in general gives the highest performance.</p>


<p style="margin-top: 1em">--kernel-variant=variant1,variant2,...
<br>
Handle system calls and ioctls arising from minor variants
of the default kernel for this platform. This is useful for
running on hacked kernels or with kernel modules which <br>
support nonstandard ioctls, for example. Use with caution.
If you don&rsquo;t understand what this option does then you
almost certainly don&rsquo;t need it. Currently known
variants <br>
are:</p>

<p style="margin-top: 1em">&Acirc;&middot; bproc: support
the sys_broc system call on x86. This is for running on
BProc, which is a minor variant of standard Linux which is
sometimes used for building clusters.</p>

<p style="margin-top: 1em">&Acirc;&middot;
android-no-hw-tls: some versions of the Android emulator for
ARM do not provide a hardware TLS (thread-local state)
register, and Valgrind crashes at startup. Use this <br>
variant to select software support for TLS.</p>

<p style="margin-top: 1em">&Acirc;&middot;
android-gpu-sgx5xx: use this to support handling of
proprietary ioctls for the PowerVR SGX 5XX series of GPUs on
Android devices. Failure to select this does not cause <br>
stability problems, but may cause Memcheck to report false
errors after the program performs GPU-specific ioctls.</p>

<p style="margin-top: 1em">&Acirc;&middot;
android-gpu-adreno3xx: similarly, use this to support
handling of proprietary ioctls for the Qualcomm Adreno 3XX
series of GPUs on Android devices.</p>


<p style="margin-top: 1em">--merge-recursive-frames=&lt;number&gt;
[default: 0] <br>
Some recursive algorithms, for example balanced binary tree
implementations, create many different stack traces, each
containing cycles of calls. A cycle is defined as two <br>
identical program counter values separated by zero or more
other program counter values. Valgrind may then use a lot of
memory to store all these stack traces. This is a poor <br>
use of memory considering that such stack traces contain
repeated uninteresting recursive calls instead of more
interesting information such as the function that has <br>
initiated the recursive call.</p>

<p style="margin-top: 1em">The option
--merge-recursive-frames=&lt;number&gt; instructs Valgrind
to detect and merge recursive call cycles having a size of
up to &lt;number&gt; frames. When such a cycle is <br>
detected, Valgrind records the cycle in the stack trace as a
unique program counter.</p>

<p style="margin-top: 1em">The value 0 (the default) causes
no recursive call merging. A value of 1 will cause stack
traces of simple recursive algorithms (for example, a
factorial implementation) to <br>
be collapsed. A value of 2 will usually be needed to
collapse stack traces produced by recursive algorithms such
as binary trees, quick sort, etc. Higher values might be
<br>
needed for more complex recursive algorithms.</p>

<p style="margin-top: 1em">Note: recursive calls are
detected by analysis of program counter values. They are not
detected by looking at function names.</p>


<p style="margin-top: 1em">--num-transtab-sectors=&lt;number&gt;
[default: 6 for Android platforms, 16 for all others] <br>
Valgrind translates and instruments your program&rsquo;s
machine code in small fragments (basic blocks). The
translations are stored in a translation cache that is
divided into a <br>
number of sections (sectors). If the cache is full, the
sector containing the oldest translations is emptied and
reused. If these old translations are needed again, Valgrind
<br>
must re-translate and re-instrument the corresponding
machine code, which is expensive. If the &quot;executed
instructions&quot; working set of a program is big,
increasing the number <br>
of sectors may improve performance by reducing the number of
re-translations needed. Sectors are allocated on demand.
Once allocated, a sector can never be freed, and <br>
occupies considerable space, depending on the tool and the
value of --avg-transtab-entry-size (about 40 MB per sector
for Memcheck). Use the option --stats=yes to obtain <br>
precise information about the memory used by a sector and
the allocation and recycling of sectors.</p>


<p style="margin-top: 1em">--avg-transtab-entry-size=&lt;number&gt;
[default: 0, meaning use tool provided default] <br>
Average size of translated basic block. This average size is
used to dimension the size of a sector. Each tool provides a
default value to be used. If this default value is <br>
too small, the translation sectors will become full too
quickly. If this default value is too big, a significant
part of the translation sector memory will be unused. Note
<br>
that the average size of a basic block translation depends
on the tool, and might depend on tool options. For example,
the memcheck option --track-origins=yes increases the <br>
size of the basic block translations. Use
--avg-transtab-entry-size to tune the size of the sectors,
either to gain memory or to avoid too many
retranslations.</p>


<p style="margin-top: 1em">--aspace-minaddr=&lt;address&gt;
[default: depends on the platform] <br>
To avoid potential conflicts with some system libraries,
Valgrind does not use the address space below
--aspace-minaddr value, keeping it reserved in case a
library <br>
specifically requests memory in this region. So, some
&quot;pessimistic&quot; value is guessed by Valgrind
depending on the platform. On linux, by default, Valgrind
avoids using the <br>
first 64MB even if typically there is no conflict in this
complete zone. You can use the option --aspace-minaddr to
have your memory hungry application benefitting from more
<br>
of this lower memory. On the other hand, if you encounter a
conflict, increasing aspace-minaddr value might solve it.
Conflicts will typically manifest themselves with mmap <br>
failures in the low range of the address space. The provided
address must be page aligned and must be equal or bigger to
0x1000 (4KB). To find the default value on your <br>
platform, do something such as valgrind -d -d date
2&gt;&amp;1 | grep -i minaddr. Values lower than 0x10000
(64KB) are known to create problems on some
distributions.</p>


<p style="margin-top: 1em">--valgrind-stacksize=&lt;number&gt;
[default: 1MB] <br>
For each thread, Valgrind needs its own
&rsquo;private&rsquo; stack. The default size for these
stacks is largely dimensioned, and so should be sufficient
in most cases. In case the size <br>
is too small, Valgrind will segfault. Before segfaulting, a
warning might be produced by Valgrind when approaching the
limit.</p>

<p style="margin-top: 1em">Use the option
--valgrind-stacksize if such an (unlikely) warning is
produced, or Valgrind dies due to a segmentation violation.
Such segmentation violations have been seen <br>
when demangling huge C++ symbols.</p>

<p style="margin-top: 1em">If your application uses many
threads and needs a lot of memory, you can gain some memory
by reducing the size of these Valgrind stacks using the
option --valgrind-stacksize.</p>

<p style="margin-top: 1em">--show-emwarns=&lt;yes|no&gt;
[default: no] <br>
When enabled, Valgrind will emit warnings about its CPU
emulation in certain cases. These are usually not
interesting.</p>


<p style="margin-top: 1em">--require-text-symbol=:sonamepatt:fnnamepatt
<br>
When a shared object whose soname matches sonamepatt is
loaded into the process, examine all the text symbols it
exports. If none of those match fnnamepatt, print an error
<br>
message and abandon the run. This makes it possible to
ensure that the run does not continue unless a given shared
object contains a particular function name.</p>

<p style="margin-top: 1em">Both sonamepatt and fnnamepatt
can be written using the usual ? and * wildcards. For
example: &quot;:*libc.so*:foo?bar&quot;. You may use
characters other than a colon to separate the <br>
two patterns. It is only important that the first character
and the separator character are the same. For example, the
above example could also be written <br>
&quot;Q*libc.so*Qfoo?bar&quot;. Multiple <br>
--require-text-symbol flags are allowed, in which case
shared objects that are loaded into the process will be
checked against all of them.</p>

<p style="margin-top: 1em">The purpose of this is to
support reliable usage of marked-up libraries. For example,
suppose we have a version of GCC&rsquo;s libgomp.so which
has been marked up with annotations <br>
to support Helgrind. It is only too easy and confusing to
load the wrong, un-annotated libgomp.so into the
application. So the idea is: add a text symbol in the
marked-up <br>
library, for example annotated_for_helgrind_3_6, and then
give the flag
--require-text-symbol=:*libgomp*so*:annotated_for_helgrind_3_6
so that when libgomp.so is loaded, <br>
Valgrind scans its symbol table, and if the symbol
isn&rsquo;t present the run is aborted, rather than
continuing silently with the un-marked-up library. Note that
you should put <br>
the entire flag in quotes to stop shells expanding up the *
and ? wildcards.</p>


<p style="margin-top: 1em">--soname-synonyms=syn1=pattern1,syn2=pattern2,...
<br>
When a shared library is loaded, Valgrind checks for
functions in the library that must be replaced or wrapped.
For example, Memcheck replaces all malloc related functions
<br>
(malloc, free, calloc, ...) with its own versions. Such
replacements are done by default only in shared libraries
whose soname matches a predefined soname pattern (e.g. <br>
libc.so* on linux). By default, no replacement is done for a
statically linked library or for alternative libraries such
as tcmalloc. In some cases, the replacements allow <br>
--soname-synonyms to specify one additional synonym pattern,
giving flexibility in the replacement.</p>

<p style="margin-top: 1em">Currently, this flexibility is
only allowed for the malloc related functions, using the
synonym somalloc. This synonym is usable for all tools doing
standard replacement of <br>
malloc related functions (e.g. memcheck, massif, drd,
helgrind, exp-dhat, exp-sgcheck).</p>

<p style="margin-top: 1em">&Acirc;&middot; Alternate malloc
library: to replace the malloc related functions in an
alternate library with soname mymalloclib.so, give the
option <br>
--soname-synonyms=somalloc=mymalloclib.so. A pattern can be
used to match multiple libraries sonames. For example,
--soname-synonyms=somalloc=*tcmalloc* will match the <br>
soname of all variants of the tcmalloc library (native,
debug, profiled, ... tcmalloc variants).</p>

<p style="margin-top: 1em">Note: the soname of a elf shared
library can be retrieved using the readelf utility.</p>

<p style="margin-top: 1em">&Acirc;&middot; Replacements in
a statically linked library are done by using the NONE
pattern. For example, if you link with libtcmalloc.a,
memcheck will properly work when you give the <br>
option --soname-synonyms=somalloc=NONE. Note that a NONE
pattern will match the main executable and any shared
library having no soname.</p>

<p style="margin-top: 1em">&Acirc;&middot; To run a
&quot;default&quot; Firefox build for Linux, in which
JEMalloc is linked in to the main executable, use
--soname-synonyms=somalloc=NONE.</p>

<p style="margin-top: 1em">DEBUGGING VALGRIND OPTIONS <br>
There are also some options for debugging Valgrind itself.
You shouldn&rsquo;t need to use them in the normal run of
things. If you wish to see the list, use the --help-debug
option.</p>

<p style="margin-top: 1em">MEMCHECK OPTIONS <br>
--leak-check=&lt;no|summary|yes|full&gt; [default: summary]
<br>
When enabled, search for memory leaks when the client
program finishes. If set to summary, it says how many leaks
occurred. If set to full or yes, each individual leak will
<br>
be shown in detail and/or counted as an error, as specified
by the options --show-leak-kinds and
--errors-for-leak-kinds.</p>


<p style="margin-top: 1em">--leak-resolution=&lt;low|med|high&gt;
[default: high] <br>
When doing leak checking, determines how willing Memcheck is
to consider different backtraces to be the same for the
purposes of merging multiple leaks into a single leak <br>
report. When set to low, only the first two entries need
match. When med, four entries have to match. When high, all
entries need to match.</p>

<p style="margin-top: 1em">For hardcore leak debugging, you
probably want to use --leak-resolution=high together with
--num-callers=40 or some such large number.</p>

<p style="margin-top: 1em">Note that the --leak-resolution
setting does not affect Memcheck&rsquo;s ability to find
leaks. It only changes how the results are presented.</p>

<p style="margin-top: 1em">--show-leak-kinds=&lt;set&gt;
[default: definite,possible] <br>
Specifies the leak kinds to show in a full leak search, in
one of the following ways:</p>

<p style="margin-top: 1em">&Acirc;&middot; a comma
separated list of one or more of definite indirect possible
reachable.</p>

<p style="margin-top: 1em">&Acirc;&middot; all to specify
the complete set (all leak kinds). It is equivalent to
--show-leak-kinds=definite,indirect,possible,reachable.</p>

<p style="margin-top: 1em">&Acirc;&middot; none for the
empty set.</p>


<p style="margin-top: 1em">--errors-for-leak-kinds=&lt;set&gt;
[default: definite,possible] <br>
Specifies the leak kinds to count as errors in a full leak
search. The &lt;set&gt; is specified similarly to
--show-leak-kinds</p>


<p style="margin-top: 1em">--leak-check-heuristics=&lt;set&gt;
[default: all] <br>
Specifies the set of leak check heuristics to be used during
leak searches. The heuristics control which interior
pointers to a block cause it to be considered as reachable.
<br>
The heuristic set is specified in one of the following
ways:</p>

<p style="margin-top: 1em">&Acirc;&middot; a comma
separated list of one or more of stdstring length64 newarray
multipleinheritance.</p>

<p style="margin-top: 1em">&Acirc;&middot; all to activate
the complete set of heuristics. It is equivalent to
--leak-check-heuristics=stdstring,length64,newarray,multipleinheritance.</p>

<p style="margin-top: 1em">&Acirc;&middot; none for the
empty set.</p>

<p style="margin-top: 1em">Note that these heuristics are
dependent on the layout of the objects produced by the C++
compiler. They have been tested with some gcc versions (e.g.
4.4 and 4.7). They <br>
might not work properly with other C++ compilers.</p>

<p style="margin-top: 1em">--show-reachable=&lt;yes|no&gt;
, --show-possibly-lost=&lt;yes|no&gt; <br>
These options provide an alternative way to specify the leak
kinds to show:</p>

<p style="margin-top: 1em">&Acirc;&middot;
--show-reachable=no --show-possibly-lost=yes is equivalent
to --show-leak-kinds=definite,possible.</p>

<p style="margin-top: 1em">&Acirc;&middot;
--show-reachable=no --show-possibly-lost=no is equivalent to
--show-leak-kinds=definite.</p>

<p style="margin-top: 1em">&Acirc;&middot;
--show-reachable=yes is equivalent to
--show-leak-kinds=all.</p>

<p style="margin-top: 1em">Note that
--show-possibly-lost=no has no effect if
--show-reachable=yes is specified.</p>


<p style="margin-top: 1em">--undef-value-errors=&lt;yes|no&gt;
[default: yes] <br>
Controls whether Memcheck reports uses of undefined value
errors. Set this to no if you don&rsquo;t want to see
undefined value errors. It also has the side effect of
speeding up <br>
Memcheck somewhat.</p>

<p style="margin-top: 1em">--track-origins=&lt;yes|no&gt;
[default: no] <br>
Controls whether Memcheck tracks the origin of uninitialised
values. By default, it does not, which means that although
it can tell you that an uninitialised value is being <br>
used in a dangerous way, it cannot tell you where the
uninitialised value came from. This often makes it difficult
to track down the root problem.</p>

<p style="margin-top: 1em">When set to yes, Memcheck keeps
track of the origins of all uninitialised values. Then, when
an uninitialised value error is reported, Memcheck will try
to show the origin of <br>
the value. An origin can be one of the following four
places: a heap block, a stack allocation, a client request,
or miscellaneous other sources (eg, a call to brk).</p>

<p style="margin-top: 1em">For uninitialised values
originating from a heap block, Memcheck shows where the
block was allocated. For uninitialised values originating
from a stack allocation, Memcheck <br>
can tell you which function allocated the value, but no more
than that -- typically it shows you the source location of
the opening brace of the function. So you should <br>
carefully check that all of the function&rsquo;s local
variables are initialised properly.</p>

<p style="margin-top: 1em">Performance overhead: origin
tracking is expensive. It halves Memcheck&rsquo;s speed and
increases memory use by a minimum of 100MB, and possibly
more. Nevertheless it can <br>
drastically reduce the effort required to identify the root
cause of uninitialised value errors, and so is often a
programmer productivity win, despite running more
slowly.</p>

<p style="margin-top: 1em">Accuracy: Memcheck tracks
origins quite accurately. To avoid very large space and time
overheads, some approximations are made. It is possible,
although unlikely, that <br>
Memcheck will report an incorrect origin, or not be able to
identify any origin.</p>

<p style="margin-top: 1em">Note that the combination
--track-origins=yes and --undef-value-errors=no is
nonsensical. Memcheck checks for and rejects this
combination at startup.</p>


<p style="margin-top: 1em">--partial-loads-ok=&lt;yes|no&gt;
[default: yes] <br>
Controls how Memcheck handles 32-, 64-, 128- and 256-bit
naturally aligned loads from addresses for which some bytes
are addressable and others are not. When yes, such loads
<br>
do not produce an address error. Instead, loaded bytes
originating from illegal addresses are marked as
uninitialised, and those corresponding to legal addresses
are handled <br>
in the normal way.</p>

<p style="margin-top: 1em">When no, loads from partially
invalid addresses are treated the same as loads from
completely invalid addresses: an illegal-address error is
issued, and the resulting bytes <br>
are marked as initialised.</p>

<p style="margin-top: 1em">Note that code that behaves in
this way is in violation of the ISO C/C++ standards, and
should be considered broken. If at all possible, such code
should be fixed.</p>


<p style="margin-top: 1em">--expensive-definedness-checks=&lt;yes|no&gt;
[default: no] <br>
Controls whether Memcheck should employ more precise but
also more expensive (time consuming) algorithms when
checking the definedness of a value. The default setting is
not <br>
to do that and it is usually sufficient. However, for highly
optimised code valgrind may sometimes incorrectly complain.
Invoking valgrind with <br>
--expensive-definedness-checks=yes helps but comes at a
performance cost. Runtime degradation of 25% have been
observed but the extra cost depends a lot on the application
at <br>
hand.</p>


<p style="margin-top: 1em">--keep-stacktraces=alloc|free|alloc-and-free|alloc-then-free|none
[default: alloc-and-free] <br>
Controls which stack trace(s) to keep for malloc&rsquo;d
and/or free&rsquo;d blocks.</p>

<p style="margin-top: 1em">With alloc-then-free, a stack
trace is recorded at allocation time, and is associated with
the block. When the block is freed, a second stack trace is
recorded, and this <br>
replaces the allocation stack trace. As a result, any
&quot;use after free&quot; errors relating to this block can
only show a stack trace for where the block was freed.</p>

<p style="margin-top: 1em">With alloc-and-free, both
allocation and the deallocation stack traces for the block
are stored. Hence a &quot;use after free&quot; error will
show both, which may make the error <br>
easier to diagnose. Compared to alloc-then-free, this
setting slightly increases Valgrind&rsquo;s memory use as
the block contains two references instead of one.</p>

<p style="margin-top: 1em">With alloc, only the allocation
stack trace is recorded (and reported). With free, only the
deallocation stack trace is recorded (and reported). These
values somewhat <br>
decrease Valgrind&rsquo;s memory and cpu usage. They can be
useful depending on the error types you are searching for
and the level of detail you need to analyse them. For
example, <br>
if you are only interested in memory leak errors, it is
sufficient to record the allocation stack traces.</p>

<p style="margin-top: 1em">With none, no stack traces are
recorded for malloc and free operations. If your program
allocates a lot of blocks and/or allocates/frees from many
different stack traces, <br>
this can significantly decrease cpu and/or memory required.
Of course, few details will be reported for errors related
to heap blocks.</p>

<p style="margin-top: 1em">Note that once a stack trace is
recorded, Valgrind keeps the stack trace in memory even if
it is not referenced by any block. Some programs (for
example, recursive <br>
algorithms) can generate a huge number of stack traces. If
Valgrind uses too much memory in such circumstances, you can
reduce the memory required with the options <br>
--keep-stacktraces and/or by using a smaller value for the
option --num-callers.</p>

<p style="margin-top: 1em">--freelist-vol=&lt;number&gt;
[default: 20000000] <br>
When the client program releases memory using free (in C) or
delete (C++), that memory is not immediately made available
for re-allocation. Instead, it is marked inaccessible <br>
and placed in a queue of freed blocks. The purpose is to
defer as long as possible the point at which freed-up memory
comes back into circulation. This increases the chance <br>
that Memcheck will be able to detect invalid accesses to
blocks for some significant period of time after they have
been freed.</p>

<p style="margin-top: 1em">This option specifies the
maximum total size, in bytes, of the blocks in the queue.
The default value is twenty million bytes. Increasing this
increases the total amount of <br>
memory used by Memcheck but may detect invalid uses of freed
blocks which would otherwise go undetected.</p>


<p style="margin-top: 1em">--freelist-big-blocks=&lt;number&gt;
[default: 1000000] <br>
When making blocks from the queue of freed blocks available
for re-allocation, Memcheck will in priority re-circulate
the blocks with a size greater or equal to <br>
--freelist-big-blocks. This ensures that freeing big blocks
(in particular freeing blocks bigger than --freelist-vol)
does not immediately lead to a re-circulation of all (or
<br>
a lot of) the small blocks in the free list. In other words,
this option increases the likelihood to discover dangling
pointers for the &quot;small&quot; blocks, even when big
blocks <br>
are freed.</p>

<p style="margin-top: 1em">Setting a value of 0 means that
all the blocks are re-circulated in a FIFO order.</p>


<p style="margin-top: 1em">--workaround-gcc296-bugs=&lt;yes|no&gt;
[default: no] <br>
When enabled, assume that reads and writes some small
distance below the stack pointer are due to bugs in GCC
2.96, and does not report them. The &quot;small
distance&quot; is 256 <br>
bytes by default. Note that GCC 2.96 is the default compiler
on some ancient Linux distributions (RedHat 7.X) and so you
may need to use this option. Do not use it if you do <br>
not have to, as it can cause real errors to be overlooked. A
better alternative is to use a more recent GCC in which this
bug is fixed.</p>

<p style="margin-top: 1em">You may also need to use this
option when working with GCC 3.X or 4.X on 32-bit PowerPC
Linux. This is because GCC generates code which occasionally
accesses below the stack <br>
pointer, particularly for floating-point to/from integer
conversions. This is in violation of the 32-bit PowerPC ELF
specification, which makes no provision for locations <br>
below the stack pointer to be accessible.</p>


<p style="margin-top: 1em">--show-mismatched-frees=&lt;yes|no&gt;
[default: yes] <br>
When enabled, Memcheck checks that heap blocks are
deallocated using a function that matches the allocating
function. That is, it expects free to be used to deallocate
blocks <br>
allocated by malloc, delete for blocks allocated by new, and
delete[] for blocks allocated by new[]. If a mismatch is
detected, an error is reported. This is in general <br>
important because in some environments, freeing with a
non-matching function can cause crashes.</p>

<p style="margin-top: 1em">There is however a scenario
where such mismatches cannot be avoided. That is when the
user provides implementations of new/new[] that call malloc
and of delete/delete[] that <br>
call free, and these functions are asymmetrically inlined.
For example, imagine that delete[] is inlined but new[] is
not. The result is that Memcheck &quot;sees&quot; all
delete[] <br>
calls as direct calls to free, even when the program source
contains no mismatched calls.</p>

<p style="margin-top: 1em">This causes a lot of confusing
and irrelevant error reports. --show-mismatched-frees=no
disables these checks. It is not generally advisable to
disable them, though, because <br>
you may miss real errors as a result.</p>


<p style="margin-top: 1em">--ignore-ranges=0xPP-0xQQ[,0xRR-0xSS]
<br>
Any ranges listed in this option (and multiple ranges can be
specified, separated by commas) will be ignored by
Memcheck&rsquo;s addressability checking.</p>

<p style="margin-top: 1em">--malloc-fill=&lt;hexnumber&gt;
<br>
Fills blocks allocated by malloc, new, etc, but not by
calloc, with the specified byte. This can be useful when
trying to shake out obscure memory corruption problems. The
<br>
allocated area is still regarded by Memcheck as undefined --
this option only affects its contents. Note that
--malloc-fill does not affect a block of memory when it is
used <br>
as argument to client requests VALGRIND_MEMPOOL_ALLOC or
VALGRIND_MALLOCLIKE_BLOCK.</p>

<p style="margin-top: 1em">--free-fill=&lt;hexnumber&gt;
<br>
Fills blocks freed by free, delete, etc, with the specified
byte value. This can be useful when trying to shake out
obscure memory corruption problems. The freed area is <br>
still regarded by Memcheck as not valid for access -- this
option only affects its contents. Note that --free-fill does
not affect a block of memory when it is used as <br>
argument to client requests VALGRIND_MEMPOOL_FREE or
VALGRIND_FREELIKE_BLOCK.</p>

<p style="margin-top: 1em">CACHEGRIND OPTIONS <br>
--I1=&lt;size&gt;,&lt;associativity&gt;,&lt;line size&gt;
<br>
Specify the size, associativity and line size of the level 1
instruction cache.</p>


<p style="margin-top: 1em">--D1=&lt;size&gt;,&lt;associativity&gt;,&lt;line
size&gt; <br>
Specify the size, associativity and line size of the level 1
data cache.</p>


<p style="margin-top: 1em">--LL=&lt;size&gt;,&lt;associativity&gt;,&lt;line
size&gt; <br>
Specify the size, associativity and line size of the
last-level cache.</p>

<p style="margin-top: 1em">--cache-sim=no|yes [yes] <br>
Enables or disables collection of cache access and miss
counts.</p>

<p style="margin-top: 1em">--branch-sim=no|yes [no] <br>
Enables or disables collection of branch instruction and
misprediction counts. By default this is disabled as it
slows Cachegrind down by approximately 25%. Note that you
<br>
cannot specify --cache-sim=no and --branch-sim=no together,
as that would leave Cachegrind with no information to
collect.</p>


<p style="margin-top: 1em">--cachegrind-out-file=&lt;file&gt;
<br>
Write the profile data to file rather than to the default
output file, cachegrind.out.&lt;pid&gt;. The %p and %q
format specifiers can be used to embed the process ID and/or
the <br>
contents of an environment variable in the name, as is the
case for the core option --log-file.</p>

<p style="margin-top: 1em">CALLGRIND OPTIONS <br>
--callgrind-out-file=&lt;file&gt; <br>
Write the profile data to file rather than to the default
output file, callgrind.out.&lt;pid&gt;. The %p and %q format
specifiers can be used to embed the process ID and/or the
<br>
contents of an environment variable in the name, as is the
case for the core option --log-file. When multiple dumps are
made, the file name is modified further; see below.</p>

<p style="margin-top: 1em">--dump-line=&lt;no|yes&gt;
[default: yes] <br>
This specifies that event counting should be performed at
source line granularity. This allows source annotation for
sources which are compiled with debug information (-g).</p>

<p style="margin-top: 1em">--dump-instr=&lt;no|yes&gt;
[default: no] <br>
This specifies that event counting should be performed at
per-instruction granularity. This allows for assembly code
annotation. Currently the results can only be displayed <br>
by KCachegrind.</p>


<p style="margin-top: 1em">--compress-strings=&lt;no|yes&gt;
[default: yes] <br>
This option influences the output format of the profile
data. It specifies whether strings (file and function names)
should be identified by numbers. This shrinks the file, <br>
but makes it more difficult for humans to read (which is not
recommended in any case).</p>

<p style="margin-top: 1em">--compress-pos=&lt;no|yes&gt;
[default: yes] <br>
This option influences the output format of the profile
data. It specifies whether numerical positions are always
specified as absolute values or are allowed to be relative
<br>
to previous numbers. This shrinks the file size.</p>

<p style="margin-top: 1em">--combine-dumps=&lt;no|yes&gt;
[default: no] <br>
When enabled, when multiple profile data parts are to be
generated these parts are appended to the same output file.
Not recommended.</p>

<p style="margin-top: 1em">--dump-every-bb=&lt;count&gt;
[default: 0, never] <br>
Dump profile data every count basic blocks. Whether a dump
is needed is only checked when Valgrind&rsquo;s internal
scheduler is run. Therefore, the minimum setting useful is
about <br>
100000. The count is a 64-bit value to make long dump
periods possible.</p>

<p style="margin-top: 1em">--dump-before=&lt;function&gt;
<br>
Dump when entering function.</p>

<p style="margin-top: 1em">--zero-before=&lt;function&gt;
<br>
Zero all costs when entering function.</p>

<p style="margin-top: 1em">--dump-after=&lt;function&gt;
<br>
Dump when leaving function.</p>

<p style="margin-top: 1em">--instr-atstart=&lt;yes|no&gt;
[default: yes] <br>
Specify if you want Callgrind to start simulation and
profiling from the beginning of the program. When set to no,
Callgrind will not be able to collect any information, <br>
including calls, but it will have at most a slowdown of
around 4, which is the minimum Valgrind overhead.
Instrumentation can be interactively enabled via
callgrind_control <br>
-i on.</p>

<p style="margin-top: 1em">Note that the resulting call
graph will most probably not contain main, but will contain
all the functions executed after instrumentation was
enabled. Instrumentation can <br>
also programatically enabled/disabled. See the Callgrind
include file callgrind.h for the macro you have to use in
your source code.</p>

<p style="margin-top: 1em">For cache simulation, results
will be less accurate when switching on instrumentation
later in the program run, as the simulator starts with an
empty cache at that moment. <br>
Switch on event collection later to cope with this
error.</p>


<p style="margin-top: 1em">--collect-atstart=&lt;yes|no&gt;
[default: yes] <br>
Specify whether event collection is enabled at beginning of
the profile run.</p>

<p style="margin-top: 1em">To only look at parts of your
program, you have two possibilities:</p>

<p style="margin-top: 1em">1. Zero event counters before
entering the program part you want to profile, and dump the
event counters to a file after leaving that program
part.</p>

<p style="margin-top: 1em">2. Switch on/off collection
state as needed to only see event counters happening while
inside of the program part you want to profile.</p>

<p style="margin-top: 1em">The second option can be used if
the program part you want to profile is called many times.
Option 1, i.e. creating a lot of dumps is not practical
here.</p>

<p style="margin-top: 1em">Collection state can be toggled
at entry and exit of a given function with the option
--toggle-collect. If you use this option, collection state
should be disabled at the <br>
beginning. Note that the specification of --toggle-collect
implicitly sets --collect-state=no.</p>

<p style="margin-top: 1em">Collection state can be toggled
also by inserting the client request
CALLGRIND_TOGGLE_COLLECT ; at the needed code positions.</p>


<p style="margin-top: 1em">--toggle-collect=&lt;function&gt;
<br>
Toggle collection on entry/exit of function.</p>

<p style="margin-top: 1em">--collect-jumps=&lt;no|yes&gt;
[default: no] <br>
This specifies whether information for (conditional) jumps
should be collected. As above, callgrind_annotate currently
is not able to show you the data. You have to use <br>
KCachegrind to get jump arrows in the annotated code.</p>


<p style="margin-top: 1em">--collect-systime=&lt;no|yes&gt;
[default: no] <br>
This specifies whether information for system call times
should be collected.</p>

<p style="margin-top: 1em">--collect-bus=&lt;no|yes&gt;
[default: no] <br>
This specifies whether the number of global bus events
executed should be collected. The event type &quot;Ge&quot;
is used for these events.</p>

<p style="margin-top: 1em">--cache-sim=&lt;yes|no&gt;
[default: no] <br>
Specify if you want to do full cache simulation. By default,
only instruction read accesses will be counted
(&quot;Ir&quot;). With cache simulation, further event
counters are enabled: <br>
Cache misses on instruction reads
(&quot;I1mr&quot;/&quot;ILmr&quot;), data read accesses
(&quot;Dr&quot;) and related cache misses
(&quot;D1mr&quot;/&quot;DLmr&quot;), data write accesses
(&quot;Dw&quot;) and related cache misses <br>
(&quot;D1mw&quot;/&quot;DLmw&quot;). For more information,
see Cachegrind: a cache and branch-prediction profiler.</p>

<p style="margin-top: 1em">--branch-sim=&lt;yes|no&gt;
[default: no] <br>
Specify if you want to do branch prediction simulation.
Further event counters are enabled: Number of executed
conditional branches and related predictor misses
(&quot;Bc&quot;/&quot;Bcm&quot;), <br>
executed indirect jumps and related misses of the jump
address predictor (&quot;Bi&quot;/&quot;Bim&quot;).</p>

<p style="margin-top: 1em">HELGRIND OPTIONS <br>
--free-is-write=no|yes [default: no] <br>
When enabled (not the default), Helgrind treats freeing of
heap memory as if the memory was written immediately before
the free. This exposes races where memory is referenced <br>
by one thread, and freed by another, but there is no
observable synchronisation event to ensure that the
reference happens before the free.</p>

<p style="margin-top: 1em">This functionality is new in
Valgrind 3.7.0, and is regarded as experimental. It is not
enabled by default because its interaction with custom
memory allocators is not well <br>
understood at present. User feedback is welcomed.</p>

<p style="margin-top: 1em">--track-lockorders=no|yes
[default: yes] <br>
When enabled (the default), Helgrind performs lock order
consistency checking. For some buggy programs, the large
number of lock order errors reported can become annoying,
<br>
particularly if you&rsquo;re only interested in race errors.
You may therefore find it helpful to disable lock order
checking.</p>


<p style="margin-top: 1em">--history-level=none|approx|full
[default: full] <br>
--history-level=full (the default) causes Helgrind collects
enough information about &quot;old&quot; accesses that it
can produce two stack traces in a race report -- both the
stack <br>
trace for the current access, and the trace for the older,
conflicting access. To limit memory usage, &quot;old&quot;
accesses stack traces are limited to a maximum of 8 entries,
even <br>
if --num-callers value is bigger.</p>

<p style="margin-top: 1em">Collecting such information is
expensive in both speed and memory, particularly for
programs that do many inter-thread synchronisation events
(locks, unlocks, etc). Without <br>
such information, it is more difficult to track down the
root causes of races. Nonetheless, you may not need it in
situations where you just want to check for the presence or
<br>
absence of races, for example, when doing regression testing
of a previously race-free program.</p>

<p style="margin-top: 1em">--history-level=none is the
opposite extreme. It causes Helgrind not to collect any
information about previous accesses. This can be
dramatically faster than <br>
--history-level=full.</p>

<p style="margin-top: 1em">--history-level=approx provides
a compromise between these two extremes. It causes Helgrind
to show a full trace for the later access, and approximate
information regarding <br>
the earlier access. This approximate information consists of
two stacks, and the earlier access is guaranteed to have
occurred somewhere between program points denoted by the
<br>
two stacks. This is not as useful as showing the exact stack
for the previous access (as --history-level=full does), but
it is better than nothing, and it is almost as fast <br>
as --history-level=none.</p>

<p style="margin-top: 1em">--conflict-cache-size=N
[default: 1000000] <br>
This flag only has any effect at --history-level=full.</p>

<p style="margin-top: 1em">Information about
&quot;old&quot; conflicting accesses is stored in a cache of
limited size, with LRU-style management. This is necessary
because it isn&rsquo;t practical to store a stack <br>
trace for every single memory access made by the program.
Historical information on not recently accessed locations is
periodically discarded, to free up space in the cache.</p>

<p style="margin-top: 1em">This option controls the size of
the cache, in terms of the number of different memory
addresses for which conflicting access information is
stored. If you find that Helgrind <br>
is showing race errors with only one stack instead of the
expected two stacks, try increasing this value.</p>

<p style="margin-top: 1em">The minimum value is 10,000 and
the maximum is 30,000,000 (thirty times the default value).
Increasing the value by 1 increases Helgrind&rsquo;s memory
requirement by very roughly <br>
100 bytes, so the maximum value will easily eat up three
extra gigabytes or so of memory.</p>

<p style="margin-top: 1em">--check-stack-refs=no|yes
[default: yes] <br>
By default Helgrind checks all data memory accesses made by
your program. This flag enables you to skip checking for
accesses to thread stacks (local variables). This can <br>
improve performance, but comes at the cost of missing races
on stack-allocated data.</p>


<p style="margin-top: 1em">--ignore-thread-creation=&lt;yes|no&gt;
[default: no] <br>
Controls whether all activities during thread creation
should be ignored. By default enabled only on Solaris.
Solaris provides higher throughput, parallelism and
scalability <br>
than other operating systems, at the cost of more
fine-grained locking activity. This means for example that
when a thread is created under glibc, just one big lock is
used <br>
for all thread setup. Solaris libc uses several fine-grained
locks and the creator thread resumes its activities as soon
as possible, leaving for example stack and TLS setup <br>
sequence to the created thread. This situation confuses
Helgrind as it assumes there is some false ordering in place
between creator and created thread; and therefore many <br>
types of race conditions in the application would not be
reported. To prevent such false ordering, this command line
option is set to yes by default on Solaris. All activity
<br>
(loads, stores, client requests) is therefore ignored
during:</p>

<p style="margin-top: 1em">&Acirc;&middot; pthread_create()
call in the creator thread</p>

<p style="margin-top: 1em">&Acirc;&middot; thread creation
phase (stack and TLS setup) in the created thread</p>

<p style="margin-top: 1em">Also new memory allocated during
thread creation is untracked, that is race reporting is
suppressed there. DRD does the same thing implicitly. This
is necessary because <br>
Solaris libc caches many objects and reuses them for
different threads and that confuses Helgrind.</p>

<p style="margin-top: 1em">DRD OPTIONS <br>
--check-stack-var=&lt;yes|no&gt; [default: no] <br>
Controls whether DRD detects data races on stack variables.
Verifying stack variables is disabled by default because
most programs do not share stack variables over threads.</p>

<p style="margin-top: 1em">--exclusive-threshold=&lt;n&gt;
[default: off] <br>
Print an error message if any mutex or writer lock has been
held longer than the time specified in milliseconds. This
option enables the detection of lock contention.</p>

<p style="margin-top: 1em">--join-list-vol=&lt;n&gt;
[default: 10] <br>
Data races that occur between a statement at the end of one
thread and another thread can be missed if memory access
information is discarded immediately after a thread has <br>
been joined. This option allows to specify for how many
joined threads memory access information should be
retained.</p>


<p style="margin-top: 1em">--first-race-only=&lt;yes|no&gt;
[default: no] <br>
Whether to report only the first data race that has been
detected on a memory location or all data races that have
been detected on a memory location.</p>

<p style="margin-top: 1em">--free-is-write=&lt;yes|no&gt;
[default: no] <br>
Whether to report races between accessing memory and freeing
memory. Enabling this option may cause DRD to run slightly
slower. Notes:</p>

<p style="margin-top: 1em">&Acirc;&middot; Don&rsquo;t
enable this option when using custom memory allocators that
use the VG_USERREQ__MALLOCLIKE_BLOCK and
VG_USERREQ__FREELIKE_BLOCK because that would result in
false <br>
positives.</p>

<p style="margin-top: 1em">&Acirc;&middot; Don&rsquo;t
enable this option when using reference-counted objects
because that will result in false positives, even when that
code has been annotated properly with <br>
ANNOTATE_HAPPENS_BEFORE and ANNOTATE_HAPPENS_AFTER. See e.g.
the output of the following command for an example: valgrind
--tool=drd --free-is-write=yes <br>
drd/tests/annotate_smart_pointer.</p>


<p style="margin-top: 1em">--report-signal-unlocked=&lt;yes|no&gt;
[default: yes] <br>
Whether to report calls to pthread_cond_signal and
pthread_cond_broadcast where the mutex associated with the
signal through pthread_cond_wait or
pthread_cond_timed_waitis <br>
not locked at the time the signal is sent. Sending a signal
without holding a lock on the associated mutex is a common
programming error which can cause subtle race <br>
conditions and unpredictable behavior. There exist some
uncommon synchronization patterns however where it is safe
to send a signal without holding a lock on the associated
<br>
mutex.</p>


<p style="margin-top: 1em">--segment-merging=&lt;yes|no&gt;
[default: yes] <br>
Controls segment merging. Segment merging is an algorithm to
limit memory usage of the data race detection algorithm.
Disabling segment merging may improve the accuracy of <br>
the so-called &rsquo;other segments&rsquo; displayed in race
reports but can also trigger an out of memory error.</p>


<p style="margin-top: 1em">--segment-merging-interval=&lt;n&gt;
[default: 10] <br>
Perform segment merging only after the specified number of
new segments have been created. This is an advanced
configuration option that allows to choose whether to
minimize <br>
DRD&rsquo;s memory usage by choosing a low value or to let
DRD run faster by choosing a slightly higher value. The
optimal value for this parameter depends on the program
being <br>
analyzed. The default value works well for most
programs.</p>

<p style="margin-top: 1em">--shared-threshold=&lt;n&gt;
[default: off] <br>
Print an error message if a reader lock has been held longer
than the specified time (in milliseconds). This option
enables the detection of lock contention.</p>

<p style="margin-top: 1em">--show-confl-seg=&lt;yes|no&gt;
[default: yes] <br>
Show conflicting segments in race reports. Since this
information can help to find the cause of a data race, this
option is enabled by default. Disabling this option makes
<br>
the output of DRD more compact.</p>


<p style="margin-top: 1em">--show-stack-usage=&lt;yes|no&gt;
[default: no] <br>
Print stack usage at thread exit time. When a program
creates a large number of threads it becomes important to
limit the amount of virtual memory allocated for thread <br>
stacks. This option makes it possible to observe how much
stack memory has been used by each thread of the client
program. Note: the DRD tool itself allocates some temporary
<br>
data on the client thread stack. The space necessary for
this temporary data must be allocated by the client program
when it allocates stack memory, but is not included in <br>
stack usage reported by DRD.</p>


<p style="margin-top: 1em">--ignore-thread-creation=&lt;yes|no&gt;
[default: no] <br>
Controls whether all activities during thread creation
should be ignored. By default enabled only on Solaris.
Solaris provides higher throughput, parallelism and
scalability <br>
than other operating systems, at the cost of more
fine-grained locking activity. This means for example that
when a thread is created under glibc, just one big lock is
used <br>
for all thread setup. Solaris libc uses several fine-grained
locks and the creator thread resumes its activities as soon
as possible, leaving for example stack and TLS setup <br>
sequence to the created thread. This situation confuses DRD
as it assumes there is some false ordering in place between
creator and created thread; and therefore many types <br>
of race conditions in the application would not be reported.
To prevent such false ordering, this command line option is
set to yes by default on Solaris. All activity <br>
(loads, stores, client requests) is therefore ignored
during:</p>

<p style="margin-top: 1em">&Acirc;&middot; pthread_create()
call in the creator thread</p>

<p style="margin-top: 1em">&Acirc;&middot; thread creation
phase (stack and TLS setup) in the created thread</p>

<p style="margin-top: 1em">--trace-addr=&lt;address&gt;
[default: none] <br>
Trace all load and store activity for the specified address.
This option may be specified more than once.</p>

<p style="margin-top: 1em">--ptrace-addr=&lt;address&gt;
[default: none] <br>
Trace all load and store activity for the specified address
and keep doing that even after the memory at that address
has been freed and reallocated.</p>

<p style="margin-top: 1em">--trace-alloc=&lt;yes|no&gt;
[default: no] <br>
Trace all memory allocations and deallocations. May produce
a huge amount of output.</p>

<p style="margin-top: 1em">--trace-barrier=&lt;yes|no&gt;
[default: no] <br>
Trace all barrier activity.</p>

<p style="margin-top: 1em">--trace-cond=&lt;yes|no&gt;
[default: no] <br>
Trace all condition variable activity.</p>


<p style="margin-top: 1em">--trace-fork-join=&lt;yes|no&gt;
[default: no] <br>
Trace all thread creation and all thread termination
events.</p>

<p style="margin-top: 1em">--trace-hb=&lt;yes|no&gt;
[default: no] <br>
Trace execution of the ANNOTATE_HAPPENS_BEFORE(),
ANNOTATE_HAPPENS_AFTER() and ANNOTATE_HAPPENS_DONE() client
requests.</p>

<p style="margin-top: 1em">--trace-mutex=&lt;yes|no&gt;
[default: no] <br>
Trace all mutex activity.</p>

<p style="margin-top: 1em">--trace-rwlock=&lt;yes|no&gt;
[default: no] <br>
Trace all reader-writer lock activity.</p>


<p style="margin-top: 1em">--trace-semaphore=&lt;yes|no&gt;
[default: no] <br>
Trace all semaphore activity.</p>

<p style="margin-top: 1em">MASSIF OPTIONS <br>
--heap=&lt;yes|no&gt; [default: yes] <br>
Specifies whether heap profiling should be done.</p>

<p style="margin-top: 1em">--heap-admin=&lt;size&gt;
[default: 8] <br>
If heap profiling is enabled, gives the number of
administrative bytes per block to use. This should be an
estimate of the average, since it may vary. For example, the
<br>
allocator used by glibc on Linux requires somewhere between
4 to 15 bytes per block, depending on various factors. That
allocator also requires admin space for freed blocks, <br>
but Massif cannot account for this.</p>

<p style="margin-top: 1em">--stacks=&lt;yes|no&gt;
[default: no] <br>
Specifies whether stack profiling should be done. This
option slows Massif down greatly, and so is off by default.
Note that Massif assumes that the main stack has size zero
<br>
at start-up. This is not true, but doing otherwise
accurately is difficult. Furthermore, starting at zero
better indicates the size of the part of the main stack that
a user <br>
program actually has control over.</p>

<p style="margin-top: 1em">--pages-as-heap=&lt;yes|no&gt;
[default: no] <br>
Tells Massif to profile memory at the page level rather than
at the malloc&rsquo;d block level. See above for
details.</p>

<p style="margin-top: 1em">--depth=&lt;number&gt; [default:
30] <br>
Maximum depth of the allocation trees recorded for detailed
snapshots. Increasing it will make Massif run somewhat more
slowly, use more memory, and produce bigger output <br>
files.</p>

<p style="margin-top: 1em">--alloc-fn=&lt;name&gt; <br>
Functions specified with this option will be treated as
though they were a heap allocation function such as malloc.
This is useful for functions that are wrappers to malloc
<br>
or new, which can fill up the allocation trees with
uninteresting information. This option can be specified
multiple times on the command line, to name multiple
functions.</p>

<p style="margin-top: 1em">Note that the named function
will only be treated this way if it is the top entry in a
stack trace, or just below another function treated this
way. For example, if you have <br>
a function malloc1 that wraps malloc, and malloc2 that wraps
malloc1, just specifying --alloc-fn=malloc2 will have no
effect. You need to specify --alloc-fn=malloc1 as well. <br>
This is a little inconvenient, but the reason is that
checking for allocation functions is slow, and it saves a
lot of time if Massif can stop looking through the stack
trace <br>
entries as soon as it finds one that doesn&rsquo;t match
rather than having to continue through all the entries.</p>

<p style="margin-top: 1em">Note that C++ names are
demangled. Note also that overloaded C++ names must be
written in full. Single quotes may be necessary to prevent
the shell from breaking them up. For <br>
example:</p>

<p style="margin-top: 1em">--alloc-fn=&rsquo;operator
new(unsigned, std::nothrow_t const&amp;)&rsquo;</p>

<p style="margin-top: 1em">--ignore-fn=&lt;name&gt; <br>
Any direct heap allocation (i.e. a call to malloc, new, etc,
or a call to a function named by an --alloc-fn option) that
occurs in a function specified by this option will be <br>
ignored. This is mostly useful for testing purposes. This
option can be specified multiple times on the command line,
to name multiple functions.</p>

<p style="margin-top: 1em">Any realloc of an ignored block
will also be ignored, even if the realloc call does not
occur in an ignored function. This avoids the possibility of
negative heap sizes if <br>
ignored blocks are shrunk with realloc.</p>

<p style="margin-top: 1em">The rules for writing C++
function names are the same as for --alloc-fn above.</p>

<p style="margin-top: 1em">--threshold=&lt;m.n&gt;
[default: 1.0] <br>
The significance threshold for heap allocations, as a
percentage of total memory size. Allocation tree entries
that account for less than this will be aggregated. Note
that <br>
this should be specified in tandem with ms_print&rsquo;s
option of the same name.</p>

<p style="margin-top: 1em">--peak-inaccuracy=&lt;m.n&gt;
[default: 1.0] <br>
Massif does not necessarily record the actual global memory
allocation peak; by default it records a peak only when the
global memory allocation size exceeds the previous <br>
peak by at least 1.0%. This is because there can be many
local allocation peaks along the way, and doing a detailed
snapshot for every one would be expensive and wasteful, as
<br>
all but one of them will be later discarded. This inaccuracy
can be changed (even to 0.0%) via this option, but Massif
will run drastically slower as the number approaches <br>
zero.</p>

<p style="margin-top: 1em">--time-unit=&lt;i|ms|B&gt;
[default: i] <br>
The time unit used for the profiling. There are three
possibilities: instructions executed (i), which is good for
most cases; real (wallclock) time (ms, i.e. milliseconds),
<br>
which is sometimes useful; and bytes allocated/deallocated
on the heap and/or stack (B), which is useful for very
short-run programs, and for testing purposes, because it is
<br>
the most reproducible across different machines.</p>

<p style="margin-top: 1em">--detailed-freq=&lt;n&gt;
[default: 10] <br>
Frequency of detailed snapshots. With --detailed-freq=1,
every snapshot is detailed.</p>

<p style="margin-top: 1em">--max-snapshots=&lt;n&gt;
[default: 100] <br>
The maximum number of snapshots recorded. If set to N, for
all programs except very short-running ones, the final
number of snapshots will be between N/2 and N.</p>

<p style="margin-top: 1em">--massif-out-file=&lt;file&gt;
[default: massif.out.%p] <br>
Write the profile data to file rather than to the default
output file, massif.out.&lt;pid&gt;. The %p and %q format
specifiers can be used to embed the process ID and/or the
<br>
contents of an environment variable in the name, as is the
case for the core option --log-file.</p>

<p style="margin-top: 1em">SGCHECK OPTIONS <br>
There are no SGCheck-specific command-line options at
present.</p>

<p style="margin-top: 1em">BBV OPTIONS <br>
--bb-out-file=&lt;name&gt; [default: bb.out.%p] <br>
This option selects the name of the basic block vector file.
The %p and %q format specifiers can be used to embed the
process ID and/or the contents of an environment <br>
variable in the name, as is the case for the core option
--log-file.</p>

<p style="margin-top: 1em">--pc-out-file=&lt;name&gt;
[default: pc.out.%p] <br>
This option selects the name of the PC file. This file holds
program counter addresses and function name info for the
various basic blocks. This can be used in conjunction <br>
with the basic block vector file to fast-forward via
function names instead of just instruction counts. The %p
and %q format specifiers can be used to embed the process ID
<br>
and/or the contents of an environment variable in the name,
as is the case for the core option --log-file.</p>

<p style="margin-top: 1em">--interval-size=&lt;number&gt;
[default: 100000000] <br>
This option selects the size of the interval to use. The
default is 100 million instructions, which is a commonly
used value. Other sizes can be used; smaller intervals can
<br>
help programs with finer-grained phases. However smaller
interval size can lead to accuracy issues due to warm-up
effects (When fast-forwarding the various architectural <br>
features will be un-initialized, and it will take some
number of instructions before they &quot;warm up&quot; to
the state a full simulation would be at without the
fast-forwarding. <br>
Large interval sizes tend to mitigate this.)</p>

<p style="margin-top: 1em">--instr-count-only [default: no]
<br>
This option tells the tool to only display instruction count
totals, and to not generate the actual basic block vector
file. This is useful for debugging, and for gathering <br>
instruction count info without generating the large basic
block vector files.</p>

<p style="margin-top: 1em">LACKEY OPTIONS <br>
--basic-counts=&lt;no|yes&gt; [default: yes] <br>
When enabled, Lackey prints the following statistics and
information about the execution of the client program:</p>

<p style="margin-top: 1em">1. The number of calls to the
function specified by the --fnname option (the default is
main). If the program has had its symbols stripped, the
count will always be zero.</p>

<p style="margin-top: 1em">2. The number of conditional
branches encountered and the number and proportion of those
taken.</p>

<p style="margin-top: 1em">3. The number of superblocks
entered and completed by the program. Note that due to
optimisations done by the JIT, this is not at all an
accurate value.</p>

<p style="margin-top: 1em">4. The number of guest (x86,
amd64, ppc, etc.) instructions and IR statements executed.
IR is Valgrind&rsquo;s RISC-like intermediate representation
via which all instrumentation <br>
is done.</p>

<p style="margin-top: 1em">5. Ratios between some of these
counts.</p>

<p style="margin-top: 1em">6. The exit code of the client
program.</p>


<p style="margin-top: 1em">--detailed-counts=&lt;no|yes&gt;
[default: no] <br>
When enabled, Lackey prints a table containing counts of
loads, stores and ALU operations, differentiated by their IR
types. The IR types are identified by their IR name <br>
(&quot;I1&quot;, &quot;I8&quot;, ... &quot;I128&quot;,
&quot;F32&quot;, &quot;F64&quot;, and &quot;V128&quot;).</p>

<p style="margin-top: 1em">--trace-mem=&lt;no|yes&gt;
[default: no] <br>
When enabled, Lackey prints the size and address of almost
every memory access made by the program. See the comments at
the top of the file lackey/lk_main.c for details about <br>
the output format, how it works, and inaccuracies in the
address trace. Note that this option produces immense
amounts of output.</p>


<p style="margin-top: 1em">--trace-superblocks=&lt;no|yes&gt;
[default: no] <br>
When enabled, Lackey prints out the address of every
superblock (a single entry, multiple exit, linear chunk of
code) executed by the program. This is primarily of interest
<br>
to Valgrind developers. See the comments at the top of the
file lackey/lk_main.c for details about the output format.
Note that this option produces large amounts of output.</p>

<p style="margin-top: 1em">--fnname=&lt;name&gt; [default:
main] <br>
Changes the function for which calls are counted when
--basic-counts=yes is specified.</p>

<p style="margin-top: 1em">SEE ALSO <br>
cg_annotate(1), callgrind_annotate(1), callgrind_control(1),
ms_print(1), $INSTALL/share/doc/valgrind/html/index.html or
http://www.valgrind.org/docs/manual/index.html, Debugging
<br>
your program using Valgrind&rsquo;s gdbserver and
GDB[1]vgdb[2], Valgrind monitor commands[3], The
Commentary[4], Scheduling and Multi-Thread Performance[5],
Cachegrind: a cache and <br>
branch-prediction profiler[6].</p>

<p style="margin-top: 1em">AUTHOR <br>
See the AUTHORS file in the valgrind distribution for a
comprehensive list of authors.</p>

<p style="margin-top: 1em">This manpage was written by
Andres Roldan &lt;aroldan@debian.org&gt; and the Valgrind
developers.</p>

<p style="margin-top: 1em">NOTES <br>
1. Debugging your program using Valgrind&rsquo;s gdbserver
and GDB <br>

http://www.valgrind.org/docs/manual/manual-core-adv.html#manual-core-adv.gdbserver</p>

<p style="margin-top: 1em">2. vgdb <br>

http://www.valgrind.org/docs/manual/manual-core-adv.html#manual-core-adv.vgdb</p>

<p style="margin-top: 1em">3. Valgrind monitor commands
<br>

http://www.valgrind.org/docs/manual/manual-core-adv.html#manual-core-adv.valgrind-monitor-commands</p>

<p style="margin-top: 1em">4. The Commentary <br>

http://www.valgrind.org/docs/manual/manual-core.html#manual-core.comment</p>

<p style="margin-top: 1em">5. Scheduling and Multi-Thread
Performance <br>

http://www.valgrind.org/docs/manual/manual-core.html#manual-core.pthreads_perf_sched</p>

<p style="margin-top: 1em">6. Cachegrind: a cache and
branch-prediction profiler <br>
http://www.valgrind.org/docs/manual/cg-manual.html</p>

<p style="margin-top: 1em">Release 3.11.0 09/23/2015
VALGRIND(1)</p>
<hr>
</body>
</html>
