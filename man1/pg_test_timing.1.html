<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
  </style>
  <title>PG_TEST_TIMING(1)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">PG_TEST_TIMING(1)</td>
    <td class="head-vol">PostgreSQL 9.2.18 Documentation</td>
    <td class="head-rtitle">PG_TEST_TIMING(1)</td>
  </tr>
</table>
<div class="manual-text">
<h1 class="Sh" title="Sh" id="NAME"><a class="selflink" href="#NAME">NAME</a></h1>
pg_test_timing - measure timing overhead
<h1 class="Sh" title="Sh" id="SYNOPSIS"><a class="selflink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<div class="Pp" style="margin-left: 15.00ex; text-indent: -15.00ex;"><b>pg_test_timing</b>
  [ <i>option</i>...]</div>
<h1 class="Sh" title="Sh" id="DESCRIPTION"><a class="selflink" href="#DESCRIPTION">DESCRIPTION</a></h1>
pg_test_timing is a tool to measure the timing overhead on your system and
  confirm that the system time never moves backwards. Systems that are slow to
  collect timing data can give less accurate <b>EXPLAIN ANALYZE</b> results.
<h1 class="Sh" title="Sh" id="OPTIONS"><a class="selflink" href="#OPTIONS">OPTIONS</a></h1>
pg_test_timing accepts the following command-line options:
<div class="Pp"></div>
<b>-d </b><b></b><i>duration</i>, <b>--duration=</b><b></b><i>duration</i>
<div style="margin-left: 4.00ex;">Specifies the test duration, in seconds.
  Longer durations give slightly better accuracy, and are more likely to
  discover problems with the system clock moving backwards. The default test
  duration is 3 seconds.</div>
<div class="Pp"></div>
<b>-V</b>, <b>--version</b>
<div style="margin-left: 4.00ex;">Print the pg_test_timing version and
  exit.</div>
<div class="Pp"></div>
<b>-?</b>, <b>--help</b>
<div style="margin-left: 4.00ex;">Show help about pg_test_timing command line
  arguments, and exit.</div>
<h1 class="Sh" title="Sh" id="USAGE"><a class="selflink" href="#USAGE">USAGE</a></h1>
<h2 class="Ss" title="Ss" id="Interpreting_results"><a class="selflink" href="#Interpreting_results">Interpreting
  results</a></h2>
Good results will show most (&gt;90%) individual timing calls take less than one
  microsecond. Average per loop overhead will be even lower, below 100
  nanoseconds. This example from an Intel i7-860 system using a TSC clock source
  shows excellent performance:
<div style="height: 1.00em;">&#x00A0;</div>
<div style="margin-left: 4.00ex;">
<pre>
Testing timing overhead for 3 seconds.
Per loop time including overhead: 35.96 nsec
Histogram of timing durations:
   &lt; usec:      count   percent
       16:          2  0.00000%
        8:         13  0.00002%
        4:        126  0.00015%
        2:    2999652  3.59518%
        1:   80435604 96.40465%
</pre>
</div>
<div class="Pp"></div>
Note that different units are used for the per loop time than the histogram. The
  loop can have resolution within a few nanoseconds (nsec), while the individual
  timing calls can only resolve down to one microsecond (usec).
<h2 class="Ss" title="Ss" id="Measuring_executor_timing_overhead"><a class="selflink" href="#Measuring_executor_timing_overhead">Measuring
  executor timing overhead</a></h2>
When the query executor is running a statement using <b>EXPLAIN ANALYZE</b>,
  individual operations are timed as well as showing a summary. The overhead of
  your system can be checked by counting rows with the psql program:
<div style="height: 1.00em;">&#x00A0;</div>
<div style="margin-left: 4.00ex;">
<pre>
CREATE TABLE t AS SELECT * FROM generate_series(1,100000);
\timing
SELECT COUNT(*) FROM t;
EXPLAIN ANALYZE SELECT COUNT(*) FROM t;
</pre>
</div>
<div class="Pp"></div>
The i7-860 system measured runs the count query in 9.8 ms while the <b>EXPLAIN
  ANALYZE</b> version takes 16.6 ms, each processing just over 100,000 rows.
  That 6.8 ms difference means the timing overhead per row is 68 ns, about twice
  what pg_test_timing estimated it would be. Even that relatively small amount
  of overhead is making the fully timed count statement take almost 70% longer.
  On more substantial queries, the timing overhead would be less problematic.
<h2 class="Ss" title="Ss" id="Changing_time_sources"><a class="selflink" href="#Changing_time_sources">Changing
  time sources</a></h2>
On some newer Linux systems, it's possible to change the clock source used to
  collect timing data at any time. A second example shows the slowdown possible
  from switching to the slower acpi_pm time source, on the same system used for
  the fast results above:
<div style="height: 1.00em;">&#x00A0;</div>
<div style="margin-left: 4.00ex;">
<pre>
# cat /sys/devices/system/clocksource/clocksource0/available_clocksource
tsc hpet acpi_pm
# echo acpi_pm &gt; /sys/devices/system/clocksource/clocksource0/current_clocksource
# pg_test_timing
Per loop time including overhead: 722.92 nsec
Histogram of timing durations:
   &lt; usec:      count   percent
       16:          3  0.00007%
        8:        563  0.01357%
        4:       3241  0.07810%
        2:    2990371 72.05956%
        1:    1155682 27.84870%
</pre>
</div>
<div class="Pp"></div>
In this configuration, the sample <b>EXPLAIN ANALYZE</b> above takes 115.9 ms.
  That's 1061 nsec of timing overhead, again a small multiple of what's measured
  directly by this utility. That much timing overhead means the actual query
  itself is only taking a tiny fraction of the accounted for time, most of it is
  being consumed in overhead instead. In this configuration, any <b>EXPLAIN
  ANALYZE</b> totals involving many timed operations would be inflated
  significantly by timing overhead.
<div class="Pp"></div>
FreeBSD also allows changing the time source on the fly, and it logs information
  about the timer selected during boot:
<div style="height: 1.00em;">&#x00A0;</div>
<div style="margin-left: 4.00ex;">
<pre>
dmesg | grep &quot;Timecounter&quot;
sysctl kern.timecounter.hardware=TSC
</pre>
</div>
<div class="Pp"></div>
Other systems may only allow setting the time source on boot. On older Linux
  systems the &quot;clock&quot; kernel setting is the only way to make this sort
  of change. And even on some more recent ones, the only option you'll see for a
  clock source is &quot;jiffies&quot;. Jiffies are the older Linux software
  clock implementation, which can have good resolution when it's backed by fast
  enough timing hardware, as in this example:
<div style="height: 1.00em;">&#x00A0;</div>
<div style="margin-left: 4.00ex;">
<pre>
$ cat /sys/devices/system/clocksource/clocksource0/available_clocksource
jiffies
$ dmesg | grep time.c
time.c: Using 3.579545 MHz WALL PM GTOD PIT/TSC timer.
time.c: Detected 2400.153 MHz processor.
$ pg_test_timing
Testing timing overhead for 3 seconds.
Per timing duration including loop overhead: 97.75 ns
Histogram of timing durations:
   &lt; usec:      count   percent
       32:          1  0.00000%
       16:          1  0.00000%
        8:         22  0.00007%
        4:       3010  0.00981%
        2:    2993204  9.75277%
        1:   27694571 90.23734%
</pre>
</div>
<h2 class="Ss" title="Ss" id="Clock_hardware_and_timing_accuracy"><a class="selflink" href="#Clock_hardware_and_timing_accuracy">Clock
  hardware and timing accuracy</a></h2>
Collecting accurate timing information is normally done on computers using
  hardware clocks with various levels of accuracy. With some hardware the
  operating systems can pass the system clock time almost directly to programs.
  A system clock can also be derived from a chip that simply provides timing
  interrupts, periodic ticks at some known time interval. In either case,
  operating system kernels provide a clock source that hides these details. But
  the accuracy of that clock source and how quickly it can return results varies
  based on the underlying hardware.
<div class="Pp"></div>
Inaccurate time keeping can result in system instability. Test any change to the
  clock source very carefully. Operating system defaults are sometimes made to
  favor reliability over best accuracy. And if you are using a virtual machine,
  look into the recommended time sources compatible with it. Virtual hardware
  faces additional difficulties when emulating timers, and there are often per
  operating system settings suggested by vendors.
<div class="Pp"></div>
The Time Stamp Counter (TSC) clock source is the most accurate one available on
  current generation CPUs. It's the preferred way to track the system time when
  it's supported by the operating system and the TSC clock is reliable. There
  are several ways that TSC can fail to provide an accurate timing source,
  making it unreliable. Older systems can have a TSC clock that varies based on
  the CPU temperature, making it unusable for timing. Trying to use TSC on some
  older multicore CPUs can give a reported time that's inconsistent among
  multiple cores. This can result in the time going backwards, a problem this
  program checks for. And even the newest systems can fail to provide accurate
  TSC timing with very aggressive power saving configurations.
<div class="Pp"></div>
Newer operating systems may check for the known TSC problems and switch to a
  slower, more stable clock source when they are seen. If your system supports
  TSC time but doesn't default to that, it may be disabled for a good reason.
  And some operating systems may not detect all the possible problems correctly,
  or will allow using TSC even in situations where it's known to be inaccurate.
<div class="Pp"></div>
The High Precision Event Timer (HPET) is the preferred timer on systems where
  it's available and TSC is not accurate. The timer chip itself is programmable
  to allow up to 100 nanosecond resolution, but you may not see that much
  accuracy in your system clock.
<div class="Pp"></div>
Advanced Configuration and Power Interface (ACPI) provides a Power Management
  (PM) Timer, which Linux refers to as the acpi_pm. The clock derived from
  acpi_pm will at best provide 300 nanosecond resolution.
<div class="Pp"></div>
Timers used on older PC hardware including the 8254 Programmable Interval Timer
  (PIT), the real-time clock (RTC), the Advanced Programmable Interrupt
  Controller (APIC) timer, and the Cyclone timer. These timers aim for
  millisecond resolution.
<h1 class="Sh" title="Sh" id="AUTHOR"><a class="selflink" href="#AUTHOR">AUTHOR</a></h1>
Ants Aasma &lt;ants.aasma@eesti.ee&gt;
<h1 class="Sh" title="Sh" id="SEE_ALSO"><a class="selflink" href="#SEE_ALSO">SEE
  ALSO</a></h1>
<b>EXPLAIN</b>(7)</div>
<table class="foot">
  <tr>
    <td class="foot-date">2016-08-08</td>
    <td class="foot-os">PostgreSQL 9.2.18</td>
  </tr>
</table>
</body>
</html>
