<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
  </style>
  <title>guestfs-faq(1)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">guestfs-faq(1)</td>
    <td class="head-vol">Virtualization Support</td>
    <td class="head-rtitle">guestfs-faq(1)</td>
  </tr>
</table>
<div class="manual-text">
<h1 class="Sh" title="Sh" id="NAME"><a class="selflink" href="#NAME">NAME</a></h1>
guestfs-faq - libguestfs Frequently Asked Questions (FAQ)
<h1 class="Sh" title="Sh" id="ABOUT_LIBGUESTFS"><a class="selflink" href="#ABOUT_LIBGUESTFS">ABOUT
  LIBGUESTFS</a></h1>
<h2 class="Ss" title="Ss" id="What_is_libguestfs?"><a class="selflink" href="#What_is_libguestfs?">What
  is libguestfs?</a></h2>
libguestfs is a way to create, access and modify disk images. You can look
  inside disk images, modify the files they contain, create them from scratch,
  resize them, and much more. It's especially useful from scripts and programs
  and from the command line.
<div class="Pp"></div>
libguestfs is a C library (hence &quot;lib-&quot;), and a set of tools built on
  this library, and bindings for many common programming languages.
<div class="Pp"></div>
For more information about what libguestfs can do read the introduction on the
  home page (http://libguestfs.org).
<h2 class="Ss" title="Ss" id="What_are_the_virt_tools?"><a class="selflink" href="#What_are_the_virt_tools?">What
  are the virt tools?</a></h2>
Virt tools (website: http://virt-tools.org) are a whole set of virtualization
  management tools aimed at system administrators. Some of them come from
  libguestfs, some from libvirt and many others from other open source projects.
  So virt tools is a superset of libguestfs. However libguestfs comes with many
  important tools. See http://libguestfs.org for a full list.
<h2 class="Ss" title="Ss" id="Does_libguestfs_need_{_libvirt_/_KVM_/_Red_Hat_/_Fedora_}?"><a class="selflink" href="#Does_libguestfs_need_{_libvirt_/_KVM_/_Red_Hat_/_Fedora_}?">Does
  libguestfs need { libvirt / KVM / Red Hat / Fedora }?</a></h2>
No!
<div class="Pp"></div>
libvirt is not a requirement for libguestfs.
<div class="Pp"></div>
libguestfs works with any disk image, including ones created in VMware, KVM,
  qemu, VirtualBox, Xen, and many other hypervisors, and ones which you have
  created from scratch.
<div class="Pp"></div>
Red&#x00A0;Hat sponsors (ie. pays for) development of libguestfs and a huge
  number of other open source projects. But you can run libguestfs and the virt
  tools on many different Linux distros and Mac OS X. We try our best to support
  all Linux distros as first-class citizens. Some virt tools have been ported to
  Windows.
<h2 class="Ss" title="Ss" id="How_does_libguestfs_compare_to_other_tools?"><a class="selflink" href="#How_does_libguestfs_compare_to_other_tools?">How
  does libguestfs compare to other tools?</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag"><i>vs. kpartx</i></dt>
  <dd class="It-tag">Libguestfs takes a different approach from kpartx. kpartx
      needs root, and mounts filesystems on the host kernel (which can be
      insecure - see <i>guestfs-security</i>(1)). Libguestfs isolates your host
      kernel from guests, is more flexible, scriptable, supports LVM, doesn't
      require root, is isolated from other processes, and cleans up after
      itself. Libguestfs is more than just file access because you can use it to
      create images from scratch.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><i>vs. vdfuse</i></dt>
  <dd class="It-tag">vdfuse is like kpartx but for VirtualBox images. See the
      kpartx comparison above. You can use libguestfs on the partition files
      exposed by vdfuse, although it's not necessary since libguestfs can access
      VirtualBox images directly.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><i>vs. qemu-nbd</i></dt>
  <dd class="It-tag">NBD (Network Block Device) is a protocol for exporting
      block devices over the network. qemu-nbd is an NBD server which can handle
      any disk format supported by qemu (eg. raw, qcow2). You can use libguestfs
      and qemu-nbd or nbdkit together to access block devices over the network,
      for example: &quot;guestfish -a nbd://remote&quot;</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><i>vs. mounting filesystems in the host</i></dt>
  <dd class="It-tag">Mounting guest filesystems in the host is insecure and
      should be avoided completely for untrusted guests. Use libguestfs to
      provide a layer of protection against filesystem exploits. See also
      <i>guestmount</i>(1).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><i>vs. parted</i></dt>
  <dd class="It-tag">Libguestfs supports LVM. Libguestfs uses parted and
      provides most parted features through the libguestfs API.</dd>
</dl>
<h1 class="Sh" title="Sh" id="GETTING_HELP_AND_REPORTING_BUGS"><a class="selflink" href="#GETTING_HELP_AND_REPORTING_BUGS">GETTING
  HELP AND REPORTING BUGS</a></h1>
<h2 class="Ss" title="Ss" id="How_do_I_know_what_version_I'm_using?"><a class="selflink" href="#How_do_I_know_what_version_I'm_using?">How
  do I know what version I'm using?</a></h2>
The simplest method is:
<div class="Pp"></div>
<pre>
 guestfish --version
</pre>
<div class="Pp"></div>
Libguestfs development happens along an unstable branch and we periodically
  create a stable branch which we backport stable patches to. To find out more,
  read &quot;LIBGUESTFS VERSION NUMBERS&quot; in <i>guestfs</i>(3).
<h2 class="Ss" title="Ss" id="How_can_I_get_help?"><a class="selflink" href="#How_can_I_get_help?">How
  can I get help?</a></h2>
<h2 class="Ss" title="Ss" id="What_mailing_lists_or_chat_rooms_are_available?"><a class="selflink" href="#What_mailing_lists_or_chat_rooms_are_available?">What
  mailing lists or chat rooms are available?</a></h2>
If you are a Red&#x00A0;Hat customer using Red Hat Enterprise Linux, please
  contact Red&#x00A0;Hat&#x00A0;Support: http://redhat.com/support
<div class="Pp"></div>
There is a mailing list, mainly for development, but users are also welcome to
  ask questions about libguestfs and the virt tools:
  https://www.redhat.com/mailman/listinfo/libguestfs
<div class="Pp"></div>
You can also talk to us on IRC channel &quot;#libguestfs&quot; on FreeNode.
  We're not always around, so please stay in the channel after asking your
  question and someone will get back to you.
<div class="Pp"></div>
For other virt tools (not ones supplied with libguestfs) there is a general virt
  tools mailing list: https://www.redhat.com/mailman/listinfo/virt-tools-list
<h2 class="Ss" title="Ss" id="How_do_I_report_bugs?"><a class="selflink" href="#How_do_I_report_bugs?">How
  do I report bugs?</a></h2>
Please use the following link to enter a bug in Bugzilla:
<div class="Pp"></div>
https://bugzilla.redhat.com/enter_bug.cgi?component=libguestfs&amp;product=Virtualization+Tools
<div class="Pp"></div>
Include as much detail as you can and a way to reproduce the problem.
<div class="Pp"></div>
Include the full output of <i>libguestfs-test-tool</i>(1).
<h1 class="Sh" title="Sh" id="COMMON_PROBLEMS"><a class="selflink" href="#COMMON_PROBLEMS">COMMON
  PROBLEMS</a></h1>
See also &quot;LIBGUESTFS GOTCHAS&quot; in <i>guestfs</i>(3) for some
  &quot;gotchas&quot; with using the libguestfs API.
<h2 class="Ss" title="Ss" id="&quot;Could_not_allocate_dynamic_translator_buffer&quot;"><a class="selflink" href="#&quot;Could_not_allocate_dynamic_translator_buffer&quot;">&quot;Could
  not allocate dynamic translator buffer&quot;</a></h2>
This obscure error is in fact an SELinux failure. You have to enable the
  following SELinux boolean:
<div class="Pp"></div>
<pre>
 setsebool -P virt_use_execmem=on
</pre>
<div class="Pp"></div>
For more information see https://bugzilla.redhat.com/show_bug.cgi?id=806106.
<h2 class="Ss" title="Ss" id="&quot;child_process_died_unexpectedly&quot;"><a class="selflink" href="#&quot;child_process_died_unexpectedly&quot;">&quot;child
  process died unexpectedly&quot;</a></h2>
[This error message was changed in libguestfs 1.21.18 to something more
  explanatory.]
<div class="Pp"></div>
This error indicates that qemu failed or the host kernel could not boot. To get
  further information about the failure, you have to run:
<div class="Pp"></div>
<pre>
 libguestfs-test-tool
</pre>
<div class="Pp"></div>
If, after using this, you still don't understand the failure, contact us (see
  previous section).
<h2 class="Ss" title="Ss" id="libguestfs:_error:_cannot_find_any_suitable_libguestfs_supermin,_fixed_or_old-style_appliance_on_LIBGUESTFS_PATH"><a class="selflink" href="#libguestfs:_error:_cannot_find_any_suitable_libguestfs_supermin,_fixed_or_old-style_appliance_on_LIBGUESTFS_PATH">libguestfs:
  error: cannot find any suitable libguestfs supermin, fixed or old-style
  appliance on LIBGUESTFS_PATH</a></h2>
<h2 class="Ss" title="Ss" id="febootstrap-supermin-helper:_ext2:_parent_directory_not_found"><a class="selflink" href="#febootstrap-supermin-helper:_ext2:_parent_directory_not_found">febootstrap-supermin-helper:
  ext2: parent directory not found</a></h2>
<h2 class="Ss" title="Ss" id="supermin-helper:_ext2:_parent_directory_not_found"><a class="selflink" href="#supermin-helper:_ext2:_parent_directory_not_found">supermin-helper:
  ext2: parent directory not found</a></h2>
[This issue is fixed permanently in libguestfs &#x2265; 1.26.]
<div class="Pp"></div>
If you see any of these errors on Debian/Ubuntu, you need to run the following
  command:
<div class="Pp"></div>
<pre>
 sudo update-guestfs-appliance
</pre>
<h2 class="Ss" title="Ss" id="&quot;Permission_denied&quot;_when_running_libguestfs_as_root"><a class="selflink" href="#&quot;Permission_denied&quot;_when_running_libguestfs_as_root">&quot;Permission
  denied&quot; when running libguestfs as root</a></h2>
You get a permission denied error when opening a disk image, even though you are
  running libguestfs as root.
<div class="Pp"></div>
This is caused by libvirt, and so only happens when using the libvirt backend.
  When run as root, libvirt decides to run the qemu appliance as user
  &quot;qemu.qemu&quot;. Unfortunately this usually means that qemu cannot open
  disk images, especially if those disk images are owned by root, or are present
  in directories which require root access.
<div class="Pp"></div>
There is a bug open against libvirt to fix this:
  https://bugzilla.redhat.com/show_bug.cgi?id=1045069
<div class="Pp"></div>
You can work around this by one of the following methods:
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">Switch to the direct backend:
    <div style="height: 1.00em;">&#x00A0;</div>
    <pre>
 export LIBGUESTFS_BACKEND=direct
    </pre>
  </dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">Don't run libguestfs as root.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">Chmod the disk image and any parent directories so that the
      qemu user can access them.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">(Nasty) Edit <i>/etc/libvirt/qemu.conf</i> and change the
      &quot;user&quot; setting.</dd>
</dl>
<h2 class="Ss" title="Ss" id="execl:_/init:_Permission_denied"><a class="selflink" href="#execl:_/init:_Permission_denied">execl:
  /init: Permission denied</a></h2>
<b>Note:</b> If this error happens when you are using a distro package of
  libguestfs (eg. from Fedora, Debian, etc) then file a bug against the distro.
  This is not an error which normal users should ever see if the distro package
  has been prepared correctly.
<div class="Pp"></div>
This error happens during the supermin boot phase of starting the appliance:
<div class="Pp"></div>
<pre>
 supermin: mounting new root on /root
 supermin: chroot
 execl: /init: Permission denied
 supermin: debug: listing directory /
 [...followed by a lot of debug output...]
</pre>
<div class="Pp"></div>
This is a complicated bug related to <i>supermin</i>(1) appliances. The
  appliance is constructed by copying files like <i>/bin/bash</i> and many
  libraries from the host. The file &quot;hostfiles&quot; lists the files that
  should be copied from the host into the appliance. If some files don't exist
  on the host then they are missed out, but if these files are needed in order
  to (eg) run <i>/bin/bash</i> then you'll see the above error.
<div class="Pp"></div>
Diagnosing the problem involves studying the libraries needed by
  <i>/bin/bash</i>, ie:
<div class="Pp"></div>
<pre>
 ldd /bin/bash
</pre>
<div class="Pp"></div>
comparing that with &quot;hostfiles&quot;, with the files actually available in
  the host filesystem, and with the debug output printed in the error message.
  Once you've worked out which file is missing, install that file using your
  package manager and try again.
<div class="Pp"></div>
You should also check that files like <i>/init</i> and <i>/bin/bash</i> (in the
  appliance) are executable. The debug output shows file modes.
<h1 class="Sh" title="Sh" id="DOWNLOADING,_INSTALLING,_COMPILING_LIBGUESTFS"><a class="selflink" href="#DOWNLOADING,_INSTALLING,_COMPILING_LIBGUESTFS">DOWNLOADING,
  INSTALLING, COMPILING LIBGUESTFS</a></h1>
<h2 class="Ss" title="Ss" id="Where_can_I_get_the_latest_binaries_for_...?"><a class="selflink" href="#Where_can_I_get_the_latest_binaries_for_...?">Where
  can I get the latest binaries for ...?</a></h2>
<dl class="Bl-tag">
  <dt class="It-tag">Fedora &#x2265; 11</dt>
  <dd class="It-tag">Use:
    <div style="height: 1.00em;">&#x00A0;</div>
    <pre>
 yum install '*guestf*'
    </pre>
    <div style="height: 1.00em;">&#x00A0;</div>
    For the latest builds, see:
      http://koji.fedoraproject.org/koji/packageinfo?packageID=8391</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">Red Hat Enterprise Linux</dt>
  <dd class="It-tag"></dd>
</dl>
<div style="margin-left: 4.00ex;">
<dl class="Bl-tag">
  <dt class="It-tag">RHEL 5</dt>
  <dd class="It-tag">The version shipped in official RHEL 5 is very old and
      should not be used except in conjunction with virt-v2v. Use the up-to-date
      libguestfs 1.20 package in EPEL 5:
    https://fedoraproject.org/wiki/EPEL</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">RHEL 6</dt>
  <dd class="It-tag"></dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">RHEL 7</dt>
  <dd class="It-tag">It is part of the default install. On RHEL 6 and 7 (only)
      you have to install &quot;libguestfs-winsupport&quot; to get Windows guest
      support.</dd>
</dl>
</div>
<div style="margin-left: 4.00ex;"></div>
<dl class="Bl-tag">
  <dt class="It-tag">Debian and Ubuntu</dt>
  <dd class="It-tag">For libguestfs &lt; 1.26, after installing libguestfs you
      need to do:
    <div style="height: 1.00em;">&#x00A0;</div>
    <pre>
 sudo update-guestfs-appliance
    </pre>
    <div style="height: 1.00em;">&#x00A0;</div>
    (This script has been removed on Debian/Ubuntu with libguestfs &#x2265; 1.26
      and instead the appliance is built on demand.)
    <div style="height: 1.00em;">&#x00A0;</div>
    On Ubuntu only:
    <div style="height: 1.00em;">&#x00A0;</div>
    <pre>
 sudo chmod 0644 /boot/vmlinuz*
    </pre>
    <div style="height: 1.00em;">&#x00A0;</div>
    You may need to add yourself to the &quot;kvm&quot; group:
    <div style="height: 1.00em;">&#x00A0;</div>
    <pre>
 sudo usermod -a -G kvm yourlogin
    </pre>
  </dd>
</dl>
<div style="margin-left: 4.00ex;">
<dl class="Bl-tag">
  <dt class="It-tag">Debian Squeeze (6)</dt>
  <dd class="It-tag">Hilko Bengen has built libguestfs in squeeze backports:
      http://packages.debian.org/search?keywords=guestfs&amp;searchon=names&amp;section=all&amp;suite=squeeze-backports</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">Debian Wheezy and later (7+)</dt>
  <dd class="It-tag">Hilko Bengen supports libguestfs on Debian. Official Debian
      packages are available:
      http://packages.debian.org/search?keywords=libguestfs</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">Ubuntu</dt>
  <dd class="It-tag">We don't have a full time Ubuntu maintainer, and the
      packages supplied by Canonical (which are outside our control) are
      sometimes broken.
    <div style="height: 1.00em;">&#x00A0;</div>
    Canonical decided to change the permissions on the kernel so that it's not
      readable except by root. This is completely stupid, but they won't change
      it (https://bugs.launchpad.net/ubuntu/+source/linux/+bug/759725). So every
      user should do this:
    <div style="height: 1.00em;">&#x00A0;</div>
    <pre>
 sudo chmod 0644 /boot/vmlinuz*
    </pre>
  </dd>
</dl>
<div style="margin-left: 4.00ex;">
<dl class="Bl-tag">
  <dt class="It-tag">Ubuntu 12.04</dt>
  <dd class="It-tag">libguestfs in this version of Ubuntu works, but you need to
      update febootstrap and seabios to the latest versions.
    <div style="height: 1.00em;">&#x00A0;</div>
    You need febootstrap &#x2265; 3.14-2 from:
      http://packages.ubuntu.com/precise/febootstrap
    <div style="height: 1.00em;">&#x00A0;</div>
    After installing or updating febootstrap, rebuild the appliance:
    <div style="height: 1.00em;">&#x00A0;</div>
    <pre>
 sudo update-guestfs-appliance
    </pre>
    <div style="height: 1.00em;">&#x00A0;</div>
    You need seabios &#x2265; 0.6.2-0ubuntu2.1 or &#x2265; 0.6.2-0ubuntu3 from:
      http://packages.ubuntu.com/precise-updates/seabios or
      http://packages.ubuntu.com/quantal/seabios
    <div style="height: 1.00em;">&#x00A0;</div>
    Also you need to do (see above):
    <div style="height: 1.00em;">&#x00A0;</div>
    <pre>
 sudo chmod 0644 /boot/vmlinuz*
    </pre>
  </dd>
</dl>
</div>
<div style="margin-left: 4.00ex;"></div>
</div>
<div style="margin-left: 4.00ex;"></div>
<dl class="Bl-tag">
  <dt class="It-tag">Gentoo</dt>
  <dd class="It-tag">Libguestfs was added to Gentoo in 2012-07 by Andreis
      Vinogradovs (libguestfs) and Maxim Koltsov (mainly hivex). Do:
    <div style="height: 1.00em;">&#x00A0;</div>
    <pre>
 emerge libguestfs
    </pre>
  </dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">SuSE</dt>
  <dd class="It-tag">Libguestfs was added to SuSE in 2012 by Olaf Hering.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ArchLinux</dt>
  <dd class="It-tag">Libguestfs was added to the AUR in 2010.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">Other Linux distro</dt>
  <dd class="It-tag">Compile from source (next section).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">Other non-Linux distro</dt>
  <dd class="It-tag">You'll have to compile from source, and port it.</dd>
</dl>
<h2 class="Ss" title="Ss" id="How_can_I_compile_and_install_libguestfs_from_source?"><a class="selflink" href="#How_can_I_compile_and_install_libguestfs_from_source?">How
  can I compile and install libguestfs from source?</a></h2>
You can compile libguestfs from git or a source tarball. Read the README file
  before starting.
<div class="Pp"></div>
Git: https://github.com/libguestfs/libguestfs Source tarballs:
  http://libguestfs.org/download
<div class="Pp"></div>
Don't run &quot;make install&quot;! Use the &quot;./run&quot; script instead
  (see README).
<h2 class="Ss" title="Ss" id="How_can_I_compile_and_install_libguestfs_if_my_distro_doesn't_have_new_enough_qemu/supermin/kernel?"><a class="selflink" href="#How_can_I_compile_and_install_libguestfs_if_my_distro_doesn't_have_new_enough_qemu/supermin/kernel?">How
  can I compile and install libguestfs if my distro doesn't have new enough
  qemu/supermin/kernel?</a></h2>
Libguestfs needs supermin 5. If supermin 5 hasn't been ported to your distro,
  then see the question below.
<div class="Pp"></div>
First compile qemu, supermin and/or the kernel from source. You do <i>not</i>
  need to &quot;make install&quot; them.
<div class="Pp"></div>
In the libguestfs source directory, create two files. &quot;localconfigure&quot;
  should contain:
<div class="Pp"></div>
<pre>
 source localenv
 #export PATH=/tmp/qemu/x86_64-softmmu:$PATH
 ./autogen.sh --prefix /usr &quot;$@&quot;
</pre>
<div class="Pp"></div>
Make &quot;localconfigure&quot; executable.
<div class="Pp"></div>
&quot;localenv&quot; should contain:
<div class="Pp"></div>
<pre>
 #export SUPERMIN=/tmp/supermin/src/supermin
 #export LIBGUESTFS_HV=/tmp/qemu/x86_64-softmmu/qemu-system-x86_64
 #export SUPERMIN_KERNEL=/tmp/linux/arch/x86/boot/bzImage
 #export SUPERMIN_KERNEL_VERSION=4.XX.0
 #export SUPERMIN_MODULES=/tmp/lib/modules/4.XX.0
</pre>
<div class="Pp"></div>
Uncomment and adjust these lines as required to use the alternate programs you
  have compiled.
<div class="Pp"></div>
Use &quot;./localconfigure&quot; instead of &quot;./configure&quot;, but
  otherwise you compile libguestfs as usual.
<div class="Pp"></div>
Don't run &quot;make install&quot;! Use the &quot;./run&quot; script instead
  (see README).
<h2 class="Ss" title="Ss" id="How_can_I_compile_and_install_libguestfs_without_supermin?"><a class="selflink" href="#How_can_I_compile_and_install_libguestfs_without_supermin?">How
  can I compile and install libguestfs without supermin?</a></h2>
If supermin 5 supports your distro, but you don't happen to have a new enough
  supermin installed, then see the previous question.
<div class="Pp"></div>
If supermin 5 doesn't support your distro at all, you will need to use the
  &quot;fixed appliance method&quot; where you use a pre-compiled binary
  appliance. To build libguestfs without supermin, you need to pass
  &quot;--disable-appliance --disable-daemon&quot; to either <i>./autogen.sh</i>
  or <i>./configure</i> (depending whether you are building respectively from
  git or from tarballs). Then, when using libguestfs, you <b>must</b> set the
  &quot;LIBGUESTFS_PATH&quot; environment variable to the directory of a
  pre-compiled appliance, as also described in &quot;FIXED APPLIANCE&quot; in
  <i>guestfs-internals</i>(1).
<div class="Pp"></div>
For pre-compiled appliances, see also:
  http://libguestfs.org/download/binaries/appliance/.
<div class="Pp"></div>
Patches to port supermin to more Linux distros are welcome.
<h2 class="Ss" title="Ss" id="How_can_I_add_support_for_sVirt?"><a class="selflink" href="#How_can_I_add_support_for_sVirt?">How
  can I add support for sVirt?</a></h2>
<b>Note for Fedora/RHEL users:</b> This configuration is the default starting
  with Fedora&#x00A0;18 and RHEL&#x00A0;7. If you find any problems, please let
  us know or file a bug.
<div class="Pp"></div>
SVirt provides a hardened appliance using SELinux, making it very hard for a
  rogue disk image to &quot;escape&quot; from the confinement of libguestfs and
  damage the host (it's fair to say that even in standard libguestfs this would
  be hard, but sVirt provides an extra layer of protection for the host and more
  importantly protects virtual machines on the same host from each other).
<div class="Pp"></div>
Currently to enable sVirt you will need libvirt &#x2265; 0.10.2 (1.0 or later
  preferred), libguestfs &#x2265; 1.20, and the SELinux policies from recent
  Fedora. If you are not running Fedora&#x00A0;18+, you will need to make
  changes to your SELinux policy - contact us on the mailing list.
<div class="Pp"></div>
Once you have the requirements, do:
<div class="Pp"></div>
<pre>
 ./configure --with-default-backend=libvirt       # libguestfs &gt;= 1.22
 ./configure --with-default-attach-method=libvirt # libguestfs &lt;= 1.20
 make
</pre>
<div class="Pp"></div>
Set SELinux to Enforcing mode, and sVirt should be used automatically.
<div class="Pp"></div>
All, or almost all, features of libguestfs should work under sVirt. There is one
  known shortcoming: <i>virt-rescue</i>(1) will not use libvirt (hence sVirt),
  but falls back to direct launch of qemu. So you won't currently get the
  benefit of sVirt protection when using virt-rescue.
<div class="Pp"></div>
You can check if sVirt is being used by enabling libvirtd logging (see
  <i>/etc/libvirt/libvirtd.log</i>), killing and restarting libvirtd, and
  checking the log files for
  &quot;Setting&#x00A0;SELinux&#x00A0;context&#x00A0;on&#x00A0;...&quot;
  messages.
<div class="Pp"></div>
In theory sVirt should support AppArmor, but we have not tried it. It will
  almost certainly require patching libvirt and writing an AppArmor policy.
<h2 class="Ss" title="Ss" id="Libguestfs_has_a_really_long_list_of_dependencies!"><a class="selflink" href="#Libguestfs_has_a_really_long_list_of_dependencies!">Libguestfs
  has a really long list of dependencies!</a></h2>
The base library doesn't depend on very much, but there are three causes of the
  long list of other dependencies:
<dl class="Bl-tag">
  <dt class="It-tag">1.</dt>
  <dd class="It-tag">Libguestfs has to be able to read and edit many different
      disk formats. For example, XFS support requires XFS tools.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">2.</dt>
  <dd class="It-tag">There are language bindings for many different languages,
      all requiring their own development tools. All language bindings (except
      C) are optional.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">3.</dt>
  <dd class="It-tag">There are some optional library features which can be
      disabled.</dd>
</dl>
<div class="Pp"></div>
Since libguestfs &#x2265; 1.26 it is possible to split up the appliance
  dependencies (item 1 in the list above) and thus have (eg)
  &quot;libguestfs-xfs&quot; as a separate subpackage for processing XFS disk
  images. We encourage downstream packagers to start splitting the base
  libguestfs package into smaller subpackages.
<h2 class="Ss" title="Ss" id="Errors_during_launch_on_Fedora_&#x2265;_18,_RHEL_&#x2265;_7"><a class="selflink" href="#Errors_during_launch_on_Fedora_&#x2265;_18,_RHEL_&#x2265;_7">Errors
  during launch on Fedora &#x2265; 18, RHEL &#x2265; 7</a></h2>
In Fedora &#x2265; 18 and RHEL &#x2265; 7, libguestfs uses libvirt to manage the
  appliance. Previously (and upstream) libguestfs runs qemu directly:
<div class="Pp"></div>
<pre>
 &#x250C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2510;
 &#x2502; libguestfs                       &#x2502;
 &#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x252C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
 &#x2502; direct backend &#x2502; libvirt backend &#x2502;
 &#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2534;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;
        &#x2193;                  &#x2193;
    &#x250C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2510;         &#x250C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2510;
    &#x2502; qemu  &#x2502;         &#x2502; libvirtd &#x2502;
    &#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;         &#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;
                           &#x2193;
                       &#x250C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2510;
                       &#x2502; qemu  &#x2502;
                       &#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;
 
    upstream          Fedora 18+
    non-Fedora         RHEL 7+
    non-RHEL
</pre>
<div class="Pp"></div>
The libvirt backend is more sophisticated, supporting SELinux/sVirt (see above),
  hotplugging and more. It is, however, more complex and so less robust.
<div class="Pp"></div>
If you have permissions problems using the libvirt backend, you can switch to
  the direct backend by setting this environment variable:
<div class="Pp"></div>
<pre>
 export LIBGUESTFS_BACKEND=direct
</pre>
<div class="Pp"></div>
before running any libguestfs program or virt tool.
<h2 class="Ss" title="Ss" id="How_can_I_switch_to_a_fixed_/_prebuilt_appliance?"><a class="selflink" href="#How_can_I_switch_to_a_fixed_/_prebuilt_appliance?">How
  can I switch to a fixed / prebuilt appliance?</a></h2>
This may improve the stability and performance of libguestfs on Fedora and RHEL.
<div class="Pp"></div>
Any time after installing libguestfs, run the following commands as root:
<div class="Pp"></div>
<pre>
 mkdir -p /usr/local/lib/guestfs/appliance
 libguestfs-make-fixed-appliance /usr/local/lib/guestfs/appliance
 ls -l /usr/local/lib/guestfs/appliance
</pre>
<div class="Pp"></div>
Now set the following environment variable before using libguestfs or any virt
  tool:
<div class="Pp"></div>
<pre>
 export LIBGUESTFS_PATH=/usr/local/lib/guestfs/appliance
</pre>
<div class="Pp"></div>
Of course you can change the path to any directory you want. You can share the
  appliance across machines that have the same architecture (eg. all x86-64),
  but note that libvirt will prevent you from sharing the appliance across NFS
  because of permissions problems (so either switch to the direct backend or
  don't use NFS).
<h2 class="Ss" title="Ss" id="How_can_I_speed_up_libguestfs_builds?"><a class="selflink" href="#How_can_I_speed_up_libguestfs_builds?">How
  can I speed up libguestfs builds?</a></h2>
By far the most important thing you can do is to install and properly configure
  Squid. Note that the default configuration that ships with Squid is rubbish,
  so configuring it is not optional.
<div class="Pp"></div>
A very good place to start with Squid configuration is here:
  https://fedoraproject.org/wiki/Extras/MockTricks#Using_Squid_to_Speed_Up_Mock_package_downloads
<div class="Pp"></div>
Make sure Squid is running, and that the environment variables $http_proxy and
  $ftp_proxy are pointing to it.
<div class="Pp"></div>
With Squid running and correctly configured, appliance builds should be reduced
  to a few minutes.
<div class="Pp"></div>
<i>How can I speed up libguestfs builds (Debian)?</i>
<div class="Pp"></div>
Hilko Bengen suggests using &quot;approx&quot; which is a Debian archive proxy
  (http://packages.debian.org/approx). This tool is documented on Debian in the
  <i>approx</i>(8) manual page.
<h1 class="Sh" title="Sh" id="SPEED,_DISK_SPACE_USED_BY_LIBGUESTFS"><a class="selflink" href="#SPEED,_DISK_SPACE_USED_BY_LIBGUESTFS">SPEED,
  DISK SPACE USED BY LIBGUESTFS</a></h1>
<b>Note:</b> Most of the information in this section has moved:
  <i>guestfs-performance</i>(1).
<h2 class="Ss" title="Ss" id="Upload_or_write_seem_very_slow."><a class="selflink" href="#Upload_or_write_seem_very_slow.">Upload
  or write seem very slow.</a></h2>
If the underlying disk is not fully allocated (eg. sparse raw or qcow2) then
  writes can be slow because the host operating system has to do costly disk
  allocations while you are writing. The solution is to use a fully allocated
  format instead, ie. non-sparse raw, or qcow2 with the
  &quot;preallocation=metadata&quot; option.
<h2 class="Ss" title="Ss" id="Libguestfs_uses_too_much_disk_space!"><a class="selflink" href="#Libguestfs_uses_too_much_disk_space!">Libguestfs
  uses too much disk space!</a></h2>
libguestfs caches a large-ish appliance in:
<div class="Pp"></div>
<pre>
 /var/tmp/.guestfs-&lt;UID&gt;
</pre>
<div class="Pp"></div>
If the environment variable &quot;TMPDIR&quot; is defined, then
  <i></i><i>$TMPDIR</i> <i>/.guestfs-&lt;UID&gt;</i> is used instead.
<div class="Pp"></div>
It is safe to delete this directory when you are not using libguestfs.
<h2 class="Ss" title="Ss" id="virt-sparsify_seems_to_make_the_image_grow_to_the_full_size_of_the_virtual_disk"><a class="selflink" href="#virt-sparsify_seems_to_make_the_image_grow_to_the_full_size_of_the_virtual_disk">virt-sparsify
  seems to make the image grow to the full size of the virtual disk</a></h2>
If the input to <i>virt-sparsify</i>(1) is raw, then the output will be raw
  sparse. Make sure you are measuring the output with a tool which understands
  sparseness such as &quot;du -sh&quot;. It can make a huge difference:
<div class="Pp"></div>
<pre>
 $ ls -lh test1.img
 -rw-rw-r--. 1 rjones rjones 100M Aug  8 08:08 test1.img
 $ du -sh test1.img
 3.6M   test1.img
</pre>
<div class="Pp"></div>
(Compare the apparent size <b>100M</b> vs the actual size <b>3.6M</b>)
<div class="Pp"></div>
If all this confuses you, use a non-sparse output format by specifying the
  <i>--convert</i> option, eg:
<div class="Pp"></div>
<pre>
 virt-sparsify --convert qcow2 disk.raw disk.qcow2
</pre>
<h2 class="Ss" title="Ss" id="Why_doesn't_virt-resize_work_on_the_disk_image_in-place?"><a class="selflink" href="#Why_doesn't_virt-resize_work_on_the_disk_image_in-place?">Why
  doesn't virt-resize work on the disk image in-place?</a></h2>
Resizing a disk image is very tricky -- especially making sure that you don't
  lose data or break the bootloader. The current method effectively creates a
  new disk image and copies the data plus bootloader from the old one. If
  something goes wrong, you can always go back to the original.
<div class="Pp"></div>
If we were to make virt-resize work in-place then there would have to be
  limitations: for example, you wouldn't be allowed to move existing partitions
  (because moving data across the same disk is most likely to corrupt data in
  the event of a power failure or crash), and LVM would be very difficult to
  support (because of the almost arbitrary mapping between LV content and
  underlying disk blocks).
<div class="Pp"></div>
Another method we have considered is to place a snapshot over the original disk
  image, so that the original data is untouched and only differences are
  recorded in the snapshot. You can do this today using &quot;qemu-img
  create&quot; + &quot;virt-resize&quot;, but qemu currently isn't smart enough
  to recognize when the same block is written back to the snapshot as already
  exists in the backing disk, so you will find that this doesn't save you any
  space or time.
<div class="Pp"></div>
In summary, this is a hard problem, and what we have now mostly works so we are
  reluctant to change it.
<h2 class="Ss" title="Ss" id="Why_doesn't_virt-sparsify_work_on_the_disk_image_in-place?"><a class="selflink" href="#Why_doesn't_virt-sparsify_work_on_the_disk_image_in-place?">Why
  doesn't virt-sparsify work on the disk image in-place?</a></h2>
In libguestfs &#x2265; 1.26, virt-sparsify can now work on disk images in place.
  Use:
<div class="Pp"></div>
<pre>
 virt-sparsify --in-place disk.img
</pre>
<div class="Pp"></div>
But first you should read &quot;IN-PLACE SPARSIFICATION&quot; in
  <i>virt-sparsify</i>(1).
<h1 class="Sh" title="Sh" id="PROBLEMS_OPENING_DISK_IMAGES"><a class="selflink" href="#PROBLEMS_OPENING_DISK_IMAGES">PROBLEMS
  OPENING DISK IMAGES</a></h1>
<h2 class="Ss" title="Ss" id="Remote_libvirt_guests_cannot_be_opened."><a class="selflink" href="#Remote_libvirt_guests_cannot_be_opened.">Remote
  libvirt guests cannot be opened.</a></h2>
Opening remote libvirt guests is not supported at this time. For example this
  won't work:
<div class="Pp"></div>
<pre>
 guestfish -c qemu://remote/system -d Guest
</pre>
<div class="Pp"></div>
To open remote disks you have to export them somehow, then connect to the
  export. For example if you decided to use NBD:
<div class="Pp"></div>
<pre>
 remote$ qemu-nbd -t -p 10809 guest.img
  local$ guestfish -a nbd://remote:10809 -i
</pre>
<div class="Pp"></div>
Other possibilities include ssh (if qemu is recent enough), NFS or iSCSI. See
  &quot;REMOTE STORAGE&quot; in <i>guestfs</i>(3).
<h2 class="Ss" title="Ss" id="How_can_I_open_this_strange_disk_source?"><a class="selflink" href="#How_can_I_open_this_strange_disk_source?">How
  can I open this strange disk source?</a></h2>
You have a disk image located inside another system that requires access via a
  library / HTTP / REST / proprietary API, or is compressed or archived in some
  way. (One example would be remote access to OpenStack glance images without
  actually downloading them.)
<div class="Pp"></div>
We have a sister project called nbdkit (https://github.com/libguestfs/nbdkit).
  This project lets you turn any disk source into an NBD server. Libguestfs can
  access NBD servers directly, eg:
<div class="Pp"></div>
<pre>
 guestfish -a nbd://remote
</pre>
<div class="Pp"></div>
nbdkit is liberally licensed, so you can link it to or include it in proprietary
  libraries and code. It also has a simple, stable plugin API so you can easily
  write plugins against the API which will continue to work in future.
<h2 class="Ss" title="Ss" id="Error_opening_VMDK_disks:_&quot;uses_a_vmdk_feature_which_is_not_supported_by_this_qemu_version:_VMDK_version_3&quot;"><a class="selflink" href="#Error_opening_VMDK_disks:_&quot;uses_a_vmdk_feature_which_is_not_supported_by_this_qemu_version:_VMDK_version_3&quot;">Error
  opening VMDK disks: &quot;uses a vmdk feature which is not supported by this
  qemu version: VMDK version 3&quot;</a></h2>
Qemu (and hence libguestfs) only supports certain VMDK disk images. Others won't
  work, giving this or similar errors.
<div class="Pp"></div>
Ideally someone would fix qemu to support the latest VMDK features, but in the
  meantime you have three options:
<dl class="Bl-tag">
  <dt class="It-tag">1.</dt>
  <dd class="It-tag">If the guest is hosted on a live, reachable ESX server,
      then locate and download the disk image called
      <i></i><i>somename</i><i>-flat.vmdk</i>. Despite the name, this is a raw
      disk image, and can be opened by anything.
    <div style="height: 1.00em;">&#x00A0;</div>
    If you have a recent enough version of qemu and libguestfs, then you may be
      able to access this disk image remotely using either HTTPS or ssh. See
      &quot;REMOTE STORAGE&quot; in <i>guestfs</i>(3).</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">2.</dt>
  <dd class="It-tag">Use VMware's proprietary vdiskmanager tool to convert the
      image to raw format.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">3.</dt>
  <dd class="It-tag">Use nbdkit with the proprietary VDDK plugin to live export
      the disk image as an NBD source. This should allow you to read and write
      the VMDK file.</dd>
</dl>
<h2 class="Ss" title="Ss" id="UFS_disks_(as_used_by_BSD)_cannot_be_opened."><a class="selflink" href="#UFS_disks_(as_used_by_BSD)_cannot_be_opened.">UFS
  disks (as used by BSD) cannot be opened.</a></h2>
The UFS filesystem format has many variants, and these are not self-identifying.
  The Linux kernel has to be told which variant of UFS it has to use, which
  libguestfs cannot know.
<div class="Pp"></div>
You have to pass the right &quot;ufstype&quot; mount option when mounting these
  filesystems.
<div class="Pp"></div>
See https://www.kernel.org/doc/Documentation/filesystems/ufs.txt
<h2 class="Ss" title="Ss" id="Windows_ReFS"><a class="selflink" href="#Windows_ReFS">Windows
  ReFS</a></h2>
Windows ReFS is Microsoft's ZFS/Btrfs copy. This filesystem has not yet been
  reverse engineered and implemented in the Linux kernel, and therefore
  libguestfs doesn't support it. At the moment it seems to be very rare &quot;in
  the wild&quot;.
<h2 class="Ss" title="Ss" id="Non-ASCII_characters_don't_appear_on_VFAT_filesystems."><a class="selflink" href="#Non-ASCII_characters_don't_appear_on_VFAT_filesystems.">Non-ASCII
  characters don't appear on VFAT filesystems.</a></h2>
Typical symptoms of this problem:
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">You get an error when you create a file where the filename
      contains non-ASCII characters, particularly non 8-bit characters from
      Asian languages (Chinese, Japanese, etc). The filesystem is VFAT.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">When you list a directory from a VFAT filesystem, filenames
      appear as question marks.</dd>
</dl>
<div class="Pp"></div>
This is a design flaw of the GNU/Linux system.
<div class="Pp"></div>
VFAT stores long filenames as UTF-16 characters. When opening or returning
  filenames, the Linux kernel has to translate these to some form of 8 bit
  string. UTF-8 would be the obvious choice, except for Linux users who persist
  in using non-UTF-8 locales (the user's locale is not known to the kernel
  because it's a function of libc).
<div class="Pp"></div>
Therefore you have to tell the kernel what translation you want done when you
  mount the filesystem. The two methods are the &quot;iocharset&quot; parameter
  (which is not relevant to libguestfs) and the &quot;utf8&quot; flag.
<div class="Pp"></div>
So to use a VFAT filesystem you must add the &quot;utf8&quot; flag when
  mounting. From guestfish, use:
<div class="Pp"></div>
<pre>
 &gt;&lt;fs&gt; mount-options utf8 /dev/sda1 /
</pre>
<div class="Pp"></div>
or on the guestfish command line:
<div class="Pp"></div>
<pre>
 guestfish [...] -m /dev/sda1:/:utf8
</pre>
<div class="Pp"></div>
or from the API:
<div class="Pp"></div>
<pre>
 guestfs_mount_options (g, &quot;utf8&quot;, &quot;/dev/sda1&quot;, &quot;/&quot;);
</pre>
<div class="Pp"></div>
The kernel will then translate filenames to and from UTF-8 strings.
<div class="Pp"></div>
We considered adding this mount option transparently, but unfortunately there
  are several problems with doing that:
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">On some Linux systems, the &quot;utf8&quot; mount option
      doesn't work. We don't precisely understand what systems or why, but this
      was reliably reported by one user.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">It would prevent you from using the &quot;iocharset&quot;
      parameter because it is incompatible with &quot;utf8&quot;. It is probably
      not a good idea to use this parameter, but we don't want to prevent
    it.</dd>
</dl>
<h2 class="Ss" title="Ss" id="Non-ASCII_characters_appear_as_underscore_(_)_on_ISO9660_filesystems."><a class="selflink" href="#Non-ASCII_characters_appear_as_underscore_(_)_on_ISO9660_filesystems.">Non-ASCII
  characters appear as underscore (_) on ISO9660 filesystems.</a></h2>
The filesystem was not prepared correctly with mkisofs or genisoimage. Make sure
  the filesystem was created using Joliet and/or Rock Ridge extensions.
  libguestfs does not require any special mount options to handle the
  filesystem.
<h2 class="Ss" title="Ss" id="Cannot_open_Windows_guests_which_use_NTFS."><a class="selflink" href="#Cannot_open_Windows_guests_which_use_NTFS.">Cannot
  open Windows guests which use NTFS.</a></h2>
You see errors like:
<div class="Pp"></div>
<pre>
 mount: unknown filesystem type 'ntfs'
</pre>
<div class="Pp"></div>
On Red Hat Enterprise Linux or CentOS &lt; 7.2, you have to install the
  libguestfs-winsupport package. In RHEL &#x2265; 7.2,
  &quot;libguestfs-winsupport&quot; is part of the base RHEL distribution, but
  see the next question.
<h2 class="Ss" title="Ss" id="&quot;mount:_unsupported_filesystem_type&quot;_with_NTFS_in_RHEL_&#x2265;_7.2"><a class="selflink" href="#&quot;mount:_unsupported_filesystem_type&quot;_with_NTFS_in_RHEL_&#x2265;_7.2">&quot;mount:
  unsupported filesystem type&quot; with NTFS in RHEL &#x2265; 7.2</a></h2>
In RHEL 7.2 we were able to add &quot;libguestfs-winsupport&quot; to the base
  RHEL distribution, but we had to disable the ability to use it for opening and
  editing filesystems. It is only supported when used with <i>virt-v2v</i>(1).
  If you try to use <i>guestfish</i>(1) or <i>guestmount</i>(1) or some other
  programs on an NTFS filesystem, you will see the error:
<div class="Pp"></div>
<pre>
 mount: unsupported filesystem type
</pre>
<div class="Pp"></div>
This is not a supported configuration, and it will not be made to work in RHEL.
  Don't bother to open a bug about it, as it will be immediately &quot;CLOSED
  -&gt; WONTFIX&quot;.
<div class="Pp"></div>
You may compile your own libguestfs removing this restriction, but that won't be
  endorsed or supported by Red Hat.
<h2 class="Ss" title="Ss" id="Cannot_open_or_inspect_RHEL_7_guests."><a class="selflink" href="#Cannot_open_or_inspect_RHEL_7_guests.">Cannot
  open or inspect RHEL 7 guests.</a></h2>
<h2 class="Ss" title="Ss" id="Cannot_open_Linux_guests_which_use_XFS."><a class="selflink" href="#Cannot_open_Linux_guests_which_use_XFS.">Cannot
  open Linux guests which use XFS.</a></h2>
RHEL 7 guests, and any other guests that use XFS, can be opened by libguestfs,
  but you have to install the &quot;libguestfs-xfs&quot; package.
<h1 class="Sh" title="Sh" id="USING_LIBGUESTFS_IN_YOUR_OWN_PROGRAMS"><a class="selflink" href="#USING_LIBGUESTFS_IN_YOUR_OWN_PROGRAMS">USING
  LIBGUESTFS IN YOUR OWN PROGRAMS</a></h1>
<h2 class="Ss" title="Ss" id="The_API_has_hundreds_of_methods,_where_do_I_start?"><a class="selflink" href="#The_API_has_hundreds_of_methods,_where_do_I_start?">The
  API has hundreds of methods, where do I start?</a></h2>
We recommend you start by reading the API overview: &quot;API OVERVIEW&quot; in
  <i>guestfs</i>(3).
<div class="Pp"></div>
Although the API overview covers the C API, it is still worth reading even if
  you are going to use another programming language, because the API is the
  same, just with simple logical changes to the names of the calls:
<div class="Pp"></div>
<pre>
                  C  guestfs_ln_sf (g, target, linkname);
             Python  g.ln_sf (target, linkname);
              OCaml  g#ln_sf target linkname;
               Perl  $g-&gt;ln_sf (target, linkname);
  Shell (guestfish)  ln-sf target linkname
                PHP  guestfs_ln_sf ($g, $target, $linkname);
</pre>
<div class="Pp"></div>
Once you're familiar with the API overview, you should look at this list of
  starting points for other language bindings: &quot;USING LIBGUESTFS WITH OTHER
  PROGRAMMING LANGUAGES&quot; in <i>guestfs</i>(3).
<h2 class="Ss" title="Ss" id="Can_I_use_libguestfs_in_my_proprietary_/_closed_source_/_commercial_program?"><a class="selflink" href="#Can_I_use_libguestfs_in_my_proprietary_/_closed_source_/_commercial_program?">Can
  I use libguestfs in my proprietary / closed source / commercial
  program?</a></h2>
In general, yes. However this is not legal advice - read the license that comes
  with libguestfs, and if you have specific questions contact a lawyer.
<div class="Pp"></div>
In the source tree the license is in the file &quot;COPYING.LIB&quot; (LGPLv2+
  for the library and bindings) and &quot;COPYING&quot; (GPLv2+ for the
  standalone programs).
<h1 class="Sh" title="Sh" id="DEBUGGING_LIBGUESTFS"><a class="selflink" href="#DEBUGGING_LIBGUESTFS">DEBUGGING
  LIBGUESTFS</a></h1>
<h2 class="Ss" title="Ss" id="Help,_it's_not_working!"><a class="selflink" href="#Help,_it's_not_working!">Help,
  it's not working!</a></h2>
If no libguestfs program seems to work at all, run the program below and paste
  the <b>complete, unedited</b> output into an email to &quot;libguestfs&quot; @
  &quot;redhat.com&quot;:
<div class="Pp"></div>
<pre>
 libguestfs-test-tool
</pre>
<div class="Pp"></div>
If a particular operation fails, supply all the information in this checklist,
  in an email to &quot;libguestfs&quot; @ &quot;redhat.com&quot;:
<dl class="Bl-tag">
  <dt class="It-tag">1.</dt>
  <dd class="It-tag">What are you trying to do?</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">2.</dt>
  <dd class="It-tag">What exact command(s) did you run?</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">3.</dt>
  <dd class="It-tag">What was the precise error or output of these
    commands?</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">4.</dt>
  <dd class="It-tag">Enable debugging, run the commands again, and capture the
      <b>complete</b> output. <b>Do not edit the output.</b>
    <div style="height: 1.00em;">&#x00A0;</div>
    <pre>
 export LIBGUESTFS_DEBUG=1
 export LIBGUESTFS_TRACE=1
    </pre>
  </dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">5.</dt>
  <dd class="It-tag">Include the version of libguestfs, the operating system
      version, and how you installed libguestfs (eg. from source, &quot;yum
      install&quot;, etc.)</dd>
</dl>
<h2 class="Ss" title="Ss" id="How_do_I_debug_when_using_any_libguestfs_program_or_tool_(eg._virt-v2v_or_virt-df)?"><a class="selflink" href="#How_do_I_debug_when_using_any_libguestfs_program_or_tool_(eg._virt-v2v_or_virt-df)?">How
  do I debug when using any libguestfs program or tool (eg. virt-v2v or
  virt-df)?</a></h2>
There are two &quot;LIBGUESTFS_*&quot; environment variables you can set in
  order to get more information from libguestfs.
<dl class="Bl-tag">
  <dt class="It-tag">&quot;LIBGUESTFS_TRACE&quot;</dt>
  <dd class="It-tag">Set this to 1 and libguestfs will print out each command /
      API call in a format which is similar to guestfish commands.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">&quot;LIBGUESTFS_DEBUG&quot;</dt>
  <dd class="It-tag">Set this to 1 in order to enable massive amounts of debug
      messages. If you think there is some problem inside the libguestfs
      appliance, then you should use this option.</dd>
</dl>
<div class="Pp"></div>
To set these from the shell, do this before running the program:
<div class="Pp"></div>
<pre>
 export LIBGUESTFS_TRACE=1
 export LIBGUESTFS_DEBUG=1
</pre>
<div class="Pp"></div>
For csh/tcsh the equivalent commands would be:
<div class="Pp"></div>
<pre>
 setenv LIBGUESTFS_TRACE 1
 setenv LIBGUESTFS_DEBUG 1
</pre>
<div class="Pp"></div>
For further information, see: &quot;ENVIRONMENT VARIABLES&quot; in
  <i>guestfs</i>(3).
<h2 class="Ss" title="Ss" id="How_do_I_debug_when_using_guestfish?"><a class="selflink" href="#How_do_I_debug_when_using_guestfish?">How
  do I debug when using guestfish?</a></h2>
You can use the same environment variables above. Alternatively use the
  guestfish options -x (to trace commands) or -v (to get the full debug output),
  or both.
<div class="Pp"></div>
For further information, see: <i>guestfish</i>(1).
<h2 class="Ss" title="Ss" id="How_do_I_debug_when_using_the_API?"><a class="selflink" href="#How_do_I_debug_when_using_the_API?">How
  do I debug when using the API?</a></h2>
Call &quot;guestfs_set_trace&quot; in <i>guestfs</i>(3) to enable command
  traces, and/or &quot;guestfs_set_verbose&quot; in <i>guestfs</i>(3) to enable
  debug messages.
<div class="Pp"></div>
For best results, call these functions as early as possible, just after creating
  the guestfs handle if you can, and definitely before calling launch.
<h2 class="Ss" title="Ss" id="How_do_I_capture_debug_output_and_put_it_into_my_logging_system?"><a class="selflink" href="#How_do_I_capture_debug_output_and_put_it_into_my_logging_system?">How
  do I capture debug output and put it into my logging system?</a></h2>
Use the event API. For examples, see: &quot;SETTING CALLBACKS TO HANDLE
  EVENTS&quot; in <i>guestfs</i>(3) and the <i>examples/debug-logging.c</i>
  program in the libguestfs sources.
<h2 class="Ss" title="Ss" id="Digging_deeper_into_the_appliance_boot_process."><a class="selflink" href="#Digging_deeper_into_the_appliance_boot_process.">Digging
  deeper into the appliance boot process.</a></h2>
Enable debugging and then read this documentation on the appliance boot process:
  <i>guestfs-internals</i>(1).
<h2 class="Ss" title="Ss" id="libguestfs_hangs_or_fails_during_run/launch."><a class="selflink" href="#libguestfs_hangs_or_fails_during_run/launch.">libguestfs
  hangs or fails during run/launch.</a></h2>
Enable debugging and look at the full output. If you cannot work out what is
  going on, file a bug report, including the <i>complete</i> output of
  <i>libguestfs-test-tool</i>(1).
<h2 class="Ss" title="Ss" id="Debugging_libvirt"><a class="selflink" href="#Debugging_libvirt">Debugging
  libvirt</a></h2>
If you are using the libvirt backend, and libvirt is failing, then you can
  enable debugging by editing <i>/etc/libvirt/libvirtd.conf</i>.
<div class="Pp"></div>
If you are running as non-root, then you have to edit a different file. Create
  <i>~/.config/libvirt/libvirtd.conf</i> containing:
<div class="Pp"></div>
<pre>
 log_level=1
 log_outputs=&quot;1:file:/tmp/libvirtd.log&quot;
</pre>
<div class="Pp"></div>
Kill any session (non-root) libvirtd that is running, and next time you run the
  libguestfs command, you should see a large amount of useful debugging
  information from libvirtd in <i>/tmp/libvirtd.log</i>
<h1 class="Sh" title="Sh" id="DESIGN/INTERNALS_OF_LIBGUESTFS"><a class="selflink" href="#DESIGN/INTERNALS_OF_LIBGUESTFS">DESIGN/INTERNALS
  OF LIBGUESTFS</a></h1>
See also <i>guestfs-internals</i>(1).
<h2 class="Ss" title="Ss" id="Why_don't_you_do_everything_through_the_FUSE_/_filesystem_interface?"><a class="selflink" href="#Why_don't_you_do_everything_through_the_FUSE_/_filesystem_interface?">Why
  don't you do everything through the FUSE / filesystem interface?</a></h2>
We offer a command called <i>guestmount</i>(1) which lets you mount guest
  filesystems on the host. This is implemented as a FUSE module. Why don't we
  just implement the whole of libguestfs using this mechanism, instead of having
  the large and rather complicated API?
<div class="Pp"></div>
The reasons are twofold. Firstly, libguestfs offers API calls for doing things
  like creating and deleting partitions and logical volumes, which don't fit
  into a filesystem model very easily. Or rather, you could fit them in: for
  example, creating a partition could be mapped to &quot;mkdir /fs/hda1&quot;
  but then you'd have to specify some method to choose the size of the partition
  (maybe &quot;echo 100M &gt; /fs/hda1/.size&quot;), and the partition type,
  start and end sectors etc., but once you've done that the filesystem-based API
  starts to look more complicated than the call-based API we currently have.
<div class="Pp"></div>
The second reason is for efficiency. FUSE itself is reasonably efficient, but it
  does make lots of small, independent calls into the FUSE module. In guestmount
  these have to be translated into messages to the libguestfs appliance which
  has a big overhead (in time and round trips). For example, reading a file in
  64 KB chunks is inefficient because each chunk would turn into a single round
  trip. In the libguestfs API it is much more efficient to download an entire
  file or directory through one of the streaming calls like
  &quot;guestfs_download&quot; or &quot;guestfs_tar_out&quot;.
<h2 class="Ss" title="Ss" id="Why_don't_you_do_everything_through_GVFS?"><a class="selflink" href="#Why_don't_you_do_everything_through_GVFS?">Why
  don't you do everything through GVFS?</a></h2>
The problems are similar to the problems with FUSE.
<div class="Pp"></div>
GVFS is a better abstraction than POSIX/FUSE. There is an FTP backend for GVFS,
  which is encouraging because FTP is conceptually similar to the libguestfs
  API. However the GVFS FTP backend makes multiple simultaneous connections in
  order to keep interactivity, which we can't easily do with libguestfs.
<h2 class="Ss" title="Ss" id="Why_can_I_write_to_the_disk,_even_though_I_added_it_read-only?"><a class="selflink" href="#Why_can_I_write_to_the_disk,_even_though_I_added_it_read-only?">Why
  can I write to the disk, even though I added it read-only?</a></h2>
<h2 class="Ss" title="Ss" id="Why_does_&quot;--ro&quot;_appear_to_have_no_effect?"><a class="selflink" href="#Why_does_&quot;--ro&quot;_appear_to_have_no_effect?">Why
  does &quot;--ro&quot; appear to have no effect?</a></h2>
When you add a disk read-only, libguestfs places a writable overlay on top of
  the underlying disk. Writes go into this overlay, and are discarded when the
  handle is closed (or &quot;guestfish&quot; etc. exits).
<div class="Pp"></div>
There are two reasons for doing it this way: Firstly read-only disks aren't
  possible in many cases (eg. IDE simply doesn't support them, so you couldn't
  have an IDE-emulated read-only disk, although this is not common in real
  libguestfs installations).
<div class="Pp"></div>
Secondly and more importantly, even if read-only disks were possible, you
  wouldn't want them. Mounting any filesystem that has a journal, even
  &quot;mount -o ro&quot;, causes writes to the filesystem because the journal
  has to be replayed and metadata updated. If the disk was truly read-only, you
  wouldn't be able to mount a dirty filesystem.
<div class="Pp"></div>
To make it usable, we create the overlay as a place to temporarily store these
  writes, and then we discard it afterwards. This ensures that the underlying
  disk is always untouched.
<div class="Pp"></div>
Note also that there is a regression test for this when building libguestfs (in
  &quot;tests/qemu&quot;). This is one reason why it's important for packagers
  to run the test suite.
<h2 class="Ss" title="Ss" id="Does_&quot;--ro&quot;_make_all_disks_read-only?"><a class="selflink" href="#Does_&quot;--ro&quot;_make_all_disks_read-only?">Does
  &quot;--ro&quot; make all disks read-only?</a></h2>
<i>No!</i> The &quot;--ro&quot; option only affects disks added on the command
  line, ie. using &quot;-a&quot; and &quot;-d&quot; options.
<div class="Pp"></div>
In guestfish, if you use the &quot;add&quot; command, then disk is added
  read-write (unless you specify the &quot;readonly:true&quot; flag explicitly
  with the command).
<h2 class="Ss" title="Ss" id="Can_I_use_&quot;guestfish_--ro&quot;_as_a_way_to_backup_my_virtual_machines?"><a class="selflink" href="#Can_I_use_&quot;guestfish_--ro&quot;_as_a_way_to_backup_my_virtual_machines?">Can
  I use &quot;guestfish --ro&quot; as a way to backup my virtual
  machines?</a></h2>
Usually this is <i>not</i> a good idea. The question is answered in more detail
  in this mailing list posting:
  https://www.redhat.com/archives/libguestfs/2010-August/msg00024.html
<div class="Pp"></div>
See also the next question.
<h2 class="Ss" title="Ss" id="Why_can't_I_run_fsck_on_a_live_filesystem_using_&quot;guestfish_--ro&quot;?"><a class="selflink" href="#Why_can't_I_run_fsck_on_a_live_filesystem_using_&quot;guestfish_--ro&quot;?">Why
  can't I run fsck on a live filesystem using &quot;guestfish
  --ro&quot;?</a></h2>
This command will usually <i>not</i> work:
<div class="Pp"></div>
<pre>
 guestfish --ro -a /dev/vg/my_root_fs run : fsck /dev/sda
</pre>
<div class="Pp"></div>
The reason for this is that qemu creates a snapshot over the original
  filesystem, but it doesn't create a strict point-in-time snapshot. Blocks of
  data on the underlying filesystem are read by qemu at different times as the
  fsck operation progresses, with host writes in between. The result is that
  fsck sees massive corruption (imaginary, not real!) and fails.
<div class="Pp"></div>
What you have to do is to create a point-in-time snapshot. If it's a logical
  volume, use an LVM2 snapshot. If the filesystem is located inside something
  like a btrfs/ZFS file, use a btrfs/ZFS snapshot, and then run the fsck on the
  snapshot. In practice you don't need to use libguestfs for this -- just run
  <i>/sbin/fsck</i> directly.
<div class="Pp"></div>
Creating point-in-time snapshots of host devices and files is outside the scope
  of libguestfs, although libguestfs can operate on them once they are created.
<h2 class="Ss" title="Ss" id="What's_the_difference_between_guestfish_and_virt-rescue?"><a class="selflink" href="#What's_the_difference_between_guestfish_and_virt-rescue?">What's
  the difference between guestfish and virt-rescue?</a></h2>
A lot of people are confused by the two superficially similar tools we provide:
<div class="Pp"></div>
<pre>
 $ guestfish --ro -a guest.img
 &gt;&lt;fs&gt; run
 &gt;&lt;fs&gt; fsck /dev/sda1
 $ virt-rescue --ro guest.img
 &gt;&lt;rescue&gt; /sbin/fsck /dev/sda1
</pre>
<div class="Pp"></div>
And the related question which then arises is why you can't type in full shell
  commands with all the --options in guestfish (but you can in
  <i>virt-rescue</i>(1)).
<div class="Pp"></div>
<i>guestfish</i>(1) is a program providing structured access to the
  <i>guestfs</i>(3) API. It happens to be a nice interactive shell too, but its
  primary purpose is structured access from shell scripts. Think of it more like
  a language binding, like Python and other bindings, but for shell. The key
  differentiating factor of guestfish (and the libguestfs API in general) is the
  ability to automate changes.
<div class="Pp"></div>
<i>virt-rescue</i>(1) is a free-for-all freeform way to boot the libguestfs
  appliance and make arbitrary changes to your VM. It's not structured, you
  can't automate it, but for making quick ad-hoc fixes to your guests, it can be
  quite useful.
<div class="Pp"></div>
But, libguestfs also has a &quot;backdoor&quot; into the appliance allowing you
  to send arbitrary shell commands. It's not as flexible as virt-rescue, because
  you can't interact with the shell commands, but here it is anyway:
<div class="Pp"></div>
<pre>
 &gt;&lt;fs&gt; debug sh &quot;cmd arg1 arg2 ...&quot;
</pre>
<div class="Pp"></div>
Note that you should <b>not</b> rely on this. It could be removed or changed in
  future. If your program needs some operation, please add it to the libguestfs
  API instead.
<h2 class="Ss" title="Ss" id="What's_the_deal_with_&quot;guestfish_-i&quot;?"><a class="selflink" href="#What's_the_deal_with_&quot;guestfish_-i&quot;?">What's
  the deal with &quot;guestfish -i&quot;?</a></h2>
<h2 class="Ss" title="Ss" id="Why_does_virt-cat_only_work_on_a_real_VM_image,_but_virt-df_works_on_any_disk_image?"><a class="selflink" href="#Why_does_virt-cat_only_work_on_a_real_VM_image,_but_virt-df_works_on_any_disk_image?">Why
  does virt-cat only work on a real VM image, but virt-df works on any disk
  image?</a></h2>
<h2 class="Ss" title="Ss" id="What_does_&quot;no_root_device_found_in_this_operating_system_image&quot;_mean?"><a class="selflink" href="#What_does_&quot;no_root_device_found_in_this_operating_system_image&quot;_mean?">What
  does &quot;no root device found in this operating system image&quot;
  mean?</a></h2>
These questions are all related at a fundamental level which may not be
  immediately obvious.
<div class="Pp"></div>
At the <i>guestfs</i>(3) API level, a &quot;disk image&quot; is just a pile of
  partitions and filesystems.
<div class="Pp"></div>
In contrast, when the virtual machine boots, it mounts those filesystems into a
  consistent hierarchy such as:
<div class="Pp"></div>
<pre>
 /          (/dev/sda2)
 &#x2502;
 &#x251C;&#x2500;&#x2500; /boot  (/dev/sda1)
 &#x2502;
 &#x251C;&#x2500;&#x2500; /home  (/dev/vg_external/Homes)
 &#x2502;
 &#x251C;&#x2500;&#x2500; /usr   (/dev/vg_os/lv_usr)
 &#x2502;
 &#x2514;&#x2500;&#x2500; /var   (/dev/vg_os/lv_var)
</pre>
<div class="Pp"></div>
(or drive letters on Windows).
<div class="Pp"></div>
The API first of all sees the disk image at the &quot;pile of filesystems&quot;
  level. But it also has a way to inspect the disk image to see if it contains
  an operating system, and how the disks are mounted when the operating system
  boots: &quot;INSPECTION&quot; in <i>guestfs</i>(3).
<div class="Pp"></div>
Users expect some tools (like <i>virt-cat</i>(1)) to work with VM paths:
<div class="Pp"></div>
<pre>
 virt-cat fedora.img /var/log/messages
</pre>
<div class="Pp"></div>
How does virt-cat know that <i>/var</i> is a separate partition? The trick is
  that virt-cat performs inspection on the disk image, and uses that to
  translate the path correctly.
<div class="Pp"></div>
Some tools (including <i>virt-cat</i>(1), <i>virt-edit</i>(1),
  <i>virt-ls</i>(1)) use inspection to map VM paths. Other tools, such as
  <i>virt-df</i>(1) and <i>virt-filesystems</i>(1) operate entirely at the raw
  &quot;big pile of filesystems&quot; level of the libguestfs API, and don't use
  inspection.
<div class="Pp"></div>
<i>guestfish</i>(1) is in an interesting middle ground. If you use the <i>-a</i>
  and <i>-m</i> command line options, then you have to tell guestfish exactly
  how to add disk images and where to mount partitions. This is the raw API
  level.
<div class="Pp"></div>
If you use the <i>-i</i> option, libguestfs performs inspection and mounts the
  filesystems for you.
<div class="Pp"></div>
The error &quot;no root device found in this operating system image&quot; is
  related to this. It means inspection was unable to locate an operating system
  within the disk image you gave it. You might see this from programs like
  virt-cat if you try to run them on something which is just a disk image, not a
  virtual machine disk image.
<h2 class="Ss" title="Ss" id="What_do_these_&quot;debug*&quot;_and_&quot;internal-*&quot;_functions_do?"><a class="selflink" href="#What_do_these_&quot;debug*&quot;_and_&quot;internal-*&quot;_functions_do?">What
  do these &quot;debug*&quot; and &quot;internal-*&quot; functions do?</a></h2>
There are some functions which are used for debugging and internal purposes
  which are <i>not</i> part of the stable API.
<div class="Pp"></div>
The &quot;debug*&quot; (or &quot;guestfs_debug*&quot;) functions, primarily
  &quot;guestfs_debug&quot; in <i>guestfs</i>(3) and a handful of others, are
  used for debugging libguestfs. Although they are not part of the stable API
  and thus may change or be removed at any time, some programs may want to call
  these while waiting for features to be added to libguestfs.
<div class="Pp"></div>
The &quot;internal-*&quot; (or &quot;guestfs_internal_*&quot;) functions are
  purely to be used by libguestfs itself. There is no reason for programs to
  call them, and programs should not try to use them. Using them will often
  cause bad things to happen, as well as not being part of the documented stable
  API.
<h1 class="Sh" title="Sh" id="DEVELOPERS"><a class="selflink" href="#DEVELOPERS">DEVELOPERS</a></h1>
<h2 class="Ss" title="Ss" id="Where_do_I_send_patches?"><a class="selflink" href="#Where_do_I_send_patches?">Where
  do I send patches?</a></h2>
Please send patches to the libguestfs mailing list
  https://www.redhat.com/mailman/listinfo/libguestfs. You don't have to be
  subscribed, but there will be a delay until your posting is manually approved.
<div class="Pp"></div>
<b>Please don't use github pull requests - they will be ignored</b>. The reasons
  are (a) we want to discuss and dissect patches on the mailing list, and (b)
  github pull requests turn into merge commits but we prefer to have a linear
  history.
<h2 class="Ss" title="Ss" id="How_do_I_propose_a_feature?"><a class="selflink" href="#How_do_I_propose_a_feature?">How
  do I propose a feature?</a></h2>
Large new features that you intend to contribute should be discussed on the
  mailing list first (https://www.redhat.com/mailman/listinfo/libguestfs). This
  avoids disappointment and wasted work if we don't think the feature would fit
  into the libguestfs project.
<div class="Pp"></div>
If you want to suggest a useful feature but don't want to write the code, you
  can file a bug (see &quot;GETTING HELP AND REPORTING BUGS&quot;) with
  &quot;RFE: &quot; at the beginning of the Summary line.
<h2 class="Ss" title="Ss" id="Who_can_commit_to_libguestfs_git?"><a class="selflink" href="#Who_can_commit_to_libguestfs_git?">Who
  can commit to libguestfs git?</a></h2>
About 5 people have commit access to github. Patches should be posted on the
  list first and ACKed. The policy for ACKing and pushing patches is outlined
  here:
<div class="Pp"></div>
https://www.redhat.com/archives/libguestfs/2012-January/msg00023.html
<h2 class="Ss" title="Ss" id="Can_I_fork_libguestfs?"><a class="selflink" href="#Can_I_fork_libguestfs?">Can
  I fork libguestfs?</a></h2>
Of course you can. Git makes it easy to fork libguestfs. Github makes it even
  easier. It's nice if you tell us on the mailing list about forks and the
  reasons for them.
<h1 class="Sh" title="Sh" id="MISCELLANEOUS_QUESTIONS"><a class="selflink" href="#MISCELLANEOUS_QUESTIONS">MISCELLANEOUS
  QUESTIONS</a></h1>
<h2 class="Ss" title="Ss" id="Can_I_monitor_the_live_disk_activity_of_a_virtual_machine_using_libguestfs?"><a class="selflink" href="#Can_I_monitor_the_live_disk_activity_of_a_virtual_machine_using_libguestfs?">Can
  I monitor the live disk activity of a virtual machine using
  libguestfs?</a></h2>
A common request is to be able to use libguestfs to monitor the live disk
  activity of a guest, for example, to get notified every time a guest creates a
  new file. Libguestfs does <i>not</i> work in the way some people imagine, as
  you can see from this diagram:
<div class="Pp"></div>
<pre>
            &#x250C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2510;
            &#x2502; monitoring program using libguestfs &#x2502;
            &#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;
                             &#x2193;
 &#x250C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2510;    &#x250C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2510;
 &#x2502; live VM   &#x2502;    &#x2502; libguestfs appliance &#x2502;
 &#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;    &#x251C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2524;
 &#x2502; kernel (1)&#x2502;    &#x2502; appliance kernel (2) &#x2502;
 &#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;    &#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;
      &#x2193;                      &#x2193; (r/o connection)
      &#x250C;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2510;
      |      disk image      |
      &#x2514;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2500;&#x2518;
</pre>
<div class="Pp"></div>
This scenario is safe (as long as you set the &quot;readonly&quot; flag when
  adding the drive). However the libguestfs appliance kernel (2) does not see
  all the changes made to the disk image, for two reasons:
<dl class="Bl-tag">
  <dt class="It-tag">i.</dt>
  <dd class="It-tag">The VM kernel (1) can cache data in memory, so it doesn't
      appear in the disk image.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">ii.</dt>
  <dd class="It-tag">The libguestfs appliance kernel (2) doesn't expect that the
      disk image is changing underneath it, so its own cache is not magically
      updated even when the VM kernel (1) does update the disk image.</dd>
</dl>
<div class="Pp"></div>
The only supported solution is to restart the entire libguestfs appliance
  whenever you want to look at changes in the disk image. At the API level that
  corresponds to calling &quot;guestfs_shutdown&quot; followed by
  &quot;guestfs_launch&quot;, which is a heavyweight operation (see also
  <i>guestfs-performance</i>(3)).
<div class="Pp"></div>
There are some unsupported hacks you can try if relaunching the appliance is
  really too costly:
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">Call &quot;guestfs_drop_caches (g, 3)&quot;. This causes
      all cached data help by the libguestfs appliance kernel (2) to be
      discarded, so it goes back to the disk image.
    <div style="height: 1.00em;">&#x00A0;</div>
    However this on its own is not sufficient, because qemu also caches some
      data. You will also need to patch libguestfs to (re-)enable the
      &quot;cache=none&quot; mode. See:
      https://rwmj.wordpress.com/2013/09/02/new-in-libguestfs-allow-cache-mode-to-be-selected/</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">Use a tool like virt-bmap instead.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">Run an agent inside the guest.</dd>
</dl>
<div class="Pp"></div>
Nothing helps if the guest is making more fundamental changes (eg. deleting
  filesystems). For those kinds of things you must relaunch the appliance.
<div class="Pp"></div>
(Note there is a third problem that you need to use consistent snapshots to
  really examine live disk images, but that's a general problem with using
  libguestfs against any live disk image.)
<h1 class="Sh" title="Sh" id="SEE_ALSO"><a class="selflink" href="#SEE_ALSO">SEE
  ALSO</a></h1>
<i>guestfish</i>(1), <i>guestfs</i>(3), http://libguestfs.org/.
<h1 class="Sh" title="Sh" id="AUTHORS"><a class="selflink" href="#AUTHORS">AUTHORS</a></h1>
Richard W.M. Jones (&quot;rjones at redhat dot com&quot;)
<h1 class="Sh" title="Sh" id="COPYRIGHT"><a class="selflink" href="#COPYRIGHT">COPYRIGHT</a></h1>
Copyright (C) 2012-2016 Red Hat Inc.
<h1 class="Sh" title="Sh" id="LICENSE"><a class="selflink" href="#LICENSE">LICENSE</a></h1>
This library is free software; you can redistribute it and/or modify it under
  the terms of the GNU Lesser General Public License as published by the Free
  Software Foundation; either version 2 of the License, or (at your option) any
  later version.
<div class="Pp"></div>
This library is distributed in the hope that it will be useful, but WITHOUT ANY
  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR
  A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more
  details.
<div class="Pp"></div>
You should have received a copy of the GNU Lesser General Public License along
  with this library; if not, write to the Free Software Foundation, Inc., 51
  Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
<h1 class="Sh" title="Sh" id="BUGS"><a class="selflink" href="#BUGS">BUGS</a></h1>
To get a list of bugs against libguestfs, use this link:
  https://bugzilla.redhat.com/buglist.cgi?component=libguestfs&amp;product=Virtualization+Tools
<div class="Pp"></div>
To report a new bug against libguestfs, use this link:
  https://bugzilla.redhat.com/enter_bug.cgi?component=libguestfs&amp;product=Virtualization+Tools
<div class="Pp"></div>
When reporting a bug, please supply:
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">The version of libguestfs.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">Where you got libguestfs (eg. which Linux distro, compiled
      from source, etc)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">Describe the bug accurately and give a way to reproduce
    it.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag">&#x2022;</dt>
  <dd class="It-tag">Run <i>libguestfs-test-tool</i>(1) and paste the
      <b>complete, unedited</b> output into the bug report.</dd>
</dl>
</div>
<table class="foot">
  <tr>
    <td class="foot-date">2016-08-08</td>
    <td class="foot-os">libguestfs-1.32.7</td>
  </tr>
</table>
</body>
</html>
