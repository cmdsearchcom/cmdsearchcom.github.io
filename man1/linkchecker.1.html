<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 16:21:57 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>LINKCHECKER(1) LinkChecker commandline usage
LINKCHECKER(1)</p>

<p style="margin-top: 1em">NAME <br>
linkchecker - command line client to check HTML documents
and websites for broken links</p>

<p style="margin-top: 1em">SYNOPSIS <br>
linkchecker [options] [file-or-url]...</p>

<p style="margin-top: 1em">DESCRIPTION <br>
LinkChecker features</p>

<p style="margin-top: 1em">&Acirc;&middot; recursive and
multithreaded checking,</p>

<p style="margin-top: 1em">&Acirc;&middot; output in
colored or normal text, HTML, SQL, CSV, XML or a sitemap
graph in different formats,</p>

<p style="margin-top: 1em">&Acirc;&middot; support for
HTTP/1.1, HTTPS, FTP, mailto:, news:, nntp:, Telnet and
local file links,</p>

<p style="margin-top: 1em">&Acirc;&middot; restriction of
link checking with URL filters,</p>

<p style="margin-top: 1em">&Acirc;&middot; proxy
support,</p>

<p style="margin-top: 1em">&Acirc;&middot;
username/password authorization for HTTP, FTP and
Telnet,</p>

<p style="margin-top: 1em">&Acirc;&middot; support for
robots.txt exclusion protocol,</p>

<p style="margin-top: 1em">&Acirc;&middot; support for
Cookies</p>

<p style="margin-top: 1em">&Acirc;&middot; support for
HTML5</p>

<p style="margin-top: 1em">&Acirc;&middot; HTML and CSS
syntax check</p>

<p style="margin-top: 1em">&Acirc;&middot; Antivirus
check</p>

<p style="margin-top: 1em">&Acirc;&middot; a command line,
GUI and web interface</p>

<p style="margin-top: 1em">EXAMPLES <br>
The most common use checks the given domain recursively:
<br>
linkchecker http://www.example.com/ <br>
Beware that this checks the whole site which can have
thousands of URLs. Use the -r option to restrict the
recursion depth. <br>
Don&rsquo;t check URLs with /secret in its name. All other
links are checked as usual: <br>
linkchecker --ignore-url=/secret mysite.example.com <br>
Checking a local HTML file on Unix: <br>
linkchecker ../bla.html <br>
Checking a local HTML file on Windows: <br>
linkchecker c:empest.html <br>
You can skip the http:// url part if the domain starts with
www.: <br>
linkchecker www.example.com <br>
You can skip the ftp:// url part if the domain starts with
ftp.: <br>
linkchecker -r0 ftp.example.com <br>
Generate a sitemap graph and convert it with the graphviz
dot utility: <br>
linkchecker -odot -v www.example.com | dot -Tps &gt;
sitemap.ps</p>

<p style="margin-top: 1em">OPTIONS <br>
General options <br>
-fFILENAME, --config=FILENAME <br>
Use FILENAME as configuration file. As default LinkChecker
uses ~/.linkchecker/linkcheckerrc.</p>

<p style="margin-top: 1em">-h, --help <br>
Help me! Print usage information for this program.</p>

<p style="margin-top: 1em">--stdin <br>
Read list of white-space separated URLs to check from
stdin.</p>

<p style="margin-top: 1em">-tNUMBER, --threads=NUMBER <br>
Generate no more than the given number of threads. Default
number of threads is 100. To disable threading specify a
non-positive number.</p>

<p style="margin-top: 1em">-V, --version <br>
Print version and exit.</p>

<p style="margin-top: 1em">--list-plugins <br>
Print available check plugins and exit.</p>

<p style="margin-top: 1em">Output options <br>
-DSTRING, --debug=STRING <br>
Print debugging output for the given logger. Available
loggers are cmdline, checking, cache, gui, dns and all.
Specifying all is an alias for specifying all available <br>
loggers. The option can be given multiple times to debug
with more than one logger. For accurate results, threading
will be disabled during debug runs.</p>

<p style="margin-top: 1em">-FTYPE[/ENCODING][/FILENAME],
--file-output=TYPE[/ENCODING][/FILENAME] <br>
Output to a file linkchecker-out.TYPE,
$HOME/.linkchecker/blacklist for blacklist output, or
FILENAME if specified. The ENCODING specifies the output
encoding, the <br>
default is that of your locale. Valid encodings are listed
at
http://docs.python.org/library/codecs.html#standard-encodings.
<br>
The FILENAME and ENCODING parts of the none output type will
be ignored, else if the file already exists, it will be
overwritten. You can specify this option more than <br>
once. Valid file output types are text, html, sql, csv, gml,
dot, xml, sitemap, none or blacklist. Default is no file
output. The various output types are documented <br>
below. Note that you can suppress all console output with
the option -o none.</p>

<p style="margin-top: 1em">--no-status <br>
Do not print check status messages.</p>

<p style="margin-top: 1em">--no-warnings <br>
Don&rsquo;t log warnings. Default is to log warnings.</p>

<p style="margin-top: 1em">-oTYPE[/ENCODING],
--output=TYPE[/ENCODING] <br>
Specify output type as text, html, sql, csv, gml, dot, xml,
sitemap, none or blacklist. Default type is text. The
various output types are documented below. <br>
The ENCODING specifies the output encoding, the default is
that of your locale. Valid encodings are listed at
http://docs.python.org/library/codecs.html#standard-encod&acirc;
<br>
ings.</p>

<p style="margin-top: 1em">-q, --quiet <br>
Quiet operation, an alias for -o none. This is only useful
with -F.</p>

<p style="margin-top: 1em">-v, --verbose <br>
Log all checked URLs. Default is to log only errors and
warnings.</p>

<p style="margin-top: 1em">-WREGEX, --warning-regex=REGEX
<br>
Define a regular expression which prints a warning if it
matches any content of the checked link. This applies only
to valid pages, so we can get their content. <br>
Use this to check for pages that contain some form of error,
for example &quot;This page has moved&quot; or &quot;Oracle
Application error&quot;. <br>
Note that multiple values can be combined in the regular
expression, for example &quot;(This page has moved|Oracle
Application error)&quot;. <br>
See section REGULAR EXPRESSIONS for more info.</p>

<p style="margin-top: 1em">Checking options <br>
--cookiefile=FILENAME <br>
Read a file with initial cookie data. The cookie data format
is explained below.</p>

<p style="margin-top: 1em">--check-extern <br>
Check external URLs.</p>

<p style="margin-top: 1em">--ignore-url=REGEX <br>
URLs matching the given regular expression will be ignored
and not checked. <br>
This option can be given multiple times. <br>
See section REGULAR EXPRESSIONS for more info.</p>

<p style="margin-top: 1em">-NSTRING, --nntp-server=STRING
<br>
Specify an NNTP server for news: links. Default is the
environment variable NNTP_SERVER. If no host is given, only
the syntax of the link is checked.</p>

<p style="margin-top: 1em">--no-follow-url=REGEX <br>
Check but do not recurse into URLs matching the given
regular expression. <br>
This option can be given multiple times. <br>
See section REGULAR EXPRESSIONS for more info.</p>

<p style="margin-top: 1em">-p, --password <br>
Read a password from console and use it for HTTP and FTP
authorization. For FTP the default password is anonymous@.
For HTTP there is no default password. See also -u.</p>

<p style="margin-top: 1em">-rNUMBER,
--recursion-level=NUMBER <br>
Check recursively all links up to given depth. A negative
depth will enable infinite recursion. Default depth is
infinite.</p>

<p style="margin-top: 1em">--timeout=NUMBER <br>
Set the timeout for connection attempts in seconds. The
default timeout is 60 seconds.</p>

<p style="margin-top: 1em">-uSTRING, --user=STRING <br>
Try the given username for HTTP and FTP authorization. For
FTP the default username is anonymous. For HTTP there is no
default username. See also -p.</p>

<p style="margin-top: 1em">--user-agent=STRING <br>
Specify the User-Agent string to send to the HTTP server,
for example &quot;Mozilla/4.0&quot;. The default is
&quot;LinkChecker/X.Y&quot; where X.Y is the current version
of LinkChecker.</p>

<p style="margin-top: 1em">CONFIGURATION FILES <br>
Configuration files can specify all options above. They can
also specify some options that cannot be set on the command
line. See linkcheckerrc(5) for more info.</p>

<p style="margin-top: 1em">OUTPUT TYPES <br>
Note that by default only errors and warnings are logged.
You should use the --verbose option to get the complete URL
list, especially when outputting a sitemap graph format.</p>

<p style="margin-top: 1em">text Standard text logger,
logging URLs in keyword: argument fashion.</p>

<p style="margin-top: 1em">html Log URLs in keyword:
argument fashion, formatted as HTML. Additionally has links
to the referenced pages. Invalid URLs have HTML and CSS
syntax check links appended.</p>

<p style="margin-top: 1em">csv Log check result in CSV
format with one URL per line.</p>

<p style="margin-top: 1em">gml Log parent-child relations
between linked URLs as a GML sitemap graph.</p>

<p style="margin-top: 1em">dot Log parent-child relations
between linked URLs as a DOT sitemap graph.</p>

<p style="margin-top: 1em">gxml Log check result as a
GraphXML sitemap graph.</p>

<p style="margin-top: 1em">xml Log check result as
machine-readable XML.</p>

<p style="margin-top: 1em">sitemap <br>
Log check result as an XML sitemap whose protocol is
documented at http://www.sitemaps.org/protocol.html.</p>

<p style="margin-top: 1em">sql Log check result as SQL
script with INSERT commands. An example script to create the
initial SQL table is included as create.sql.</p>

<p style="margin-top: 1em">blacklist <br>
Suitable for cron jobs. Logs the check result into a file
~/.linkchecker/blacklist which only contains entries with
invalid URLs and the number of times they have failed.</p>

<p style="margin-top: 1em">none Logs nothing. Suitable for
debugging or checking the exit code.</p>

<p style="margin-top: 1em">REGULAR EXPRESSIONS <br>
LinkChecker accepts Python regular expressions. See
http://docs.python.org/howto/regex.html for an
introduction.</p>

<p style="margin-top: 1em">An addition is that a leading
exclamation mark negates the regular expression.</p>

<p style="margin-top: 1em">COOKIE FILES <br>
A cookie file contains standard HTTP header (RFC 2616) data
with the following possible names:</p>

<p style="margin-top: 1em">Host (required) <br>
Sets the domain the cookies are valid for.</p>

<p style="margin-top: 1em">Path (optional) <br>
Gives the path the cookies are value for; default path is
/.</p>

<p style="margin-top: 1em">Set-cookie (required) <br>
Set cookie name/value. Can be given more than once.</p>

<p style="margin-top: 1em">Multiple entries are separated
by a blank line. The example below will send two cookies to
all URLs starting with http://example.com/hello/ and one to
all URLs starting with <br>
https://example.org/:</p>

<p style="margin-top: 1em">Host: example.com <br>
Path: /hello <br>
Set-cookie: ID=&quot;smee&quot; <br>
Set-cookie: spam=&quot;egg&quot;</p>

<p style="margin-top: 1em">Host: example.org <br>
Set-cookie: baggage=&quot;elitist&quot;;
comment=&quot;hologram&quot;</p>

<p style="margin-top: 1em">PROXY SUPPORT <br>
To use a proxy on Unix or Windows set the $http_proxy,
$https_proxy or $ftp_proxy environment variables to the
proxy URL. The URL should be of the form <br>
http://[user:pass@]host[:port]. LinkChecker also detects
manual proxy settings of Internet Explorer under Windows
systems, and gconf or KDE on Linux systems. On a Mac use the
<br>
Internet Config to select a proxy. You can also set a
comma-separated domain list in the $no_proxy environment
variables to ignore any proxy settings for these domains.
Setting <br>
a HTTP proxy on Unix for example looks like this:</p>

<p style="margin-top: 1em">export
http_proxy=&quot;http://proxy.example.com:8080&quot;</p>

<p style="margin-top: 1em">Proxy authentication is also
supported:</p>

<p style="margin-top: 1em">export
http_proxy=&quot;http://user1:mypass@proxy.example.org:8081&quot;</p>

<p style="margin-top: 1em">Setting a proxy on the Windows
command prompt:</p>

<p style="margin-top: 1em">set
http_proxy=http://proxy.example.com:8080</p>

<p style="margin-top: 1em">PERFORMED CHECKS <br>
All URLs have to pass a preliminary syntax test. Minor
quoting mistakes will issue a warning, all other invalid
syntax issues are errors. After the syntax check passes, the
URL <br>
is queued for connection checking. All connection check
types are described below.</p>

<p style="margin-top: 1em">HTTP links (http:, https:) <br>
After connecting to the given HTTP server the given path or
query is requested. All redirections are followed, and if
user/password is given it will be used as authoriza&acirc;
<br>
tion when necessary. All final HTTP status codes other than
2xx are errors. HTML page contents are checked for
recursion.</p>

<p style="margin-top: 1em">Local files (file:) <br>
A regular, readable file that can be opened is valid. A
readable directory is also valid. All other files, for
example device files, unreadable or non-existing files are
<br>
errors. HTML or other parseable file contents are checked
for recursion.</p>

<p style="margin-top: 1em">Mail links (mailto:) <br>
A mailto: link eventually resolves to a list of email
addresses. If one address fails, the whole list will fail.
For each mail address we check the following things: <br>
1) Check the adress syntax, both of the part before and
after <br>
the @ sign. <br>
2) Look up the MX DNS records. If we found no MX record,
<br>
print an error. <br>
3) Check if one of the mail hosts accept an SMTP connection.
<br>
Check hosts with higher priority first. <br>
If no host accepts SMTP, we print a warning. <br>
4) Try to verify the address with the VRFY command. If we
got <br>
an answer, print the verified address as an info.</p>

<p style="margin-top: 1em">FTP links (ftp:)</p>

<p style="margin-top: 1em">For FTP links we do:</p>

<p style="margin-top: 1em">1) connect to the specified host
<br>
2) try to login with the given user and password. The
default <br>
user is &lsquo;&lsquo;anonymous&lsquo;&lsquo;, the default
password is &lsquo;&lsquo;anonymous@&lsquo;&lsquo;. <br>
3) try to change to the given directory <br>
4) list the file with the NLST command</p>

<p style="margin-top: 1em">Telnet links
(&lsquo;&lsquo;telnet:&lsquo;&lsquo;)</p>

<p style="margin-top: 1em">We try to connect and if
user/password are given, login to the <br>
given telnet server.</p>

<p style="margin-top: 1em">NNTP links
(&lsquo;&lsquo;news:&lsquo;&lsquo;,
&lsquo;&lsquo;snews:&lsquo;&lsquo;,
&lsquo;&lsquo;nntp&lsquo;&lsquo;)</p>

<p style="margin-top: 1em">We try to connect to the given
NNTP server. If a news group or <br>
article is specified, try to request it from the server.</p>

<p style="margin-top: 1em">Unsupported links
(&lsquo;&lsquo;javascript:&lsquo;&lsquo;, etc.)</p>

<p style="margin-top: 1em">An unsupported link will only
print a warning. No further checking <br>
will be made.</p>

<p style="margin-top: 1em">The complete list of recognized,
but unsupported links can be found <br>
in the linkcheck/checker/unknownurl.py source file. <br>
The most prominent of them should be JavaScript links.</p>

<p style="margin-top: 1em">PLUGINS <br>
There are two plugin types: connection and content plugins.
Connection plugins are run after a successful connection to
the URL host. Content plugins are run if the URL type <br>
has content (mailto: URLs have no content for example) and
if the check is not forbidden (ie. by HTTP robots.txt). See
linkchecker --list-plugins for a list of plugins and their
<br>
documentation. All plugins are enabled via the
linkcheckerrc(5) configuration file.</p>

<p style="margin-top: 1em">RECURSION <br>
Before descending recursively into a URL, it has to fulfill
several conditions. They are checked in this order:</p>

<p style="margin-top: 1em">1. A URL must be valid.</p>

<p style="margin-top: 1em">2. A URL must be parseable. This
currently includes HTML files, <br>
Opera bookmarks files, and directories. If a file type
cannot <br>
be determined (for example it does not have a common HTML
file <br>
extension, and the content does not look like HTML), it is
assumed <br>
to be non-parseable.</p>

<p style="margin-top: 1em">3. The URL content must be
retrievable. This is usually the case <br>
except for example mailto: or unknown URL types.</p>

<p style="margin-top: 1em">4. The maximum recursion level
must not be exceeded. It is configured <br>
with the --recursion-level option and is unlimited per
default.</p>

<p style="margin-top: 1em">5. It must not match the ignored
URL list. This is controlled with <br>
the --ignore-url option.</p>

<p style="margin-top: 1em">6. The Robots Exclusion Protocol
must allow links in the URL to be <br>
followed recursively. This is checked by searching for a
<br>
&quot;nofollow&quot; directive in the HTML header data.</p>

<p style="margin-top: 1em">Note that the directory
recursion reads all files in that directory, not just a
subset like index.htm*.</p>

<p style="margin-top: 1em">NOTES <br>
URLs on the commandline starting with ftp. are treated like
ftp://ftp., URLs starting with www. are treated like
http://www.. You can also give local files as arguments.</p>

<p style="margin-top: 1em">If you have your system
configured to automatically establish a connection to the
internet (e.g. with diald), it will connect when checking
links not pointing to your local host. <br>
Use the --ignore-url option to prevent this.</p>

<p style="margin-top: 1em">Javascript links are not
supported.</p>

<p style="margin-top: 1em">If your platform does not
support threading, LinkChecker disables it
automatically.</p>

<p style="margin-top: 1em">You can supply multiple
user/password pairs in a configuration file.</p>

<p style="margin-top: 1em">When checking news: links the
given NNTP host doesn&rsquo;t need to be the same as the
host of the user browsing your pages.</p>

<p style="margin-top: 1em">ENVIRONMENT <br>
NNTP_SERVER - specifies default NNTP server <br>
http_proxy - specifies default HTTP proxy server <br>
ftp_proxy - specifies default FTP proxy server <br>
no_proxy - comma-separated list of domains to not contact
over a proxy server <br>
LC_MESSAGES, LANG, LANGUAGE - specify output language</p>

<p style="margin-top: 1em">RETURN VALUE <br>
The return value is 2 when</p>

<p style="margin-top: 1em">&Acirc;&middot; a program error
occurred.</p>

<p style="margin-top: 1em">The return value is 1 when</p>

<p style="margin-top: 1em">&Acirc;&middot; invalid links
were found or</p>

<p style="margin-top: 1em">&Acirc;&middot; link warnings
were found and warnings are enabled</p>

<p style="margin-top: 1em">Else the return value is
zero.</p>

<p style="margin-top: 1em">LIMITATIONS <br>
LinkChecker consumes memory for each queued URL to check.
With thousands of queued URLs the amount of consumed memory
can become quite large. This might slow down the program or
<br>
even the whole system.</p>

<p style="margin-top: 1em">FILES <br>
~/.linkchecker/linkcheckerrc - default configuration file
<br>
~/.linkchecker/blacklist - default blacklist logger output
filename <br>
linkchecker-out.TYPE - default logger file output name <br>

http://docs.python.org/library/codecs.html#standard-encodings
- valid output encodings <br>
http://docs.python.org/howto/regex.html - regular expression
documentation</p>

<p style="margin-top: 1em">SEE ALSO <br>
linkcheckerrc(5)</p>

<p style="margin-top: 1em">AUTHOR <br>
Bastian Kleineidam &lt;bastian.kleineidam@web.de&gt;</p>

<p style="margin-top: 1em">COPYRIGHT <br>
Copyright &Acirc;&copy; 2000-2014 Bastian Kleineidam</p>

<p style="margin-top: 1em">LinkChecker 2010-07-01
LINKCHECKER(1)</p>
<hr>
</body>
</html>
