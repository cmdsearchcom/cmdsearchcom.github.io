<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 16:26:56 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>NCCOPY(1) UNIDATA UTILITIES NCCOPY(1)</p>

<p style="margin-top: 1em">NAME <br>
nccopy - Copy a netCDF file, optionally changing format,
compression, or chunking in the output.</p>

<p style="margin-top: 1em">SYNOPSIS <br>
nccopy [-k kind_name ] [-kind_code] [-d n ] [-s] [-c
chunkspec ] [-u] [-w] [-[v|V] var1,...] [-[g|G] grp1,...]
[-m bufsize ] [-h chunk_cache ] [-e cache_elems ] [-r] <br>
infile outfile</p>

<p style="margin-top: 1em">DESCRIPTION <br>
The nccopy utility copies an input netCDF file in any
supported format variant to an output netCDF file,
optionally converting the output to any compatible netCDF
format variant, <br>
compressing the data, or rechunking the data. For example,
if built with the netCDF-3 library, a netCDF classic file
may be copied to a netCDF 64-bit offset file, permitting
<br>
larger variables. If built with the netCDF-4 library, a
netCDF classic file may be copied to a netCDF-4 file or to a
netCDF-4 classic model file as well, permitting data
com&acirc; <br>
pression, efficient schema changes, larger variable sizes,
and use of other netCDF-4 features.</p>

<p style="margin-top: 1em">If no output format is
specified, with either -k kind_name or -kind_code, then the
output will use the same format as the input, unless the
input is classic or 64-bit offset and <br>
either chunking or compression is specified, in which case
the output will be netCDF-4 classic model format. Attempting
some kinds of format conversion will result in an error,
<br>
if the conversion is not possible. For example, an attempt
to copy a netCDF-4 file that uses features of the enhanced
model, such as groups or variable-length strings, to any of
<br>
the other kinds of netCDF formats that use the classic model
will result in an error.</p>

<p style="margin-top: 1em">nccopy also serves as an example
of a generic netCDF-4 program, with its ability to read any
valid netCDF file and handle nested groups, strings, and
user-defined types, includ&acirc; <br>
ing arbitrarily nested compound types, variable-length
types, and data of any valid netCDF-4 type.</p>

<p style="margin-top: 1em">If DAP support was enabled when
nccopy was built, the file name may specify a DAP URL. This
may be used to convert data on DAP servers to local netCDF
files.</p>

<p style="margin-top: 1em">OPTIONS <br>
-k kind_name <br>
Use format name to specify the kind of file to be created
and, by inference, the data model (i.e. netcdf-3 (classic)
or netcdf-4 (enhanced)). The possible arguments are:</p>

<p style="margin-top: 1em">&rsquo;nc3&rsquo; or
&rsquo;classic&rsquo; =&gt; netCDF classic format</p>

<p style="margin-top: 1em">&rsquo;nc6&rsquo; or
&rsquo;64-bit offset&rsquo; =&gt; netCDF 64-bit format</p>

<p style="margin-top: 1em">&rsquo;nc4&rsquo; or
&rsquo;netCDF-4&rsquo; =&gt; netCDF-4 format (enhanced data
model)</p>

<p style="margin-top: 1em">&rsquo;nc7&rsquo; or
&rsquo;netCDF-4 classic model&rsquo; =&gt; netCDF-4 classic
model format</p>

<p style="margin-top: 1em">Note: The old format numbers
&rsquo;1&rsquo;, &rsquo;2&rsquo;, &rsquo;3&rsquo;,
&rsquo;4&rsquo;, equivalent to the format names
&rsquo;nc3&rsquo;, &rsquo;nc6&rsquo;, &rsquo;nc4&rsquo;, or
&rsquo;nc7&rsquo; respectively, are also still accepted but
deprecated, due to <br>
easy confusion between format numbers and format names.</p>

<p style="margin-top: 1em">[-kind_code] <br>
Use format numeric code (instead of format name) to specify
the kind of file to be created and, by inference, the data
model (i.e. netcdf-3 (classic) versus netcdf-4 (en&acirc;
<br>
hanced)). The numeric codes are:</p>

<p style="margin-top: 1em">3 =&gt; netcdf classic
format</p>

<p style="margin-top: 1em">6 =&gt; netCDF 64-bit format</p>

<p style="margin-top: 1em">4 =&gt; netCDF-4 format
(enhanced data model)</p>

<p style="margin-top: 1em">7 =&gt; netCDF-4 classic model
format <br>
The numeric code &quot;7&quot; is used because
&quot;7=3+4&quot;, specifying the format that uses the
netCDF-3 data model for compatibility with the netCDF-4
storage format for performance. Credit <br>
is due to NCO for use of these numeric codes instead of the
old and confusing format numbers.</p>

<p style="margin-top: 1em">-d n <br>
For netCDF-4 output, including netCDF-4 classic model,
specify deflation level (level of compression) for variable
data output. 0 corresponds to no compression and 9 to <br>
maximum compression, with higher levels of compression
requiring marginally more time to compress or uncompress
than lower levels. Compression achieved may also depend on
<br>
output chunking parameters. If this option is specified for
a classic format or 64-bit offset format input file, it is
not necessary to also specify that the output <br>
should be netCDF-4 classic model, as that will be the
default. If this option is not specified and the input file
has compressed variables, the compression will still be <br>
preserved in the output, using the same chunking as in the
input by default.</p>

<p style="margin-top: 1em">Note that nccopy requires all
variables to be compressed using the same compression level,
but the API has no such restriction. With a program you can
customize compres&acirc; <br>
sion for each variable independently.</p>

<p style="margin-top: 1em">-s For netCDF-4 output,
including netCDF-4 classic model, specify shuffling of
variable data bytes before compression or after
decompression. Shuffling refers to interlacing <br>
of bytes in a chunk so that the first bytes of all values
are contiguous in storage, followed by all the second bytes,
and so on, which often improves compression. This <br>
option is ignored unless a non-zero deflation level is
specified. Using -d0 to specify no deflation on input data
that has been compressed and shuffled turns off both <br>
compression and shuffling in the output.</p>

<p style="margin-top: 1em">-u Convert any unlimited size
dimensions in the input to fixed size dimensions in the
output. This can speed up variable-at-a-time access, but
slow down record-at-a-time ac&acirc; <br>
cess to multiple variables along an unlimited dimension.</p>

<p style="margin-top: 1em">-w Keep output in memory (as a
diskless netCDF file) until output is closed, at which time
output file is written to disk. This can greatly speedup
operations such as con&acirc; <br>
verting unlimited dimension to fixed size (-u option),
chunking, rechunking, or compressing the input. It requires
that available memory is large enough to hold the out&acirc;
<br>
put file. This option may provide a larger speedup than
careful tuning of the -m, -h, or -e options, and it&rsquo;s
certainly a lot simpler.</p>

<p style="margin-top: 1em">-c chunkspec <br>
For netCDF-4 output, including netCDF-4 classic model,
specify chunking (multidimensional tiling) for variable data
in the output. This is useful to specify the units of <br>
disk access, compression, or other filters such as
checksums. Changing the chunking in a netCDF file can also
greatly speedup access, by choosing chunk shapes that are
<br>
appropriate for the most common access patterns.</p>

<p style="margin-top: 1em">The chunkspec argument is a
string of comma-separated associations, each specifying a
dimension name, a &rsquo;/&rsquo; character, and optionally
the corresponding chunk length for <br>
that dimension. No blanks should appear in the chunkspec
string, except possibly escaped blanks that are part of a
dimension name. A chunkspec names at least one dimen&acirc;
<br>
sion, and may omit dimensions which are not to be chunked or
for which the default chunk length is desired. If a
dimension name is followed by a &rsquo;/&rsquo; character
but no sub&acirc; <br>
sequent chunk length, the actual dimension length is
assumed. If copying a classic model file to a netCDF-4
output file and not naming all dimensions in the chunkspec,
<br>
unnamed dimensions will also use the actual dimension length
for the chunk length. An example of a chunkspec for
variables that use &rsquo;m&rsquo; and &rsquo;n&rsquo;
dimensions might be <br>
&rsquo;m/100,n/200&rsquo; to specify 100 by 200 chunks. To
see the chunking resulting from copying with a chunkspec,
use the &rsquo;-s&rsquo; option of ncdump on the output
file.</p>

<p style="margin-top: 1em">The chunkspec &rsquo;/&rsquo;
that omits all dimension names and corresponding chunk
lengths specifies that no chunking is to occur in the
output, so can be used to unchunk all the <br>
chunked variables. To see the chunking resulting from
copying with a chunkspec, use the &rsquo;-s&rsquo; option of
ncdump on the output file.</p>

<p style="margin-top: 1em">As an I/O optimization, nccopy
has a threshold for the minimum size of non-record variables
that get chunked, currently 8192 bytes. In the future, use
of this threshold <br>
and its size may be settable in an option.</p>

<p style="margin-top: 1em">Note that nccopy requires
variables that share a dimension to also share the chunk
size associated with that dimension, but the programming
interface has no such restric&acirc; <br>
tion. If you need to customize chunking for variables
independently, you will need to use the library API in a
custom utility program.</p>

<p style="margin-top: 1em">-v var1,... <br>
The output will include data values for the specified
variables, in addition to the declarations of all
dimensions, variables, and attributes. One or more variables
must <br>
be specified by name in the comma-delimited list following
this option. The list must be a single argument to the
command, hence cannot contain unescaped blanks or other <br>
white space characters. The named variables must be valid
netCDF variables in the input-file. A variable within a
group in a netCDF-4 file may be specified with an
abso&acirc; <br>
lute path name, such as &quot;/GroupA/GroupA2/var&quot;. Use
of a relative path name such as &rsquo;var&rsquo; or
&quot;grp/var&quot; specifies all matching variable names in
the file. The default, <br>
without this option, is to include data values for all
variables in the output.</p>

<p style="margin-top: 1em">-V var1,... <br>
The output will include the specified variables only but all
dimensions and global or group attributes. One or more
variables must be specified by name in the
comma-delim&acirc; <br>
ited list following this option. The list must be a single
argument to the command, hence cannot contain unescaped
blanks or other white space characters. The named
vari&acirc; <br>
ables must be valid netCDF variables in the input-file. A
variable within a group in a netCDF-4 file may be specified
with an absolute path name, such as <br>
&rsquo;/GroupA/GroupA2/var&rsquo;. Use of a relative path
name such as &rsquo;var&rsquo; or &rsquo;grp/var&rsquo;
specifies all matching variable names in the file. The
default, without this option, is to <br>
include all variables in the output.</p>

<p style="margin-top: 1em">-g grp1,... <br>
The output will include data values only for the specified
groups. One or more groups must be specified by name in the
comma-delimited list following this option. The <br>
list must be a single argument to the command. The named
groups must be valid netCDF groups in the input-file. The
default, without this option, is to include data values <br>
for all groups in the output.</p>

<p style="margin-top: 1em">-G grp1,... <br>
The output will include only the specified groups. One or
more groups must be specified by name in the comma-delimited
list following this option. The list must be a sin&acirc;
<br>
gle argument to the command. The named groups must be valid
netCDF groups in the input-file. The default, without this
option, is to include all groups in the output.</p>

<p style="margin-top: 1em">-m bufsize <br>
An integer or floating-point number that specifies the size,
in bytes, of the copy buffer used to copy large variables. A
suffix of K, M, G, or T multiplies the copy buf&acirc; <br>
fer size by one thousand, million, billion, or trillion,
respectively. The default is 5 Mbytes, but will be increased
if necessary to hold at least one chunk of netCDF-4 <br>
chunked variables in the input file. You may want to specify
a value larger than the default for copying large files over
high latency networks. Using the &rsquo;-w&rsquo; option
<br>
may provide better performance, if the output fits in
memory.</p>

<p style="margin-top: 1em">-h chunk_cache <br>
For netCDF-4 output, including netCDF-4 classic model, an
integer or floating-point number that specifies the size in
bytes of chunk cache allocated for each chunked vari&acirc;
<br>
able. This is not a property of the file, but merely a
performance tuning parameter for avoiding compressing or
decompressing the same data multiple times while copying
<br>
and changing chunk shapes. A suffix of K, M, G, or T
multiplies the chunk cache size by one thousand, million,
billion, or trillion, respectively. The default is <br>
4.194304 Mbytes (or whatever was specified for the
configure-time constant CHUNK_CACHE_SIZE when the netCDF
library was built). Ideally, the nccopy utility should
accept <br>
only one memory buffer size and divide it optimally between
a copy buffer and chunk cache, but no general algorithm for
computing the optimum chunk cache size has been im&acirc;
<br>
plemented yet. Using the &rsquo;-w&rsquo; option may provide
better performance, if the output fits in memory.</p>

<p style="margin-top: 1em">-e cache_elems <br>
For netCDF-4 output, including netCDF-4 classic model,
specifies number of chunks that the chunk cache can hold. A
suffix of K, M, G, or T multiplies the number of chunks <br>
that can be held in the cache by one thousand, million,
billion, or trillion, respectively. This is not a property
of the file, but merely a performance tuning parameter <br>
for avoiding compressing or decompressing the same data
multiple times while copying and changing chunk shapes. The
default is 1009 (or whatever was specified for the <br>
configure-time constant CHUNK_CACHE_NELEMS when the netCDF
library was built). Ideally, the nccopy utility should
determine an optimum value for this parameter, but no <br>
general algorithm for computing the optimum number of chunk
cache elements has been implemented yet.</p>

<p style="margin-top: 1em">-r Read netCDF classic or 64-bit
offset input file into a diskless netCDF file in memory
before copying. Requires that input file be small enough to
fit into memory. For <br>
nccopy, this doesn&rsquo;t seem to provide any significant
speedup, so may not be a useful option.</p>

<p style="margin-top: 1em">EXAMPLES <br>
Make a copy of foo1.nc, a netCDF file of any type, to
foo2.nc, a netCDF file of the same type:</p>

<p style="margin-top: 1em">nccopy foo1.nc foo2.nc</p>

<p style="margin-top: 1em">Note that the above copy will
not be as fast as use of cp or other simple copy utility,
because the file is copied using only the netCDF API. If the
input file has extra bytes <br>
after the end of the netCDF data, those will not be copied,
because they are not accessible through the netCDF
interface. If the original file was generated in &quot;No
fill&quot; mode so <br>
that fill values are not stored for padding for data
alignment, the output file may have different padding
bytes.</p>

<p style="margin-top: 1em">Convert a netCDF-4 classic model
file, compressed.nc, that uses compression, to a netCDF-3
file classic.nc:</p>

<p style="margin-top: 1em">nccopy -k classic compressed.nc
classic.nc</p>

<p style="margin-top: 1em">Note that &rsquo;nc3&rsquo;
could be used instead of &rsquo;classic&rsquo;.</p>

<p style="margin-top: 1em">Download the variable
&rsquo;time_bnds&rsquo; and its associated attributes from
an OPeNDAP server and copy the result to a netCDF file named
&rsquo;tb.nc&rsquo;:</p>

<p style="margin-top: 1em">nccopy
&rsquo;http://test.opendap.org/opendap/data/nc/sst.mnmean.nc.gz?time_bnds&rsquo;
tb.nc</p>

<p style="margin-top: 1em">Note that URLs that name
specific variables as command-line arguments should
generally be quoted, to avoid the shell interpreting special
characters such as &rsquo;?&rsquo;.</p>

<p style="margin-top: 1em">Compress all the variables in
the input file foo.nc, a netCDF file of any type, to the
output file bar.nc:</p>

<p style="margin-top: 1em">nccopy -d1 foo.nc bar.nc</p>

<p style="margin-top: 1em">If foo.nc was a classic or
64-bit offset netCDF file, bar.nc will be a netCDF-4 classic
model netCDF file, because the classic and 64-bit offset
format variants don&rsquo;t support <br>
compression. If foo.nc was a netCDF-4 file with some
variables compressed using various deflation levels, the
output will also be a netCDF-4 file of the same type, but
all the <br>
variables, including any uncompressed variables in the
input, will now use deflation level 1.</p>

<p style="margin-top: 1em">Assume the input data includes
gridded variables that use time, lat, lon dimensions, with
1000 times by 1000 latitudes by 1000 longitudes, and that
the time dimension varies most <br>
slowly. Also assume that users want quick access to data at
all times for a small set of lat-lon points. Accessing data
for 1000 times would typically require accessing 1000 <br>
disk blocks, which may be slow.</p>

<p style="margin-top: 1em">Reorganizing the data into
chunks on disk that have all the time in each chunk for a
few lat and lon coordinates would greatly speed up such
access. To chunk the data in the in&acirc; <br>
put file slow.nc, a netCDF file of any type, to the output
file fast.nc, you could use;</p>

<p style="margin-top: 1em">nccopy -c
time/1000,lat/40,lon/40 slow.nc fast.nc</p>

<p style="margin-top: 1em">to specify data chunks of 1000
times, 40 latitudes, and 40 longitudes. If you had enough
memory to contain the output file, you could speed up the
rechunking operation signifi&acirc; <br>
cantly by creating the output in memory before writing it to
disk on close:</p>

<p style="margin-top: 1em">nccopy -w -c
time/1000,lat/40,lon/40 slow.nc fast.nc</p>

<p style="margin-top: 1em">SEE ALSO <br>
ncdump(1),ncgen(1),netcdf(3)</p>

<p style="margin-top: 1em">Release 4.2 2012-03-08
NCCOPY(1)</p>
<hr>
</body>
</html>
