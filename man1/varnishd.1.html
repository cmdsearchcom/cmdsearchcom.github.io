<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 16:41:58 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>VARNISHD(1) VARNISHD(1)</p>

<p style="margin-top: 1em">NAME <br>
varnishd - HTTP accelerator daemon</p>

<p style="margin-top: 1em">SYNOPSIS <br>
varnishd [-a address[:port][,PROTO]] [-b host[:port]] [-C]
[-d] [-F] [-f config] [-h type[,options]] [-I clifile] [-i
identity] [-j jail[,jailoptions]] [-l vsl[,vsm]] [-M <br>
address:port] [-n name] [-P file] [-p param=value] [-r
param[,param...]] [-S secret-file] [-s
[name=]kind[,options]] [-T address[:port]] [-t TTL] [-V] [-W
waiter] [-x parame&acirc; <br>
ter|vsl|cli|builtin] [-?]</p>

<p style="margin-top: 1em">DESCRIPTION <br>
The varnishd daemon accepts HTTP requests from clients,
passes them on to a backend server and caches the returned
documents to better satisfy future requests for the same
docu&acirc; <br>
ment.</p>

<p style="margin-top: 1em">OPTIONS <br>
Basic options <br>
-a &lt;address[:port][,PROTO]&gt; <br>
Listen for client requests on the specified address and
port. The address can be a host name
(&quot;localhost&quot;), an IPv4 dotted-quad
(&quot;127.0.0.1&quot;), or an IPv6 address enclosed <br>
in square brackets (&quot;[::1]&quot;). If address is not
specified, varnishd will listen on all available IPv4 and
IPv6 interfaces. If port is not specified, port 80 (http) is
<br>
used. An additional protocol type can be set for the
listening socket with PROTO. Valid protocol types are:
HTTP/1 (default), and PROXY. Multiple listening addresses
<br>
can be specified by using multiple -a arguments.</p>

<p style="margin-top: 1em">-b &lt;host[:port]&gt; <br>
Use the specified host as backend server. If port is not
specified, the default is 8080. -b can be used only once,
and not together with -f.</p>

<p style="margin-top: 1em">-f config <br>
Use the specified VCL configuration file instead of the
builtin default. See vcl(7) for details on VCL syntax.</p>

<p style="margin-top: 1em">If a single -f option is used,
then the VCL instance loaded from the file is named
&quot;boot&quot; and immediately becomes active. If more
than one -f option is used, the VCL <br>
instances are named &quot;boot0&quot;, &quot;boot1&quot; and
so forth, in the order corresponding to the -f arguments,
and the last one is named &quot;boot&quot;, which becomes
active.</p>

<p style="margin-top: 1em">Either -b or one or more -f
options must be specified, but not both, and they cannot
both be left out, unless -d is used to start varnishd in
debugging mode. If the empty <br>
string is specified as the sole -f option, then varnishd
starts without starting the worker process, and the
management process will accept CLI commands. You can also
<br>
combine an empty -f option with an initialization script (-I
option) and the child process will be started if there is an
active VCL at the end of the initialization.</p>

<p style="margin-top: 1em">-n name <br>
Specify the name for this instance. Amongst other things,
this name is used to construct the name of the directory in
which varnishd keeps temporary files and persistent <br>
state. If the specified name begins with a forward slash, it
is interpreted as the absolute path to the directory which
should be used for this purpose.</p>

<p style="margin-top: 1em">Documentation options <br>
For these options, varnishd prints information to standard
output and exits. When a -x option is used, it must be the
only option (it outputs documentation in reStructuredText,
<br>
aka RST).</p>

<p style="margin-top: 1em">-? <br>
Print the usage message.</p>

<p style="margin-top: 1em">-x parameter <br>
Print documentation of the runtime parameters (-p options),
see List of Parameters.</p>

<p style="margin-top: 1em">-x vsl Print documentation of
the tags used in the Varnish shared memory log, see
vsl(7).</p>

<p style="margin-top: 1em">-x cli Print documentation of
the command line interface, see varnish-cli(7).</p>

<p style="margin-top: 1em">-x builtin <br>
Print the contents of the default VCL program
builtin.vcl.</p>

<p style="margin-top: 1em">Operations options <br>
-F Do not fork, run in the foreground. Only one of -F or -d
can be specified, and -F cannot be used together with
-C.</p>

<p style="margin-top: 1em">-T &lt;address[:port]&gt; <br>
Offer a management interface on the specified address and
port. See varnish-cli(7) for documentation of the management
commands. To disable the management interface use <br>
none.</p>

<p style="margin-top: 1em">-M &lt;address:port&gt; <br>
Connect to this port and offer the command line interface.
Think of it as a reverse shell. When running with -M and
there is no backend defined the child process (the <br>
cache) will not start initially.</p>

<p style="margin-top: 1em">-P file <br>
Write the PID of the process to the specified file.</p>

<p style="margin-top: 1em">-i identity <br>
Specify the identity of the Varnish server. This can be
accessed using server.identity from VCL.</p>

<p style="margin-top: 1em">-I clifile <br>
Execute the management commands in the file given as clifile
before the the worker process starts, see CLI Command
File.</p>

<p style="margin-top: 1em">Tuning options <br>
-t TTL Specifies the default time to live (TTL) for cached
objects. This is a shortcut for specifying the default_ttl
run-time parameter.</p>

<p style="margin-top: 1em">-p &lt;param=value&gt; <br>
Set the parameter specified by param to the specified value,
see List of Parameters for details. This option can be used
multiple times to specify multiple parameters.</p>

<p style="margin-top: 1em">-s &lt;[name=]type[,options]&gt;
<br>
Use the specified storage backend. See Storage Backend
section.</p>

<p style="margin-top: 1em">This option can be used multiple
times to specify multiple storage files. Names are
referenced in logs, VCL, statistics, etc.</p>

<p style="margin-top: 1em">-l &lt;vsl[,vsm]&gt; <br>
Specifies size of shmlog file. vsl is the space for the VSL
records [80M] and vsm is the space for stats counters [1M].
Scaling suffixes like &rsquo;K&rsquo; and &rsquo;M&rsquo;
can be used up to <br>
(G)igabytes. Default is 81 Megabytes.</p>

<p style="margin-top: 1em">Security options <br>
-r &lt;param[,param...]&gt; <br>
Make the listed parameters read only. This gives the system
administrator a way to limit what the Varnish CLI can do.
Consider making parameters such as cc_command, <br>
vcc_allow_inline_c and vmod_path read only as these can
potentially be used to escalate privileges from the CLI.</p>

<p style="margin-top: 1em">-S secret-file <br>
Path to a file containing a secret used for authorizing
access to the management port. If not provided a new secret
will be drawn from the system PRNG. To disable authen&acirc;
<br>
tication use none.</p>

<p style="margin-top: 1em">-j &lt;jail[,jailoptions]&gt;
<br>
Specify the jailing mechanism to use. See Jail section.</p>

<p style="margin-top: 1em">Advanced, development and
debugging options <br>
-d Enables debugging mode: The parent process runs in the
foreground with a CLI connection on stdin/stdout, and the
child process must be started explicitly with a CLI
com&acirc; <br>
mand. Terminating the parent process will also terminate the
child.</p>

<p style="margin-top: 1em">Only one of -d or -F can be
specified, and -d cannot be used together with -C.</p>

<p style="margin-top: 1em">-C Print VCL code compiled to C
language and exit. Specify the VCL file to compile with the
-f option. Either -f or -b must be used with -C, and -C
cannot be used with -F or <br>
-d.</p>

<p style="margin-top: 1em">-V Display the version number
and exit. This must be the only option.</p>

<p style="margin-top: 1em">-h &lt;type[,options]&gt; <br>
Specifies the hash algorithm. See Hash Algorithm section for
a list of supported algorithms.</p>

<p style="margin-top: 1em">-W waiter <br>
Specifies the waiter type to use.</p>

<p style="margin-top: 1em">Hash Algorithm <br>
The following hash algorithms are available:</p>

<p style="margin-top: 1em">-h critbit <br>
self-scaling tree structure. The default hash algorithm in
Varnish Cache 2.1 and onwards. In comparison to a more
traditional B tree the critbit tree is almost completely
<br>
lockless. Do not change this unless you are certain what
you&rsquo;re doing.</p>

<p style="margin-top: 1em">-h simple_list <br>
A simple doubly-linked list. Not recommended for production
use.</p>

<p style="margin-top: 1em">-h &lt;classic[,buckets]&gt;
<br>
A standard hash table. The hash key is the CRC32 of the
object&rsquo;s URL modulo the size of the hash table. Each
table entry points to a list of elements which share the
same <br>
hash key. The buckets parameter specifies the number of
entries in the hash table. The default is 16383.</p>

<p style="margin-top: 1em">Storage Backend <br>
The following storage types are available:</p>

<p style="margin-top: 1em">-s &lt;malloc[,size]&gt; <br>
malloc is a memory based backend.</p>

<p style="margin-top: 1em">-s
&lt;file,path[,size[,granularity[,advice]]]&gt; <br>
The file backend stores data in a file on disk. The file
will be accessed using mmap.</p>

<p style="margin-top: 1em">The path is mandatory. If path
points to a directory, a temporary file will be created in
that directory and immediately unlinked. If path points to a
non-existing file, <br>
the file will be created.</p>

<p style="margin-top: 1em">If size is omitted, and path
points to an existing file with a size greater than zero,
the size of that file will be used. If not, an error is
reported.</p>

<p style="margin-top: 1em">Granularity sets the allocation
block size. Defaults to the system page size or the
filesystem block size, whichever is larger.</p>

<p style="margin-top: 1em">Advice tells the kernel how
varnishd expects to use this mapped region so that the
kernel can choose the appropriate read-ahead and caching
techniques. Possible values are <br>
normal, random and sequencial, corresponding to MADV_NORMAL,
MADV_RANDOM and MADV_SEQUENTIAL madvise() advice argument,
respectively. Defaults to random.</p>

<p style="margin-top: 1em">-s &lt;persistent,path,size&gt;
<br>
Persistent storage. Varnish will store objects in a file in
a manner that will secure the survival of most of the
objects in the event of a planned or unplanned shutdown <br>
of Varnish. The persistent storage backend has multiple
issues with it and will likely be removed from a future
version of Varnish.</p>

<p style="margin-top: 1em">Jail <br>
Varnish jails are a generalization over various platform
specific methods to reduce the privileges of varnish
processes. They may have specific options. Available jails
are:</p>

<p style="margin-top: 1em">-j solaris <br>
Reduce privileges(5) for varnishd and sub-process to the
minimally required set. Only available on platforms which
have the setppriv(2) call.</p>

<p style="margin-top: 1em">-j
&lt;unix[,user=&lsquo;user&lsquo;][,ccgroup=&lsquo;group&lsquo;][,workuser=&lsquo;user&lsquo;]&gt;
<br>
Default on all other platforms when varnishd is either
started with an effective uid of 0 (&quot;as root&quot;) or
as user varnish.</p>

<p style="margin-top: 1em">With the unix jail mechanism
activated, varnish will switch to an alternative user for
subprocesses and change the effective uid of the master
process whenever possible.</p>

<p style="margin-top: 1em">The optional user argument
specifies which alternative user to use. It defaults to
varnish.</p>

<p style="margin-top: 1em">The optional ccgroup argument
specifies a group to add to varnish subprocesses requiring
access to a c-compiler. There is no default.</p>

<p style="margin-top: 1em">The optional workuser argument
specifies an alternative user to use for the worker process.
It defaults to vcache.</p>

<p style="margin-top: 1em">-j none <br>
last resort jail choice: With jail mechanism none, varnish
will run all processes with the privileges it was started
with.</p>

<p style="margin-top: 1em">Management Interface <br>
If the -T option was specified, varnishd will offer a
command-line management interface on the specified address
and port. The recommended way of connecting to the
command-line <br>
management interface is through varnishadm(1).</p>

<p style="margin-top: 1em">The commands available are
documented in varnish-cli(7).</p>

<p style="margin-top: 1em">CLI Command File <br>
The -I option makes it possible to run arbitrary management
commands when varnishd is launched, before the worker
process is started. In particular, this is the way to load
con&acirc; <br>
figurations, apply labels to them, and make a VCL instance
active that uses those labels on startup:</p>

<p style="margin-top: 1em">vcl.load panic
/etc/varnish_panic.vcl <br>
vcl.load siteA0 /etc/varnish_siteA.vcl <br>
vcl.load siteB0 /etc/varnish_siteB.vcl <br>
vcl.load siteC0 /etc/varnish_siteC.vcl <br>
vcl.label siteA siteA0 <br>
vcl.label siteB siteB0 <br>
vcl.label siteC siteC0 <br>
vcl.load main /etc/varnish_main.vcl <br>
vcl.use main</p>

<p style="margin-top: 1em">If a command in the file is
prefixed with &rsquo;-&rsquo;, failure will not abort the
startup.</p>

<p style="margin-top: 1em">RUN TIME PARAMETERS <br>
Run Time Parameter Flags <br>
Runtime parameters are marked with shorthand flags to avoid
repeating the same text over and over in the table below.
The meaning of the flags are:</p>

<p style="margin-top: 1em">&Acirc;&middot; experimental</p>

<p style="margin-top: 1em">We have no solid information
about good/bad/optimal values for this parameter. Feedback
with experience and observations are most welcome.</p>

<p style="margin-top: 1em">&Acirc;&middot; delayed</p>

<p style="margin-top: 1em">This parameter can be changed on
the fly, but will not take effect immediately.</p>

<p style="margin-top: 1em">&Acirc;&middot; restart</p>

<p style="margin-top: 1em">The worker process must be
stopped and restarted, before this parameter takes
effect.</p>

<p style="margin-top: 1em">&Acirc;&middot; reload</p>

<p style="margin-top: 1em">The VCL programs must be
reloaded for this parameter to take effect.</p>

<p style="margin-top: 1em">&Acirc;&middot; experimental</p>

<p style="margin-top: 1em">We&rsquo;re not really sure
about this parameter, tell us what you find.</p>

<p style="margin-top: 1em">&Acirc;&middot; wizard</p>

<p style="margin-top: 1em">Do not touch unless you really
know what you&rsquo;re doing.</p>

<p style="margin-top: 1em">&Acirc;&middot; only_root</p>

<p style="margin-top: 1em">Only works if varnishd is
running as root.</p>

<p style="margin-top: 1em">Default Value Exceptions on 32
bit Systems <br>
Be aware that on 32 bit systems, certain default values are
reduced relative to the values listed below, in order to
conserve VM space:</p>

<p style="margin-top: 1em">&Acirc;&middot;
workspace_client: 16k</p>

<p style="margin-top: 1em">&Acirc;&middot; http_resp_size:
8k</p>

<p style="margin-top: 1em">&Acirc;&middot; http_req_size:
12k</p>

<p style="margin-top: 1em">&Acirc;&middot;
gzip_stack_buffer: 4k</p>

<p style="margin-top: 1em">&Acirc;&middot;
thread_pool_stack: 64k</p>

<p style="margin-top: 1em">List of Parameters <br>
This text is produced from the same text you will find in
the CLI if you use the param.show command:</p>

<p style="margin-top: 1em">accept_filter <br>
NB: This parameter depends on a feature which is not
available on all platforms.</p>

<p style="margin-top: 1em">&Acirc;&middot; Units: bool</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: off</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:</p>

<p style="margin-top: 1em">Enable kernel
accept-filters.</p>

<p style="margin-top: 1em">acceptor_sleep_decay <br>
&Acirc;&middot; Default: 0.9</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 0</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum: 1</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">If we run out of resources, such
as file descriptors or worker threads, the acceptor will
sleep between accepts. This parameter (multiplicatively)
reduce the sleep duration for <br>
each successful accept. (ie: 0.9 = reduce by 10%)</p>

<p style="margin-top: 1em">acceptor_sleep_incr <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum:
1.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">If we run out of resources, such
as file descriptors or worker threads, the acceptor will
sleep between accepts. This parameter control how much
longer we sleep, each time we <br>
fail to accept a new connection.</p>

<p style="margin-top: 1em">acceptor_sleep_max <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
0.050</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum:
10.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">If we run out of resources, such
as file descriptors or worker threads, the acceptor will
sleep between accepts. This parameter limits how long it can
sleep between attempts to <br>
accept new connections.</p>

<p style="margin-top: 1em">auto_restart <br>
&Acirc;&middot; Units: bool</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: on</p>

<p style="margin-top: 1em">Automatically restart the
child/worker process if it dies.</p>

<p style="margin-top: 1em">backend_idle_timeout <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
60.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
1.000</p>

<p style="margin-top: 1em">Timeout before we close unused
backend connections.</p>

<p style="margin-top: 1em">ban_cutoff <br>
&Acirc;&middot; Units: bans</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 0</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 0</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">Expurge long tail content from
the cache to keep the number of bans below this value. 0
disables. This is a safety net to avoid bad response times
due to bans being tested at <br>
lookup time. Setting a cutoff trades response time for cache
efficiency. The recommended value is proportional to
rate(bans_lurker_tests_tested) / n_objects while the ban
lurker <br>
is working, which is the number of bans the system can
sustain. The additional latency due to request ban testing
is in the order of ban_cutoff /
rate(bans_lurker_tests_tested). <br>
For example, for rate(bans_lurker_tests_tested) = 2M/s and a
tolerable latency of 100ms, a good value for ban_cutoff may
be 200K.</p>

<p style="margin-top: 1em">ban_dups <br>
&Acirc;&middot; Units: bool</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: on</p>

<p style="margin-top: 1em">Eliminate older identical bans
when a new ban is added. This saves CPU cycles by not
comparing objects to identical bans. This is a waste of time
if you have many bans which <br>
are never identical.</p>

<p style="margin-top: 1em">ban_lurker_age <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
60.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">The ban lurker will ignore bans
until they are this old. When a ban is added, the active
traffic will be tested against it as part of object lookup.
Because many applications <br>
issue bans in bursts, this parameter holds the ban-lurker
off until the rush is over. This should be set to the
approximate time which a ban-burst takes.</p>

<p style="margin-top: 1em">ban_lurker_batch <br>
&Acirc;&middot; Default: 1000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 1</p>

<p style="margin-top: 1em">The ban lurker sleeps
${ban_lurker_sleep} after examining this many objects. Use
this to pace the ban-lurker if it eats too many
resources.</p>

<p style="margin-top: 1em">ban_lurker_holdoff <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
0.010</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">How long the ban lurker sleeps
when giving way to lookup due to lock contention.</p>

<p style="margin-top: 1em">ban_lurker_sleep <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
0.010</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">How long the ban lurker sleeps
after examining ${ban_lurker_batch} objects. Use this to
pace the ban-lurker if it eats too many resources. A value
of zero will disable the ban <br>
lurker entirely.</p>

<p style="margin-top: 1em">between_bytes_timeout <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
60.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">We only wait for this many
seconds between bytes received from the backend before
giving up the fetch. A value of zero means never give up.
VCL values, per backend or per back&acirc; <br>
end request take precedence. This parameter does not apply
to pipe&rsquo;ed requests.</p>

<p style="margin-top: 1em">cc_command <br>
&Acirc;&middot; Default: exec clang -g -O2 -Wall -Werror
-Wno-error=unused-result t-Werror t-Wall t-Wno-format-y2k
t-W t-Wstrict-prototypes t-Wmissing-prototypes
t-Wpointer-arith t-Wre&acirc; <br>
turn-type t-Wcast-qual t-Wwrite-strings t-Wswitch t-Wshadow
t-Wunused-parameter t-Wcast-align t-Wchar-subscripts
t-Wnested-externs t-Wextra t-Wno-sign-compare
-fstack-pro&acirc; <br>
tector -Wno-pointer-sign -Wno-address
-Wno-missing-field-initializers -pthread -fpic -shared
-Wl,-x -o %o %s</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
must_reload</p>

<p style="margin-top: 1em">Command used for compiling the C
source code to a dlopen(3) loadable object. Any occurrence
of %s in the string will be replaced with the source file
name, and %o will be <br>
replaced with the output file name.</p>

<p style="margin-top: 1em">cli_buffer <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 8k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 4k</p>

<p style="margin-top: 1em">Size of buffer for CLI command
input. You may need to increase this if you have big VCL
files and use the vcl.inline CLI command. NB: Must be
specified with -p to have effect.</p>

<p style="margin-top: 1em">cli_limit <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 48k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
128b</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum:
99999999b</p>

<p style="margin-top: 1em">Maximum size of CLI response. If
the response exceeds this limit, the response code will be
201 instead of 200 and the last line will indicate the
truncation.</p>

<p style="margin-top: 1em">cli_timeout <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
60.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">Timeout for the childs replies
to CLI requests from the mgt_param.</p>

<p style="margin-top: 1em">clock_skew <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 10</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 0</p>

<p style="margin-top: 1em">How much clockskew we are
willing to accept between the backend and our own clock.</p>

<p style="margin-top: 1em">clock_step <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
1.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">How much observed clock step we
are willing to accept before we panic.</p>

<p style="margin-top: 1em">connect_timeout <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
3.500</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">Default connection timeout for
backend connections. We only try to connect to the backend
for this many seconds before giving up. VCL can override
this default value for each <br>
backend and backend request.</p>

<p style="margin-top: 1em">critbit_cooloff <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
180.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
60.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum:
254.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
wizard</p>

<p style="margin-top: 1em">How long the critbit hasher
keeps deleted objheads on the cooloff list.</p>

<p style="margin-top: 1em">debug <br>
&Acirc;&middot; Default: none</p>

<p style="margin-top: 1em">Enable/Disable various kinds of
debugging.</p>

<p style="margin-top: 1em">none Disable all debugging</p>

<p style="margin-top: 1em">Use +/- prefix to set/reset
individual bits:</p>

<p style="margin-top: 1em">req_state <br>
VSL Request state engine</p>

<p style="margin-top: 1em">workspace <br>
VSL Workspace operations</p>

<p style="margin-top: 1em">waiter VSL Waiter internals</p>

<p style="margin-top: 1em">waitinglist <br>
VSL Waitinglist events</p>

<p style="margin-top: 1em">syncvsl <br>
Make VSL synchronous</p>

<p style="margin-top: 1em">hashedge <br>
Edge cases in Hash</p>

<p style="margin-top: 1em">vclrel Rapid VCL release</p>

<p style="margin-top: 1em">lurker VSL Ban lurker</p>

<p style="margin-top: 1em">esi_chop <br>
Chop ESI fetch to bits</p>

<p style="margin-top: 1em">flush_head <br>
Flush after http1 head</p>

<p style="margin-top: 1em">vtc_mode <br>
Varnishtest Mode</p>

<p style="margin-top: 1em">witness <br>
Emit WITNESS lock records</p>

<p style="margin-top: 1em">vsm_keep <br>
Keep the VSM file on restart</p>

<p style="margin-top: 1em">drop_pools <br>
Drop thread pools (testing)</p>

<p style="margin-top: 1em">slow_acceptor <br>
Slow down Acceptor</p>

<p style="margin-top: 1em">h2_nocheck <br>
Disable various H2 checks</p>

<p style="margin-top: 1em">default_grace <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
10.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
obj_sticky</p>

<p style="margin-top: 1em">Default grace period. We will
deliver an object this long after it has expired, provided
another thread is attempting to get a new copy.</p>

<p style="margin-top: 1em">default_keep <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
obj_sticky</p>

<p style="margin-top: 1em">Default keep period. We will
keep a useless object around this long, making it available
for conditional backend fetches. That means that the object
will be removed from the <br>
cache at the end of ttl+grace+keep.</p>

<p style="margin-top: 1em">default_ttl <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
120.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
obj_sticky</p>

<p style="margin-top: 1em">The TTL assigned to objects if
neither the backend nor the VCL code assigns one.</p>

<p style="margin-top: 1em">feature <br>
&Acirc;&middot; Default: none</p>

<p style="margin-top: 1em">Enable/Disable various minor
features.</p>

<p style="margin-top: 1em">none Disable all features.</p>

<p style="margin-top: 1em">Use +/- prefix to enable/disable
individual feature:</p>

<p style="margin-top: 1em">short_panic <br>
Short panic message.</p>

<p style="margin-top: 1em">wait_silo <br>
Wait for persistent silo.</p>

<p style="margin-top: 1em">no_coredump <br>
No coredumps.</p>

<p style="margin-top: 1em">esi_ignore_https <br>
Treat HTTPS as HTTP in ESI:includes</p>

<p style="margin-top: 1em">esi_disable_xml_check <br>
Don&rsquo;t check of body looks like XML</p>

<p style="margin-top: 1em">esi_ignore_other_elements <br>
Ignore non-esi XML-elements</p>

<p style="margin-top: 1em">esi_remove_bom <br>
Remove UTF-8 BOM</p>

<p style="margin-top: 1em">https_scheme <br>
Also split https URIs</p>

<p style="margin-top: 1em">http2 Support HTTP/2
protocol</p>

<p style="margin-top: 1em">fetch_chunksize <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 16k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 4k</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">The default chunksize used by
fetcher. This should be bigger than the majority of objects
with short TTLs. Internal limits in the storage_file module
makes increases above 128kb <br>
a dubious idea.</p>

<p style="margin-top: 1em">fetch_maxchunksize <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
0.25G</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 64k</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">The maximum chunksize we attempt
to allocate from storage. Making this too large may cause
delays and storage fragmentation.</p>

<p style="margin-top: 1em">first_byte_timeout <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
60.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">Default timeout for receiving
first byte from backend. We only wait for this many seconds
for the first byte before giving up. A value of 0 means it
will never time out. VCL can <br>
override this default value for each backend and backend
request. This parameter does not apply to pipe.</p>

<p style="margin-top: 1em">gzip_buffer <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 32k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 2k</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">Size of malloc buffer used for
gzip processing. These buffers are used for in-transit data,
for instance gunzip&rsquo;ed data being sent to a
client.Making this space to small results <br>
in more overhead, writes to sockets etc, making it too big
is probably just a waste of memory.</p>

<p style="margin-top: 1em">gzip_level <br>
&Acirc;&middot; Default: 6</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 0</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum: 9</p>

<p style="margin-top: 1em">Gzip compression level: 0=debug,
1=fast, 9=best</p>

<p style="margin-top: 1em">gzip_memlevel <br>
&Acirc;&middot; Default: 8</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 1</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum: 9</p>

<p style="margin-top: 1em">Gzip memory level 1=slow/least,
9=fast/most compression. Memory impact is 1=1k, 2=2k, ...
9=256k.</p>

<p style="margin-top: 1em">h2_rx_window_increment <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 1M</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 1M</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum: 1G</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
wizard</p>

<p style="margin-top: 1em">HTTP2 Receive Window Increments.
How big credits we send in WINDOW_UPDATE frames Only affects
incoming request bodies (ie: POST, PUT etc.)</p>

<p style="margin-top: 1em">h2_rx_window_low_water <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 10M</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
65535b</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum: 1G</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
wizard</p>

<p style="margin-top: 1em">HTTP2 Receive Window low water
mark. We try to keep the window at least this big Only
affects incoming request bodies (ie: POST, PUT etc.)</p>

<p style="margin-top: 1em">http_gzip_support <br>
&Acirc;&middot; Units: bool</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: on</p>

<p style="margin-top: 1em">Enable gzip support. When
enabled Varnish request compressed objects from the backend
and store them compressed. If a client does not support gzip
encoding Varnish will uncom&acirc; <br>
press compressed objects on demand. Varnish will also
rewrite the Accept-Encoding header of clients indicating
support for gzip to: <br>
Accept-Encoding: gzip</p>

<p style="margin-top: 1em">Clients that do not support gzip
will have their Accept-Encoding header removed. For more
information on how gzip is implemented please see the
chapter on gzip in the Varnish <br>
reference.</p>

<p style="margin-top: 1em">http_max_hdr <br>
&Acirc;&middot; Units: header lines</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 64</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 32</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum:
65535</p>

<p style="margin-top: 1em">Maximum number of HTTP header
lines we allow in {req|resp|bereq|beresp}.http (obj.http is
autosized to the exact number of headers). Cheap, ~20 bytes,
in terms of workspace mem&acirc; <br>
ory. Note that the first line occupies five header
lines.</p>

<p style="margin-top: 1em">http_range_support <br>
&Acirc;&middot; Units: bool</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: on</p>

<p style="margin-top: 1em">Enable support for HTTP Range
headers.</p>

<p style="margin-top: 1em">http_req_hdr_len <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 8k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 40b</p>

<p style="margin-top: 1em">Maximum length of any HTTP
client request header we will allow. The limit is inclusive
its continuation lines.</p>

<p style="margin-top: 1em">http_req_size <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 32k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.25k</p>

<p style="margin-top: 1em">Maximum number of bytes of HTTP
client request we will deal with. This is a limit on all
bytes up to the double blank line which ends the HTTP
request. The memory for the <br>
request is allocated from the client workspace (param:
workspace_client) and this parameter limits how much of that
the request is allowed to take up.</p>

<p style="margin-top: 1em">http_resp_hdr_len <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 8k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 40b</p>

<p style="margin-top: 1em">Maximum length of any HTTP
backend response header we will allow. The limit is
inclusive its continuation lines.</p>

<p style="margin-top: 1em">http_resp_size <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 32k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.25k</p>

<p style="margin-top: 1em">Maximum number of bytes of HTTP
backend response we will deal with. This is a limit on all
bytes up to the double blank line which ends the HTTP
request. The memory for the <br>
request is allocated from the backend workspace (param:
workspace_backend) and this parameter limits how much of
that the request is allowed to take up.</p>

<p style="margin-top: 1em">idle_send_timeout <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
60.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
delayed</p>

<p style="margin-top: 1em">Time to wait with no data sent.
If no data has been transmitted in this many seconds the
session is closed. See setsockopt(2) under SO_SNDTIMEO for
more information.</p>

<p style="margin-top: 1em">listen_depth <br>
&Acirc;&middot; Units: connections</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
1024</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 0</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
must_restart</p>

<p style="margin-top: 1em">Listen queue depth.</p>

<p style="margin-top: 1em">lru_interval <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
2.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">Grace period before object moves
on LRU list. Objects are only moved to the front of the LRU
list if they have not been moved there already inside this
timeout period. This <br>
reduces the amount of lock operations necessary for LRU list
access.</p>

<p style="margin-top: 1em">max_esi_depth <br>
&Acirc;&middot; Units: levels</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 5</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 0</p>

<p style="margin-top: 1em">Maximum depth of esi:include
processing.</p>

<p style="margin-top: 1em">max_restarts <br>
&Acirc;&middot; Units: restarts</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 4</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 0</p>

<p style="margin-top: 1em">Upper limit on how many times a
request can restart. Be aware that restarts are likely to
cause a hit against the backend, so don&rsquo;t increase
thoughtlessly.</p>

<p style="margin-top: 1em">max_retries <br>
&Acirc;&middot; Units: retries</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 4</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 0</p>

<p style="margin-top: 1em">Upper limit on how many times a
backend fetch can retry.</p>

<p style="margin-top: 1em">nuke_limit <br>
&Acirc;&middot; Units: allocations</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 50</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 0</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">Maximum number of objects we
attempt to nuke in order to make space for a object
body.</p>

<p style="margin-top: 1em">pcre_match_limit <br>
&Acirc;&middot; Default: 10000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 1</p>

<p style="margin-top: 1em">The limit for the number of
calls to the internal match() function in pcre_exec().</p>

<p style="margin-top: 1em">(See: PCRE_EXTRA_MATCH_LIMIT in
pcre docs.)</p>

<p style="margin-top: 1em">This parameter limits how much
CPU time regular expression matching can soak up.</p>

<p style="margin-top: 1em">pcre_match_limit_recursion <br>
&Acirc;&middot; Default: 20</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 1</p>

<p style="margin-top: 1em">The recursion depth-limit for
the internal match() function in a pcre_exec().</p>

<p style="margin-top: 1em">(See:
PCRE_EXTRA_MATCH_LIMIT_RECURSION in pcre docs.)</p>

<p style="margin-top: 1em">This puts an upper limit on the
amount of stack used by PCRE for certain classes of regular
expressions.</p>

<p style="margin-top: 1em">We have set the default value
low in order to prevent crashes, at the cost of possible
regexp matching failures.</p>

<p style="margin-top: 1em">Matching failures will show up
in the log as VCL_Error messages with regexp errors -27 or
-21.</p>

<p style="margin-top: 1em">Testcase r01576 can be useful
when tuning this parameter.</p>

<p style="margin-top: 1em">ping_interval <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 3</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 0</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
must_restart</p>

<p style="margin-top: 1em">Interval between pings from
parent to child. Zero will disable pinging entirely, which
makes it possible to attach a debugger to the child.</p>

<p style="margin-top: 1em">pipe_timeout <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
60.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">Idle timeout for PIPE sessions.
If nothing have been received in either direction for this
many seconds, the session is closed.</p>

<p style="margin-top: 1em">pool_req <br>
&Acirc;&middot; Default: 10,100,10</p>

<p style="margin-top: 1em">Parameters for per worker pool
request memory pool. The three numbers are:</p>

<p style="margin-top: 1em">min_pool <br>
minimum size of free pool.</p>

<p style="margin-top: 1em">max_pool <br>
maximum size of free pool.</p>

<p style="margin-top: 1em">max_age <br>
max age of free element.</p>

<p style="margin-top: 1em">pool_sess <br>
&Acirc;&middot; Default: 10,100,10</p>

<p style="margin-top: 1em">Parameters for per worker pool
session memory pool. The three numbers are:</p>

<p style="margin-top: 1em">min_pool <br>
minimum size of free pool.</p>

<p style="margin-top: 1em">max_pool <br>
maximum size of free pool.</p>

<p style="margin-top: 1em">max_age <br>
max age of free element.</p>

<p style="margin-top: 1em">pool_vbo <br>
&Acirc;&middot; Default: 10,100,10</p>

<p style="margin-top: 1em">Parameters for backend object
fetch memory pool. The three numbers are:</p>

<p style="margin-top: 1em">min_pool <br>
minimum size of free pool.</p>

<p style="margin-top: 1em">max_pool <br>
maximum size of free pool.</p>

<p style="margin-top: 1em">max_age <br>
max age of free element.</p>

<p style="margin-top: 1em">prefer_ipv6 <br>
&Acirc;&middot; Units: bool</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: off</p>

<p style="margin-top: 1em">Prefer IPv6 address when
connecting to backends which have both IPv4 and IPv6
addresses.</p>

<p style="margin-top: 1em">rush_exponent <br>
&Acirc;&middot; Units: requests per request</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 3</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 2</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">How many parked request we start
for each completed request on the object. NB: Even with the
implict delay of delivery, this parameter controls an
exponential increase in number <br>
of worker threads.</p>

<p style="margin-top: 1em">send_timeout <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
600.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
delayed</p>

<p style="margin-top: 1em">Send timeout for client
connections. If the HTTP response hasn&rsquo;t been
transmitted in this many seconds the session is closed. See
setsockopt(2) under SO_SNDTIMEO for more infor&acirc; <br>
mation.</p>

<p style="margin-top: 1em">shm_reclen <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
255b</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 16b</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum:
4084</p>

<p style="margin-top: 1em">Old name for vsl_reclen, use
that instead.</p>

<p style="margin-top: 1em">shortlived <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
10.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">Objects created with
(ttl+grace+keep) shorter than this are always put in
transient storage.</p>

<p style="margin-top: 1em">sigsegv_handler <br>
&Acirc;&middot; Units: bool</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: on</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
must_restart</p>

<p style="margin-top: 1em">Install a signal handler which
tries to dump debug information on segmentation faults, bus
errors and abort signals.</p>

<p style="margin-top: 1em">syslog_cli_traffic <br>
&Acirc;&middot; Units: bool</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: on</p>

<p style="margin-top: 1em">Log all CLI traffic to
syslog(LOG_INFO).</p>

<p style="margin-top: 1em">tcp_fastopen <br>
&Acirc;&middot; Units: bool</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: off</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
must_restart</p>

<p style="margin-top: 1em">Enable TCP Fast Open
extension.</p>

<p style="margin-top: 1em">tcp_keepalive_intvl <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
75.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
1.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum:
100.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">The number of seconds between
TCP keep-alive probes.</p>

<p style="margin-top: 1em">tcp_keepalive_probes <br>
&Acirc;&middot; Units: probes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 9</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 1</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum: 100</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">The maximum number of TCP
keep-alive probes to send before giving up and killing the
connection if no response is obtained from the other
end.</p>

<p style="margin-top: 1em">tcp_keepalive_time <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
7200.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
1.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum:
7200.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">The number of seconds a
connection needs to be idle before TCP begins sending out
keep-alive probes.</p>

<p style="margin-top: 1em">thread_pool_add_delay <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">Wait at least this long after
creating a thread.</p>

<p style="margin-top: 1em">Some (buggy) systems may need a
short (sub-second) delay between creating threads. Set this
to a few milliseconds if you see the
&rsquo;threads_failed&rsquo; counter grow too much.</p>

<p style="margin-top: 1em">Setting this too high results in
insufficient worker threads.</p>

<p style="margin-top: 1em">thread_pool_destroy_delay <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
1.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.010</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags: delayed,
experimental</p>

<p style="margin-top: 1em">Wait this long after destroying
a thread.</p>

<p style="margin-top: 1em">This controls the decay of
thread pools when idle(-ish).</p>

<p style="margin-top: 1em">thread_pool_fail_delay <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
0.200</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.010</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">Wait at least this long after a
failed thread creation before trying to create another
thread.</p>

<p style="margin-top: 1em">Failure to create a worker
thread is often a sign that the end is near, because the
process is running out of some resource. This delay tries to
not rush the end on needlessly.</p>

<p style="margin-top: 1em">If thread creation failures are
a problem, check that thread_pool_max is not too high.</p>

<p style="margin-top: 1em">It may also help to increase
thread_pool_timeout and thread_pool_min, to reduce the rate
at which treads are destroyed and later recreated.</p>

<p style="margin-top: 1em">thread_pool_max <br>
&Acirc;&middot; Units: threads</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
5000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 100</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
delayed</p>

<p style="margin-top: 1em">The maximum number of worker
threads in each pool.</p>

<p style="margin-top: 1em">Do not set this higher than you
have to, since excess worker threads soak up RAM and CPU and
generally just get in the way of getting work done.</p>

<p style="margin-top: 1em">thread_pool_min <br>
&Acirc;&middot; Units: threads</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 100</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum:
5000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
delayed</p>

<p style="margin-top: 1em">The minimum number of worker
threads in each pool.</p>

<p style="margin-top: 1em">Increasing this may help ramp up
faster from low load situations or when threads have
expired.</p>

<p style="margin-top: 1em">Minimum is 10 threads.</p>

<p style="margin-top: 1em">thread_pool_reserve <br>
&Acirc;&middot; Units: threads</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 0</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum: 95</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
delayed</p>

<p style="margin-top: 1em">The number of worker threads
reserved for vital tasks in each pool.</p>

<p style="margin-top: 1em">Tasks may require other tasks to
complete (for example, client requests may require backend
requests). This reserve is to ensure that such tasks still
get to run even under high <br>
load.</p>

<p style="margin-top: 1em">Increasing the reserve may help
setups with a high number of backend requests at the expense
of client performance. Setting it too high will waste
resources by keeping threads <br>
unused.</p>

<p style="margin-top: 1em">Default is 0 to auto-tune
(currently 5% of thread_pool_min). Minimum is 1 otherwise,
maximum is 95% of thread_pool_min.</p>

<p style="margin-top: 1em">thread_pool_stack <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 48k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 16k</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
delayed</p>

<p style="margin-top: 1em">Worker thread stack size. This
will likely be rounded up to a multiple of 4k (or whatever
the page_size might be) by the kernel.</p>

<p style="margin-top: 1em">The required stack size is
primarily driven by the depth of the call-tree. The most
common relevant determining factors in varnish core code are
GZIP (un)compression, ESI pro&acirc; <br>
cessing and regular expression matches. VMODs may also
require significant amounts of additional stack. The nesting
depth of VCL subs is another factor, although typically not
<br>
predominant.</p>

<p style="margin-top: 1em">The stack size is per thread, so
the maximum total memory required for worker thread stacks
is in the order of size = thread_pools x thread_pool_max x
thread_pool_stack.</p>

<p style="margin-top: 1em">Thus, in particular for setups
with many threads, keeping the stack size at a minimum helps
reduce the amount of memory required by Varnish.</p>

<p style="margin-top: 1em">On the other hand,
thread_pool_stack must be large enough under all
circumstances, otherwise varnish will crash due to a stack
overflow. Usually, a stack overflow manifests <br>
itself as a segmentation fault (aka segfault / SIGSEGV) with
the faulting address being near the stack pointer (sp).</p>

<p style="margin-top: 1em">Unless stack usage can be
reduced, thread_pool_stack must be increased when a stack
overflow occurs. Setting it in 150%-200% increments is
recommended until stack overflows cease <br>
to occur.</p>

<p style="margin-top: 1em">thread_pool_timeout <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
300.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
10.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags: delayed,
experimental</p>

<p style="margin-top: 1em">Thread idle threshold.</p>

<p style="margin-top: 1em">Threads in excess of
thread_pool_min, which have been idle for at least this
long, will be destroyed.</p>

<p style="margin-top: 1em">thread_pools <br>
&Acirc;&middot; Units: pools</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 2</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 1</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum: 32</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags: delayed,
experimental</p>

<p style="margin-top: 1em">Number of worker thread
pools.</p>

<p style="margin-top: 1em">Increasing the number of worker
pools decreases lock contention. Each worker pool also has a
thread accepting new connections, so for very high rates of
incoming new connections <br>
on systems with many cores, increasing the worker pools may
be required.</p>

<p style="margin-top: 1em">Too many pools waste CPU and RAM
resources, and more than one pool for each CPU is most
likely detrimental to performance.</p>

<p style="margin-top: 1em">Can be increased on the fly, but
decreases require a restart to take effect.</p>

<p style="margin-top: 1em">thread_queue_limit <br>
&Acirc;&middot; Default: 20</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 0</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">Permitted request queue length
per thread-pool.</p>

<p style="margin-top: 1em">This sets the number of requests
we will queue, waiting for an available thread. Above this
limit sessions will be dropped instead of queued.</p>

<p style="margin-top: 1em">thread_stats_rate <br>
&Acirc;&middot; Units: requests</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 10</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 0</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">Worker threads accumulate
statistics, and dump these into the global stats counters if
the lock is free when they finish a job (request/fetch etc.)
This parameters defines the <br>
maximum number of jobs a worker thread may handle, before it
is forced to dump its accumulated stats into the global
counters.</p>

<p style="margin-top: 1em">timeout_idle <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
5.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">Idle timeout for client
connections. A connection is considered idle, until we have
received the full request headers.</p>

<p style="margin-top: 1em">timeout_linger <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
0.050</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
experimental</p>

<p style="margin-top: 1em">How long the worker thread
lingers on an idle session before handing it over to the
waiter. When sessions are reused, as much as half of all
reuses happen within the first 100 <br>
msec of the previous request completing. Setting this too
high results in worker threads not doing anything for their
keep, setting it too low just means that more sessions take
<br>
a detour around the waiter.</p>

<p style="margin-top: 1em">vcc_allow_inline_c <br>
&Acirc;&middot; Units: bool</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: off</p>

<p style="margin-top: 1em">Allow inline C code in VCL.</p>

<p style="margin-top: 1em">vcc_err_unref <br>
&Acirc;&middot; Units: bool</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: on</p>

<p style="margin-top: 1em">Unreferenced VCL objects result
in error.</p>

<p style="margin-top: 1em">vcc_unsafe_path <br>
&Acirc;&middot; Units: bool</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: on</p>

<p style="margin-top: 1em">Allow &rsquo;/&rsquo; in vmod
&amp; include paths. Allow &rsquo;import ... from
...&rsquo;.</p>

<p style="margin-top: 1em">vcl_cooldown <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
600.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.000</p>

<p style="margin-top: 1em">How long a VCL is kept warm
after being replaced as the active VCL (granularity
approximately 30 seconds).</p>

<p style="margin-top: 1em">vcl_dir <br>
&Acirc;&middot; Default:
/opt/varnish/etc/varnish:/opt/varnish/share/varnish/vcl</p>

<p style="margin-top: 1em">Old name for vcl_path, use that
instead.</p>

<p style="margin-top: 1em">vcl_path <br>
&Acirc;&middot; Default:
/opt/varnish/etc/varnish:/opt/varnish/share/varnish/vcl</p>

<p style="margin-top: 1em">Directory (or colon separated
list of directories) from which relative VCL filenames
(vcl.load and include) are to be found. By default Varnish
searches VCL files in both the <br>
system configuration and shared data directories to allow
packages to drop their VCL files in a standard location
where relative includes would work.</p>

<p style="margin-top: 1em">vmod_dir <br>
&Acirc;&middot; Default: /opt/varnish/lib/varnish/vmods</p>

<p style="margin-top: 1em">Old name for vmod_path, use that
instead.</p>

<p style="margin-top: 1em">vmod_path <br>
&Acirc;&middot; Default: /opt/varnish/lib/varnish/vmods</p>

<p style="margin-top: 1em">Directory (or colon separated
list of directories) where VMODs are to be found.</p>

<p style="margin-top: 1em">vsl_buffer <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 4k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 267</p>

<p style="margin-top: 1em">Bytes of
(req-/backend-)workspace dedicated to buffering VSL records.
When this parameter is adjusted, most likely
workspace_client and workspace_backend will have to be <br>
adjusted by the same amount.</p>

<p style="margin-top: 1em">Setting this too high costs
memory, setting it too low will cause more VSL flushes and
likely increase lock-contention on the VSL mutex.</p>

<p style="margin-top: 1em">The minimum tracks the
vsl_reclen parameter + 12 bytes.</p>

<p style="margin-top: 1em">vsl_mask <br>
&Acirc;&middot; Default:
-VCL_trace,-WorkThread,-Hash,-VfpAcct</p>

<p style="margin-top: 1em">Mask individual VSL messages
from being logged.</p>

<p style="margin-top: 1em">default <br>
Set default value</p>

<p style="margin-top: 1em">Use +/- prefix in front of VSL
tag name, to mask/unmask individual VSL messages.</p>

<p style="margin-top: 1em">vsl_reclen <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
255b</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 16b</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum:
4084b</p>

<p style="margin-top: 1em">Maximum number of bytes in SHM
log record.</p>

<p style="margin-top: 1em">The maximum tracks the
vsl_buffer parameter - 12 bytes.</p>

<p style="margin-top: 1em">vsl_space <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 80M</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 1M</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum: 4G</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
must_restart</p>

<p style="margin-top: 1em">The amount of space to allocate
for the VSL fifo buffer in the VSM memory segment. If you
make this too small, varnish{ncsa|log} etc will not be able
to keep up. Making it too <br>
large just costs memory resources.</p>

<p style="margin-top: 1em">vsm_free_cooldown <br>
&Acirc;&middot; Units: seconds</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
60.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
10.000</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum:
600.000</p>

<p style="margin-top: 1em">How long VSM memory is kept warm
after a deallocation (granularity approximately 2
seconds).</p>

<p style="margin-top: 1em">vsm_space <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 1M</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 1M</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum: 4G</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
must_restart</p>

<p style="margin-top: 1em">The amount of space to allocate
for stats counters in the VSM memory segment. If you make
this too small, some counters will be invisible. Making it
too large just costs memory <br>
resources.</p>

<p style="margin-top: 1em">workspace_backend <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 64k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 1k</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
delayed</p>

<p style="margin-top: 1em">Bytes of HTTP protocol workspace
for backend HTTP req/resp. If larger than 4k, use a multiple
of 4k for VM efficiency.</p>

<p style="margin-top: 1em">workspace_client <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 64k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum: 9k</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
delayed</p>

<p style="margin-top: 1em">Bytes of HTTP protocol workspace
for clients HTTP req/resp. Use a multiple of 4k for VM
efficiency. For HTTP/2 compliance this must be at least 20k,
in order to receive full&acirc; <br>
size (=16k) frames from the client. That usually happens
only in POST/PUT bodies. For other traffic-patterns smaller
values work just fine.</p>

<p style="margin-top: 1em">workspace_session <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default:
0.50k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.25k</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
delayed</p>

<p style="margin-top: 1em">Allocation size for session
structure and workspace. The workspace is primarily used for
TCP connection addresses. If larger than 4k, use a multiple
of 4k for VM efficiency.</p>

<p style="margin-top: 1em">workspace_thread <br>
&Acirc;&middot; Units: bytes</p>

<p style="margin-top: 1em">&Acirc;&middot; Default: 2k</p>

<p style="margin-top: 1em">&Acirc;&middot; Minimum:
0.25k</p>

<p style="margin-top: 1em">&Acirc;&middot; Maximum: 8k</p>

<p style="margin-top: 1em">&Acirc;&middot; Flags:
delayed</p>

<p style="margin-top: 1em">Bytes of auxiliary workspace per
thread. This workspace is used for certain temporary data
structures during the operation of a worker thread. One use
is for the io-vectors for <br>
writing requests and responses to sockets, having too little
space will result in more writev(2) system calls, having too
much just wastes the space.</p>

<p style="margin-top: 1em">EXIT CODES <br>
Varnish and bundled tools will, in most cases, exit with one
of the following codes</p>

<p style="margin-top: 1em">&Acirc;&middot; 0 OK</p>

<p style="margin-top: 1em">&Acirc;&middot; 1 Some error
which could be system-dependent and/or transient</p>

<p style="margin-top: 1em">&Acirc;&middot; 2 Serious
configuration / parameter error - retrying with the same
configuration / parameters is most likely useless</p>

<p style="margin-top: 1em">The varnishd master process may
also OR its exit code</p>

<p style="margin-top: 1em">&Acirc;&middot; with 0x20 when
the varnishd child process died,</p>

<p style="margin-top: 1em">&Acirc;&middot; with 0x40 when
the varnishd child process was terminated by a signal
and</p>

<p style="margin-top: 1em">&Acirc;&middot; with 0x80 when a
core was dumped.</p>

<p style="margin-top: 1em">SEE ALSO <br>
&Acirc;&middot; varnishlog(1)</p>

<p style="margin-top: 1em">&Acirc;&middot;
varnishhist(1)</p>

<p style="margin-top: 1em">&Acirc;&middot;
varnishncsa(1)</p>

<p style="margin-top: 1em">&Acirc;&middot;
varnishstat(1)</p>

<p style="margin-top: 1em">&Acirc;&middot;
varnishtop(1)</p>

<p style="margin-top: 1em">&Acirc;&middot;
varnish-cli(7)</p>

<p style="margin-top: 1em">&Acirc;&middot; vcl(7)</p>

<p style="margin-top: 1em">HISTORY <br>
The varnishd daemon was developed by Poul-Henning Kamp in
cooperation with Verdens Gang AS and Varnish Software.</p>

<p style="margin-top: 1em">This manual page was written by
Dag-Erling Sm&Atilde;&cedil;rgrav with updates by Stig
Sandbeck Mathisen &lt;ssm@debian.org&gt;, Nils Goroll and
others.</p>

<p style="margin-top: 1em">COPYRIGHT <br>
This document is licensed under the same licence as Varnish
itself. See LICENCE for details.</p>

<p style="margin-top: 1em">&Acirc;&middot; Copyright (c)
2007-2015 Varnish Software AS</p>
 
<p style="margin-top: 1em">VARNISHD(1)</p>
<hr>
</body>
</html>
