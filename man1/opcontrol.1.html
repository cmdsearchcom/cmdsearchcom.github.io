<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 16:28:34 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>OPCONTROL(1) General Commands Manual OPCONTROL(1)</p>

<p style="margin-top: 1em">NAME <br>
opcontrol - control OProfile profiling</p>

<p style="margin-top: 1em">SYNOPSIS <br>
opcontrol [ options ]</p>

<p style="margin-top: 1em">DESCRIPTION <br>
opcontrol can be used to start profiling, end a profiling
session, dump profile data, and set up the profiling
parameters.</p>

<p style="margin-top: 1em">OPTIONS <br>
--help / -? <br>
Show help message.</p>

<p style="margin-top: 1em">--version / -v <br>
Show version.</p>

<p style="margin-top: 1em">--list-events / -l <br>
Shows the monitorable events.</p>

<p style="margin-top: 1em">--init Load the OProfile module
if required and make the OProfile driver interface
available.</p>

<p style="margin-top: 1em">--setup <br>
Followed by list options for profiling setup. Store setup in
~root/.oprofile/daemonrc. Optional.</p>

<p style="margin-top: 1em">--status <br>
Show configuration information.</p>

<p style="margin-top: 1em">--start-daemon <br>
Start the oprofile daemon without starting profiling.</p>

<p style="margin-top: 1em">--start / -s <br>
Start data collection with either arguments provided by
--setup or with information saved in
~root/.oprofile/daemonrc.</p>

<p style="margin-top: 1em">--dump / -d <br>
Force a flush of the collected profiling data to the
daemon.</p>

<p style="margin-top: 1em">--stop / -t <br>
Stop data collection.</p>

<p style="margin-top: 1em">--shutdown / -h <br>
Stop data collection and kill the daemon.</p>

<p style="margin-top: 1em">--reset <br>
Clear out data from current session, but leaves saved
sessions.</p>

<p style="margin-top: 1em">--save=sessionname <br>
Save data from current session to sessionname.</p>

<p style="margin-top: 1em">--deinit <br>
Shut down daemon. Unload the oprofile module and
oprofilefs.</p>

<p style="margin-top: 1em">--session-dir=dir_path <br>
Use sample database out of directory dir_path instead of the
default location (/var/lib/oprofile).</p>

<p style="margin-top: 1em">--buffer-size=num <br>
Set kernel buffer to num samples. The buffer watershed needs
to be tweaked when changing this value. Rules: A non-zero
value goes into effect after a
&rsquo;--shutdown/start&rsquo; <br>
sequence. A value of zero sets this parameter back to
default value, but does not go into effect until after
&rsquo;--deinit/init&rsquo; sequence.</p>

<p style="margin-top: 1em">--buffer-watershed=num <br>
Set kernel buffer watershed to num samples. When buffer-size
- buffer-watershed free entries remain in the kernel buffer,
data will be flushed to the daemon. Most useful <br>
values are in the range [0.25 - 0.5] * buffer-size. Same
rules as defined for buffer-size.</p>

<p style="margin-top: 1em">--cpu-buffer-size=num <br>
Set kernel per-cpu buffer to num samples. If you profile at
high rate it can help to increase this if the log file show
excessive count of sample lost cpu buffer overflow. <br>
Same rules as defined for buffer-size.</p>

<p style="margin-top: 1em">--event / -e
[event|&quot;default&quot;] <br>
Specify an event to measure for the hardware performance
counters, or &quot;default&quot; for the default event. The
event is of the form
&quot;CPU_CLK_UNHALTED:30000:0:1:1&quot; where the <br>
numeric values are count, unit mask, kernel-space counting,
user-space counting, respectively. Note that this over-rides
all previous events selected; if you want to pro&acirc; <br>
file with two or more events simultaneously, you must
specify them on the same opcontrol invocation. You can
specify unit mask values using either a numerical value (hex
<br>
values must begin with &quot;0x&quot;) or a symbolic name
(if the name=&lt;um_name&gt; field is shown in the ophelp
output). For some named unit masks, the hex value is not
unique; thus, <br>
OProfile tools enforce specifying such unit masks value by
name.</p>

<p style="margin-top: 1em">--separate / -p
[none,lib,kernel,thread,cpu,all] <br>
Separate samples based on the given separator.
&rsquo;lib&rsquo; separates dynamically linked library
samples per application. &rsquo;kernel&rsquo; separates
kernel and kernel module samples per <br>
application; &rsquo;kernel&rsquo; implies
&rsquo;library&rsquo;. &rsquo;thread&rsquo; gives separation
for each thread and task. &rsquo;cpu&rsquo; separates for
each CPU. &rsquo;all&rsquo; implies all of the above options
and <br>
&rsquo;none&rsquo; turns off separation.</p>

<p style="margin-top: 1em">--callgraph / -c [#depth] <br>
Enable callgraph sample collection with a maximum depth. Use
0 to disable callgraph profiling. This option is available
on x86 using a 2.6+ kernel with callgraph support <br>
enabled. It is also available on PowerPC using a 2.6.17+
kernel.</p>

<p style="margin-top: 1em">--image / -i
[name,name...|&quot;all&quot;] <br>
Only profile the given absolute paths to binaries, or
&quot;all&quot; to profile everything (the default).</p>

<p style="margin-top: 1em">--vmlinux=file <br>
vmlinux kernel image.</p>

<p style="margin-top: 1em">--no-vmlinux <br>
Use this when you don&rsquo;t have a kernel vmlinux file,
and you don&rsquo;t want to profile the kernel.</p>

<p style="margin-top: 1em">--verbose / -V [options] <br>
Be verbose in the daemon log. This has a high overhead.</p>

<p style="margin-top: 1em">--kernel-range=start,end <br>
Set kernel range vma address in hexadecimal.</p>

<p style="margin-top: 1em">OPTIONS (specific to Xen) <br>
--xen=file <br>
Xen image</p>

<p style="margin-top: 1em">--active-domains=&lt;list&gt;
<br>
List of domain ids participating in a multi-domain profiling
session. Each of the specified domains must run an instance
of oprofile. The sequence of opcontrol commands <br>
in each domain must follow a given order which is specified
in the oprofile user manual. If more than one domain is
specified in &lt;list&gt; they should be separated using
com&acirc; <br>
mas. This option can only be used in domain 0 which is the
only domain that can coordinate a multi-domain profiling
session. Including domain 0 in the list of active <br>
domains is optional. (e.g. --active-domains=2,5,6 and
--active-domains=0,2,5,6 are equivalent). This option can
only be specified if --start-daemon is also specified and
<br>
it is only valid for the current run of the oprofile daemon;
e.g. the list of active domains is not persistent.</p>


<p style="margin-top: 1em">--passive-domains=&lt;list&gt;or--domains=&lt;list&gt;
<br>
List of domain ids to be profiled, separated by commas. As
opposed to the --active-domains option, the domains
specified with this option do not need to run oprofile. <br>
This makes profiling multiple domains easier. However, with
the passive-domains option, samples in user level processes
and kernel modules cannot be mapped to specific <br>
symbols and are aggregated under a generic class. Both
--active-domains and --passive-domains options can be
specified in the same command, but the same domain cannot be
<br>
specified in both options. This option can only be specified
if either --start or --start-daemon is specified on the same
command and it is only valid for the current run <br>
of the oprofile daemon; e.g. the list of passive domains is
not persistent.</p>


<p style="margin-top: 1em">--passive-images=&lt;list&gt;or--domains-images=&lt;list&gt;
<br>
List of kernel images associated with the domains specified
in the --passive-domains option, also separated by commas.
The association between the images and domains is <br>
based on the order they are specified in both options.</p>

<p style="margin-top: 1em">OPTIONS (specific to System z)
<br>
--s390hwsampbufsize=num <br>
Number of 2MB areas used per CPU for storing sample data.
The best size for the sample memory depends on the
particular system and the workload to be measured. Providing
<br>
the sampler with too little memory results in lost samples.
Reserving too much system memory for the sampler impacts the
overall performance and, hence, also the workload <br>
to be measured.</p>

<p style="margin-top: 1em">ENVIRONMENT <br>
No special environment variables are recognised by
opcontrol.</p>

<p style="margin-top: 1em">FILES <br>
/root/.oprofile/daemonrc <br>
Configuration file for opcontrol</p>

<p style="margin-top: 1em">/var/lib/oprofile/samples/ <br>
The location of the generated sample files.</p>

<p style="margin-top: 1em">VERSION <br>
This man page is current for oprofile-0.9.9.</p>

<p style="margin-top: 1em">SEE ALSO <br>
/usr/share/doc/oprofile/, oprofile(1)</p>

<p style="margin-top: 1em">4th Berkeley Distribution Tue 06
December 2016 OPCONTROL(1)</p>
<hr>
</body>
</html>
