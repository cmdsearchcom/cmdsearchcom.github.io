<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
  </style>
  <title>bzip2(1)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">bzip2(1)</td>
    <td class="head-vol">General Commands Manual</td>
    <td class="head-rtitle">bzip2(1)</td>
  </tr>
</table>
<div class="manual-text">
<h1 class="Sh" title="Sh" id="NAME"><a class="selflink" href="#NAME">NAME</a></h1>
bzip2, bunzip2 - a block-sorting file compressor, v1.0.6
<div>&#x00A0;</div>
bzcat - decompresses files to stdout
<div>&#x00A0;</div>
bzip2recover - recovers data from damaged bzip2 files
<div style="height: 1.00em;">&#x00A0;</div>
<h1 class="Sh" title="Sh" id="SYNOPSIS"><a class="selflink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<b>bzip2</b> [<b> -cdfkqstvzVL123456789 </b>] [ <i>filenames ...</i> ]
<div>&#x00A0;</div>
<b>bunzip2</b> [<b> -fkvsVL </b>] [ <i>filenames ...</i> ]
<div>&#x00A0;</div>
<b>bzcat</b> [<b> -s </b>] [ <i>filenames ...</i> ]
<div>&#x00A0;</div>
<b>bzip2recover</b> <i>filename</i>
<div style="height: 1.00em;">&#x00A0;</div>
<h1 class="Sh" title="Sh" id="DESCRIPTION"><a class="selflink" href="#DESCRIPTION">DESCRIPTION</a></h1>
<i>bzip2</i> compresses files using the Burrows-Wheeler block sorting text
  compression algorithm, and Huffman coding. Compression is generally
  considerably better than that achieved by more conventional LZ77/LZ78-based
  compressors, and approaches the performance of the PPM family of statistical
  compressors.
<div style="height: 1.00em;">&#x00A0;</div>
The command-line options are deliberately very similar to those of <i>GNU
  gzip,</i> but they are not identical.
<div style="height: 1.00em;">&#x00A0;</div>
<i>bzip2</i> expects a list of file names to accompany the command-line flags.
  Each file is replaced by a compressed version of itself, with the name
  &quot;original_name.bz2&quot;. Each compressed file has the same modification
  date, permissions, and, when possible, ownership as the corresponding
  original, so that these properties can be correctly restored at decompression
  time. File name handling is naive in the sense that there is no mechanism for
  preserving original file names, permissions, ownerships or dates in
  filesystems which lack these concepts, or have serious file name length
  restrictions, such as MS-DOS.
<div style="height: 1.00em;">&#x00A0;</div>
<i>bzip2</i> and <i>bunzip2</i> will by default not overwrite existing files. If
  you want this to happen, specify the -f flag.
<div style="height: 1.00em;">&#x00A0;</div>
If no file names are specified, <i>bzip2</i> compresses from standard input to
  standard output. In this case, <i>bzip2</i> will decline to write compressed
  output to a terminal, as this would be entirely incomprehensible and therefore
  pointless.
<div style="height: 1.00em;">&#x00A0;</div>
<i>bunzip2</i> (or <i>bzip2 -d)</i> decompresses all specified files. Files
  which were not created by <i>bzip2</i> will be detected and ignored, and a
  warning issued. <i>bzip2</i> attempts to guess the filename for the
  decompressed file from that of the compressed file as follows:
<div style="height: 1.00em;">&#x00A0;</div>
<br/>
 filename.bz2 becomes filename
<br/>
 filename.bz becomes filename
<br/>
 filename.tbz2 becomes filename.tar
<br/>
 filename.tbz becomes filename.tar
<br/>
 anyothername becomes anyothername.out
<div style="height: 1.00em;">&#x00A0;</div>
If the file does not end in one of the recognised endings, <i>.bz2,</i>
  <i>.bz,</i> <i>.tbz2</i> or <i>.tbz,</i> <i>bzip2</i> complains that it cannot
  guess the name of the original file, and uses the original name with
  <i>.out</i> appended.
<div style="height: 1.00em;">&#x00A0;</div>
As with compression, supplying no filenames causes decompression from standard
  input to standard output.
<div style="height: 1.00em;">&#x00A0;</div>
<i>bunzip2</i> will correctly decompress a file which is the concatenation of
  two or more compressed files. The result is the concatenation of the
  corresponding uncompressed files. Integrity testing (-t) of concatenated
  compressed files is also supported.
<div style="height: 1.00em;">&#x00A0;</div>
You can also compress or decompress files to the standard output by giving the
  -c flag. Multiple files may be compressed and decompressed like this. The
  resulting outputs are fed sequentially to stdout. Compression of multiple
  files in this manner generates a stream containing multiple compressed file
  representations. Such a stream can be decompressed correctly only by
  <i>bzip2</i> version 0.9.0 or later. Earlier versions of <i>bzip2</i> will
  stop after decompressing the first file in the stream.
<div style="height: 1.00em;">&#x00A0;</div>
<i>bzcat</i> (or <i>bzip2 -dc)</i> decompresses all specified files to the
  standard output.
<div style="height: 1.00em;">&#x00A0;</div>
<i>bzip2</i> will read arguments from the environment variables <i>BZIP2</i> and
  <i>BZIP,</i> in that order, and will process them before any arguments read
  from the command line. This gives a convenient way to supply default
  arguments.
<div style="height: 1.00em;">&#x00A0;</div>
Compression is always performed, even if the compressed file is slightly larger
  than the original. Files of less than about one hundred bytes tend to get
  larger, since the compression mechanism has a constant overhead in the region
  of 50 bytes. Random data (including the output of most file compressors) is
  coded at about 8.05 bits per byte, giving an expansion of around 0.5%.
<div style="height: 1.00em;">&#x00A0;</div>
As a self-check for your protection, <i>bzip2</i> uses 32-bit CRCs to make sure
  that the decompressed version of a file is identical to the original. This
  guards against corruption of the compressed data, and against undetected bugs
  in <i>bzip2</i> (hopefully very unlikely). The chances of data corruption
  going undetected is microscopic, about one chance in four billion for each
  file processed. Be aware, though, that the check occurs upon decompression, so
  it can only tell you that something is wrong. It can't help you recover the
  original uncompressed data. You can use <i>bzip2recover</i> to try to recover
  data from damaged files.
<div style="height: 1.00em;">&#x00A0;</div>
Return values: 0 for a normal exit, 1 for environmental problems (file not
  found, invalid flags, I/O errors, &amp;c), 2 to indicate a corrupt compressed
  file, 3 for an internal consistency error (eg, bug) which caused <i>bzip2</i>
  to panic.
<div style="height: 1.00em;">&#x00A0;</div>
<h1 class="Sh" title="Sh" id="OPTIONS"><a class="selflink" href="#OPTIONS">OPTIONS</a></h1>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-c --stdout</b></dt>
  <dd class="It-tag">Compress or decompress to standard output.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-d --decompress</b></dt>
  <dd class="It-tag">Force decompression. <i>bzip2,</i> <i>bunzip2</i> and
      <i>bzcat</i> are really the same program, and the decision about what
      actions to take is done on the basis of which name is used. This flag
      overrides that mechanism, and forces <i>bzip2</i> to decompress.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-z --compress</b></dt>
  <dd class="It-tag">The complement to -d: forces compression, regardless of the
      invocation name.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-t --test</b></dt>
  <dd class="It-tag">Check integrity of the specified file(s), but don't
      decompress them. This really performs a trial decompression and throws
      away the result.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-f --force</b></dt>
  <dd class="It-tag">Force overwrite of output files. Normally, <i>bzip2</i>
      will not overwrite existing output files. Also forces <i>bzip2</i> to
      break hard links to files, which it otherwise wouldn't do.
    <div style="height: 1.00em;">&#x00A0;</div>
    bzip2 normally declines to decompress files which don't have the correct
      magic header bytes. If forced (-f), however, it will pass such files
      through unmodified. This is how GNU gzip behaves.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-k --keep</b></dt>
  <dd class="It-tag">Keep (don't delete) input files during compression or
      decompression.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-s --small</b></dt>
  <dd class="It-tag">Reduce memory usage, for compression, decompression and
      testing. Files are decompressed and tested using a modified algorithm
      which only requires 2.5 bytes per block byte. This means any file can be
      decompressed in 2300k of memory, albeit at about half the normal speed.
    <div style="height: 1.00em;">&#x00A0;</div>
    During compression, -s selects a block size of 200k, which limits memory use
      to around the same figure, at the expense of your compression ratio. In
      short, if your machine is low on memory (8 megabytes or less), use -s for
      everything. See MEMORY MANAGEMENT below.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-q --quiet</b></dt>
  <dd class="It-tag">Suppress non-essential warning messages. Messages
      pertaining to I/O errors and other critical events will not be
    suppressed.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-v --verbose</b></dt>
  <dd class="It-tag">Verbose mode -- show the compression ratio for each file
      processed. Further -v's increase the verbosity level, spewing out lots of
      information which is primarily of interest for diagnostic purposes.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-L --license -V --version</b></dt>
  <dd class="It-tag">Display the software version, license terms and
    conditions.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-1 (or --fast) to -9 (or --best)</b></dt>
  <dd class="It-tag">Set the block size to 100 k, 200 k .. 900 k when
      compressing. Has no effect when decompressing. See MEMORY MANAGEMENT
      below. The --fast and --best aliases are primarily for GNU gzip
      compatibility. In particular, --fast doesn't make things significantly
      faster. And --best merely selects the default behaviour.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--</b></dt>
  <dd class="It-tag">Treats all subsequent arguments as file names, even if they
      start with a dash. This is so you can handle files with names beginning
      with a dash, for example: bzip2 -- -myfilename.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--repetitive-fast --repetitive-best</b></dt>
  <dd class="It-tag">These flags are redundant in versions 0.9.5 and above. They
      provided some coarse control over the behaviour of the sorting algorithm
      in earlier versions, which was sometimes useful. 0.9.5 and above have an
      improved algorithm which renders these flags irrelevant.
    <div style="height: 1.00em;">&#x00A0;</div>
  </dd>
</dl>
<h1 class="Sh" title="Sh" id="MEMORY_MANAGEMENT"><a class="selflink" href="#MEMORY_MANAGEMENT">MEMORY
  MANAGEMENT</a></h1>
<i>bzip2</i> compresses large files in blocks. The block size affects both the
  compression ratio achieved, and the amount of memory needed for compression
  and decompression. The flags -1 through -9 specify the block size to be
  100,000 bytes through 900,000 bytes (the default) respectively. At
  decompression time, the block size used for compression is read from the
  header of the compressed file, and <i>bunzip2</i> then allocates itself just
  enough memory to decompress the file. Since block sizes are stored in
  compressed files, it follows that the flags -1 to -9 are irrelevant to and so
  ignored during decompression.
<div style="height: 1.00em;">&#x00A0;</div>
Compression and decompression requirements, in bytes, can be estimated as:
<div style="height: 1.00em;">&#x00A0;</div>
<br/>
 Compression: 400k + ( 8 x block size )
<div style="height: 1.00em;">&#x00A0;</div>
<br/>
 Decompression: 100k + ( 4 x block size ), or
<br/>
 100k + ( 2.5 x block size )
<div style="height: 1.00em;">&#x00A0;</div>
Larger block sizes give rapidly diminishing marginal returns. Most of the
  compression comes from the first two or three hundred k of block size, a fact
  worth bearing in mind when using <i>bzip2</i> on small machines. It is also
  important to appreciate that the decompression memory requirement is set at
  compression time by the choice of block size.
<div style="height: 1.00em;">&#x00A0;</div>
For files compressed with the default 900k block size, <i>bunzip2</i> will
  require about 3700 kbytes to decompress. To support decompression of any file
  on a 4 megabyte machine, <i>bunzip2</i> has an option to decompress using
  approximately half this amount of memory, about 2300 kbytes. Decompression
  speed is also halved, so you should use this option only where necessary. The
  relevant flag is -s.
<div style="height: 1.00em;">&#x00A0;</div>
In general, try and use the largest block size memory constraints allow, since
  that maximises the compression achieved. Compression and decompression speed
  are virtually unaffected by block size.
<div style="height: 1.00em;">&#x00A0;</div>
Another significant point applies to files which fit in a single block -- that
  means most files you'd encounter using a large block size. The amount of real
  memory touched is proportional to the size of the file, since the file is
  smaller than a block. For example, compressing a file 20,000 bytes long with
  the flag -9 will cause the compressor to allocate around 7600k of memory, but
  only touch 400k + 20000 * 8 = 560 kbytes of it. Similarly, the decompressor
  will allocate 3700k but only touch 100k + 20000 * 4 = 180 kbytes.
<div style="height: 1.00em;">&#x00A0;</div>
Here is a table which summarises the maximum memory usage for different block
  sizes. Also recorded is the total compressed size for 14 files of the Calgary
  Text Compression Corpus totalling 3,141,622 bytes. This column gives some feel
  for how compression varies with block size. These figures tend to understate
  the advantage of larger block sizes for larger files, since the Corpus is
  dominated by smaller files.
<div style="height: 1.00em;">&#x00A0;</div>
<br/>
 Compress Decompress Decompress Corpus
<br/>
 Flag usage usage -s usage Size
<div style="height: 1.00em;">&#x00A0;</div>
<br/>
 -1 1200k 500k 350k 914704
<br/>
 -2 2000k 900k 600k 877703
<br/>
 -3 2800k 1300k 850k 860338
<br/>
 -4 3600k 1700k 1100k 846899
<br/>
 -5 4400k 2100k 1350k 845160
<br/>
 -6 5200k 2500k 1600k 838626
<br/>
 -7 6100k 2900k 1850k 834096
<br/>
 -8 6800k 3300k 2100k 828642
<br/>
 -9 7600k 3700k 2350k 828642
<div style="height: 1.00em;">&#x00A0;</div>
<h1 class="Sh" title="Sh" id="RECOVERING_DATA_FROM_DAMAGED_FILES"><a class="selflink" href="#RECOVERING_DATA_FROM_DAMAGED_FILES">RECOVERING
  DATA FROM DAMAGED FILES</a></h1>
<i>bzip2</i> compresses files in blocks, usually 900kbytes long. Each block is
  handled independently. If a media or transmission error causes a multi-block
  .bz2 file to become damaged, it may be possible to recover data from the
  undamaged blocks in the file.
<div style="height: 1.00em;">&#x00A0;</div>
The compressed representation of each block is delimited by a 48-bit pattern,
  which makes it possible to find the block boundaries with reasonable
  certainty. Each block also carries its own 32-bit CRC, so damaged blocks can
  be distinguished from undamaged ones.
<div style="height: 1.00em;">&#x00A0;</div>
<i>bzip2recover</i> is a simple program whose purpose is to search for blocks in
  .bz2 files, and write each block out into its own .bz2 file. You can then use
  <i>bzip2</i> -t to test the integrity of the resulting files, and decompress
  those which are undamaged.
<div style="height: 1.00em;">&#x00A0;</div>
<i>bzip2recover</i> takes a single argument, the name of the damaged file, and
  writes a number of files &quot;rec00001file.bz2&quot;,
  &quot;rec00002file.bz2&quot;, etc, containing the extracted blocks. The output
  filenames are designed so that the use of wildcards in subsequent processing
  -- for example, &quot;bzip2 -dc rec*file.bz2 &gt; recovered_data&quot; --
  processes the files in the correct order.
<div style="height: 1.00em;">&#x00A0;</div>
<i>bzip2recover</i> should be of most use dealing with large .bz2 files, as
  these will contain many blocks. It is clearly futile to use it on damaged
  single-block files, since a damaged block cannot be recovered. If you wish to
  minimise any potential data loss through media or transmission errors, you
  might consider compressing with a smaller block size.
<div style="height: 1.00em;">&#x00A0;</div>
<h1 class="Sh" title="Sh" id="PERFORMANCE_NOTES"><a class="selflink" href="#PERFORMANCE_NOTES">PERFORMANCE
  NOTES</a></h1>
The sorting phase of compression gathers together similar strings in the file.
  Because of this, files containing very long runs of repeated symbols, like
  &quot;aabaabaabaab ...&quot; (repeated several hundred times) may compress
  more slowly than normal. Versions 0.9.5 and above fare much better than
  previous versions in this respect. The ratio between worst-case and
  average-case compression time is in the region of 10:1. For previous versions,
  this figure was more like 100:1. You can use the -vvvv option to monitor
  progress in great detail, if you want.
<div style="height: 1.00em;">&#x00A0;</div>
Decompression speed is unaffected by these phenomena.
<div style="height: 1.00em;">&#x00A0;</div>
<i>bzip2</i> usually allocates several megabytes of memory to operate in, and
  then charges all over it in a fairly random fashion. This means that
  performance, both for compressing and decompressing, is largely determined by
  the speed at which your machine can service cache misses. Because of this,
  small changes to the code to reduce the miss rate have been observed to give
  disproportionately large performance improvements. I imagine <i>bzip2</i> will
  perform best on machines with very large caches.
<div style="height: 1.00em;">&#x00A0;</div>
<h1 class="Sh" title="Sh" id="CAVEATS"><a class="selflink" href="#CAVEATS">CAVEATS</a></h1>
I/O error messages are not as helpful as they could be. <i>bzip2</i> tries hard
  to detect I/O errors and exit cleanly, but the details of what the problem is
  sometimes seem rather misleading.
<div style="height: 1.00em;">&#x00A0;</div>
This manual page pertains to version 1.0.6 of <i>bzip2.</i> Compressed data
  created by this version is entirely forwards and backwards compatible with the
  previous public releases, versions 0.1pl2, 0.9.0, 0.9.5, 1.0.0, 1.0.1, 1.0.2
  and above, but with the following exception: 0.9.0 and above can correctly
  decompress multiple concatenated compressed files. 0.1pl2 cannot do this; it
  will stop after decompressing just the first file in the stream.
<div style="height: 1.00em;">&#x00A0;</div>
<i>bzip2recover</i> versions prior to 1.0.2 used 32-bit integers to represent
  bit positions in compressed files, so they could not handle compressed files
  more than 512 megabytes long. Versions 1.0.2 and above use 64-bit ints on some
  platforms which support them (GNU supported targets, and Windows). To
  establish whether or not bzip2recover was built with such a limitation, run it
  without arguments. In any event you can build yourself an unlimited version if
  you can recompile it with MaybeUInt64 set to be an unsigned 64-bit integer.
<div style="height: 1.00em;">&#x00A0;</div>
<div style="height: 1.00em;">&#x00A0;</div>
<div style="height: 1.00em;">&#x00A0;</div>
<h1 class="Sh" title="Sh" id="AUTHOR"><a class="selflink" href="#AUTHOR">AUTHOR</a></h1>
Julian Seward, jsewardbzip.org.
<div style="height: 1.00em;">&#x00A0;</div>
http://www.bzip.org
<div style="height: 1.00em;">&#x00A0;</div>
The ideas embodied in <i>bzip2</i> are due to (at least) the following people:
  Michael Burrows and David Wheeler (for the block sorting transformation),
  David Wheeler (again, for the Huffman coder), Peter Fenwick (for the
  structured coding model in the original <i>bzip,</i> and many refinements),
  and Alistair Moffat, Radford Neal and Ian Witten (for the arithmetic coder in
  the original <i>bzip).</i> I am much indebted for their help, support and
  advice. See the manual in the source distribution for pointers to sources of
  documentation. Christian von Roques encouraged me to look for faster sorting
  algorithms, so as to speed up compression. Bela Lubkin encouraged me to
  improve the worst-case compression performance. Donna Robinson XMLised the
  documentation. The bz* scripts are derived from those of GNU gzip. Many people
  sent patches, helped with portability problems, lent machines, gave advice and
  were generally helpful.</div>
<table class="foot">
  <tr>
    <td class="foot-date"></td>
    <td class="foot-os"></td>
  </tr>
</table>
</body>
</html>
