<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <style>
    table.head, table.foot { width: 100%; }
    td.head-rtitle, td.foot-os { text-align: right; }
    td.head-vol { text-align: center; }
    div.Pp { margin: 1ex 0ex; }
  </style>
  <title>CPFIND(1)</title>
</head>
<body>
<table class="head">
  <tr>
    <td class="head-ltitle">CPFIND(1)</td>
    <td class="head-vol">HUGIN</td>
    <td class="head-rtitle">CPFIND(1)</td>
  </tr>
</table>
<div class="manual-text">
<h1 class="Sh" title="Sh" id="NAME"><a class="selflink" href="#NAME">NAME</a></h1>
cpfind - Feature matching for panoramic stitching
<h1 class="Sh" title="Sh" id="SYNOPSIS"><a class="selflink" href="#SYNOPSIS">SYNOPSIS</a></h1>
<b>cpfind</b> [options] -o <i>output_project</i> <i>project.pto</i>
<div class="Pp"></div>
<b>cpfind</b> [options] -k i0 -k i1 [...] <i>project.pto</i>
<div class="Pp"></div>
<b>cpfind</b> [options] --kall <i>project.pto</i>
<h1 class="Sh" title="Sh" id="DESCRIPTION"><a class="selflink" href="#DESCRIPTION">DESCRIPTION</a></h1>
<b>cpfind</b> cpfind is a control-point detector for Hugin. It expects a project
  file as input and writes a project file with control-points on success. It
  depends on reasonable lens information in the input project file.
<div class="Pp"></div>
The first step is the feature description: In this step the images of the
  project file are loaded and so called keypoints are searched. They describe
  destinctive features in the image. <b>cpfind</b> uses a gradient based
  descriptor for the feature description of the keypoints.
<div class="Pp"></div>
In a second step, the feature matching, all keypoints of two images are matched
  against each other to find features which are on both images. If this matching
  was successfull two keypoints in the two images become one control point.
<h1 class="Sh" title="Sh" id="USAGE"><a class="selflink" href="#USAGE">USAGE</a></h1>
<h2 class="Ss" title="Ss" id="Rectilinear_and_fisheye_images"><a class="selflink" href="#Rectilinear_and_fisheye_images">Rectilinear
  and fisheye images</a></h2>
Cpfind can find control points in rectilinear and fisheye images. To achieve
  good control points images with a high horizontal field of view (e.g. ultra
  wide rectilinear or fisheye) are therefor remapped into a conformal space
  (cpfind is using the stereographic projection) and the feature matching occurs
  in this space. Before writing the control points the coordinates are remapped
  back to the image space. This happens automatic depending on the information
  about the lens in the input project file. So check that your input project
  file contains reasonable information about the used lens.
<h2 class="Ss" title="Ss" id="Using_celeste"><a class="selflink" href="#Using_celeste">Using
  celeste</a></h2>
Outdoor panorama often contains clouds. Clouds are bad areas for setting control
  points because they are moving object. Cpfind can use the same algorithm as
  celeste_standalone to masked out areas which contains clouds. (This is only
  done internal for the keypoint finding step and does not change the alpha
  channel of your image. If you want to generate a mask image use
  celeste_standalone). To run cpfind with celeste use
<div class="Pp"></div>
<pre>
   cpfind --celeste -o output.pto input.pto
</pre>
<div class="Pp"></div>
Using cpfind with integrated celeste should be superior against using cpfind and
  celeste_standalone sequential. When running cpfind with celeste areas of
  clouds, which often contains keypoints with a high quality measure, are
  disregarded and areas without clouds are used instead. When running cpfind
  without celeste also keypoints on clouds are found. When afterwards running
  celeste_standalone these control points are removed. In the worst case all
  control points of a certain image pair are removed.
<div class="Pp"></div>
So running cpfind with celeste leads to a better &quot;control point
  quality&quot; for outdoor panorama (e.g. panorama with clouds). Running cpfind
  with celeste takes longer than cpfind alone. So for indoor panorama this
  option does not need to specified (because of longer computation time).
<div class="Pp"></div>
The celeste step can be fine tuned by the parameters --celesteRadius and
  --celesteThreshold.
<h2 class="Ss" title="Ss" id="Matching_strategy"><a class="selflink" href="#Matching_strategy">Matching
  strategy</a></h2>
<i>All pairs</i>
<div class="Pp"></div>
This is the default matching strategy. Here all image pairs are matched against
  each other. E.g. if your project contains 5 images then cpfind matches the
  image pairs: 0-1, 0-2, 0-3, 0-4, 1-2, 1-3, 1-4, 2-3, 2-4 and 3-4
<div class="Pp"></div>
This strategy works for all shooting strategy (single-row, multi-row,
  unordered). It finds (nearly) all connected image pairs. But it is
  computational expensive for projects with many images, because it test many
  image pairs which are not connected.
<div class="Pp"></div>
<i>Linear match</i>
<div class="Pp"></div>
This matching strategy works best for single row panoramas:
<div class="Pp"></div>
<pre>
   cpfind --linearmatch -o output.pto input.pto
</pre>
<div class="Pp"></div>
This will only detect matches between adjacent images, e.g. for the 5 image
  example it will matches images pairs 0-1, 1-2, 2-3 and 3-4. The matching
  distance can be increased with the switch --linearmatchlen. E.g. with
  --linearmatchlen 2 cpfind will match a image with the next image and the image
  after next, in our example it would be 0-1, 0-2, 1-2, 1-3, 2-3, 2-4 and 3-4.
<div class="Pp"></div>
<i>Multirow matching</i>
<div class="Pp"></div>
This is an optimized matching strategy for single and multi-row panorama:
<div class="Pp"></div>
<pre>
   cpfind --multirow -o output.pto input.pto
</pre>
<div class="Pp"></div>
The algorithm is the same as described in multi-row panorama. By integrating
  this algorithm into cpfind it is faster by using several cores of modern CPUs
  and don't caching the keypoints to disc (which is time consuming). If you want
  to use this multi-row matching inside hugin set the control point detector
  type to All images at once.
<div class="Pp"></div>
<i>Keypoints caching to disc</i>
<div class="Pp"></div>
The calculation of keypoints takes some time. So cpfind offers the possibility
  to save the keypoints to a file and reuse them later again. With --kall the
  keypoints for all images in the project are saved to disc. If you only want
  the keypoints of particular image use the parameter -k with the image number:
<div class="Pp"></div>
<pre>
   cpfind --kall input.pto
   cpfind -k 0 -k 1 input.pto
</pre>
<div class="Pp"></div>
The keypoint files are saved by default into the same directory as the images
  with the extension .key. In this case no matching of images occurs and
  therefore no output project file needs to specified. If cpfind finds keyfiles
  for an image in the project it will use them automatically and not run the
  feature descriptor again on this image. If you want to save them to annother
  directory use the --keypath switch.
<div class="Pp"></div>
This procedure can also be automate with the switch --cache:
<div class="Pp"></div>
<pre>
   cpfind --cache -o output.pto input.pto
</pre>
<div class="Pp"></div>
In this case it tries to load existing keypoint files. For images, which don't
  have a keypoint file, the keypoints are detected and save to the file. Then it
  matches all loaded and newly found keypoints and writes the output project.
<div class="Pp"></div>
If you don't need the keyfile longer, the can be deleted automatic by
<div class="Pp"></div>
<pre>
   cpfind --clean input.pto
</pre>
<h1 class="Sh" title="Sh" id="EXTENDED_OPTIONS"><a class="selflink" href="#EXTENDED_OPTIONS">EXTENDED
  OPTIONS</a></h1>
<h2 class="Ss" title="Ss" id="Feature_description"><a class="selflink" href="#Feature_description">Feature
  description</a></h2>
For speed reasons cpfind is using images, which are scaled to their half width
  and height, to find keypoints. With the switch --fullscale cpfind is working
  on the full scale images. This takes longer but can provide &quot;better&quot;
  and/or more control points.
<div class="Pp"></div>
The feature description step can be fine-tuned by the parameters:
<dl class="Bl-tag">
  <dt class="It-tag"><b>--sieve1width</b> &lt;int&gt;</dt>
  <dd class="It-tag">Sieve 1: Number of buckets on width (default: 10)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--sieve1height</b> &lt;int&gt;</dt>
  <dd class="It-tag">Sieve 1: Number of buckets on height (default: 10)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--sieve1size</b> &lt;int&gt;</dt>
  <dd class="It-tag">Sieve 1: Max points per bucket (default: 100)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--kdtreesteps</b> &lt;int&gt;</dt>
  <dd class="It-tag">KDTree: search steps (default: 200)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--kdtreeseconddist</b> &lt;double&gt;</dt>
  <dd class="It-tag"></dd>
</dl>
<div class="Pp"></div>
KDTree: distance of 2nd match (default: 0.25)
<div class="Pp"></div>
Cpfind stores maximal sieve1width * sieve1height * sieve1size keypoints per
  image. If you have only a small overlap, e.g. for 360 degree panorama shoot
  with fisheye images, you can get better results if you increase sieve1size.
  You can also try to increase sieve1width and/or sieve1height.
<h2 class="Ss" title="Ss" id="Feature_matching"><a class="selflink" href="#Feature_matching">Feature
  matching</a></h2>
Fine-tuning of the matching step by the following parameters:
<dl class="Bl-tag">
  <dt class="It-tag"><b>--ransaciter</b> &lt;int&gt;</dt>
  <dd class="It-tag">Ransac: iterations (default: 1000)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--ransacdist</b> &lt;int&gt;</dt>
  <dd class="It-tag">Ransac: homography estimation distance threshold (pixels)
      (default: 25)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--ransacmode</b> (auto, hom, rpy, rpyv, rpyb)</dt>
  <dd class="It-tag">Select the model used in the ransac step.
    <div style="height: 1.00em;">&#x00A0;</div>
    hom: Assume a homography. Only applicable for non-wide angle
    <br/>
     views. Uses the original panomatic code. It is also more flexible
    <br/>
     than required and can generate false matches, particularly if most
    <br/>
     of the matches are located on a single line.
    <div style="height: 1.00em;">&#x00A0;</div>
    rpy: Align images using roll, pitch and yaw. This requires a good
    <br/>
     estimate for the horizontal field of view (and distortion, for
    <br/>
     heavily distorted images). It is the preferred mode if a
    <br/>
     calibrated lens is used, or the HFOV could be read successfully
    <br/>
     from the EXIF data.
    <div style="height: 1.00em;">&#x00A0;</div>
    rpyv: Align pair by optimizing roll, pitch, yaw and field of
    <br/>
     view. Should work without prior knowledge of the field of view,
    <br/>
     but might fail more often, due to error function used in the
    <br/>
     panotools optimizer, it tends to shrink the fov to 0.
    <div style="height: 1.00em;">&#x00A0;</div>
    rpyvb: Align pair by optimizing roll, pitch, yaw, field of view and
    <br/>
     the &quot;b&quot; distortion parameter. Probably very fragile, just
    <br/>
     implemented for testing.
    <div style="height: 1.00em;">&#x00A0;</div>
    auto: Use homography for images with hfov &lt; 65 degrees and rpy
    otherwise.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--minmatches</b> &lt;int&gt;</dt>
  <dd class="It-tag">Minimum matches (default: 4)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--sieve2width</b> &lt;int&gt;</dt>
  <dd class="It-tag">Sieve 2: Number of buckets on width (default: 5)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--sieve2height</b> &lt;int&gt;</dt>
  <dd class="It-tag">Sieve 2: Number of buckets on height (default: 5)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--sieve2size</b> &lt;int&gt;</dt>
  <dd class="It-tag">Sieve 2: Max points per bucket (default: 2)
    <div style="height: 1.00em;">&#x00A0;</div>
    Cpfind generates between minmatches and sieve2width * sieve2height *
      sieve2size control points between an image pair. (Default setting is
      between 4 and 50 (=5*5*2) control points per image pair.) If less then
      minmatches control points are found for a given image pairs these control
      points are disregarded and this image pair is considers as not connected.
      For narrow overlaps you can try to decrease minmatches, but this increases
      the risk of getting wrong control points.</dd>
</dl>
<h1 class="Sh" title="Sh" id="OPTIONS"><a class="selflink" href="#OPTIONS">OPTIONS</a></h1>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--celesteRadius</b> &lt;int&gt;</dt>
  <dd class="It-tag">Radius for celeste (default 20)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--celesteThreshold</b> &lt;double&gt;</dt>
  <dd class="It-tag">Threshold for celeste (default 0.5)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--celeste</b></dt>
  <dd class="It-tag">Run celeste sky identification after loading images, this
      ignores all features associated with 'clouds'.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-p &lt;string</b>, <b>--keypath</b> &lt;string&gt;</dt>
  <dd class="It-tag">Path to cache keyfiles</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--clean</b></dt>
  <dd class="It-tag">Clean up cached keyfiles</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-c</b>, <b>--cache</b></dt>
  <dd class="It-tag">Caches keypoints to external file</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--kall</b></dt>
  <dd class="It-tag">Write keyfiles for all images</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-k</b> &lt;int&gt;, <b>--writekeyfile</b>
    &lt;int&gt;</dt>
  <dd class="It-tag">Write a keyfile for this image number (accepted multiple
      times)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-o</b> &lt;string&gt;, <b>--output</b>
    &lt;string&gt;</dt>
  <dd class="It-tag">Output file, required</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-n</b> &lt;int&gt;, <b>--ncores</b> &lt;int&gt;</dt>
  <dd class="It-tag">Number of CPU/Cores (default:autodetect)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-t</b>, <b>--test</b></dt>
  <dd class="It-tag">Enables test mode</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--fullscale</b></dt>
  <dd class="It-tag">Uses full scale image to detect keypoints
    (default:false)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--sieve1width</b> &lt;int&gt;</dt>
  <dd class="It-tag">Sieve 1 : Number of buckets on width (default : 10)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--sieve1height</b> &lt;int&gt;</dt>
  <dd class="It-tag">Sieve 1 : Number of buckets on height (default : 10)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--sieve1size</b> &lt;int&gt;</dt>
  <dd class="It-tag">Sieve 1 : Max points per bucket (default : 100)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--kdtreesteps</b> &lt;int&gt;</dt>
  <dd class="It-tag">KDTree : search steps (default : 200)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--kdtreeseconddist</b> &lt;double&gt;</dt>
  <dd class="It-tag">KDTree : distance of 2nd match (default : 0.15)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--multirow</b></dt>
  <dd class="It-tag">Enable heuristic multi row matching (default: off)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--linearmatch</b></dt>
  <dd class="It-tag">Enable linear images matching (default : all pairs)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--linearmatchlen</b> &lt;int&gt;</dt>
  <dd class="It-tag">Number of images to match in linear matching
    (default:1)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--minmatches</b> &lt;int&gt;</dt>
  <dd class="It-tag">Minimum matches (default : 4)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--ransaciter</b> &lt;int&gt;</dt>
  <dd class="It-tag">Ransac : iterations (default : 1000)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--ransacdist</b> &lt;int&gt;</dt>
  <dd class="It-tag">Ransac : homography estimation distance threshold (pixels)
      (default : 25)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--sieve2width</b> &lt;int&gt;</dt>
  <dd class="It-tag">Sieve 2 : Number of buckets on width (default : 5)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--sieve2height</b> &lt;int&gt;</dt>
  <dd class="It-tag">Sieve 2 : Number of buckets on height (default : 5)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--sieve2size</b> &lt;int&gt;</dt>
  <dd class="It-tag">Sieve 2 : Max points per bucket (default : 2)</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--</b>, <b>--ignore_rest</b></dt>
  <dd class="It-tag">Ignores the rest of the labeled arguments following this
      flag.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>--version</b></dt>
  <dd class="It-tag">Displays version information and exits.</dd>
</dl>
<dl class="Bl-tag">
  <dt class="It-tag"><b>-h</b>, <b>--help</b></dt>
  <dd class="It-tag">Displays usage information and exits.</dd>
</dl>
<h1 class="Sh" title="Sh" id="AUTHORS"><a class="selflink" href="#AUTHORS">AUTHORS</a></h1>
Anael Orlinski, Pablo d'Angelo, Antoine Deleforge, Thomas Modes</div>
<table class="foot">
  <tr>
    <td class="foot-date">2016-11-07</td>
    <td class="foot-os">&quot;Version: 2016.2.0&quot;</td>
  </tr>
</table>
</body>
</html>
