<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 16:09:34 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>FFMPEG-DEVICES(1) FFMPEG-DEVICES(1)</p>

<p style="margin-top: 1em">NAME <br>
ffmpeg-devices - FFmpeg devices</p>

<p style="margin-top: 1em">DESCRIPTION <br>
This document describes the input and output devices
provided by the libavdevice library.</p>

<p style="margin-top: 1em">DEVICE OPTIONS <br>
The libavdevice library provides the same interface as
libavformat. Namely, an input device is considered like a
demuxer, and an output device like a muxer, and the
interface and <br>
generic device options are the same provided by libavformat
(see the ffmpeg-formats manual).</p>

<p style="margin-top: 1em">In addition each input or output
device may support so-called private options, which are
specific for that component.</p>

<p style="margin-top: 1em">Options may be set by specifying
-option value in the FFmpeg tools, or by setting the value
explicitly in the device &quot;AVFormatContext&quot; options
or using the libavutil/opt.h API <br>
for programmatic use.</p>

<p style="margin-top: 1em">INPUT DEVICES <br>
Input devices are configured elements in FFmpeg which enable
accessing the data coming from a multimedia device attached
to your system.</p>

<p style="margin-top: 1em">When you configure your FFmpeg
build, all the supported input devices are enabled by
default. You can list all available ones using the configure
option &quot;--list-indevs&quot;.</p>

<p style="margin-top: 1em">You can disable all the input
devices using the configure option
&quot;--disable-indevs&quot;, and selectively enable an
input device using the option
&quot;--enable-indev=INDEV&quot;, or you can <br>
disable a particular input device using the option
&quot;--disable-indev=INDEV&quot;.</p>

<p style="margin-top: 1em">The option &quot;-devices&quot;
of the ff* tools will display the list of supported input
devices.</p>

<p style="margin-top: 1em">A description of the currently
available input devices follows.</p>

<p style="margin-top: 1em">alsa <br>
ALSA (Advanced Linux Sound Architecture) input device.</p>

<p style="margin-top: 1em">To enable this input device
during configuration you need libasound installed on your
system.</p>

<p style="margin-top: 1em">This device allows capturing
from an ALSA device. The name of the device to capture has
to be an ALSA card identifier.</p>

<p style="margin-top: 1em">An ALSA identifier has the
syntax:</p>


<p style="margin-top: 1em">hw:&lt;CARD&gt;[,&lt;DEV&gt;[,&lt;SUBDEV&gt;]]</p>

<p style="margin-top: 1em">where the DEV and SUBDEV
components are optional.</p>

<p style="margin-top: 1em">The three arguments (in order:
CARD,DEV,SUBDEV) specify card number or identifier, device
number and subdevice number (-1 means any).</p>

<p style="margin-top: 1em">To see the list of cards
currently recognized by your system check the files
/proc/asound/cards and /proc/asound/devices.</p>

<p style="margin-top: 1em">For example to capture with
ffmpeg from an ALSA device with card id 0, you may run the
command:</p>

<p style="margin-top: 1em">ffmpeg -f alsa -i hw:0
alsaout.wav</p>

<p style="margin-top: 1em">For more information see:
&lt;http://www.alsa-project.org/alsa-doc/alsa-lib/pcm.html&gt;</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">sample_rate <br>
Set the sample rate in Hz. Default is 48000.</p>

<p style="margin-top: 1em">channels <br>
Set the number of channels. Default is 2.</p>

<p style="margin-top: 1em">avfoundation <br>
AVFoundation input device.</p>

<p style="margin-top: 1em">AVFoundation is the currently
recommended framework by Apple for streamgrabbing on OSX
&gt;= 10.7 as well as on iOS. The older QTKit framework has
been marked deprecated since OSX <br>
version 10.7.</p>

<p style="margin-top: 1em">The input filename has to be
given in the following syntax:</p>

<p style="margin-top: 1em">-i
&quot;[[VIDEO]:[AUDIO]]&quot;</p>

<p style="margin-top: 1em">The first entry selects the
video input while the latter selects the audio input. The
stream has to be specified by the device name or the device
index as shown by the device <br>
list. Alternatively, the video and/or audio input device can
be chosen by index using the</p>

<p style="margin-top: 1em">B&lt;-video_device_index
E&lt;lt&gt;INDEXE&lt;gt&gt;&gt;</p>

<p style="margin-top: 1em">and/or</p>

<p style="margin-top: 1em">B&lt;-audio_device_index
E&lt;lt&gt;INDEXE&lt;gt&gt;&gt;</p>

<p style="margin-top: 1em">, overriding any device name or
index given in the input filename.</p>

<p style="margin-top: 1em">All available devices can be
enumerated by using -list_devices true, listing all device
names and corresponding indices.</p>

<p style="margin-top: 1em">There are two device name
aliases:</p>

<p style="margin-top: 1em">&quot;default&quot; <br>
Select the AVFoundation default device of the corresponding
type.</p>

<p style="margin-top: 1em">&quot;none&quot; <br>
Do not record the corresponding media type. This is
equivalent to specifying an empty device name or index.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">AVFoundation supports the
following options:</p>

<p style="margin-top: 1em">-list_devices &lt;TRUE|FALSE&gt;
<br>
If set to true, a list of all available input devices is
given showing all device names and indices.</p>

<p style="margin-top: 1em">-video_device_index
&lt;INDEX&gt; <br>
Specify the video device by its index. Overrides anything
given in the input filename.</p>

<p style="margin-top: 1em">-audio_device_index
&lt;INDEX&gt; <br>
Specify the audio device by its index. Overrides anything
given in the input filename.</p>

<p style="margin-top: 1em">-pixel_format &lt;FORMAT&gt;
<br>
Request the video device to use a specific pixel format. If
the specified format is not supported, a list of available
formats is given and the first one in this list is <br>
used instead. Available pixel formats are: &quot;monob,
rgb555be, rgb555le, rgb565be, rgb565le, rgb24, bgr24, 0rgb,
bgr0, 0bgr, rgb0, <br>
bgr48be, uyvy422, yuva444p, yuva444p16le, yuv444p,
yuv422p16, yuv422p10, yuv444p10, <br>
yuv420p, nv12, yuyv422, gray&quot;</p>

<p style="margin-top: 1em">-framerate <br>
Set the grabbing frame rate. Default is &quot;ntsc&quot;,
corresponding to a frame rate of &quot;30000/1001&quot;.</p>

<p style="margin-top: 1em">-video_size <br>
Set the video frame size.</p>

<p style="margin-top: 1em">-capture_cursor <br>
Capture the mouse pointer. Default is 0.</p>

<p style="margin-top: 1em">-capture_mouse_clicks <br>
Capture the screen mouse clicks. Default is 0.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">&Acirc;&middot; Print the list
of AVFoundation supported devices and exit:</p>

<p style="margin-top: 1em">$ ffmpeg -f avfoundation
-list_devices true -i &quot;&quot;</p>

<p style="margin-top: 1em">&Acirc;&middot; Record video
from video device 0 and audio from audio device 0 into
out.avi:</p>

<p style="margin-top: 1em">$ ffmpeg -f avfoundation -i
&quot;0:0&quot; out.avi</p>

<p style="margin-top: 1em">&Acirc;&middot; Record video
from video device 2 and audio from audio device 1 into
out.avi:</p>

<p style="margin-top: 1em">$ ffmpeg -f avfoundation
-video_device_index 2 -i &quot;:1&quot; out.avi</p>

<p style="margin-top: 1em">&Acirc;&middot; Record video
from the system default video device using the pixel format
bgr0 and do not record any audio into out.avi:</p>

<p style="margin-top: 1em">$ ffmpeg -f avfoundation
-pixel_format bgr0 -i &quot;default:none&quot; out.avi</p>

<p style="margin-top: 1em">bktr <br>
BSD video input device.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">framerate <br>
Set the frame rate.</p>

<p style="margin-top: 1em">video_size <br>
Set the video frame size. Default is &quot;vga&quot;.</p>

<p style="margin-top: 1em">standard <br>
Available values are:</p>

<p style="margin-top: 1em">pal <br>
ntsc <br>
secam <br>
paln <br>
palm <br>
ntscj</p>

<p style="margin-top: 1em">decklink <br>
The decklink input device provides capture capabilities for
Blackmagic DeckLink devices.</p>

<p style="margin-top: 1em">To enable this input device, you
need the Blackmagic DeckLink SDK and you need to configure
with the appropriate &quot;--extra-cflags&quot; and
&quot;--extra-ldflags&quot;. On Windows, you need to <br>
run the IDL files through widl.</p>

<p style="margin-top: 1em">DeckLink is very picky about the
formats it supports. Pixel format is uyvy422 or v210,
framerate and video size must be determined for your device
with -list_formats 1. Audio <br>
sample rate is always 48 kHz and the number of channels can
be 2, 8 or 16. Note that all audio channels are bundled in
one single audio track.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">list_devices <br>
If set to true, print a list of devices and exit. Defaults
to false.</p>

<p style="margin-top: 1em">list_formats <br>
If set to true, print a list of supported formats and exit.
Defaults to false.</p>

<p style="margin-top: 1em">bm_v210 <br>
If set to 1, video is captured in 10 bit v210 instead of
uyvy422. Not all Blackmagic devices support this option.</p>

<p style="margin-top: 1em">teletext_lines <br>
If set to nonzero, an additional teletext stream will be
captured from the vertical ancillary data. This option is a
bitmask of the VBI lines checked, specifically lines 6 to
<br>
22, and lines 318 to 335. Line 6 is the LSB in the mask.
Selected lines which do not contain teletext information
will be ignored. You can use the special all constant to
<br>
select all possible lines, or standard to skip lines 6, 318
and 319, which are not compatible with all receivers.
Capturing teletext only works for SD PAL sources in 8 bit
<br>
mode. To use this option, ffmpeg needs to be compiled with
&quot;--enable-libzvbi&quot;.</p>

<p style="margin-top: 1em">channels <br>
Defines number of audio channels to capture. Must be 2, 8 or
16. Defaults to 2.</p>

<p style="margin-top: 1em">duplex_mode <br>
Sets the decklink device duplex mode. Must be unset, half or
full. Defaults to unset.</p>

<p style="margin-top: 1em">video_input <br>
Sets the video input source. Must be unset, sdi, hdmi,
optical_sdi, component, composite or s_video. Defaults to
unset.</p>

<p style="margin-top: 1em">audio_input <br>
Sets the audio input source. Must be unset, embedded,
aes_ebu, analog, analog_xlr, analog_rca or microphone.
Defaults to unset.</p>

<p style="margin-top: 1em">video_pts <br>
Sets the video packet timestamp source. Must be video,
audio, reference or wallclock. Defaults to video.</p>

<p style="margin-top: 1em">audio_pts <br>
Sets the audio packet timestamp source. Must be video,
audio, reference or wallclock. Defaults to audio.</p>

<p style="margin-top: 1em">draw_bars <br>
If set to true, color bars are drawn in the event of a
signal loss. Defaults to true.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">&Acirc;&middot; List input
devices:</p>

<p style="margin-top: 1em">ffmpeg -f decklink -list_devices
1 -i dummy</p>

<p style="margin-top: 1em">&Acirc;&middot; List supported
formats:</p>

<p style="margin-top: 1em">ffmpeg -f decklink -list_formats
1 -i &rsquo;Intensity Pro&rsquo;</p>

<p style="margin-top: 1em">&Acirc;&middot; Capture video
clip at 1080i50 (format 11):</p>

<p style="margin-top: 1em">ffmpeg -f decklink -i
&rsquo;Intensity Pro@11&rsquo; -acodec copy -vcodec copy
output.avi</p>

<p style="margin-top: 1em">&Acirc;&middot; Capture video
clip at 1080i50 10 bit:</p>

<p style="margin-top: 1em">ffmpeg -bm_v210 1 -f decklink -i
&rsquo;UltraStudio Mini Recorder@11&rsquo; -acodec copy
-vcodec copy output.avi</p>

<p style="margin-top: 1em">&Acirc;&middot; Capture video
clip at 1080i50 with 16 audio channels:</p>

<p style="margin-top: 1em">ffmpeg -channels 16 -f decklink
-i &rsquo;UltraStudio Mini Recorder@11&rsquo; -acodec copy
-vcodec copy output.avi</p>

<p style="margin-top: 1em">dshow <br>
Windows DirectShow input device.</p>

<p style="margin-top: 1em">DirectShow support is enabled
when FFmpeg is built with the mingw-w64 project. Currently
only audio and video devices are supported.</p>

<p style="margin-top: 1em">Multiple devices may be opened
as separate inputs, but they may also be opened on the same
input, which should improve synchronism between them.</p>

<p style="margin-top: 1em">The input name should be in the
format:</p>


<p style="margin-top: 1em">&lt;TYPE&gt;=&lt;NAME&gt;[:&lt;TYPE&gt;=&lt;NAME&gt;]</p>

<p style="margin-top: 1em">where TYPE can be either audio
or video, and NAME is the device&rsquo;s name or alternative
name..</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">If no options are specified, the
device&rsquo;s defaults are used. If the device does not
support the requested options, it will fail to open.</p>

<p style="margin-top: 1em">video_size <br>
Set the video size in the captured video.</p>

<p style="margin-top: 1em">framerate <br>
Set the frame rate in the captured video.</p>

<p style="margin-top: 1em">sample_rate <br>
Set the sample rate (in Hz) of the captured audio.</p>

<p style="margin-top: 1em">sample_size <br>
Set the sample size (in bits) of the captured audio.</p>

<p style="margin-top: 1em">channels <br>
Set the number of channels in the captured audio.</p>

<p style="margin-top: 1em">list_devices <br>
If set to true, print a list of devices and exit.</p>

<p style="margin-top: 1em">list_options <br>
If set to true, print a list of selected device&rsquo;s
options and exit.</p>

<p style="margin-top: 1em">video_device_number <br>
Set video device number for devices with the same name
(starts at 0, defaults to 0).</p>

<p style="margin-top: 1em">audio_device_number <br>
Set audio device number for devices with the same name
(starts at 0, defaults to 0).</p>

<p style="margin-top: 1em">pixel_format <br>
Select pixel format to be used by DirectShow. This may only
be set when the video codec is not set or set to
rawvideo.</p>

<p style="margin-top: 1em">audio_buffer_size <br>
Set audio device buffer size in milliseconds (which can
directly impact latency, depending on the device). Defaults
to using the audio device&rsquo;s default buffer size <br>
(typically some multiple of 500ms). Setting this value too
low can degrade performance. See also <br>

&lt;http://msdn.microsoft.com/en-us/library/windows/desktop/dd377582(v=vs.85).aspx&gt;</p>

<p style="margin-top: 1em">video_pin_name <br>
Select video capture pin to use by name or alternative
name.</p>

<p style="margin-top: 1em">audio_pin_name <br>
Select audio capture pin to use by name or alternative
name.</p>

<p style="margin-top: 1em">crossbar_video_input_pin_number
<br>
Select video input pin number for crossbar device. This will
be routed to the crossbar device&rsquo;s Video Decoder
output pin. Note that changing this value can affect future
<br>
invocations (sets a new default) until system reboot
occurs.</p>

<p style="margin-top: 1em">crossbar_audio_input_pin_number
<br>
Select audio input pin number for crossbar device. This will
be routed to the crossbar device&rsquo;s Audio Decoder
output pin. Note that changing this value can affect future
<br>
invocations (sets a new default) until system reboot
occurs.</p>

<p style="margin-top: 1em">show_video_device_dialog <br>
If set to true, before capture starts, popup a display
dialog to the end user, allowing them to change video filter
properties and configurations manually. Note that for <br>
crossbar devices, adjusting values in this dialog may be
needed at times to toggle between PAL (25 fps) and NTSC
(29.97) input frame rates, sizes, interlacing, etc. Changing
<br>
these values can enable different scan rates/frame rates and
avoiding green bars at the bottom, flickering scan lines,
etc. Note that with some devices, changing these <br>
properties can also affect future invocations (sets new
defaults) until system reboot occurs.</p>

<p style="margin-top: 1em">show_audio_device_dialog <br>
If set to true, before capture starts, popup a display
dialog to the end user, allowing them to change audio filter
properties and configurations manually.</p>


<p style="margin-top: 1em">show_video_crossbar_connection_dialog
<br>
If set to true, before capture starts, popup a display
dialog to the end user, allowing them to manually modify
crossbar pin routings, when it opens a video device.</p>


<p style="margin-top: 1em">show_audio_crossbar_connection_dialog
<br>
If set to true, before capture starts, popup a display
dialog to the end user, allowing them to manually modify
crossbar pin routings, when it opens an audio device.</p>

<p style="margin-top: 1em">show_analog_tv_tuner_dialog <br>
If set to true, before capture starts, popup a display
dialog to the end user, allowing them to manually modify TV
channels and frequencies.</p>


<p style="margin-top: 1em">show_analog_tv_tuner_audio_dialog
<br>
If set to true, before capture starts, popup a display
dialog to the end user, allowing them to manually modify TV
audio (like mono vs. stereo, Language A,B or C).</p>

<p style="margin-top: 1em">audio_device_load <br>
Load an audio capture filter device from file instead of
searching it by name. It may load additional parameters too,
if the filter supports the serialization of its <br>
properties to. To use this an audio capture source has to be
specified, but it can be anything even fake one.</p>

<p style="margin-top: 1em">audio_device_save <br>
Save the currently used audio capture filter device and its
parameters (if the filter supports it) to a file. If a file
with the same name exists it will be overwritten.</p>

<p style="margin-top: 1em">video_device_load <br>
Load a video capture filter device from file instead of
searching it by name. It may load additional parameters too,
if the filter supports the serialization of its <br>
properties to. To use this a video capture source has to be
specified, but it can be anything even fake one.</p>

<p style="margin-top: 1em">video_device_save <br>
Save the currently used video capture filter device and its
parameters (if the filter supports it) to a file. If a file
with the same name exists it will be overwritten.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">&Acirc;&middot; Print the list
of DirectShow supported devices and exit:</p>

<p style="margin-top: 1em">$ ffmpeg -list_devices true -f
dshow -i dummy</p>

<p style="margin-top: 1em">&Acirc;&middot; Open video
device Camera:</p>

<p style="margin-top: 1em">$ ffmpeg -f dshow -i
video=&quot;Camera&quot;</p>

<p style="margin-top: 1em">&Acirc;&middot; Open second
video device with name Camera:</p>

<p style="margin-top: 1em">$ ffmpeg -f dshow
-video_device_number 1 -i video=&quot;Camera&quot;</p>

<p style="margin-top: 1em">&Acirc;&middot; Open video
device Camera and audio device Microphone:</p>

<p style="margin-top: 1em">$ ffmpeg -f dshow -i
video=&quot;Camera&quot;:audio=&quot;Microphone&quot;</p>

<p style="margin-top: 1em">&Acirc;&middot; Print the list
of supported options in selected device and exit:</p>

<p style="margin-top: 1em">$ ffmpeg -list_options true -f
dshow -i video=&quot;Camera&quot;</p>

<p style="margin-top: 1em">&Acirc;&middot; Specify pin
names to capture by name or alternative name, specify
alternative device name:</p>

<p style="margin-top: 1em">$ ffmpeg -f dshow
-audio_pin_name &quot;Audio Out&quot; -video_pin_name 2 -i
video=video=&quot;@device_pnp_\?ci#ven_1a0a&amp;dev_6200&amp;subsys_62021461&amp;rev_01#4&amp;e2c7dd6&amp;0&amp;00e1#{65e8773d-8f56-11d0-a3b9-00a0c9223196}ca465100-deb0-4d59-818f-8c477184adf6}&quot;:audio=&quot;Microphone&quot;</p>

<p style="margin-top: 1em">&Acirc;&middot; Configure a
crossbar device, specifying crossbar pins, allow user to
adjust video capture properties at startup:</p>

<p style="margin-top: 1em">$ ffmpeg -f dshow
-show_video_device_dialog true
-crossbar_video_input_pin_number 0 <br>
-crossbar_audio_input_pin_number 3 -i video=&quot;AVerMedia
BDA Analog Capture&quot;:audio=&quot;AVerMedia BDA Analog
Capture&quot;</p>

<p style="margin-top: 1em">dv1394 <br>
Linux DV 1394 input device.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">framerate <br>
Set the frame rate. Default is 25.</p>

<p style="margin-top: 1em">standard <br>
Available values are:</p>

<p style="margin-top: 1em">pal <br>
ntsc</p>

<p style="margin-top: 1em">Default value is
&quot;ntsc&quot;.</p>

<p style="margin-top: 1em">fbdev <br>
Linux framebuffer input device.</p>

<p style="margin-top: 1em">The Linux framebuffer is a
graphic hardware-independent abstraction layer to show
graphics on a computer monitor, typically on the console. It
is accessed through a file device <br>
node, usually /dev/fb0.</p>

<p style="margin-top: 1em">For more detailed information
read the file Documentation/fb/framebuffer.txt included in
the Linux source tree.</p>

<p style="margin-top: 1em">See also
&lt;http://linux-fbdev.sourceforge.net/&gt;, and
fbset(1).</p>

<p style="margin-top: 1em">To record from the framebuffer
device /dev/fb0 with ffmpeg:</p>

<p style="margin-top: 1em">ffmpeg -f fbdev -framerate 10 -i
/dev/fb0 out.avi</p>

<p style="margin-top: 1em">You can take a single screenshot
image with the command:</p>

<p style="margin-top: 1em">ffmpeg -f fbdev -framerate 1 -i
/dev/fb0 -frames:v 1 screenshot.jpeg</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">framerate <br>
Set the frame rate. Default is 25.</p>

<p style="margin-top: 1em">gdigrab <br>
Win32 GDI-based screen capture device.</p>

<p style="margin-top: 1em">This device allows you to
capture a region of the display on Windows.</p>

<p style="margin-top: 1em">There are two options for the
input filename:</p>

<p style="margin-top: 1em">desktop</p>

<p style="margin-top: 1em">or</p>

<p style="margin-top: 1em">title=&lt;window_title&gt;</p>

<p style="margin-top: 1em">The first option will capture
the entire desktop, or a fixed region of the desktop. The
second option will instead capture the contents of a single
window, regardless of its <br>
position on the screen.</p>

<p style="margin-top: 1em">For example, to grab the entire
desktop using ffmpeg:</p>

<p style="margin-top: 1em">ffmpeg -f gdigrab -framerate 6
-i desktop out.mpg</p>

<p style="margin-top: 1em">Grab a 640x480 region at
position &quot;10,20&quot;:</p>

<p style="margin-top: 1em">ffmpeg -f gdigrab -framerate 6
-offset_x 10 -offset_y 20 -video_size vga -i desktop
out.mpg</p>

<p style="margin-top: 1em">Grab the contents of the window
named &quot;Calculator&quot;</p>

<p style="margin-top: 1em">ffmpeg -f gdigrab -framerate 6
-i title=Calculator out.mpg</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">draw_mouse <br>
Specify whether to draw the mouse pointer. Use the value 0
to not draw the pointer. Default value is 1.</p>

<p style="margin-top: 1em">framerate <br>
Set the grabbing frame rate. Default value is
&quot;ntsc&quot;, corresponding to a frame rate of
&quot;30000/1001&quot;.</p>

<p style="margin-top: 1em">show_region <br>
Show grabbed region on screen.</p>

<p style="margin-top: 1em">If show_region is specified with
1, then the grabbing region will be indicated on screen.
With this option, it is easy to know what is being grabbed
if only a portion of the <br>
screen is grabbed.</p>

<p style="margin-top: 1em">Note that show_region is
incompatible with grabbing the contents of a single
window.</p>

<p style="margin-top: 1em">For example:</p>

<p style="margin-top: 1em">ffmpeg -f gdigrab -show_region 1
-framerate 6 -video_size cif -offset_x 10 -offset_y 20 -i
desktop out.mpg</p>

<p style="margin-top: 1em">video_size <br>
Set the video frame size. The default is to capture the full
screen if desktop is selected, or the full window size if
title=window_title is selected.</p>

<p style="margin-top: 1em">offset_x <br>
When capturing a region with video_size, set the distance
from the left edge of the screen or desktop.</p>

<p style="margin-top: 1em">Note that the offset calculation
is from the top left corner of the primary monitor on
Windows. If you have a monitor positioned to the left of
your primary monitor, you will <br>
need to use a negative offset_x value to move the region to
that monitor.</p>

<p style="margin-top: 1em">offset_y <br>
When capturing a region with video_size, set the distance
from the top edge of the screen or desktop.</p>

<p style="margin-top: 1em">Note that the offset calculation
is from the top left corner of the primary monitor on
Windows. If you have a monitor positioned above your primary
monitor, you will need to <br>
use a negative offset_y value to move the region to that
monitor.</p>

<p style="margin-top: 1em">iec61883 <br>
FireWire DV/HDV input device using libiec61883.</p>

<p style="margin-top: 1em">To enable this input device, you
need libiec61883, libraw1394 and libavc1394 installed on
your system. Use the configure option
&quot;--enable-libiec61883&quot; to compile with the device
<br>
enabled.</p>

<p style="margin-top: 1em">The iec61883 capture device
supports capturing from a video device connected via
IEEE1394 (FireWire), using libiec61883 and the new Linux
FireWire stack (juju). This is the <br>
default DV/HDV input method in Linux Kernel 2.6.37 and
later, since the old FireWire stack was removed.</p>

<p style="margin-top: 1em">Specify the FireWire port to be
used as input file, or &quot;auto&quot; to choose the first
port connected.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">dvtype <br>
Override autodetection of DV/HDV. This should only be used
if auto detection does not work, or if usage of a different
device type should be prohibited. Treating a DV device <br>
as HDV (or vice versa) will not work and result in undefined
behavior. The values auto, dv and hdv are supported.</p>

<p style="margin-top: 1em">dvbuffer <br>
Set maximum size of buffer for incoming data, in frames. For
DV, this is an exact value. For HDV, it is not frame exact,
since HDV does not have a fixed frame size.</p>

<p style="margin-top: 1em">dvguid <br>
Select the capture device by specifying its GUID. Capturing
will only be performed from the specified device and fails
if no device with the given GUID is found. This is <br>
useful to select the input if multiple devices are connected
at the same time. Look at /sys/bus/firewire/devices to find
out the GUIDs.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">&Acirc;&middot; Grab and show
the input of a FireWire DV/HDV device.</p>

<p style="margin-top: 1em">ffplay -f iec61883 -i auto</p>

<p style="margin-top: 1em">&Acirc;&middot; Grab and record
the input of a FireWire DV/HDV device, using a packet buffer
of 100000 packets if the source is HDV.</p>

<p style="margin-top: 1em">ffmpeg -f iec61883 -i auto
-hdvbuffer 100000 out.mpg</p>

<p style="margin-top: 1em">jack <br>
JACK input device.</p>

<p style="margin-top: 1em">To enable this input device
during configuration you need libjack installed on your
system.</p>

<p style="margin-top: 1em">A JACK input device creates one
or more JACK writable clients, one for each audio channel,
with name client_name:input_N, where client_name is the name
provided by the <br>
application, and N is a number which identifies the channel.
Each writable client will send the acquired data to the
FFmpeg input device.</p>

<p style="margin-top: 1em">Once you have created one or
more JACK readable clients, you need to connect them to one
or more JACK writable clients.</p>

<p style="margin-top: 1em">To connect or disconnect JACK
clients you can use the jack_connect and jack_disconnect
programs, or do it through a graphical interface, for
example with qjackctl.</p>

<p style="margin-top: 1em">To list the JACK clients and
their properties you can invoke the command jack_lsp.</p>

<p style="margin-top: 1em">Follows an example which shows
how to capture a JACK readable client with ffmpeg.</p>

<p style="margin-top: 1em"># Create a JACK writable client
with name &quot;ffmpeg&quot;. <br>
$ ffmpeg -f jack -i ffmpeg -y out.wav</p>

<p style="margin-top: 1em"># Start the sample jack_metro
readable client. <br>
$ jack_metro -b 120 -d 0.2 -f 4000</p>

<p style="margin-top: 1em"># List the current JACK clients.
<br>
$ jack_lsp -c <br>
system:capture_1 <br>
system:capture_2 <br>
system:playback_1 <br>
system:playback_2 <br>
ffmpeg:input_1 <br>
metro:120_bpm</p>

<p style="margin-top: 1em"># Connect metro to the ffmpeg
writable client. <br>
$ jack_connect metro:120_bpm ffmpeg:input_1</p>

<p style="margin-top: 1em">For more information read:
&lt;http://jackaudio.org/&gt;</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">channels <br>
Set the number of channels. Default is 2.</p>

<p style="margin-top: 1em">lavfi <br>
Libavfilter input virtual device.</p>

<p style="margin-top: 1em">This input device reads data
from the open output pads of a libavfilter filtergraph.</p>

<p style="margin-top: 1em">For each filtergraph open
output, the input device will create a corresponding stream
which is mapped to the generated output. Currently only
video data is supported. The <br>
filtergraph is specified through the option graph.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">graph <br>
Specify the filtergraph to use as input. Each video open
output must be labelled by a unique string of the form
&quot;outN&quot;, where N is a number starting from 0
corresponding to <br>
the mapped input stream generated by the device. The first
unlabelled output is automatically assigned to the
&quot;out0&quot; label, but all the others need to be
specified <br>
explicitly.</p>

<p style="margin-top: 1em">The suffix &quot;+subcc&quot;
can be appended to the output label to create an extra
stream with the closed captions packets attached to that
output (experimental; only for EIA-608 / <br>
CEA-708 for now). The subcc streams are created after all
the normal streams, in the order of the corresponding
stream. For example, if there is &quot;out19+subcc&quot;,
&quot;out7+subcc&quot; <br>
and up to &quot;out42&quot;, the stream #43 is subcc for
stream #7 and stream #44 is subcc for stream #19.</p>

<p style="margin-top: 1em">If not specified defaults to the
filename specified for the input device.</p>

<p style="margin-top: 1em">graph_file <br>
Set the filename of the filtergraph to be read and sent to
the other filters. Syntax of the filtergraph is the same as
the one specified by the option graph.</p>

<p style="margin-top: 1em">dumpgraph <br>
Dump graph to stderr.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">&Acirc;&middot; Create a color
video stream and play it back with ffplay:</p>

<p style="margin-top: 1em">ffplay -f lavfi -graph
&quot;color=c=pink [out0]&quot; dummy</p>

<p style="margin-top: 1em">&Acirc;&middot; As the previous
example, but use filename for specifying the graph
description, and omit the &quot;out0&quot; label:</p>

<p style="margin-top: 1em">ffplay -f lavfi color=c=pink</p>

<p style="margin-top: 1em">&Acirc;&middot; Create three
different video test filtered sources and play them:</p>

<p style="margin-top: 1em">ffplay -f lavfi -graph
&quot;testsrc [out0]; testsrc,hflip [out1]; testsrc,negate
[out2]&quot; test3</p>

<p style="margin-top: 1em">&Acirc;&middot; Read an audio
stream from a file using the amovie source and play it back
with ffplay:</p>

<p style="margin-top: 1em">ffplay -f lavfi
&quot;amovie=test.wav&quot;</p>

<p style="margin-top: 1em">&Acirc;&middot; Read an audio
stream and a video stream and play it back with ffplay:</p>

<p style="margin-top: 1em">ffplay -f lavfi
&quot;movie=test.avi[out0];amovie=test.wav[out1]&quot;</p>

<p style="margin-top: 1em">&Acirc;&middot; Dump decoded
frames to images and closed captions to a file
(experimental):</p>

<p style="margin-top: 1em">ffmpeg -f lavfi -i
&quot;movie=test.ts[out0+subcc]&quot; -map v frame%08d.png
-map s -c copy -f rawvideo subcc.bin</p>

<p style="margin-top: 1em">libcdio <br>
Audio-CD input device based on libcdio.</p>

<p style="margin-top: 1em">To enable this input device
during configuration you need libcdio installed on your
system. It requires the configure option
&quot;--enable-libcdio&quot;.</p>

<p style="margin-top: 1em">This device allows playing and
grabbing from an Audio-CD.</p>

<p style="margin-top: 1em">For example to copy with ffmpeg
the entire Audio-CD in /dev/sr0, you may run the
command:</p>

<p style="margin-top: 1em">ffmpeg -f libcdio -i /dev/sr0
cd.wav</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">speed <br>
Set drive reading speed. Default value is 0.</p>

<p style="margin-top: 1em">The speed is specified CD-ROM
speed units. The speed is set through the libcdio
&quot;cdio_cddap_speed_set&quot; function. On many CD-ROM
drives, specifying a value too large will <br>
result in using the fastest speed.</p>

<p style="margin-top: 1em">paranoia_mode <br>
Set paranoia recovery mode flags. It accepts one of the
following values:</p>

<p style="margin-top: 1em">disable <br>
verify <br>
overlap <br>
neverskip <br>
full</p>

<p style="margin-top: 1em">Default value is disable.</p>

<p style="margin-top: 1em">For more information about the
available recovery modes, consult the paranoia project
documentation.</p>

<p style="margin-top: 1em">libdc1394 <br>
IIDC1394 input device, based on libdc1394 and
libraw1394.</p>

<p style="margin-top: 1em">Requires the configure option
&quot;--enable-libdc1394&quot;.</p>

<p style="margin-top: 1em">openal <br>
The OpenAL input device provides audio capture on all
systems with a working OpenAL 1.1 implementation.</p>

<p style="margin-top: 1em">To enable this input device
during configuration, you need OpenAL headers and libraries
installed on your system, and need to configure FFmpeg with
&quot;--enable-openal&quot;.</p>

<p style="margin-top: 1em">OpenAL headers and libraries
should be provided as part of your OpenAL implementation, or
as an additional download (an SDK). Depending on your
installation you may need to <br>
specify additional flags via the &quot;--extra-cflags&quot;
and &quot;--extra-ldflags&quot; for allowing the build
system to locate the OpenAL headers and libraries.</p>

<p style="margin-top: 1em">An incomplete list of OpenAL
implementations follows:</p>

<p style="margin-top: 1em">Creative <br>
The official Windows implementation, providing hardware
acceleration with supported devices and software fallback.
See &lt;http://openal.org/&gt;.</p>

<p style="margin-top: 1em">OpenAL Soft <br>
Portable, open source (LGPL) software implementation.
Includes backends for the most common sound APIs on the
Windows, Linux, Solaris, and BSD operating systems. See <br>
&lt;http://kcat.strangesoft.net/openal.html&gt;.</p>

<p style="margin-top: 1em">Apple <br>
OpenAL is part of Core Audio, the official Mac OS X Audio
interface. See
&lt;http://developer.apple.com/technologies/mac/audio-and-video.html&gt;</p>

<p style="margin-top: 1em">This device allows one to
capture from an audio input device handled through
OpenAL.</p>

<p style="margin-top: 1em">You need to specify the name of
the device to capture in the provided filename. If the empty
string is provided, the device will automatically select the
default device. You can <br>
get the list of the supported devices by using the option
list_devices.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">channels <br>
Set the number of channels in the captured audio. Only the
values 1 (monaural) and 2 (stereo) are currently supported.
Defaults to 2.</p>

<p style="margin-top: 1em">sample_size <br>
Set the sample size (in bits) of the captured audio. Only
the values 8 and 16 are currently supported. Defaults to
16.</p>

<p style="margin-top: 1em">sample_rate <br>
Set the sample rate (in Hz) of the captured audio. Defaults
to 44.1k.</p>

<p style="margin-top: 1em">list_devices <br>
If set to true, print a list of devices and exit. Defaults
to false.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">Print the list of OpenAL
supported devices and exit:</p>

<p style="margin-top: 1em">$ ffmpeg -list_devices true -f
openal -i dummy out.ogg</p>

<p style="margin-top: 1em">Capture from the OpenAL device
DR-BT101 via PulseAudio:</p>

<p style="margin-top: 1em">$ ffmpeg -f openal -i
&rsquo;DR-BT101 via PulseAudio&rsquo; out.ogg</p>

<p style="margin-top: 1em">Capture from the default device
(note the empty string &rsquo;&rsquo; as filename):</p>

<p style="margin-top: 1em">$ ffmpeg -f openal -i
&rsquo;&rsquo; out.ogg</p>

<p style="margin-top: 1em">Capture from two devices
simultaneously, writing to two different files, within the
same ffmpeg command:</p>

<p style="margin-top: 1em">$ ffmpeg -f openal -i
&rsquo;DR-BT101 via PulseAudio&rsquo; out1.ogg -f openal -i
&rsquo;ALSA Default&rsquo; out2.ogg</p>

<p style="margin-top: 1em">Note: not all OpenAL
implementations support multiple simultaneous capture - try
the latest OpenAL Soft if the above does not work.</p>

<p style="margin-top: 1em">oss <br>
Open Sound System input device.</p>

<p style="margin-top: 1em">The filename to provide to the
input device is the device node representing the OSS input
device, and is usually set to /dev/dsp.</p>

<p style="margin-top: 1em">For example to grab from
/dev/dsp using ffmpeg use the command:</p>

<p style="margin-top: 1em">ffmpeg -f oss -i /dev/dsp
/tmp/oss.wav</p>

<p style="margin-top: 1em">For more information about OSS
see:
&lt;http://manuals.opensound.com/usersguide/dsp.html&gt;</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">sample_rate <br>
Set the sample rate in Hz. Default is 48000.</p>

<p style="margin-top: 1em">channels <br>
Set the number of channels. Default is 2.</p>

<p style="margin-top: 1em">pulse <br>
PulseAudio input device.</p>

<p style="margin-top: 1em">To enable this output device you
need to configure FFmpeg with
&quot;--enable-libpulse&quot;.</p>

<p style="margin-top: 1em">The filename to provide to the
input device is a source device or the string
&quot;default&quot;</p>

<p style="margin-top: 1em">To list the PulseAudio source
devices and their properties you can invoke the command
pactl list sources.</p>

<p style="margin-top: 1em">More information about
PulseAudio can be found on
&lt;http://www.pulseaudio.org&gt;.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">server <br>
Connect to a specific PulseAudio server, specified by an IP
address. Default server is used when not provided.</p>

<p style="margin-top: 1em">name <br>
Specify the application name PulseAudio will use when
showing active clients, by default it is the
&quot;LIBAVFORMAT_IDENT&quot; string.</p>

<p style="margin-top: 1em">stream_name <br>
Specify the stream name PulseAudio will use when showing
active streams, by default it is &quot;record&quot;.</p>

<p style="margin-top: 1em">sample_rate <br>
Specify the samplerate in Hz, by default 48kHz is used.</p>

<p style="margin-top: 1em">channels <br>
Specify the channels in use, by default 2 (stereo) is
set.</p>

<p style="margin-top: 1em">frame_size <br>
Specify the number of bytes per frame, by default it is set
to 1024.</p>

<p style="margin-top: 1em">fragment_size <br>
Specify the minimal buffering fragment in PulseAudio, it
will affect the audio latency. By default it is unset.</p>

<p style="margin-top: 1em">wallclock <br>
Set the initial PTS using the current time. Default is
1.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">Record a stream from default
device:</p>

<p style="margin-top: 1em">ffmpeg -f pulse -i default
/tmp/pulse.wav</p>

<p style="margin-top: 1em">qtkit <br>
QTKit input device.</p>

<p style="margin-top: 1em">The filename passed as input is
parsed to contain either a device name or index. The device
index can also be given by using -video_device_index. A
given device index will <br>
override any given device name. If the desired device
consists of numbers only, use -video_device_index to
identify it. The default device will be chosen if an empty
string or <br>
the device name &quot;default&quot; is given. The available
devices can be enumerated by using -list_devices.</p>

<p style="margin-top: 1em">ffmpeg -f qtkit -i &quot;0&quot;
out.mpg</p>

<p style="margin-top: 1em">ffmpeg -f qtkit
-video_device_index 0 -i &quot;&quot; out.mpg</p>

<p style="margin-top: 1em">ffmpeg -f qtkit -i
&quot;default&quot; out.mpg</p>

<p style="margin-top: 1em">ffmpeg -f qtkit -list_devices
true -i &quot;&quot;</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">frame_rate <br>
Set frame rate. Default is 30.</p>

<p style="margin-top: 1em">list_devices <br>
If set to &quot;true&quot;, print a list of devices and
exit. Default is &quot;false&quot;.</p>

<p style="margin-top: 1em">video_device_index <br>
Select the video device by index for devices with the same
name (starts at 0).</p>

<p style="margin-top: 1em">sndio <br>
sndio input device.</p>

<p style="margin-top: 1em">To enable this input device
during configuration you need libsndio installed on your
system.</p>

<p style="margin-top: 1em">The filename to provide to the
input device is the device node representing the sndio input
device, and is usually set to /dev/audio0.</p>

<p style="margin-top: 1em">For example to grab from
/dev/audio0 using ffmpeg use the command:</p>

<p style="margin-top: 1em">ffmpeg -f sndio -i /dev/audio0
/tmp/oss.wav</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">sample_rate <br>
Set the sample rate in Hz. Default is 48000.</p>

<p style="margin-top: 1em">channels <br>
Set the number of channels. Default is 2.</p>

<p style="margin-top: 1em">video4linux2, v4l2 <br>
Video4Linux2 input video device.</p>

<p style="margin-top: 1em">&quot;v4l2&quot; can be used as
alias for &quot;video4linux2&quot;.</p>

<p style="margin-top: 1em">If FFmpeg is built with
v4l-utils support (by using the &quot;--enable-libv4l2&quot;
configure option), it is possible to use it with the
&quot;-use_libv4l2&quot; input device option.</p>

<p style="margin-top: 1em">The name of the device to grab
is a file device node, usually Linux systems tend to
automatically create such nodes when the device (e.g. an USB
webcam) is plugged into the <br>
system, and has a name of the kind /dev/videoN, where N is a
number associated to the device.</p>

<p style="margin-top: 1em">Video4Linux2 devices usually
support a limited set of widthxheight sizes and frame rates.
You can check which are supported using -list_formats all
for Video4Linux2 devices. <br>
Some devices, like TV cards, support one or more standards.
It is possible to list all the supported standards using
-list_standards all.</p>

<p style="margin-top: 1em">The time base for the timestamps
is 1 microsecond. Depending on the kernel version and
configuration, the timestamps may be derived from the real
time clock (origin at the Unix <br>
Epoch) or the monotonic clock (origin usually at boot time,
unaffected by NTP or manual changes to the clock). The
-timestamps abs or -ts abs option can be used to force <br>
conversion into the real time clock.</p>

<p style="margin-top: 1em">Some usage examples of the
video4linux2 device with ffmpeg and ffplay:</p>

<p style="margin-top: 1em">&Acirc;&middot; List supported
formats for a video4linux2 device:</p>

<p style="margin-top: 1em">ffplay -f video4linux2
-list_formats all /dev/video0</p>

<p style="margin-top: 1em">&Acirc;&middot; Grab and show
the input of a video4linux2 device:</p>

<p style="margin-top: 1em">ffplay -f video4linux2
-framerate 30 -video_size hd720 /dev/video0</p>

<p style="margin-top: 1em">&Acirc;&middot; Grab and record
the input of a video4linux2 device, leave the frame rate and
size as previously set:</p>

<p style="margin-top: 1em">ffmpeg -f video4linux2
-input_format mjpeg -i /dev/video0 out.mpeg</p>

<p style="margin-top: 1em">For more information about
Video4Linux, check &lt;http://linuxtv.org/&gt;.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">standard <br>
Set the standard. Must be the name of a supported standard.
To get a list of the supported standards, use the
list_standards option.</p>

<p style="margin-top: 1em">channel <br>
Set the input channel number. Default to -1, which means
using the previously selected channel.</p>

<p style="margin-top: 1em">video_size <br>
Set the video frame size. The argument must be a string in
the form WIDTHxHEIGHT or a valid size abbreviation.</p>

<p style="margin-top: 1em">pixel_format <br>
Select the pixel format (only valid for raw video
input).</p>

<p style="margin-top: 1em">input_format <br>
Set the preferred pixel format (for raw video) or a codec
name. This option allows one to select the input format,
when several are available.</p>

<p style="margin-top: 1em">framerate <br>
Set the preferred video frame rate.</p>

<p style="margin-top: 1em">list_formats <br>
List available formats (supported pixel formats, codecs, and
frame sizes) and exit.</p>

<p style="margin-top: 1em">Available values are:</p>

<p style="margin-top: 1em">all Show all available
(compressed and non-compressed) formats.</p>

<p style="margin-top: 1em">raw Show only raw video
(non-compressed) formats.</p>

<p style="margin-top: 1em">compressed <br>
Show only compressed formats.</p>

<p style="margin-top: 1em">list_standards <br>
List supported standards and exit.</p>

<p style="margin-top: 1em">Available values are:</p>

<p style="margin-top: 1em">all Show all supported
standards.</p>

<p style="margin-top: 1em">timestamps, ts <br>
Set type of timestamps for grabbed frames.</p>

<p style="margin-top: 1em">Available values are:</p>

<p style="margin-top: 1em">default <br>
Use timestamps from the kernel.</p>

<p style="margin-top: 1em">abs Use absolute timestamps
(wall clock).</p>

<p style="margin-top: 1em">mono2abs <br>
Force conversion from monotonic to absolute timestamps.</p>

<p style="margin-top: 1em">Default value is
&quot;default&quot;.</p>

<p style="margin-top: 1em">use_libv4l2 <br>
Use libv4l2 (v4l-utils) conversion functions. Default is
0.</p>

<p style="margin-top: 1em">vfwcap <br>
VfW (Video for Windows) capture input device.</p>

<p style="margin-top: 1em">The filename passed as input is
the capture driver number, ranging from 0 to 9. You may use
&quot;list&quot; as filename to print a list of drivers. Any
other filename will be interpreted <br>
as device number 0.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">video_size <br>
Set the video frame size.</p>

<p style="margin-top: 1em">framerate <br>
Set the grabbing frame rate. Default value is
&quot;ntsc&quot;, corresponding to a frame rate of
&quot;30000/1001&quot;.</p>

<p style="margin-top: 1em">x11grab <br>
X11 video input device.</p>

<p style="margin-top: 1em">To enable this input device
during configuration you need libxcb installed on your
system. It will be automatically detected during
configuration.</p>

<p style="margin-top: 1em">Alternatively, the configure
option --enable-x11grab exists for legacy Xlib users.</p>

<p style="margin-top: 1em">This device allows one to
capture a region of an X11 display.</p>

<p style="margin-top: 1em">The filename passed as input has
the syntax:</p>


<p style="margin-top: 1em">[&lt;hostname&gt;]:&lt;display_number&gt;.&lt;screen_number&gt;[+&lt;x_offset&gt;,&lt;y_offset&gt;]</p>


<p style="margin-top: 1em">hostname:display_number.screen_number
specifies the X11 display name of the screen to grab from.
hostname can be omitted, and defaults to
&quot;localhost&quot;. The environment variable <br>
DISPLAY contains the default display name.</p>

<p style="margin-top: 1em">x_offset and y_offset specify
the offsets of the grabbed area with respect to the top-left
border of the X11 screen. They default to 0.</p>

<p style="margin-top: 1em">Check the X11 documentation
(e.g. man X) for more detailed information.</p>

<p style="margin-top: 1em">Use the xdpyinfo program for
getting basic information about the properties of your X11
display (e.g. grep for &quot;name&quot; or
&quot;dimensions&quot;).</p>

<p style="margin-top: 1em">For example to grab from :0.0
using ffmpeg:</p>

<p style="margin-top: 1em">ffmpeg -f x11grab -framerate 25
-video_size cif -i :0.0 out.mpg</p>

<p style="margin-top: 1em">Grab at position
&quot;10,20&quot;:</p>

<p style="margin-top: 1em">ffmpeg -f x11grab -framerate 25
-video_size cif -i :0.0+10,20 out.mpg</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">draw_mouse <br>
Specify whether to draw the mouse pointer. A value of 0
specifies not to draw the pointer. Default value is 1.</p>

<p style="margin-top: 1em">follow_mouse <br>
Make the grabbed area follow the mouse. The argument can be
&quot;centered&quot; or a number of pixels PIXELS.</p>

<p style="margin-top: 1em">When it is specified with
&quot;centered&quot;, the grabbing region follows the mouse
pointer and keeps the pointer at the center of region;
otherwise, the region follows only when the <br>
mouse pointer reaches within PIXELS (greater than zero) to
the edge of region.</p>

<p style="margin-top: 1em">For example:</p>

<p style="margin-top: 1em">ffmpeg -f x11grab -follow_mouse
centered -framerate 25 -video_size cif -i :0.0 out.mpg</p>

<p style="margin-top: 1em">To follow only when the mouse
pointer reaches within 100 pixels to edge:</p>

<p style="margin-top: 1em">ffmpeg -f x11grab -follow_mouse
100 -framerate 25 -video_size cif -i :0.0 out.mpg</p>

<p style="margin-top: 1em">framerate <br>
Set the grabbing frame rate. Default value is
&quot;ntsc&quot;, corresponding to a frame rate of
&quot;30000/1001&quot;.</p>

<p style="margin-top: 1em">show_region <br>
Show grabbed region on screen.</p>

<p style="margin-top: 1em">If show_region is specified with
1, then the grabbing region will be indicated on screen.
With this option, it is easy to know what is being grabbed
if only a portion of the <br>
screen is grabbed.</p>

<p style="margin-top: 1em">region_border <br>
Set the region border thickness if -show_region 1 is used.
Range is 1 to 128 and default is 3 (XCB-based x11grab
only).</p>

<p style="margin-top: 1em">For example:</p>

<p style="margin-top: 1em">ffmpeg -f x11grab -show_region 1
-framerate 25 -video_size cif -i :0.0+10,20 out.mpg</p>

<p style="margin-top: 1em">With follow_mouse:</p>

<p style="margin-top: 1em">ffmpeg -f x11grab -follow_mouse
centered -show_region 1 -framerate 25 -video_size cif -i
:0.0 out.mpg</p>

<p style="margin-top: 1em">video_size <br>
Set the video frame size. Default value is
&quot;vga&quot;.</p>

<p style="margin-top: 1em">use_shm <br>
Use the MIT-SHM extension for shared memory. Default value
is 1. It may be necessary to disable it for remote displays
(legacy x11grab only).</p>

<p style="margin-top: 1em">grab_x <br>
grab_y <br>
Set the grabbing region coordinates. They are expressed as
offset from the top left corner of the X11 window and
correspond to the x_offset and y_offset parameters in the
<br>
device name. The default value for both options is 0.</p>

<p style="margin-top: 1em">OUTPUT DEVICES <br>
Output devices are configured elements in FFmpeg that can
write multimedia data to an output device attached to your
system.</p>

<p style="margin-top: 1em">When you configure your FFmpeg
build, all the supported output devices are enabled by
default. You can list all available ones using the configure
option &quot;--list-outdevs&quot;.</p>

<p style="margin-top: 1em">You can disable all the output
devices using the configure option
&quot;--disable-outdevs&quot;, and selectively enable an
output device using the option
&quot;--enable-outdev=OUTDEV&quot;, or you <br>
can disable a particular input device using the option
&quot;--disable-outdev=OUTDEV&quot;.</p>

<p style="margin-top: 1em">The option &quot;-devices&quot;
of the ff* tools will display the list of enabled output
devices.</p>

<p style="margin-top: 1em">A description of the currently
available output devices follows.</p>

<p style="margin-top: 1em">alsa <br>
ALSA (Advanced Linux Sound Architecture) output device.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">&Acirc;&middot; Play a file on
default ALSA device:</p>

<p style="margin-top: 1em">ffmpeg -i INPUT -f alsa
default</p>

<p style="margin-top: 1em">&Acirc;&middot; Play a file on
soundcard 1, audio device 7:</p>

<p style="margin-top: 1em">ffmpeg -i INPUT -f alsa
hw:1,7</p>

<p style="margin-top: 1em">caca <br>
CACA output device.</p>

<p style="margin-top: 1em">This output device allows one to
show a video stream in CACA window. Only one CACA window is
allowed per application, so you can have only one instance
of this output device in <br>
an application.</p>

<p style="margin-top: 1em">To enable this output device you
need to configure FFmpeg with &quot;--enable-libcaca&quot;.
libcaca is a graphics library that outputs text instead of
pixels.</p>

<p style="margin-top: 1em">For more information about
libcaca, check: &lt;http://caca.zoy.org/wiki/libcaca&gt;</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">window_title <br>
Set the CACA window title, if not specified default to the
filename specified for the output device.</p>

<p style="margin-top: 1em">window_size <br>
Set the CACA window size, can be a string of the form
widthxheight or a video size abbreviation. If not specified
it defaults to the size of the input video.</p>

<p style="margin-top: 1em">driver <br>
Set display driver.</p>

<p style="margin-top: 1em">algorithm <br>
Set dithering algorithm. Dithering is necessary because the
picture being rendered has usually far more colours than the
available palette. The accepted values are listed <br>
with &quot;-list_dither algorithms&quot;.</p>

<p style="margin-top: 1em">antialias <br>
Set antialias method. Antialiasing smoothens the rendered
image and avoids the commonly seen staircase effect. The
accepted values are listed with &quot;-list_dither <br>
antialiases&quot;.</p>

<p style="margin-top: 1em">charset <br>
Set which characters are going to be used when rendering
text. The accepted values are listed with &quot;-list_dither
charsets&quot;.</p>

<p style="margin-top: 1em">color <br>
Set color to be used when rendering text. The accepted
values are listed with &quot;-list_dither colors&quot;.</p>

<p style="margin-top: 1em">list_drivers <br>
If set to true, print a list of available drivers and
exit.</p>

<p style="margin-top: 1em">list_dither <br>
List available dither options related to the argument. The
argument must be one of &quot;algorithms&quot;,
&quot;antialiases&quot;, &quot;charsets&quot;,
&quot;colors&quot;.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">&Acirc;&middot; The following
command shows the ffmpeg output is an CACA window, forcing
its size to 80x25:</p>

<p style="margin-top: 1em">ffmpeg -i INPUT -vcodec rawvideo
-pix_fmt rgb24 -window_size 80x25 -f caca -</p>

<p style="margin-top: 1em">&Acirc;&middot; Show the list of
available drivers and exit:</p>

<p style="margin-top: 1em">ffmpeg -i INPUT -pix_fmt rgb24
-f caca -list_drivers true -</p>

<p style="margin-top: 1em">&Acirc;&middot; Show the list of
available dither colors and exit:</p>

<p style="margin-top: 1em">ffmpeg -i INPUT -pix_fmt rgb24
-f caca -list_dither colors -</p>

<p style="margin-top: 1em">decklink <br>
The decklink output device provides playback capabilities
for Blackmagic DeckLink devices.</p>

<p style="margin-top: 1em">To enable this output device,
you need the Blackmagic DeckLink SDK and you need to
configure with the appropriate &quot;--extra-cflags&quot;
and &quot;--extra-ldflags&quot;. On Windows, you need to
<br>
run the IDL files through widl.</p>

<p style="margin-top: 1em">DeckLink is very picky about the
formats it supports. Pixel format is always uyvy422,
framerate and video size must be determined for your device
with -list_formats 1. Audio <br>
sample rate is always 48 kHz.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">list_devices <br>
If set to true, print a list of devices and exit. Defaults
to false.</p>

<p style="margin-top: 1em">list_formats <br>
If set to true, print a list of supported formats and exit.
Defaults to false.</p>

<p style="margin-top: 1em">preroll <br>
Amount of time to preroll video in seconds. Defaults to
0.5.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">&Acirc;&middot; List output
devices:</p>

<p style="margin-top: 1em">ffmpeg -i test.avi -f decklink
-list_devices 1 dummy</p>

<p style="margin-top: 1em">&Acirc;&middot; List supported
formats:</p>

<p style="margin-top: 1em">ffmpeg -i test.avi -f decklink
-list_formats 1 &rsquo;DeckLink Mini Monitor&rsquo;</p>

<p style="margin-top: 1em">&Acirc;&middot; Play video
clip:</p>

<p style="margin-top: 1em">ffmpeg -i test.avi -f decklink
-pix_fmt uyvy422 &rsquo;DeckLink Mini Monitor&rsquo;</p>

<p style="margin-top: 1em">&Acirc;&middot; Play video clip
with non-standard framerate or video size:</p>

<p style="margin-top: 1em">ffmpeg -i test.avi -f decklink
-pix_fmt uyvy422 -s 720x486 -r 24000/1001 &rsquo;DeckLink
Mini Monitor&rsquo;</p>

<p style="margin-top: 1em">fbdev <br>
Linux framebuffer output device.</p>

<p style="margin-top: 1em">The Linux framebuffer is a
graphic hardware-independent abstraction layer to show
graphics on a computer monitor, typically on the console. It
is accessed through a file device <br>
node, usually /dev/fb0.</p>

<p style="margin-top: 1em">For more detailed information
read the file Documentation/fb/framebuffer.txt included in
the Linux source tree.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">xoffset <br>
yoffset <br>
Set x/y coordinate of top left corner. Default is 0.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">Play a file on framebuffer
device /dev/fb0. Required pixel format depends on current
framebuffer settings.</p>

<p style="margin-top: 1em">ffmpeg -re -i INPUT -vcodec
rawvideo -pix_fmt bgra -f fbdev /dev/fb0</p>

<p style="margin-top: 1em">See also
&lt;http://linux-fbdev.sourceforge.net/&gt;, and
fbset(1).</p>

<p style="margin-top: 1em">opengl <br>
OpenGL output device.</p>

<p style="margin-top: 1em">To enable this output device you
need to configure FFmpeg with
&quot;--enable-opengl&quot;.</p>

<p style="margin-top: 1em">This output device allows one to
render to OpenGL context. Context may be provided by
application or default SDL window is created.</p>

<p style="margin-top: 1em">When device renders to external
context, application must implement handlers for following
messages: &quot;AV_DEV_TO_APP_CREATE_WINDOW_BUFFER&quot; -
create OpenGL context on current <br>
thread. &quot;AV_DEV_TO_APP_PREPARE_WINDOW_BUFFER&quot; -
make OpenGL context current.
&quot;AV_DEV_TO_APP_DISPLAY_WINDOW_BUFFER&quot; - swap
buffers. &quot;AV_DEV_TO_APP_DESTROY_WINDOW_BUFFER&quot; -
<br>
destroy OpenGL context. Application is also required to
inform a device about current resolution by sending
&quot;AV_APP_TO_DEV_WINDOW_SIZE&quot; message.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">background <br>
Set background color. Black is a default.</p>

<p style="margin-top: 1em">no_window <br>
Disables default SDL window when set to non-zero value.
Application must provide OpenGL context and both
&quot;window_size_cb&quot; and
&quot;window_swap_buffers_cb&quot; callbacks when set.</p>

<p style="margin-top: 1em">window_title <br>
Set the SDL window title, if not specified default to the
filename specified for the output device. Ignored when
no_window is set.</p>

<p style="margin-top: 1em">window_size <br>
Set preferred window size, can be a string of the form
widthxheight or a video size abbreviation. If not specified
it defaults to the size of the input video, downscaled <br>
according to the aspect ratio. Mostly usable when no_window
is not set.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">Play a file on SDL window using
OpenGL rendering:</p>

<p style="margin-top: 1em">ffmpeg -i INPUT -f opengl
&quot;window title&quot;</p>

<p style="margin-top: 1em">oss <br>
OSS (Open Sound System) output device.</p>

<p style="margin-top: 1em">pulse <br>
PulseAudio output device.</p>

<p style="margin-top: 1em">To enable this output device you
need to configure FFmpeg with
&quot;--enable-libpulse&quot;.</p>

<p style="margin-top: 1em">More information about
PulseAudio can be found on
&lt;http://www.pulseaudio.org&gt;</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">server <br>
Connect to a specific PulseAudio server, specified by an IP
address. Default server is used when not provided.</p>

<p style="margin-top: 1em">name <br>
Specify the application name PulseAudio will use when
showing active clients, by default it is the
&quot;LIBAVFORMAT_IDENT&quot; string.</p>

<p style="margin-top: 1em">stream_name <br>
Specify the stream name PulseAudio will use when showing
active streams, by default it is set to the specified output
name.</p>

<p style="margin-top: 1em">device <br>
Specify the device to use. Default device is used when not
provided. List of output devices can be obtained with
command pactl list sinks.</p>

<p style="margin-top: 1em">buffer_size <br>
buffer_duration <br>
Control the size and duration of the PulseAudio buffer. A
small buffer gives more control, but requires more frequent
updates.</p>

<p style="margin-top: 1em">buffer_size specifies size in
bytes while buffer_duration specifies duration in
milliseconds.</p>

<p style="margin-top: 1em">When both options are provided
then the highest value is used (duration is recalculated to
bytes using stream parameters). If they are set to 0 (which
is default), the device <br>
will use the default PulseAudio duration value. By default
PulseAudio set buffer duration to around 2 seconds.</p>

<p style="margin-top: 1em">prebuf <br>
Specify pre-buffering size in bytes. The server does not
start with playback before at least prebuf bytes are
available in the buffer. By default this option is
initialized <br>
to the same value as buffer_size or buffer_duration
(whichever is bigger).</p>

<p style="margin-top: 1em">minreq <br>
Specify minimum request size in bytes. The server does not
request less than minreq bytes from the client, instead
waits until the buffer is free enough to request more bytes
<br>
at once. It is recommended to not set this option, which
will initialize this to a value that is deemed sensible by
the server.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">Play a file on default device on
default server:</p>

<p style="margin-top: 1em">ffmpeg -i INPUT -f pulse
&quot;stream name&quot;</p>

<p style="margin-top: 1em">sdl <br>
SDL (Simple DirectMedia Layer) output device.</p>

<p style="margin-top: 1em">This output device allows one to
show a video stream in an SDL window. Only one SDL window is
allowed per application, so you can have only one instance
of this output device in <br>
an application.</p>

<p style="margin-top: 1em">To enable this output device you
need libsdl installed on your system when configuring your
build.</p>

<p style="margin-top: 1em">For more information about SDL,
check: &lt;http://www.libsdl.org/&gt;</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">window_title <br>
Set the SDL window title, if not specified default to the
filename specified for the output device.</p>

<p style="margin-top: 1em">icon_title <br>
Set the name of the iconified SDL window, if not specified
it is set to the same value of window_title.</p>

<p style="margin-top: 1em">window_size <br>
Set the SDL window size, can be a string of the form
widthxheight or a video size abbreviation. If not specified
it defaults to the size of the input video, downscaled <br>
according to the aspect ratio.</p>

<p style="margin-top: 1em">window_fullscreen <br>
Set fullscreen mode when non-zero value is provided. Default
value is zero.</p>

<p style="margin-top: 1em">Interactive commands</p>

<p style="margin-top: 1em">The window created by the device
can be controlled through the following interactive
commands.</p>

<p style="margin-top: 1em">q, ESC <br>
Quit the device immediately.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">The following command shows the
ffmpeg output is an SDL window, forcing its size to the qcif
format:</p>

<p style="margin-top: 1em">ffmpeg -i INPUT -vcodec rawvideo
-pix_fmt yuv420p -window_size qcif -f sdl &quot;SDL
output&quot;</p>

<p style="margin-top: 1em">sndio <br>
sndio audio output device.</p>

<p style="margin-top: 1em">xv <br>
XV (XVideo) output device.</p>

<p style="margin-top: 1em">This output device allows one to
show a video stream in a X Window System window.</p>

<p style="margin-top: 1em">Options</p>

<p style="margin-top: 1em">display_name <br>
Specify the hardware display name, which determines the
display and communications domain to be used.</p>

<p style="margin-top: 1em">The display name or DISPLAY
environment variable can be a string in the format
hostname[:number[.screen_number]].</p>

<p style="margin-top: 1em">hostname specifies the name of
the host machine on which the display is physically
attached. number specifies the number of the display server
on that host machine. <br>
screen_number specifies the screen to be used on that
server.</p>

<p style="margin-top: 1em">If unspecified, it defaults to
the value of the DISPLAY environment variable.</p>

<p style="margin-top: 1em">For example,
&quot;dual-headed:0.1&quot; would specify screen 1 of
display 0 on the machine named
&lsquo;&lsquo;dual-headed&rsquo;&rsquo;.</p>

<p style="margin-top: 1em">Check the X11 specification for
more detailed information about the display name format.</p>

<p style="margin-top: 1em">window_id <br>
When set to non-zero value then device doesn&rsquo;t create
new window, but uses existing one with provided window_id.
By default this options is set to zero and device creates
its <br>
own window.</p>

<p style="margin-top: 1em">window_size <br>
Set the created window size, can be a string of the form
widthxheight or a video size abbreviation. If not specified
it defaults to the size of the input video. Ignored when
<br>
window_id is set.</p>

<p style="margin-top: 1em">window_x <br>
window_y <br>
Set the X and Y window offsets for the created window. They
are both set to 0 by default. The values may be ignored by
the window manager. Ignored when window_id is set.</p>

<p style="margin-top: 1em">window_title <br>
Set the window title, if not specified default to the
filename specified for the output device. Ignored when
window_id is set.</p>

<p style="margin-top: 1em">For more information about
XVideo see &lt;http://www.x.org/&gt;.</p>

<p style="margin-top: 1em">Examples</p>

<p style="margin-top: 1em">&Acirc;&middot; Decode, display
and encode video input with ffmpeg at the same time:</p>

<p style="margin-top: 1em">ffmpeg -i INPUT OUTPUT -f xv
display</p>

<p style="margin-top: 1em">&Acirc;&middot; Decode and
display the input video to multiple X11 windows:</p>

<p style="margin-top: 1em">ffmpeg -i INPUT -f xv normal -vf
negate -f xv negated</p>

<p style="margin-top: 1em">SEE ALSO <br>
ffmpeg(1), ffplay(1), ffprobe(1), ffserver(1),
libavdevice(3)</p>

<p style="margin-top: 1em">AUTHORS <br>
The FFmpeg developers.</p>

<p style="margin-top: 1em">For details about the
authorship, see the Git history of the project
(git://source.ffmpeg.org/ffmpeg), e.g. by typing the command
git log in the FFmpeg source directory, or <br>
browsing the online repository at
&lt;http://source.ffmpeg.org&gt;.</p>

<p style="margin-top: 1em">Maintainers for the specific
components are listed in the file MAINTAINERS in the source
code tree.</p>
 
<p style="margin-top: 1em">FFMPEG-DEVICES(1)</p>
<hr>
</body>
</html>
