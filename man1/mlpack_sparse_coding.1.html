<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 16:25:48 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>mlpack_sparse_coding(1) General Commands Manual
mlpack_sparse_coding(1)</p>

<p style="margin-top: 1em">NAME <br>
mlpack_sparse_coding - sparse coding</p>

<p style="margin-top: 1em">SYNOPSIS <br>
mlpack_sparse_coding [-h] [-v] [-k int] [-c string] [-d
string] [-i string] [-m string] [-l double] [-L double] [-n
int] [-w double] [-N] [-o double] [-M string] [-s int] [-T
string] [-t string] -V</p>

<p style="margin-top: 1em">DESCRIPTION <br>
An implementation of Sparse Coding with Dictionary Learning,
which achieves sparsity via an l1-norm regularizer on the
codes (LASSO) or an (l1+l2)-norm regularizer on the codes
<br>
(the Elastic Net). Given a dense data matrix X with n points
and d dimensions, sparse coding seeks to find a dense
dictionary matrix D with k atoms in d dimensions, and a
sparse <br>
coding matrix Z with n points in k dimensions.</p>

<p style="margin-top: 1em">The original data matrix X can
then be reconstructed as D * Z. Therefore, this program
finds a representation of each point in X as a sparse linear
combination of atoms in the <br>
dictionary D.</p>

<p style="margin-top: 1em">The sparse coding is found with
an algorithm which alternates between a dictionary step,
which updates the dictionary D, and a sparse coding step,
which updates the sparse coding <br>
matrix.</p>

<p style="margin-top: 1em">Once a dictionary D is found,
the sparse coding model may be used to encode other
matrices, and saved for future usage.</p>

<p style="margin-top: 1em">To run this program, either an
input matrix or an already-saved sparse coding model must be
specified. An input matrix may be specified with the
--training_file (-t) option, <br>
along with the number of atoms in the dictionary (--atoms,
or -k). It is also possible to specify an initial dictionary
for the optimization, with the --initial_dictionary (-i)
<br>
option. An input model may be specified with the
--input_model_file (-m) option. There are also other
training options available.</p>

<p style="margin-top: 1em">As an example, to build a sparse
coding model on the dataset in data.csv using 200 atoms and
an l1-regularization parameter of 0.1, saving the model into
model.xml, use</p>

<p style="margin-top: 1em">$ sparse_coding -t data.csv -k
200 -l 0.1 -M model.xml</p>

<p style="margin-top: 1em">Then, this model could be used
to encode a new matrix, otherdata.csv, and save the output
codes to codes.csv:</p>

<p style="margin-top: 1em">$ sparse_coding -m model.xml -T
otherdata.csv -c codes.csv</p>

<p style="margin-top: 1em">OPTIONS <br>
--atoms (-k) [int] <br>
Number of atoms in the dictionary. Default value 0.</p>

<p style="margin-top: 1em">--codes_file (-c) [string] <br>
Filename to save the output sparse codes to. Default value
&rsquo;&rsquo;. --dictionary_file (-d) [string] Filename to
save the output dictionary to. Default value
&rsquo;&rsquo;.</p>

<p style="margin-top: 1em">--help (-h) <br>
Default help info.</p>

<p style="margin-top: 1em">--info [string] <br>
Get help on a specific module or option. Default value
&rsquo;&rsquo;. --initial_dictionary (-i) [string] Filename
for optional initial dictionary. Default value
&rsquo;&rsquo;. <br>
--input_model_file (-m) [string] File containing input
sparse coding model. Default value &rsquo;&rsquo;.</p>

<p style="margin-top: 1em">--lambda1 (-l) [double] <br>
Sparse coding l1-norm regularization parameter. Default
value 0.</p>

<p style="margin-top: 1em">--lambda2 (-L) [double] <br>
Sparse coding l2-norm regularization parameter. Default
value 0.</p>

<p style="margin-top: 1em">--max_iterations (-n) [int] <br>
Maximum number of iterations for sparse coding (0 indicates
no limit). Default value 0. --newton_tolerance (-w) [double]
Tolerance for convergence of Newton method. <br>
Default value 1e-06.</p>

<p style="margin-top: 1em">--normalize (-N) <br>
If set, the input data matrix will be normalized before
coding. --objective_tolerance (-o) [double] Tolerance for
convergence of the objective function. Default value <br>
0.01. --output_model_file (-M) [string] File to save trained
sparse coding model to. Default value &rsquo;&rsquo;.</p>

<p style="margin-top: 1em">--seed (-s) [int] <br>
Random seed. If 0, &rsquo;std::time(NULL)&rsquo; is used.
Default value 0.</p>

<p style="margin-top: 1em">--test_file (-T) [string] <br>
File containing data matrix to be encoded by trained model.
Default value &rsquo;&rsquo;. --training_file (-t) [string]
Filename of the training data (X). Default value
&rsquo;&rsquo;.</p>

<p style="margin-top: 1em">--verbose (-v) <br>
Display informational messages and the full list of
parameters and timers at the end of execution.</p>

<p style="margin-top: 1em">--version (-V) <br>
Display the version of mlpack.</p>

<p style="margin-top: 1em">ADDITIONAL INFORMATION
ADDITIONAL INFORMATION <br>
For further information, including relevant papers,
citations, and theory, For further information, including
relevant papers, citations, and theory, consult the
documentation <br>
found at http://www.mlpack.org or included with your consult
the documentation found at http://www.mlpack.org or included
with your DISTRIBUTION OF MLPACK. DISTRIBUTION OF <br>
MLPACK.</p>
 
<p style="margin-top: 1em">mlpack_sparse_coding(1)</p>
<hr>
</body>
</html>
