<!-- Creator     : groff version 1.22.3 -->
<!-- CreationDate: Sun Aug 27 15:53:07 2017 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p       { margin-top: 0; margin-bottom: 0; vertical-align: top }
       pre     { margin-top: 0; margin-bottom: 0; vertical-align: top }
       table   { margin-top: 0; margin-bottom: 0; vertical-align: top }
       h1      { text-align: center }
</style>
<title></title>
</head>
<body>

<hr>


<p>AUTOCLASS(1) General Commands Manual AUTOCLASS(1)</p>

<p style="margin-top: 1em">NAME <br>
autoclass - automatically discover classes in data</p>

<p style="margin-top: 1em">SYNOPSIS <br>
autoclass -search data_file header_file model_file
s_param_file <br>
autoclass -report results_file search_file r_params_file
<br>
autoclass -predict results_file search_file results_file</p>

<p style="margin-top: 1em">DESCRIPTION <br>
AutoClass solves the problem of automatic discovery of
classes in data (sometimes called clustering, or
unsupervised learning), as distinct from the generation of
class descrip&acirc; <br>
tions from labeled examples (called supervised learning). It
aims to discover the &quot;natural&quot; classes in the
data. AutoClass is applicable to observations of things that
can be <br>
described by a set of attributes, without referring to other
things. The data values corresponding to each attribute are
limited to be either numbers or the elements of a fixed <br>
set of symbols. With numeric data, a measurement error must
be provided.</p>

<p style="margin-top: 1em">AutoClass is looking for the
best classification(s) of the data it can find. A
classification is composed of:</p>

<p style="margin-top: 1em">1) A set of classes, each of
which is described by a set of class parameters, which
specify how the class is distributed along the various
attributes. For example, &quot;height <br>
normally distributed with mean 4.67 ft and standard
deviation .32 ft&quot;,</p>

<p style="margin-top: 1em">2) A set of class weights,
describing what percentage of cases are likely to be in each
class.</p>

<p style="margin-top: 1em">3) A probabilistic assignment of
cases in the data to these classes. I.e. for each case, the
relative probability that it is a member of each class.</p>

<p style="margin-top: 1em">As a strictly Bayesian system
(accept no substitutes!), the quality measure AutoClass uses
is the total probability that, had you known nothing about
your data or its domain, you <br>
would have found this set of data generated by this
underlying model. This includes the prior probability that
the &quot;world&quot; would have chosen this number of
classes, this set of <br>
relative class weights, and this set of parameters for each
class, and the likelihood that such a set of classes would
have generated this set of values for the attributes in the
<br>
data cases.</p>

<p style="margin-top: 1em">These probabilities are
typically very small, in the range of e^-30000, and so are
usually expressed in exponential notation.</p>

<p style="margin-top: 1em">When run with the -search
command, AutoClass searches for a classification. The
required arguments are the paths to the four input files,
which supply the data, the data format, <br>
the desired classification model, and the search parameters,
respectively.</p>

<p style="margin-top: 1em">By default, AutoClass writes
intermediate results in a binary file. With the -report
command, AutoClass generates an ASCII report. The arguments
are the full path names of the <br>
.results, .search, and .r-params files.</p>

<p style="margin-top: 1em">When run with the -predict
command, AutoClass predicts the class membership of a
&quot;test&quot; data set based on classes found in a
&quot;training&quot; data set (see &quot;PREDICTIONS&quot;
below).</p>

<p style="margin-top: 1em">INPUT FILES <br>
An AutoClass data set resides in two files. There is a
header file (file type &quot;hd2&quot;) that describes the
specific data format and attribute definitions. The actual
data values <br>
are in a data file (file type &quot;db2&quot;). We use two
files to allow editing of data descriptions without having
to deal with the entire data set. This makes it easy to
experiment <br>
with different descriptions of the database without having
to reproduce the data set. Internally, an AutoClass database
structure is identified by its header and data files, and
<br>
the number of data loaded.</p>

<p style="margin-top: 1em">For more detailed information on
the formats of these files, see
/usr/share/doc/autoclass/preparation-c.text.</p>

<p style="margin-top: 1em">DATA FILE <br>
The data file contains a sequence of data objects (datum or
case) terminated by the end of the file. The number of
values for each data object must be equal to the number of
<br>
attributes defined in the header file. Data objects must be
groups of tokens delimited by &quot;new-line&quot;.
Attributes are typed as REAL, DISCRETE, or DUMMY. Real
attribute values <br>
are numbers, either integer or floating point. Discrete
attribute values can be strings, symbols, or integers. A
dummy attribute value can be any of these types. Dummys are
<br>
read in but otherwise ignored -- they will be set to zeros
in the the internal database. Thus the actual values will
not be available for use in report output. To have these
<br>
attribute values available, use either type REAL or type
DISCRETE, and define their model type as IGNORE in the
.model file. Missing values for any attribute type may be
repre&acirc; <br>
sented by either &quot;?&quot;, or other token specified in
the header file. All are translated to a special unique
value after being read, so this symbol is effectively
reserved for <br>
unknown/missing values.</p>

<p style="margin-top: 1em">For example: <br>
white 38.991306 0.54248405 2 2 1 <br>
red 25.254923 0.5010235 9 2 1 <br>
yellow 32.407973 ? 8 2 1 <br>
all_white 28.953982 0.5267696 0 1 1</p>

<p style="margin-top: 1em">HEADER FILE <br>
The header file specifies the data file format, and the
definitions of the data attributes. The header file
functional specifications consists of two parts -- the data
set for&acirc; <br>
mat definition specifications, and the attribute
descriptors. &quot;;&quot; in column 1 identifies a
comment.</p>

<p style="margin-top: 1em">A header file follows this
general format:</p>

<p style="margin-top: 1em">;; num_db2_format_defs value
(number of format def lines <br>
;; that follow), range of n is 1 -&gt; 5 <br>
num_db2_format_defs n <br>
;; number_of_attributes token and value required <br>
number_of_attributes &lt;as required&gt; <br>
;; following are optional - default values are specified
<br>
separator_char &rsquo; &rsquo; <br>
comment_char &rsquo;;&rsquo; <br>
unknown_token &rsquo;?&rsquo; <br>
separator_char &rsquo;,&rsquo;</p>

<p style="margin-top: 1em">;; attribute descriptors <br>
;; &lt;zero-based att#&gt; &lt;att_type&gt;
&lt;att_sub_type&gt; &lt;att_description&gt; <br>
;; &lt;att_param_pairs&gt;</p>

<p style="margin-top: 1em">Each attribute descriptor is a
line of:</p>

<p style="margin-top: 1em">Attribute index (zero based,
beginning in column 1) <br>
Attribute type. See below. <br>
Attribute subtype. See below <br>
Attribute description: symbol (no embedded blanks) or <br>
string; &lt;= 40 characters <br>
Specific property and value pairs. <br>
Currently available combinations:</p>

<p style="margin-top: 1em">type subtype property type(s)
<br>
---- -------- --------------- <br>
dummy none/nil -- <br>
discrete nominal range <br>
real location error <br>
real scalar zero_point rel_error</p>

<p style="margin-top: 1em">The ERROR property should
represent your best estimate of the average error expected
in the measurement and recording of that real attribute.
Lacking better information, the <br>
error can be taken as 1/2 the minimum possible difference
between measured values. It can be argued that real values
are often truncated, so that smaller errors may be
justi&acirc; <br>
fied, particularly for generated data. But AutoClass only
sees the recorded values. So it needs the error in the
recorded values, rather than the actual measurement error.
<br>
Setting this error much smaller than the minimum expressible
difference implies the possibility of values that cannot be
expressed in the data. Worse, it implies that two
iden&acirc; <br>
tical values must represent measurements that were much
closer than they might actually have been. This leads to
over-fitting of the classification.</p>

<p style="margin-top: 1em">The REL_ERROR property is used
for SCALAR reals when the error is proportional to the
measured value. The ERROR property is not supported.</p>

<p style="margin-top: 1em">AutoClass uses the error as a
lower bound on the width of the normal distribution. So
small error estimates tend to give narrower peaks and to
increase both the number of <br>
classes and the classification probability. Broad error
estimates tend to limit the number of classes.</p>

<p style="margin-top: 1em">The scalar ZERO_POINT property
is the smallest value that the measurement process could
have produced. This is often 0.0, or less by some error
range. Similarly, the bounded <br>
real&rsquo;s min and max properties are exclusive bounds on
the attributes generating process. For a calculated
percentage these would be 0-e and 100+e, where e is an error
value. <br>
The discrete attribute&rsquo;s range is the number of
possible values the attribute can take on. This range must
include unknown as a value when such values occur.</p>

<p style="margin-top: 1em">Header File Example:</p>

<p style="margin-top: 1em">!#; AutoClass C header file --
extension .hd2 <br>
!#; the following chars in column 1 make the line a comment:
<br>
!#; &rsquo;!&rsquo;, &rsquo;#&rsquo;, &rsquo;;&rsquo;,
&rsquo; &rsquo;, and &rsquo;0 (empty line)</p>

<p style="margin-top: 1em">;#! num_db2_format_defs &lt;num
of def lines -- min 1, max 4&gt; <br>
num_db2_format_defs 2 <br>
;; required <br>
number_of_attributes 7 <br>
;; optional - default values are specified <br>
;; separator_char &rsquo; &rsquo; <br>
;; comment_char &rsquo;;&rsquo; <br>
;; unknown_token &rsquo;?&rsquo; <br>
separator_char &rsquo;,&rsquo;</p>

<p style="margin-top: 1em">;; &lt;zero-based att#&gt;
&lt;att_type&gt; &lt;att_sub_type&gt;
&lt;att_description&gt; <br>
&lt;att_param_pairs&gt; <br>
0 dummy nil &quot;True class, range = 1 - 3&quot; <br>
1 real location &quot;X location, m. in range of 25.0 -
40.0&quot; error .25 <br>
2 real location &quot;Y location, m. in range of 0.5 -
0.7&quot; error .05 <br>
3 real scalar &quot;Weight, kg. in range of 5.0 - 10.0&quot;
zero_point 0.0 <br>
rel_error .001 <br>
4 discrete nominal &quot;Truth value, range = 1 - 2&quot;
range 2 <br>
5 discrete nominal &quot;Color of foobar, 10 values&quot;
range 10 <br>
6 discrete nominal Spectral_color_group range 6</p>

<p style="margin-top: 1em">MODEL FILE <br>
A classification of a data set is made with respect to a
model which specifies the form of the probability
distribution function for classes in that data set. Normally
the model <br>
structure is defined in a model file (file type
&quot;model&quot;), containing one or more models.
Internally, a model is defined relative to a particular
database. Thus it is identified <br>
by the corresponding database, the model&rsquo;s model file
and its sequential position in the file.</p>

<p style="margin-top: 1em">Each model is specified by one
or more model group definition lines. Each model group line
associates attribute indices with a model term type.</p>

<p style="margin-top: 1em">Here is an example model
file:</p>

<p style="margin-top: 1em"># AutoClass C model file --
extension .model <br>
model_index 0 7 <br>
ignore 0 <br>
single_normal_cn 3 <br>
single_normal_cn 17 18 21 <br>
multi_normal_cn 1 2 <br>
multi_normal_cn 8 9 10 <br>
multi_normal_cn 11 12 13 <br>
single_multinomial default</p>

<p style="margin-top: 1em">Here, the first line is a
comment. The following characters in column 1 make the line
a comment: &lsquo;!&rsquo;, &lsquo;#&rsquo;, &lsquo;
&rsquo;, &lsquo;;&rsquo;, and &lsquo;0 (empty line).</p>

<p style="margin-top: 1em">The tokens &quot;model_index n
m&quot; must appear on the first non-comment line, and
precede the model term definition lines. n is the zero-based
model index, typically 0 where there is <br>
only one model -- the majority of search situations. m is
the number of model term definition lines that follow.</p>

<p style="margin-top: 1em">The last seven lines are model
group lines. Each model group line consists of:</p>

<p style="margin-top: 1em">A model term type (one of
single_multinomial, single_normal_cm, single_normal_cn,
multi_normal_cn, or ignore).</p>

<p style="margin-top: 1em">A list of attribute indices (the
attribute set list), or the symbol default. Attribute
indices are zero-based. Single model terms may have one or
more attribute indices on each <br>
line, while multi model terms require two or more attribute
indices per line. An attribute index must not appear more
than once in a model list.</p>

<p style="margin-top: 1em">Notes:</p>

<p style="margin-top: 1em">1) At least one model definition
is required (model_index token).</p>

<p style="margin-top: 1em">2) There may be multiple entries
in a model for any model term type.</p>

<p style="margin-top: 1em">3) Model term types currently
consist of:</p>

<p style="margin-top: 1em">single_multinomial <br>
models discrete attributes as multinomials, with missing
values.</p>

<p style="margin-top: 1em">single_normal_cn <br>
models real valued attributes as normals; no missing
values.</p>

<p style="margin-top: 1em">single_normal_cm <br>
models real valued attributes with missing values.</p>

<p style="margin-top: 1em">multi_normal_cn <br>
is a covariant normal model without missing values.</p>

<p style="margin-top: 1em">ignore allows the model to
ignore one or more attributes. ignore is not a valid default
model term type.</p>

<p style="margin-top: 1em">See the documentation in
models-c.text for further information about specific model
terms.</p>

<p style="margin-top: 1em">4) Single_normal_cn,
single_normal_cm, and multi_normal_cn modeled data, whose
subtype is scalar (value distribution is away from 0.0, and
is thus not a &quot;normal&quot; distribu&acirc; <br>
tion) will be log transformed and modeled with the
log-normal model. For data whose subtype is location (value
distribution is around 0.0), no transform is done, and the
<br>
normal model is used.</p>

<p style="margin-top: 1em">SEARCHING <br>
AutoClass, when invoked in the &quot;search&quot; mode will
check the validity of the set of data, header, model, and
search parameter files. Errors will stop the search from
starting, <br>
and warnings will ask the user whether to continue. A
history of the error and warning messages is saved, by
default, in the log file.</p>

<p style="margin-top: 1em">Once you have succeeded in
describing your data with a header file and model file that
passes the AUTOCLASS -SEARCH &lt;...&gt; input checks, you
will have entered the search domain <br>
where AutoClass classifies your data. (At last!)</p>

<p style="margin-top: 1em">The main function to use in
finding a good classification of your data is AUTOCLASS
-SEARCH, and using it will take most of the computation
time. Searches are invoked with:</p>

<p style="margin-top: 1em">autoclass -search &lt;.db2 file
path&gt; &lt;.hd2 file path&gt; <br>
&lt;.model file path&gt; &lt;.s-params file path&gt;</p>

<p style="margin-top: 1em">All files must be specified as
fully qualified relative or absolute pathnames. File name
extensions (file types) for all files are forced to
canonical values required by the Au&acirc; <br>
toClass program:</p>

<p style="margin-top: 1em">data file (&quot;ascii&quot;)
db2 <br>
data file (&quot;binary&quot;) db2-bin <br>
header file hd2 <br>
model file model <br>
search params file s-params</p>

<p style="margin-top: 1em">The sample-run
(/usr/share/doc/autoclass/examples/) that comes with
AutoClass shows some sample searches, and browsing these is
probably the fastest way to get familiar with how <br>
to do searches. The test data sets located under
/usr/share/doc/autoclass/examples/ will show you some other
header (.hd2), model (.model), and search params (.s-params)
file <br>
setups. The remainder of this section describes how to do
searches in somewhat more detail.</p>

<p style="margin-top: 1em">The bold faced tokens below are
generally search params file parameters. For more
information on the s-params file, see SEARCH PARAMETERS
below, or /usr/share/doc/auto&acirc; <br>
class/search-c.text.gz.</p>

<p style="margin-top: 1em">WHAT RESULTS ARE <br>
AutoClass is looking for the best classification(s) of the
data it can find. A classification is composed of:</p>

<p style="margin-top: 1em">1) a set of classes, each of
which is described by a set of class parameters, which
specify how the class is distributed along the various
attributes. For example, &quot;height <br>
normally distributed with mean 4.67 ft and standard
deviation .32 ft&quot;,</p>

<p style="margin-top: 1em">2) a set of class weights,
describing what percentage of cases are likely to be in each
class.</p>

<p style="margin-top: 1em">3) a probabilistic assignment of
cases in the data to these classes. I.e. for each case, the
relative probability that it is a member of each class.</p>

<p style="margin-top: 1em">As a strictly Bayesian system
(accept no substitutes!), the quality measure AutoClass uses
is the total probability that, had you known nothing about
your data or its domain, you <br>
would have found this set of data generated by this
underlying model. This includes the prior probability that
the &quot;world&quot; would have chosen this number of
classes, this set of <br>
relative class weights, and this set of parameters for each
class, and the likelihood that such a set of classes would
have generated this set of values for the attributes in the
<br>
data cases.</p>

<p style="margin-top: 1em">These probabilities are
typically very small, in the range of e^-30000, and so are
usually expressed in exponential notation.</p>

<p style="margin-top: 1em">WHAT RESULTS MEAN <br>
It is important to remember that all of these probabilities
are GIVEN that the real model is in the model family that
AutoClass has restricted its attention to. If AutoClass is
<br>
looking for Gaussian classes and the real classes are
Poisson, then the fact that AutoClass found 5 Gaussian
classes may not say much about how many Poisson classes
there really <br>
are.</p>

<p style="margin-top: 1em">The relative probability between
different classifications found can be very large, like
e^1000, so the very best classification found is usually
overwhelmingly more probable <br>
than the rest (and overwhelmingly less probable than any
better classifications as yet undiscovered). If AutoClass
should manage to find two classifications that are within
<br>
about exp(5-10) of each other (i.e. within 100 to 10,000
times more probable) then you should consider them to be
about equally probable, as our computation is usually not
more <br>
accurate than this (and sometimes much less).</p>

<p style="margin-top: 1em">HOW IT WORKS <br>
AutoClass repeatedly creates a random classification and
then tries to massage this into a high probability
classification though local changes, until it converges to
some &quot;local <br>
maximum&quot;. It then remembers what it found and starts
over again, continuing until you tell it to stop. Each
effort is called a &quot;try&quot;, and the computed
probability is intended <br>
to cover the whole volume in parameter space around this
maximum, rather than just the peak.</p>

<p style="margin-top: 1em">The standard approach to
massaging is to</p>

<p style="margin-top: 1em">1) Compute the probabilistic
class memberships of cases using the class parameters and
the implied relative likelihoods.</p>

<p style="margin-top: 1em">2) Using the new class members,
compute class statistics (like mean) and revise the class
parameters.</p>

<p style="margin-top: 1em">and repeat till they stop
changing. There are three available convergence algorithms:
&quot;converge_search_3&quot; (the default),
&quot;converge_search_4&quot; and &quot;converge&quot;.
Their specification <br>
is controlled by search params file parameter
try_fn_type.</p>

<p style="margin-top: 1em">WHEN TO STOP <br>
You can tell AUTOCLASS -SEARCH to stop by: 1) giving a
max_duration (in seconds) argument at the beginning; 2)
giving a max_n_tries (an integer) argument at the beginning;
or 3) <br>
by typing a &quot;q&quot; and &lt;return&gt; after you have
seen enough tries. The max_duration and max_n_tries
arguments are useful if you desire to run AUTOCLASS -SEARCH
in batch mode. If <br>
you are restarting AUTOCLASS -SEARCH from a previous search,
the value of max_n_tries you provide, for instance 3, will
tell the program to compute 3 more tries in addition to <br>
however many it has already done. The same incremental
behavior is exhibited by max_duration.</p>

<p style="margin-top: 1em">Deciding when to stop is a
judgment call and it&rsquo;s up to you. Since the search
includes a random component, there&rsquo;s always the chance
that if you let it keep going it will find <br>
something better. So you need to trade off how much better
it might be with how long it might take to find it. The
search status reports that are printed when a new best
clas&acirc; <br>
sification is found are intended to provide you information
to help you make this tradeoff.</p>

<p style="margin-top: 1em">One clear sign that you should
probably stop is if most of the classifications found are
duplicates of previous ones (flagged by &quot;dup&quot; as
they are found). This should only hap&acirc; <br>
pen for very small sets of data or when fixing a very small
number of classes, like two.</p>

<p style="margin-top: 1em">Our experience is that for
moderately large to extremely large data sets (~200 to
~10,000 datum), it is necessary to run AutoClass for at
least 50 trials.</p>

<p style="margin-top: 1em">WHAT GETS RETURNED <br>
Just before returning, AUTOCLASS -SEARCH will give short
descriptions of the best classifications found. How many
will be described can be controlled with
n_final_summary.</p>

<p style="margin-top: 1em">By default AUTOCLASS -SEARCH
will write out a number of files, both at the end and
periodically during the search (in case your system crashes
before it finishes). These files <br>
will all have the same name (taken from the search params
pathname [&lt;name&gt;.s-params]), and differ only in their
file extensions. If your search runs are very long and there
is a <br>
possibility that your machine may crash, you can have
intermediate &quot;results&quot; files written out. These
can be used to restart your search run with minimum loss of
search effort. <br>
See the documentation file
/usr/share/doc/autoclass/checkpoint-c.text.</p>

<p style="margin-top: 1em">A &quot;.log&quot; file will
hold a listing of most of what was printed to the screen
during the run, unless you set log_file_p to false to say
you want no such foolishness. Unless re&acirc; <br>
sults_file_p is false, a binary &quot;.results-bin&quot;
file (the default) or an ASCII &quot;.results&quot; text
file, will hold the best classifications that were returned,
and unless <br>
search_file_p is false, a &quot;.search&quot; file will hold
the record of the search tries. save_compact_p controls
whether the &quot;results&quot; files are saved as binary or
ASCII text.</p>

<p style="margin-top: 1em">If the C global variable
&quot;G_safe_file_writing_p&quot; is defined as TRUE in
&quot;autoclass-c/prog/globals.c&quot;, the names of
&quot;results&quot; files (those that contain the saved
classifications) <br>
are modified internally to account for redundant file
writing. If the search params file name is
&quot;my_saved_clsfs&quot; you will see the following
&quot;results&quot; file names (ignoring di&acirc; <br>
rectories and pathnames for this example)</p>

<p style="margin-top: 1em">save_compact_p = true -- <br>
&quot;my_saved_clsfs.results-bin&quot; - completely written
file <br>
&quot;my_saved_clsfs.results-tmp-bin&quot; - partially
written file, renamed <br>
when complete</p>

<p style="margin-top: 1em">save_compact_p = false -- <br>
&quot;my_saved_clsfs.results&quot; - completely written file
<br>
&quot;my_saved_clsfs.results-tmp&quot; - partially written
file, renamed <br>
when complete</p>

<p style="margin-top: 1em">If check pointing is being done,
these additional names will appear</p>

<p style="margin-top: 1em">save_compact_p = true -- <br>
&quot;my_saved_clsfs.chkpt-bin&quot; - completely written
checkpoint file <br>
&quot;my_saved_clsfs.chkpt-tmp-bin&quot; - partially written
checkpoint file, <br>
renamed when complete <br>
save_compact_p = false -- <br>
&quot;my_saved_clsfs.chkpt&quot; - completely written
checkpoint file <br>
&quot;my_saved_clsfs.chkpt-tmp&quot; - partially written
checkpoint file, <br>
renamed when complete</p>

<p style="margin-top: 1em">HOW TO GET STARTED <br>
The way to invoke AUTOCLASS -SEARCH is:</p>

<p style="margin-top: 1em">autoclass -search &lt;.db2 file
path&gt; &lt;.hd2 file path&gt; <br>
&lt;.model file path&gt; &lt;.s-params file path&gt;</p>

<p style="margin-top: 1em">To restart a previous search,
specify that force_new_search_p has the value false in the
search params file, since its default is true. Specifying
false tells AUTOCLASS -SEARCH <br>
to try to find a previous compatible search
(&lt;...&gt;.results[-bin] &amp; &lt;...&gt;.search) to
continue from, and will restart using it if found. To force
a new search instead of restart&acirc; <br>
ing an old one, give the parameter force_new_search_p the
value of true, or use the default. If there is an existing
search (&lt;...&gt;.results[-bin] &amp; &lt;...&gt;.search),
the user will <br>
be asked to confirm continuation since continuation will
discard the existing search.</p>

<p style="margin-top: 1em">If a previous search is
continued, the message &quot;RESTARTING SEARCH&quot; will be
given instead of the usual &quot;BEGINNING SEARCH&quot;. It
is generally better to continue a previous search <br>
than to start a new one, unless you are trying a
significantly different search method, in which case
statistics from the previous search may mislead the current
one.</p>

<p style="margin-top: 1em">STATUS REPORTS <br>
A running commentary on the search will be printed to the
screen and to the log file (unless log_file_p is false).
Note that the &quot;.log&quot; file will contain a listing
of all de&acirc; <br>
fault search params values, and the values of all params
that are overridden.</p>

<p style="margin-top: 1em">After each try a very short
report (only a few characters long) is given. After each new
best classification, a longer report is given, but no more
often than min_report_period <br>
(default is 30 seconds).</p>

<p style="margin-top: 1em">SEARCH VARIATIONS <br>
AUTOCLASS -SEARCH by default uses a certain standard search
method or &quot;try function&quot; (try_fn_type =
&quot;converge_search_3&quot;). Two others are also
available: &quot;converge_search_4&quot; and <br>
&quot;converge&quot;). They are provided in case your
problem is one that may happen to benefit from them. In
general the default method will result in finding better
classifications at <br>
the expense of a longer search time. The default was chosen
so as to be robust, giving even performance across many
problems. The alternatives to the default may do better on
<br>
some problems, but may do substantially worse on others.</p>

<p style="margin-top: 1em">&quot;converge_search_3&quot;
uses an absolute stopping criterion (rel_delta_range,
default value of 0.0025) which tests the variation of each
class of the delta of the log approximate- <br>
marginal-likelihood of the class statistics with-respect-to
the class hypothesis (class-&gt;log_a_w_s_h_j) divided by
the class weight (class-&gt;w_j) between successive
convergence <br>
cycles. Increasing this value loosens the convergence and
reduces the number of cycles. Decreasing this value tightens
the convergence and increases the number of cycles.
n_av&acirc; <br>
erage (default value of 3) specifies how many successive
cycles must meet the stopping criterion before the trial
terminates.</p>

<p style="margin-top: 1em">&quot;converge_search_4&quot;
uses an absolute stopping criterion (cs4_delta_range,
default value of 0.0025) which tests the variation of each
class of the slope for each class of log ap&acirc; <br>
proximate-marginal-likelihood of the class statistics
with-respect-to the class hypothesis
(class-&gt;log_a_w_s_h_j) divided by the class weight
(class-&gt;w_j) over sigma_beta_n_val&acirc; <br>
ues (default value 6) convergence cycles. Increasing the
value of cs4_delta_range loosens the convergence and reduces
the number of cycles. Decreasing this value tightens the
<br>
convergence and increases the number of cycles.
Computationally, this try function is more expensive than
&quot;converge_search_3&quot;, but may prove useful if the
computational &quot;noise&quot; <br>
is significant compared to the variations in the computed
values. Key calculations are done in double precision
floating point, and for the largest data base we have tested
so <br>
far ( 5,420 cases of 93 attributes), computational noise has
not been a problem, although the value of max_cycles needed
to be increased to 400.</p>

<p style="margin-top: 1em">&quot;converge&quot; uses one of
two absolute stopping criterion which test the variation of
the classification (clsf) log_marginal (clsf-&gt;log_a_x_h)
delta between successive convergence <br>
cycles. The largest of halt_range (default value 0.5) and
halt_factor * current_clsf_log_marginal) is used (default
value of halt_factor is 0.0001). Increasing these values
<br>
loosens the convergence and reduces the number of cycles.
Decreasing these values tightens the convergence and
increases the number of cycles. n_average (default value of
3) <br>
specifies how many cycles must meet the stopping criteria
before the trial terminates. This is a very approximate
stopping criterion, but will give you some feel for the kind
of <br>
classifications to expect. It would be useful for
&quot;exploratory&quot; searches of a data base.</p>

<p style="margin-top: 1em">The purpose of reconverge_type =
&quot;chkpt&quot; is to complete an interrupted
classification by continuing from its last checkpoint. The
purpose of reconverge_type = &quot;results&quot; is to <br>
attempt further refinement of the best completed
classification using a different value of try_fn_type
(&quot;converge_search_3&quot;,
&quot;converge_search_4&quot;, &quot;converge&quot;). If
max_n_tries is <br>
greater than 1, then in each case, after the reconvergence
has completed, AutoClass will perform further search trials
based on the parameter values in the &lt;...&gt;.s-params
file.</p>

<p style="margin-top: 1em">With the use of reconverge_type
( default value &quot;&quot;), you may apply more than one
try function to a classification. Say you generate several
exploratory trials using try_fn_type <br>
= &quot;converge&quot;, and quit the search saving .search
and .results[-bin] files. Then you can begin another search
with try_fn_type = &quot;converge_search_3&quot;,
reconverge_type = &quot;results&quot;, <br>
and max_n_tries = 1. This will result in the further
convergence of the best classification generated with
try_fn_type = &quot;converge&quot;, with try_fn_type =
&quot;converge_search_3&quot;. <br>
When AutoClass completes this search try, you will have an
additional refined classification.</p>

<p style="margin-top: 1em">A good way to verify that any of
the alternate try_fun_type are generating a well converged
classification is to run AutoClass in prediction mode on the
same data used for gener&acirc; <br>
ating the classification. Then generate and compare the
corresponding case or class cross reference files for the
original classification and the prediction. Small
differences <br>
between these files are to be expected, while large
differences indicate incomplete convergence. Differences
between such file pairs should, on average and modulo class
dele&acirc; <br>
tions, decrease monotonically with further convergence.</p>

<p style="margin-top: 1em">The standard way to create a
random classification to begin a try is with the default
value of &quot;random&quot; for start_fn_type. At this point
there are no alternatives. Specifying <br>
&quot;block&quot; for start_fn_type produces repeatable
non-random searches. That is how the &lt;..&gt;.s-params
files in the autoclass-c/data/.. sub-directories are
specified. This is how de&acirc; <br>
velopment testing is done.</p>

<p style="margin-top: 1em">max_cycles controls the maximum
number of convergence cycles that will be performed in any
one trial by the convergence functions. Its default value is
200. The screen output <br>
shows a period (&quot;.&quot;) for each cycle completed. If
your search trials run for 200 cycles, then either your data
base is very complex (increase the value), or the
try_fn_type is <br>
not adequate for situation (try another of the available
ones, and use converge_print_p to get more information on
what is going on).</p>

<p style="margin-top: 1em">Specifying converge_print_p to
be true will generate a brief print-out for each cycle which
will provide information so that you can modify the default
values of rel_delta_range <br>
&amp; n_average for &quot;converge_search_3&quot;;
cs4_delta_range &amp; sigma_beta_n_values for
&quot;converge_search_4&quot;; and halt_range, halt_factor,
and n_average for &quot;converge&quot;. Their default
val&acirc; <br>
ues are given in the &lt;..&gt;.s-params files in the
autoclass-c/data/.. sub-directories.</p>

<p style="margin-top: 1em">HOW MANY CLASSES? <br>
Each new try begins with a certain number of classes and may
end up with a smaller number, as some classes may drop out
of the convergence. In general, you want to begin the try
<br>
with some number of classes that previous tries have
indicated look promising, and you want to be sure you are
fishing around elsewhere in case you missed something
before.</p>

<p style="margin-top: 1em">n_classes_fn_type =
&quot;random_ln_normal&quot; is the default way to make this
choice. It fits a log normal to the number of classes
(usually called &quot;j&quot; for short) of the 10 best
clas&acirc; <br>
sifications found so far, and randomly selects from that.
There is currently no alternative.</p>

<p style="margin-top: 1em">To start the game off, the
default is to go down start_j_list for the first few tries,
and then switch to n_classes_fn_type. If you believe that
the probable number of classes <br>
in your data base is say 75, then instead of using the
default value of start_j_list (2, 3, 5, 7, 10, 15, 25),
specify something like 50, 60, 70, 80, 90, 100.</p>

<p style="margin-top: 1em">If one wants to always look for,
say, three classes, one can use fixed_j and override the
above. Search status reports will describe what the current
method for choosing j is.</p>

<p style="margin-top: 1em">DO I HAVE ENOUGH MEMORY AND DISK
SPACE? <br>
Internally, the storage requirements in the current system
are of order n_classes_per_clsf * (n_data + n_stored_clsfs *
n_attributes * n_attribute_values). This depends on the <br>
number of cases, the number of attributes, the values per
attribute (use 2 if a real value), and the number of
classifications stored away for comparison to see if others
are du&acirc; <br>
plicates -- controlled by max_n_store (default value = 10).
The search process does not itself consume significant
memory, but storage of the results may do so.</p>

<p style="margin-top: 1em">AutoClass C is configured to
handle a maximum of 999 attributes. If you attempt to run
with more than that you will get array bound violations. In
that case, change these con&acirc; <br>
figuration parameters in prog/autoclass.h and recompile
AutoClass C:</p>

<p style="margin-top: 1em">#define ALL_ATTRIBUTES 999 <br>
#define VERY_LONG_STRING_LENGTH 20000 <br>
#define VERY_LONG_TOKEN_LENGTH 500</p>

<p style="margin-top: 1em">For example, these values will
handle several thousand attributes:</p>

<p style="margin-top: 1em">#define ALL_ATTRIBUTES 9999 <br>
#define VERY_LONG_STRING_LENGTH 50000 <br>
#define VERY_LONG_TOKEN_LENGTH 50000</p>

<p style="margin-top: 1em">Disk space taken up by the
&quot;log&quot; file will of course depend on the duration
of the search. n_save (default value = 2) determines how
many best classifications are saved into the <br>
&quot;.results[-bin]&quot; file. save_compact_p controls
whether the &quot;results&quot; and &quot;checkpoint&quot;
files are saved as binary. Binary files are faster and more
compact, but are not portable. <br>
The default value of save_compact_p is true, which causes
binary files to be written.</p>

<p style="margin-top: 1em">If the time taken to save the
&quot;results&quot; files is a problem, consider increasing
min_save_period (default value = 1800 seconds or 30
minutes). Files are saved to disk this often <br>
if there is anything different to report.</p>

<p style="margin-top: 1em">JUST HOW SLOW IS IT? <br>
Compute time is of order n_data * n_attributes * n_classes *
n_tries * converge_cycles_per_try. The major uncertainties
in this are the number of basic back and forth cycles till
<br>
convergence in each try, and of course the number of tries.
The number of cycles per trial is typically 10-100 for
try_fn_type &quot;converge&quot;, and 10-200+ for
&quot;converge_search_3&quot; <br>
and &quot;converge_search-4&quot;. The maximum number is
specified by max_n_tries (default value = 200). The number
of trials is up to you and your available computing
resources.</p>

<p style="margin-top: 1em">The running time of very large
data sets will be quite uncertain. We advise that a few
small scale test runs be made on your system to determine a
baseline. Specify n_data to <br>
limit how many data vectors are read. Given a very large
quantity of data, AutoClass may find its most probable
classifications at upwards of a hundred classes, and this
will <br>
require that start_j_list be specified appropriately (See
above section HOW MANY CLASSES?). If you are quite certain
that you only want a few classes, you can force AutoClass to
<br>
search with a fixed number of classes specified by fixed_j.
You will then need to run separate searches with each
different fixed number of classes.</p>

<p style="margin-top: 1em">CHANGING FILENAMES IN A SAVED
CLASSIFICATION FILE <br>
AutoClass caches the data, header, and model file pathnames
in the saved classification structure of the binary
(&quot;.results-bin&quot;) or ASCII (&quot;.results&quot;)
&quot;results&quot; files. If the <br>
&quot;results&quot; and &quot;search&quot; files are moved
to a different directory location, the search cannot be
successfully restarted if you have used absolute pathnames.
Thus it is advanta&acirc; <br>
geous to run invoke AutoClass in a parent directory of the
data, header, and model files, so that relative pathnames
can be used. Since the pathnames cached will then be
rela&acirc; <br>
tive, the files can be moved to a different host or file
system and restarted -- providing the same relative pathname
hierarchy exists.</p>

<p style="margin-top: 1em">However, since the
&quot;.results&quot; file is ASCII text, those pathnames
could be changed with a text editor (save_compact_p must be
specified as false).</p>

<p style="margin-top: 1em">SEARCH PARAMETERS <br>
The search is controlled by the &quot;.s-params&quot; file.
In this file, an empty line or a line starting with one of
these characters is treated as a comment: &quot;#&quot;,
&quot;!&quot;, or &quot;;&quot;. The pa&acirc; <br>
rameter name and its value can be separated by an equal
sign, a space, or a tab:</p>

<p style="margin-top: 1em">n_clsfs 1 <br>
n_clsfs = 1 <br>
n_clsfs&lt;tab&gt;1</p>

<p style="margin-top: 1em">Spaces are ignored if
&quot;=&quot; or &quot;&lt;tab&gt;&quot; are used as
separators. Note there are no trailing semicolons.</p>

<p style="margin-top: 1em">The search parameters, with
their default values, are as follows:</p>

<p style="margin-top: 1em">rel_error = 0.01 <br>
Specifies the relative difference measure used by
clsf-DS-%=, when deciding if a new clsf is a duplicate of an
old one.</p>

<p style="margin-top: 1em">start_j_list = 2, 3, 5, 7, 10,
15, 25 <br>
Initially try these numbers of classes, so as not to narrow
the search too quickly. The state of this list is saved in
the &lt;..&gt;.search file and used on restarts, unless <br>
an override specification of start_j_list is made in the
.s-params file for the restart run. This list should bracket
your expected number of classes, and by a wide mar&acirc;
<br>
gin! &quot;start_j_list = -999&quot; specifies an empty list
(allowed only on restarts)</p>

<p style="margin-top: 1em">n_classes_fn_type =
&quot;random_ln_normal&quot; <br>
Once start_j_list is exhausted, AutoClass will call this
function to decide how many classes to start with on the
next try, based on the 10 best classifications found so <br>
far. Currently only &quot;random_ln_normal&quot; is
available.</p>

<p style="margin-top: 1em">fixed_j = 0 <br>
When fixed_j &gt; 0, overrides start_j_list and
n_classes_fn_type, and AutoClass will always use this value
for the initial number of classes.</p>

<p style="margin-top: 1em">min_report_period = 30 <br>
Wait at least this time (in seconds) since last report until
reporting verbosely again. Should be set longer than the
expected run time when checking for repeatability of <br>
results. For repeatable results, also see
force_new_search_p, start_fn_type and randomize_random_p.
NOTE: At least one of &quot;interactive_p&quot;,
&quot;max_duration&quot;, and <br>
&quot;max_n_tries&quot; must be active. Otherwise AutoClass
will run indefinitely. See below.</p>

<p style="margin-top: 1em">interactive_p = true <br>
When false, allows run to continue until otherwise halted.
When true, standard input is queried on each cycle for the
quit character &quot;q&quot;, which, when detected, triggers
<br>
an immediate halt.</p>

<p style="margin-top: 1em">max_duration = 0 <br>
When = 0, allows run to continue until otherwise halted.
When &gt; 0, specifies the maximum number of seconds to
run.</p>

<p style="margin-top: 1em">max_n_tries = 0 <br>
When = 0, allows run to continue until otherwise halted.
When &gt; 0, specifies the maximum number of tries to
make.</p>

<p style="margin-top: 1em">n_save = 2 <br>
Save this many clsfs to disk in the .results[-bin] and
.search files. if 0, don&rsquo;t save anything (no .search
&amp; .results[-bin] files).</p>

<p style="margin-top: 1em">log_file_p = true <br>
If false, do not write a log file.</p>

<p style="margin-top: 1em">search_file_p = true <br>
If false, do not write a search file.</p>

<p style="margin-top: 1em">results_file_p = true <br>
If false, do not write a results file.</p>

<p style="margin-top: 1em">min_save_period = 1800 <br>
CPU crash protection. This specifies the maximum time, in
seconds, that AutoClass will run before it saves the current
results to disk. The default time is 30 minutes.</p>

<p style="margin-top: 1em">max_n_store = 10 <br>
Specifies the maximum number of classifications stored
internally.</p>

<p style="margin-top: 1em">n_final_summary = 10 <br>
Specifies the number of trials to be printed out after
search ends.</p>

<p style="margin-top: 1em">start_fn_type =
&quot;random&quot; <br>
One of {&quot;random&quot;, &quot;block&quot;}. This
specifies the type of class initialization. For normal
search, use &quot;random&quot;, which randomly selects
instances to be initial class means, <br>
and adds appropriate variances. For testing with repeatable
search, use &quot;block&quot;, which partitions the database
into successive blocks of near equal size. For repeatable
<br>
results, also see force_new_search_p, min_report_period, and
randomize_random_p.</p>

<p style="margin-top: 1em">try_fn_type =
&quot;converge_search_3&quot; <br>
One of {&quot;converge_search_3&quot;,
&quot;converge_search_4&quot;, &quot;converge&quot;}. These
specify alternate search stopping criteria.
&quot;converge&quot; merely tests the rate of change of the
<br>
log_marginal classification probability
(clsf-&gt;log_a_x_h), without checking rate of change of
individual classes(see halt_range and halt_factor).
&quot;converge_search_3&quot; and <br>
&quot;converge_search_4&quot; each monitor the ratio
class-&gt;log_a_w_s_h_j/class-&gt;w_j for all classes, and
continue convergence until all pass the quiescence criteria
for n_average <br>
cycles. &quot;converge_search_3&quot; tests differences
between successive convergence cycles (see rel_delta_range).
This provides a reasonable, general purpose stopping
criteria. <br>
&quot;converge_search_4&quot; averages the ratio over
&quot;sigma_beta_n_values&quot; cycles (see
cs4_delta_range). This is preferred when converge_search_3
produces many similar classes.</p>

<p style="margin-top: 1em">initial_cycles_p = true <br>
If true, perform base_cycle in initialize_parameters. false
is used only for testing.</p>

<p style="margin-top: 1em">save_compact_p = true <br>
true saves classifications as machine dependent binary
(.results-bin &amp; .chkpt-bin). false saves as ascii text
(.results &amp; .chkpt)</p>

<p style="margin-top: 1em">read_compact_p = true <br>
true reads classifications as machine dependent binary
(.results-bin &amp; .chkpt-bin). false reads as ascii text
(.results &amp; .chkpt).</p>

<p style="margin-top: 1em">randomize_random_p = true <br>
false seeds lrand48, the pseudo-random number function with
1 to give repeatable test cases. true uses universal time
clock as the seed, giving semi-random searches. For <br>
repeatable results, also see force_new_search_p,
min_report_period and start_fn_type.</p>

<p style="margin-top: 1em">n_data = 0 <br>
With n_data = 0, the entire database is read from .db2. With
n_data &gt; 0, only this number of data are read.</p>

<p style="margin-top: 1em">halt_range = 0.5 <br>
Passed to try_fn_type &quot;converge&quot;. With the
&quot;converge&quot; try_fn_type, convergence is halted when
the larger of halt_range and (halt_factor *
current_log_marginal) exceeds <br>
the difference between successive cycle values of the
classification log_marginal (clsf-&gt;log_a_x_h). Decreasing
this value may tighten the convergence and increase the <br>
number of cycles.</p>

<p style="margin-top: 1em">halt_factor = 0.0001 <br>
Passed to try_fn_type &quot;converge&quot;. With the
&quot;converge&quot; try_fn_type, convergence is halted when
the larger of halt_range and (halt_factor *
current_log_marginal) exceeds <br>
the difference between successive cycle values of the
classification log_marginal (clsf-&gt;log_a_x_h). Decreasing
this value may tighten the convergence and increase the <br>
number of cycles.</p>

<p style="margin-top: 1em">rel_delta_range = 0.0025 <br>
Passed to try function &quot;converge_search_3&quot;, which
monitors the ratio of log approx-marginal-likelihood of
class statistics with-respect-to the class hypothesis <br>
(class-&gt;log_a_w_s_h_j) divided by the class weight
(class-&gt;w_j), for each class.
&quot;converge_search_3&quot; halts convergence when the
difference between cycles, of this ratio, <br>
for every class, has been exceeded by
&quot;rel_delta_range&quot; for &quot;n_average&quot;
cycles. Decreasing &quot;rel_delta_range&quot; tightens the
convergence and increases the number of cycles.</p>

<p style="margin-top: 1em">cs4_delta_range = 0.0025 <br>
Passed to try function &quot;converge_search_4&quot;, which
monitors the ratio of
(class-&gt;log_a_w_s_h_j)/(class-&gt;w_j), for each class,
averaged over &quot;sigma_beta_n_values&quot; conver&acirc;
<br>
gence cycles. &quot;converge_search_4&quot; halts
convergence when the maximum difference in average values of
this ratio falls below &quot;cs4_delta_range&quot;.
Decreasing <br>
&quot;cs4_delta_range&quot; tightens the convergence and
increases the number of cycles.</p>

<p style="margin-top: 1em">n_average = 3 <br>
Passed to try functions &quot;converge_search_3&quot; and
&quot;converge&quot;. The number of cycles for which the
convergence criterion must be satisfied for the trial to
terminate.</p>

<p style="margin-top: 1em">sigma_beta_n_values = 6 <br>
Passed to try_fn_type &quot;converge_search_4&quot;. The
number of past values to use in computing sigma^2 (noise)
and beta^2 (signal).</p>

<p style="margin-top: 1em">max_cycles = 200 <br>
This is the maximum number of cycles permitted for any one
convergence of a classification, regardless of any other
stopping criteria. This is very dependent upon your <br>
database and choice of model and convergence parameters, but
should be about twice the average number of cycles reported
in the screen dump and .log file</p>

<p style="margin-top: 1em">converge_print_p = false <br>
If true, the selected try function will print to the screen
values useful in specifying non-default values for
halt_range, halt_factor, rel_delta_range, n_average,
sig&acirc; <br>
ma_beta_n_values, and range_factor.</p>

<p style="margin-top: 1em">force_new_search_p = true <br>
If true, will ignore any previous search results, discarding
the existing .search and .results[-bin] files after
confirmation by the user; if false, will continue the <br>
search using the existing .search and .results[-bin] files.
For repeatable results, also see min_report_period,
start_fn_type and randomize_random_p.</p>

<p style="margin-top: 1em">checkpoint_p = false <br>
If true, checkpoints of the current classification will be
written every &quot;min_checkpoint_period&quot; seconds,
with file extension .chkpt[-bin]. This is only useful for
very <br>
large classifications</p>

<p style="margin-top: 1em">min_checkpoint_period = 10800
<br>
If checkpoint_p = true, the checkpointed classification will
be written this often - in seconds (default = 3 hours)</p>

<p style="margin-top: 1em">reconverge_type = &quot; <br>
Can be either &quot;chkpt&quot; or &quot;results&quot;. If
&quot;checkpoint_p&quot; = true and
&quot;reconverge_type&quot; = &quot;chkpt&quot;, then
continue convergence of the classification contained in <br>
&lt;...&gt;.chkpt[-bin]. If &quot;checkpoint_p &quot; =
false and &quot;reconverge_type&quot; = &quot;results&quot;,
continue convergence of the best classification contained in
&lt;...&gt;.results[-bin].</p>

<p style="margin-top: 1em">screen_output_p = true <br>
If false, no output is directed to the screen. Assuming
log_file_p = true, output will be directed to the log file
only.</p>

<p style="margin-top: 1em">break_on_warnings_p = true <br>
The default value asks the user whether or not to continue,
when data definition warnings are found. If specified as
false, then AutoClass will continue, despite warnings <br>
-- the warning will continue to be output to the terminal
and the log file.</p>

<p style="margin-top: 1em">free_storage_p = true <br>
The default value tells AutoClass to free the majority of
its allocated storage. This is not required, and in the case
of the DEC Alpha causes core dump [is this still <br>
true?]. If specified as false, AutoClass will not attempt to
free storage.</p>

<p style="margin-top: 1em">HOW TO GET AUTOCLASS C TO
PRODUCE REPEATABLE RESULTS <br>
In some situations, repeatable classifications are required:
comparing basic AutoClass C integrity on different
platforms, porting AutoClass C to a new platform, etc. In
order <br>
to accomplish this two things are necessary: 1) the same
random number generator must be used, and 2) the search
parameters must be specified properly.</p>

<p style="margin-top: 1em">Random Number Generator. This
implementation of AutoClass C uses the Unix srand48/lrand48
random number generator which generates pseudo-random
numbers using the well-known lin&acirc; <br>
ear congruential algorithm and 48-bit integer arithmetic.
lrand48() returns non- negative long integers uniformly
distributed over the interval [0, 2**31].</p>

<p style="margin-top: 1em">Search Parameters. The following
.s-params file parameters should be specified:</p>

<p style="margin-top: 1em">force_new_search_p = true <br>
start_fn_type &quot;block&quot; <br>
randomize_random_p = false <br>
;; specify the number of trials you wish to run <br>
max_n_tries = 50 <br>
;; specify a time greater than duration of run <br>
min_report_period = 30000</p>

<p style="margin-top: 1em">Note that no current best
classification reports will be produced. Only a final
classification summary will be output.</p>

<p style="margin-top: 1em">CHECKPOINTING <br>
With very large databases there is a significant probability
of a system crash during any one classification try. Under
such circumstances it is advisable to take the time to <br>
checkpoint the calculations for possible restart.</p>

<p style="margin-top: 1em">Checkpointing is initiated by
specifying &quot;checkpoint_p = true&quot; in the
&quot;.s-params&quot; file. This causes the inner
convergence step, to save a copy of the classification onto
the <br>
checkpoint file each time the classification is updated,
providing a certain period of time has elapsed. The file
extension is &quot;.chkpt[-bin]&quot;.</p>

<p style="margin-top: 1em">Each time a AutoClass completes
a cycle, a &quot;.&quot; is output to the screen to provide
you with information to be used in setting the
min_checkpoint_period value (default 10800 sec&acirc; <br>
onds or 3 hours). There is obviously a trade-off between
frequency of checkpointing and the probability that your
machine may crash, since the repetitive writing of the
check&acirc; <br>
point file will slow the search process.</p>

<p style="margin-top: 1em">Restarting AutoClass Search:</p>

<p style="margin-top: 1em">To recover the classification
and continue the search after rebooting and reloading
AutoClass, specify reconverge_type = &quot;chkpt&quot; in
the &quot;.s-params&quot; file (specify <br>
force_new_search_p as false).</p>

<p style="margin-top: 1em">AutoClass will reload the
appropriate database and models, provided there has been no
change in their filenames since the time they were loaded
for the checkpointed classifica&acirc; <br>
tion run. The &quot;.s-params&quot; file contains any
non-default arguments that were provided to the original
call.</p>

<p style="margin-top: 1em">In the beginning of a search,
before start_j_list has been emptied, it will be necessary
to trim the original list to what would have remained in the
crashed search. This can be <br>
determined by looking at the &quot;.log&quot; file to
determine what values were already used. If the start_j_list
has been emptied, then an empty start_j_list should be
specified in the <br>
&quot;.s-params&quot; file. This is done either by</p>

<p style="margin-top: 1em">start_j_list =</p>

<p style="margin-top: 1em">or</p>

<p style="margin-top: 1em">start_j_list = -9999</p>

<p style="margin-top: 1em">Here is an a set of scripts to
demonstrate check-pointing:</p>

<p style="margin-top: 1em">autoclass -search
data/glass/glassc.db2 data/glass/glass-3c.hd2
data/glass/glass-mnc.model
data/glass/glassc-chkpt.s-params</p>

<p style="margin-top: 1em">Run 1) <br>
## glassc-chkpt.s-params <br>
max_n_tries = 2 <br>
force_new_search_p = true <br>
## -------------------- <br>
;; run to completion</p>

<p style="margin-top: 1em">Run 2) <br>
## glassc-chkpt.s-params <br>
force_new_search_p = false <br>
max_n_tries = 10 <br>
checkpoint_p = true <br>
min_checkpoint_period = 2 <br>
## -------------------- <br>
;; after 1 checkpoint, ctrl-C to simulate cpu crash</p>

<p style="margin-top: 1em">Run 3) <br>
## glassc-chkpt.s-params <br>
force_new_search_p = false <br>
max_n_tries = 1 <br>
checkpoint_p = true <br>
min_checkpoint_period = 1 <br>
reconverge_type = &quot;chkpt&quot; <br>
## -------------------- <br>
;; checkpointed trial should finish</p>

<p style="margin-top: 1em">OUTPUT FILES <br>
The standard reports are</p>

<p style="margin-top: 1em">1) Attribute influence values:
presents the relative influence or significance of the
data&rsquo;s attributes both globally (averaged over all
classes), and locally (specifically <br>
for each class). A heuristic for relative class strength is
also listed;</p>

<p style="margin-top: 1em">2) Cross-reference by case
(datum) number: lists the primary class probability for each
datum, ordered by case number. When report_mode =
&quot;data&quot;, additional lesser class <br>
probabilities (greater than or equal to 0.001) are listed
for each datum;</p>

<p style="margin-top: 1em">3) Cross-reference by class
number: for each class the primary class probability and any
lesser class probabilities (greater than or equal to 0.001)
are listed for each datum <br>
in the class, ordered by case number. It is also possible to
list, for each datum, the values of attributes, which you
select.</p>

<p style="margin-top: 1em">The attribute influence values
report attempts to provide relative measures of the
&quot;influence&quot; of the data attributes on the classes
found by the classification. The normalized <br>
class strengths, the normalized attribute influence values
summed over all classes, and the individual influence values
(I[jkl]) are all only relative measures and should be
in&acirc; <br>
terpreted with more meaning than rank ordering, but not like
anything approaching absolute values.</p>

<p style="margin-top: 1em">The reports are output to files
whose names and pathnames are taken from the
&quot;.r-params&quot; file pathname. The report file types
(extensions) are:</p>

<p style="margin-top: 1em">influence values report <br>
&quot;influ-o-text-n&quot; or
&quot;influ-no-text-n&quot;</p>

<p style="margin-top: 1em">cross-reference by case <br>
&quot;case-text-n&quot;</p>

<p style="margin-top: 1em">cross-reference by class <br>
&quot;class-text-n&quot;</p>

<p style="margin-top: 1em">or, if report_mode is overridden
to &quot;data&quot;:</p>

<p style="margin-top: 1em">influence values report <br>
&quot;influ-o-data-n&quot; or
&quot;influ-no-data-n&quot;</p>

<p style="margin-top: 1em">cross-reference by case <br>
&quot;case-data-n&quot;</p>

<p style="margin-top: 1em">cross-reference by class <br>
&quot;class-data-n&quot;</p>

<p style="margin-top: 1em">where n is the classification
number from the &quot;results&quot; file. The first or best
classification is numbered 1, the next best 2, etc. The
default is to generate reports only for <br>
the best classification in the &quot;results&quot; file. You
can produce reports for other saved classifications by using
report params keywords n_clsfs and clsf_n_list. The
&quot;influ-o- <br>
text-n&quot; file type is the default
(order_attributes_by_influence_p = true), and lists each
class&rsquo;s attributes in descending order of attribute
influence value. If the value of <br>
order_attributes_by_influence_p is overridden to be false in
the &lt;...&gt;.r-params file, then each class&rsquo;s
attributes will be listed in ascending order by attribute
number. The ex&acirc; <br>
tension of the file generated will be
&quot;influ-no-text-n&quot;. This method of listing
facilitates the visual comparison of attribute values
between classes.</p>

<p style="margin-top: 1em">For example, this command:</p>

<p style="margin-top: 1em">autoclass -reports
sample/imports-85c.results-bin <br>
sample/imports-85c.search sample/imports-85c.r-params</p>

<p style="margin-top: 1em">with this line in the
&quot;.r-params&quot; file:</p>

<p style="margin-top: 1em">xref_class_report_att_list = 2,
5, 6</p>

<p style="margin-top: 1em">will generate these output
files:</p>

<p style="margin-top: 1em">imports-85.influ-o-text-1 <br>
imports-85.case-text-1 <br>
imports-85.class-text-1</p>

<p style="margin-top: 1em">The AutoClass C reports provide
the capability to compute sigma class contour values for
specified pairs of real valued attributes, when generating
the influence values report <br>
with the data option (report_mode = &quot;data&quot;). Note
that sigma class contours are not generated from discrete
type attributes.</p>

<p style="margin-top: 1em">The sigma contours are the two
dimensional equivalent of n-sigma error bars in one
dimension. Specifically, for two independent attributes the
n-sigma contour is defined as the <br>
ellipse where</p>

<p style="margin-top: 1em">((x - xMean) / xSigma)^2 + ((y -
yMean) / ySigma)^2 == n</p>

<p style="margin-top: 1em">With covariant attributes, the
n-sigma contours are defined identically, in the rotated
coordinate system of the distribution&rsquo;s principle
axes. Thus independent attributes give <br>
ellipses oriented parallel with the attribute axes, while
the axes of sigma contours of covariant attributes are
rotated about the center determined by the means. In either
case <br>
the sigma contour represents a line where the class
probability is constant, irrespective of any other class
probabilities.</p>

<p style="margin-top: 1em">With three or more attributes
the n-sigma contours become k-dimensional ellipsoidal
surfaces. This code takes advantage of the fact that the
parallel projection of an n-dimen&acirc; <br>
sional ellipsoid, onto any 2-dim plane, is bounded by an
ellipse. In this simplified case of projecting the single
sigma ellipsoid onto the coordinate planes, it is also true
<br>
that the 2-dim covariances of this ellipse are equal to the
corresponding elements of the n-dim ellipsoid&rsquo;s
covariances. The Eigen-system of the 2-dim covariance then
gives the <br>
variances w.r.t. the principal components of the eclipse,
and the rotation that aligns it with the data. This
represents the best way to display a distribution in the
marginal <br>
plane.</p>

<p style="margin-top: 1em">To get contour values, set the
keyword sigma_contours_att_list to a list of real valued
attribute indices (from .hd2 file), and request an influence
values report with the data <br>
option. For example,</p>

<p style="margin-top: 1em">report_mode = &quot;data&quot;
<br>
sigma_contours_att_list = 3, 4, 5, 8, 15</p>

<p style="margin-top: 1em">OUTPUT REPORT PARAMETERS <br>
The contents of the output report are controlled by the
&quot;.r-params&quot; file. In this file, an empty line or a
line starting with one of these characters is treated as a
comment: <br>
&quot;#&quot;, &quot;!&quot;, or &quot;;&quot;. The
parameter name and its value can be separated by an equal
sign, a space, or a tab:</p>

<p style="margin-top: 1em">n_clsfs 1 <br>
n_clsfs = 1 <br>
n_clsfs&lt;tab&gt;1</p>

<p style="margin-top: 1em">Spaces are ignored if
&quot;=&quot; or &quot;&lt;tab&gt;&quot; are used as
separators. Note there are no trailing semicolons.</p>

<p style="margin-top: 1em">The following are the allowed
parameters and their default values:</p>

<p style="margin-top: 1em">n_clsfs = 1 <br>
number of clsfs in the .results file for which to generate
reports, starting with the first or &quot;best&quot;.</p>

<p style="margin-top: 1em">clsf_n_list = <br>
if specified, this is a one-based index list of clsfs in the
clsf sequence read from the .results file. It overrides
&quot;n_clsfs&quot;. For example:</p>

<p style="margin-top: 1em">clsf_n_list = 1, 2</p>

<p style="margin-top: 1em">will produce the same output
as</p>

<p style="margin-top: 1em">n_clsfs = 2</p>

<p style="margin-top: 1em">but</p>

<p style="margin-top: 1em">clsf_n_list = 2</p>

<p style="margin-top: 1em">will only output the
&quot;second best&quot; classification report.</p>

<p style="margin-top: 1em">report_type = <br>
type of reports to generate: &quot;all&quot;,
&quot;influence_values&quot;, &quot;xref_case&quot;, or
&quot;xref_class&quot;.</p>

<p style="margin-top: 1em">report_mode = <br>
mode of reports to generate. &quot;text&quot; is formatted
text layout. &quot;data&quot; is numerical -- suitable for
further processing.</p>

<p style="margin-top: 1em">comment_data_headers_p = false
<br>
the default value does not insert # in column 1 of most
report_mode = &quot;data&quot; header lines. If specified as
true, the comment character will be inserted in most header
<br>
lines.</p>

<p style="margin-top: 1em">num_atts_to_list = <br>
if specified, the number of attributes to list in influence
values report. if not specified, all attributes will be
listed. (e.g. &quot;num_atts_to_list = 5&quot;)</p>

<p style="margin-top: 1em">xref_class_report_att_list =
<br>
if specified, a list of attribute numbers (zero-based),
whose values will be output in the &quot;xref_class&quot;
report along with the case probabilities. if not specified,
no at&acirc; <br>
tributes values will be output. (e.g.
&quot;xref_class_report_att_list = 1, 2, 3&quot;)</p>

<p style="margin-top: 1em">order_attributes_by_influence_p
= true <br>
The default value lists each class&rsquo;s attributes in
descending order of attribute influence value, and uses
&quot;.influ-o-text-n&quot; as the influence values report
file type. If <br>
specified as false, then each class&rsquo;s attributes will
be listed in ascending order by attribute number. The
extension of the file generated will be
&quot;influ-no-text-n&quot;.</p>

<p style="margin-top: 1em">break_on_warnings_p = true <br>
The default value asks the user whether to continue or not
when data definition warnings are found. If specified as
false, then AutoClass will continue, despite warnings <br>
-- the warning will continue to be output to the
terminal.</p>

<p style="margin-top: 1em">free_storage_p = true <br>
The default value tells AutoClass to free the majority of
its allocated storage. This is not required, and in the case
of the DEC Alpha causes a core dump [is this still <br>
true?]. If specified as false, AutoClass will not attempt to
free storage.</p>

<p style="margin-top: 1em">max_num_xref_class_probs = 5
<br>
Determines how many lessor class probabilities will be
printed for the case and class cross-reference reports. The
default is to print the most probable class probability <br>
value and up to 4 lessor class prob- ibilities. Note this is
true for both the &quot;text&quot; and &quot;data&quot;
class cross-reference reports, but only true for the
&quot;data&quot; case cross- <br>
reference report. The &quot;text&quot; case cross-reference
report only has the most probable class probability.</p>

<p style="margin-top: 1em">sigma_contours_att_list = <br>
If specified, a list of real valued attribute indices (from
.hd2 file) will be to compute sigma class contour values,
when generating influence values report with the data <br>
option (report_mode = &quot;data&quot;). If not specified,
there will be no sigma class contour output. (e.g.
&quot;sigma_contours_att_list = 3, 4, 5, 8, 15&quot;)</p>

<p style="margin-top: 1em">INTERPRETATION OF AUTOCLASS
RESULTS <br>
WHAT HAVE YOU GOT? <br>
Now you have run AutoClass on your data set -- what have you
got? Typically, the AutoClass search procedure finds many
classifications, but only saves the few best. These are <br>
now available for inspection and interpretation. The most
important indicator of the relative merits of these
alternative classifications is Log total posterior
probability val&acirc; <br>
ue. Note that since the probability lies between 1 and 0,
the corresponding Log probability is negative and ranges
from 0 to negative infinity. The difference between these
Log <br>
probability values raised to the power e gives the relative
probability of the alternatives classifications. So a
difference of, say 100, implies one classification is e^100
~= <br>
10^43 more likely than the other. However, these numbers can
be very misleading, since they give the relative probability
of alternative classifications under the AutoClass as&acirc;
<br>
sumptions.</p>

<p style="margin-top: 1em">ASSUMPTIONS <br>
Specifically, the most important AutoClass assumptions are
the use of normal models for real variables, and the
assumption of independence of attributes within a class.
Since <br>
these assumptions are often violated in practice, the
difference in posterior probability of alternative
classifications can be partly due to one classification
being closer to <br>
satisfying the assumptions than another, rather than to a
real difference in classification quality. Another source of
uncertainty about the utility of Log probability values is
<br>
that they do not take into account any specific prior
knowledge the user may have about the domain. This means
that it is often worth looking at alternative
classifications to <br>
see if you can interpret them, but it is worth starting from
the most probable first. Note that if the Log probability
value is much greater than that for the one class case, it
<br>
is saying that there is overwhelming evidence for some
structure in the data, and part of this structure has been
captured by the AutoClass classification.</p>

<p style="margin-top: 1em">INFLUENCE REPORT <br>
So you have now picked a classification you want to examine,
based on its Log probability value; how do you examine it?
The first thing to do is to generate an
&quot;influence&quot; re&acirc; <br>
port on the classification using the report generation
facilities documented in
/usr/share/doc/autoclass/reports-c.text. An influence report
is designed to summarize the impor&acirc; <br>
tant information buried in the AutoClass data
structures.</p>

<p style="margin-top: 1em">The first part of this report
gives the heuristic class &quot;strengths&quot;. Class
&quot;strength&quot; is here defined as the geometric mean
probability that any instance &quot;belonging to&quot;
class, <br>
would have been generated from the class probability model.
It thus provides a heuristic measure of how strongly each
class predicts &quot;its&quot; instances.</p>

<p style="margin-top: 1em">The second part is a listing of
the overall &quot;influence&quot; of each of the attributes
used in the classification. These give a rough heuristic
measure of the relative importance of <br>
each attribute in the classification. Attribute
&quot;influence values&quot; are a class probability
weighted average of the &quot;influence&quot; of each
attribute in the classes, as described be&acirc; <br>
low.</p>

<p style="margin-top: 1em">The next part of the report is a
summary description of each of the classes. The classes are
arbitrarily numbered from 0 up to n, in order of descending
class weight. A class <br>
weight of say 34.1 means that the weighted sum of membership
probabilities for class is 34.1. Note that a class weight of
34 does not necessarily mean that 34 cases belong to <br>
that class, since many cases may have only partial
membership in that class. Within each class, attributes or
attribute sets are ordered by the &quot;influence&quot; of
their model term.</p>

<p style="margin-top: 1em">CROSS ENTROPY <br>
A commonly used measure of the divergence between two
probability distributions is the cross entropy: the sum over
all possible values x, of
P(x|c...)*log[P(x|c...)/P(x|g...)], <br>
where c... and g... define the distributions. It ranges from
zero, for identical distributions, to infinite for
distributions placing probability 1 on differing values of
an at&acirc; <br>
tribute. With conditionally independent terms in the
probability distributions, the cross entropy can be factored
to a sum over these terms. These factors provide a measure
of <br>
the corresponding modeled attribute&rsquo;s influence in
differentiating the two distributions.</p>

<p style="margin-top: 1em">We define the modeled
term&rsquo;s &quot;influence&quot; on a class to be the
cross entropy term for the class distribution w.r.t. the
global class distribution of the single class
classifica&acirc; <br>
tion. &quot;Influence&quot; is thus a measure of how
strongly the model term helps differentiate the class from
the whole data set. With independently modeled attributes,
the influence <br>
can legitimately be ascribed to the attribute itself. With
correlated or covariant attributes sets, the cross entropy
factor is a function of the entire set, and we distribute
<br>
the influence value equally over the modeled attributes.</p>

<p style="margin-top: 1em">ATTRIBUTE INFLUENCE VALUES <br>
In the &quot;influence&quot; report on each class, the
attribute parameters for that class are given in order of
highest influence value for the model term attribute sets.
Only the first <br>
few attribute sets usually have significant influence
values. If an influence value drops below about 20% of the
highest value, then it is probably not significant, but all
at&acirc; <br>
tribute sets are listed for completeness. In addition to the
influence value for each attribute set, the values of the
attribute set parameters in that class are given along <br>
with the corresponding &quot;global&quot; values. The global
values are computed directly from the data independent of
the classification. For example, if the class mean of
attribute <br>
&quot;temperature&quot; is 90 with standard deviation of
2.5, but the global mean is 68 with a standard deviation of
16.3, then this class has selected out cases with much
higher than av&acirc; <br>
erage temperature, and a rather small spread in this high
range. Similarly, for discrete attribute sets, the
probability of each outcome in that class is given, along
with the <br>
corresponding global probability -- ordered by its
significance: the absolute value of (log
{&lt;local-probability&gt; / &lt;global-probability&gt;}).
The sign of the significance value <br>
shows the direction of change from the global class. This
information gives an overview of how each class differs from
the average for all the data, in order of the most
signif&acirc; <br>
icant differences.</p>

<p style="margin-top: 1em">CLASS AND CASE REPORTS <br>
Having gained a description of the classes from the
&quot;influence&quot; report, you may want to follow-up to
see which classes your favorite cases ended up in.
Conversely, you may want <br>
to see which cases belong to a particular class. For this
kind of cross-reference information two complementary
reports can be generated. These are more fully documented in
<br>
/usr/share/doc/autoclass/reports-c.text. The
&quot;class&quot; report, lists all the cases which have
significant membership in each class and the degree to which
each such case belongs to <br>
that class. Cases whose class membership is less than 90% in
the current class have their other class membership listed
as well. The cases within a class are ordered in in&acirc;
<br>
creasing case number. The alternative &quot;cases&quot;
report states which class (or classes) a case belongs to,
and the membership probability in the most probable class.
These two re&acirc; <br>
ports allow you to find which cases belong to which classes
or the other way around. If nearly every case has close to
99% membership in a single class, then it means that the
<br>
classes are well separated, while a high degree of
cross-membership indicates that the classes are heavily
overlapped. Highly overlapped classes are an indication that
the idea <br>
of classification is breaking down and that groups of
mutually highly overlapped classes, a kind of meta class, is
probably a better way of understanding the data.</p>

<p style="margin-top: 1em">COMPARING CLASS WEIGHTS AND
CLASS/CASE REPORT ASSIGNMENTS <br>
The class weight given as the class probability parameter,
is essentially the sum over all data instances, of the
normalized probability that the instance is a member of the
<br>
class. It is probably an error on our part that we format
this number as an integer in the report, rather than
emphasizing its real nature. You will find the actual real
value <br>
recorded as the w_j parameter in the class_DS structures on
any .results[-bin] file.</p>

<p style="margin-top: 1em">The .case and .class reports
give probabilities that cases are members of classes. Any
assignment of cases to classes requires some decision rule.
The maximum probability as&acirc; <br>
signment rule is often implicitly assumed, but it cannot be
expected that the resulting partition sizes will equal the
class weights unless nearly all class membership
probabili&acirc; <br>
ties are effectively one or zero. With non-1/0 membership
probabilities, matching the class weights requires summing
the probabilities.</p>

<p style="margin-top: 1em">In addition, there is the
question of completeness of the EM (expectation
maximization) convergence. EM alternates between estimating
class parameters and estimating class mem&acirc; <br>
bership probabilities. These estimates converge on each
other, but never actually meet. AutoClass implements several
convergence algorithms with alternate stopping criteria
us&acirc; <br>
ing appropriate parameters in the .s-params file. Proper
setting of these parameters, to get reasonably complete and
efficient convergence may require experimentation.</p>

<p style="margin-top: 1em">ALTERNATIVE CLASSIFICATIONS <br>
In summary, the various reports that can be generated give
you a way of viewing the current classification. It is
usually a good idea to look at alternative classifications
even <br>
though they do not have the minimum Log probability values.
These other classifications usually have classes that
correspond closely to strong classes in other
classifications, <br>
but can differ in the weak classes. The &quot;strength&quot;
of a class within a classification can usually be judged by
how dramatically the highest influence value attributes in
the <br>
class differ from the corresponding global attributes. If
none of the classifications seem quite satisfactory, it is
always possible to run AutoClass again to generate new
clas&acirc; <br>
sifications.</p>

<p style="margin-top: 1em">WHAT NEXT? <br>
Finally, the question of what to do after you have found an
insightful classification arises. Usually, classification is
a preliminary data analysis step for examining a set of <br>
cases (things, examples, etc.) to see if they can be grouped
so that members of the group are &quot;similar&quot; to each
other. AutoClass gives such a grouping without the user
having to <br>
define a similarity measure. The built-in
&quot;similarity&quot; measure is the mutual predictiveness
of the cases. The next step is to try to &quot;explain&quot;
why some objects are more like <br>
others than those in a different group. Usually, domain
knowledge suggests an answer. For example, a classification
of people based on income, buying habits, location, age,
<br>
etc., may reveal particular social classes that were not
obvious before the classification analysis. To obtain
further information about such classes, further information,
such <br>
as number of cars, what TV shows are watched, etc., would
reveal even more information. Longitudinal studies would
give information about how social classes arise and what
in&acirc; <br>
fluences their attitudes -- all of which is going way beyond
the initial classification.</p>

<p style="margin-top: 1em">PREDICTIONS <br>
Classifications can be used to predict class membership for
new cases. So in addition to possibly giving you some
insight into the structure behind your data, you can now use
<br>
AutoClass directly to make predictions, and compare
AutoClass to other learning systems.</p>

<p style="margin-top: 1em">This technique for predicting
class probabilities is applicable to all attributes,
regardless of data type/sub_type or likelihood model term
type.</p>

<p style="margin-top: 1em">In the event that the class
membership of a data case does not exceed 0.0099999 for any
of the &quot;training&quot; classes, the following message
will appear in the screen output for each <br>
case:</p>

<p style="margin-top: 1em">xref_get_data: case_num xxx
=&gt; class 9999</p>

<p style="margin-top: 1em">Class 9999 members will appear
in the &quot;case&quot; and &quot;class&quot;
cross-reference reports with a class membership of 1.0.</p>

<p style="margin-top: 1em">Cautionary Points:</p>

<p style="margin-top: 1em">The usual way of using AutoClass
is to put all of your data in a data_file, describe that
data with model and header files, and run &quot;autoclass
-search&quot;. Now, instead of one da&acirc; <br>
ta_file you will have two, a training_data_file and a
test_data_file.</p>

<p style="margin-top: 1em">It is most important that both
databases have the same AutoClass internal representation.
Should this not be true, AutoClass will exit, or possibly in
in some situations, crash. <br>
The prediction mode is designed to hopefully direct the user
into conforming to this requirement.</p>

<p style="margin-top: 1em">Preparation:</p>

<p style="margin-top: 1em">Prediction requires having a
training classification and a test database. The training
classification is generated by the running of
&quot;autoclass -search&quot; on the training da&acirc; <br>
ta_file (&quot;data/soybean/soyc.db2&quot;), for
example:</p>

<p style="margin-top: 1em">autoclass -search
data/soybean/soyc.db2 data/soybean/soyc.hd2 <br>
data/soybean/soyc.model data/soybean/soyc.s-params</p>

<p style="margin-top: 1em">This will produce
&quot;soyc.results-bin&quot; and &quot;soyc.search&quot;.
Then create a &quot;reports&quot; parameter file, such as
&quot;soyc.r-params&quot; (see
/usr/share/doc/autoclass/reports-c.text), and run <br>
AutoClass in &quot;reports&quot; mode, such as:</p>

<p style="margin-top: 1em">autoclass -reports
data/soybean/soyc.results-bin <br>
data/soybean/soyc.search data/soybean/soyc.r-params</p>

<p style="margin-top: 1em">This will generate class and
case cross-reference files, and an influence values file.
The file names are based on the &quot;.r-params&quot; file
name:</p>

<p style="margin-top: 1em">data/soybean/soyc.class-text-1
<br>
data/soybean/soyc.case-text-1 <br>
data/soybean/soyc.influ-text-1</p>

<p style="margin-top: 1em">These will describe the classes
found in the training_data_file. Now this classification can
be used to predict the probabilistic class membership of the
test_data_file cases <br>
(&quot;data/soybean/soyc-predict.db2&quot;) in the
training_data_file classes.</p>

<p style="margin-top: 1em">autoclass -predict
data/soybean/soyc-predict.db2 <br>
data/soybean/soyc.results-bin data/soybean/soyc.search <br>
data/soybean/soyc.r-params</p>

<p style="margin-top: 1em">This will generate class and
case cross-reference files for the test_data_file cases
predicting their probabilistic class memberships in the
training_data_file classes. The file <br>
names are based on the &quot;.db2&quot; file name:</p>


<p style="margin-top: 1em">data/soybean/soyc-predict.class-text-1
<br>
data/soybean/soyc-predict.case-text-1</p>

<p style="margin-top: 1em">SEE ALSO <br>
AutoClass is documented fully here:</p>


<p style="margin-top: 1em">/usr/share/doc/autoclass/introduction-c.text
Guide to the documentation</p>


<p style="margin-top: 1em">/usr/share/doc/autoclass/preparation-c.text
How to prepare data for use by AutoClass</p>


<p style="margin-top: 1em">/usr/share/doc/autoclass/search-c.text
How to run AutoClass to find classifications.</p>


<p style="margin-top: 1em">/usr/share/doc/autoclass/reports-c.text
How to examine the classification in various ways.</p>


<p style="margin-top: 1em">/usr/share/doc/autoclass/interpretation-c.text
How to interpret AutoClass results.</p>


<p style="margin-top: 1em">/usr/share/doc/autoclass/checkpoint-c.text
Protocols for running a checkpointed search.</p>


<p style="margin-top: 1em">/usr/share/doc/autoclass/prediction-c.text
Use classifications to predict class membership for new
cases.</p>

<p style="margin-top: 1em">These provide supporting
documentation:</p>


<p style="margin-top: 1em">/usr/share/doc/autoclass/classes-c.text
What classification is all about, for beginners.</p>


<p style="margin-top: 1em">/usr/share/doc/autoclass/models-c.text
Brief descriptions of the model term implementations.</p>

<p style="margin-top: 1em">The mathematical theory behind
AutoClass is explained in these documents:</p>


<p style="margin-top: 1em">/usr/share/doc/autoclass/kdd-95.ps
Postscript file containing: P. Cheeseman, J. Stutz,
&quot;Bayesian Classification (AutoClass): Theory and
Results&quot;, in &quot;Advances in Knowledge Dis&acirc;
<br>
covery and Data Mining&quot;, Usama M. Fayyad, Gregory
Piatetsky-Shapiro, Padhraic Smyth, &amp; Ramasamy
Uthurusamy, Eds. The AAAI Press, Menlo Park, expected fall
1995.</p>


<p style="margin-top: 1em">/usr/share/doc/autoclass/tr-fia-90-12-7-01.ps
Postscript file containing: R. Hanson, J. Stutz, P.
Cheeseman, &quot;Bayesian Classification Theory&quot;,
Technical Report FIA-90-12-7-01, <br>
NASA Ames Research Center, Artificial Intelligence Branch,
May 1991 (The figures are not included, since they were
inserted by &quot;cut-and-paste&quot; methods into the
original &quot;camera- <br>
ready&quot; copy.)</p>

<p style="margin-top: 1em">AUTHORS <br>
Dr. Peter Cheeseman <br>
Principal Investigator - NASA Ames, Computational Sciences
Division <br>
cheesem@ptolemy.arc.nasa.gov</p>

<p style="margin-top: 1em">John Stutz <br>
Research Programmer - NASA Ames, Computational Sciences
Division <br>
stutz@ptolemy.arc.nasa.gov</p>

<p style="margin-top: 1em">Will Taylor <br>
Support Programmer - NASA Ames, Computational Sciences
Division <br>
taylor@ptolemy.arc.nasa.gov</p>

<p style="margin-top: 1em">SEE ALSO <br>
multimix(1).</p>

<p style="margin-top: 1em">December 9, 2001
AUTOCLASS(1)</p>
<hr>
</body>
</html>
